<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="深度学习,Attention,Transformer,机器学习,每日论文,经典算法,NLP," />





  <link rel="alternate" href="/atom.xml" title="凛冬将至" type="application/atom+xml" />






<meta name="description" content="Self-Attention谁先提出的，各文章里写的不一样，Attention Is All You Need中说是Jakob.2016年提出的，An Attentive Survey of Attention Models中说是Yang et al. 2016，本篇介绍后者。">
<meta property="og:type" content="article">
<meta property="og:title" content="Hierarchical Attention Networks">
<meta property="og:url" content="http://wangdongdong122.github.io/2021/06/21/2021-06-21-Hierarchical-Attention/index.html">
<meta property="og:site_name" content="凛冬将至">
<meta property="og:description" content="Self-Attention谁先提出的，各文章里写的不一样，Attention Is All You Need中说是Jakob.2016年提出的，An Attentive Survey of Attention Models中说是Yang et al. 2016，本篇介绍后者。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://wangdongdong122.github.io/2021/06/21/2021-06-21-Hierarchical-Attention/1624323245414_src-1624427147187.JPG">
<meta property="article:published_time" content="2021-06-21T01:26:17.000Z">
<meta property="article:modified_time" content="2021-06-27T02:17:56.439Z">
<meta property="article:author" content="Dongdong Wang">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="Attention">
<meta property="article:tag" content="Transformer">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="每日论文">
<meta property="article:tag" content="经典算法">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://wangdongdong122.github.io/2021/06/21/2021-06-21-Hierarchical-Attention/1624323245414_src-1624427147187.JPG">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://wangdongdong122.github.io/2021/06/21/2021-06-21-Hierarchical-Attention/"/>





  <title>Hierarchical Attention Networks | 凛冬将至</title>
  








<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">凛冬将至</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">冬天的故事</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://wangdongdong122.github.io/2021/06/21/2021-06-21-Hierarchical-Attention/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="凛冬将至">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Hierarchical Attention Networks</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-06-21T09:26:17+08:00">
                2021-06-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Self-Attention谁先提出的，各文章里写的不一样，<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Attention Is All You Need</a>中说是<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1606.01933.pdf">Jakob.2016</a>年提出的，<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.02874.pdf">An Attentive Survey of Attention Models</a>中说是<a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/N16-1174.pdf">Yang et al. 2016</a>，本篇介绍后者。</p>
<span id="more"></span>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>核心思路：</p>
<ol>
<li>分层（hierarchical structure）：先构建“词 → 句子”级的表达，再聚合到文档级，即“句子 → 文档”</li>
<li>Attention：不同的词和句子包含的信息和重要程度都依赖于上下文，为了将其考虑进来，所以作者用两层的Attention</li>
</ol>
<p>作者没有提self-attention，应该是还没意识到这一点的牛逼之处。</p>
<h2 id="Hierarchical-Attention-Networks"><a href="#Hierarchical-Attention-Networks" class="headerlink" title="Hierarchical Attention Networks"></a>Hierarchical Attention Networks</h2><h3 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h3><p>encoder采用GRU产生，原理及结构省略</p>
<h3 id="Hierarchical-Attention"><a href="#Hierarchical-Attention" class="headerlink" title="Hierarchical Attention"></a>Hierarchical Attention</h3><p>数据表达</p>
<ul>
<li>sentences $\vec{s_i}$ ,$i=1,2,…L$</li>
<li>words represents: $w_{it}$, $t ∈ [1, T]$,   $\vec{s_i}$ contains $T$ words</li>
</ul>
<h4 id="Word-Encoder"><a href="#Word-Encoder" class="headerlink" title="Word Encoder"></a>Word Encoder</h4><p>先embedding，过双向GRU，将隐层concatenate起来</p>
<ol>
<li>word embedding: $W_e$, $x_{ij}=W_ew_{ij}$</li>
<li>forward GRU: $\overset{\rightarrow}{h_{it}}=\overset{\rightarrow}{GRU}(x_{it}),\ t ∈ [1, T]$</li>
<li>backward GRU:  $\overset{\leftarrow}{h_{it}}=\overset{\leftarrow}{GRU}(x_{it}),\ t ∈ [T, 1]$</li>
<li>concatenate:  $h_{it}=[\overset{\rightarrow}{h_{it}},\overset{\leftarrow}{h_{it}}]$</li>
</ol>
<h4 id="Word-Attention"><a href="#Word-Attention" class="headerlink" title="Word Attention"></a>Word Attention</h4><p>将对句子含义起重要作用的词提取出来，聚合成一个句子向量。先将所有的（$t ∈ [1, T]$）$h_{it}$过全连接得到Key: $u_{it}$；然后和随机变量的query: $u_w$求相似度分布: $\alpha$；最后将最开始的  $h_{it}$作为Value，加权得到sentence vector: $s_i$。所有信息都是从$h_{it}$中得到。</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}
u_{it} &=& tanh(W_wh_{it}+b_w) \tag{FC layer}  \\                 
\\
\alpha_{it} &=& \frac{exp(u^{T}_{it}u_w)}{\sum_{t}{exp(u^{T}_{it}u_w)}}  
\tag{measure similarity & normalize}
\\
\\
s_i &=& \sum_{t}{\alpha_{it}h_{it}}
\tag{weighted sum}


\end{eqnarray*}</script><p>其中$ u_w$(word context vector)是随机初始化，然后在训练过程中学习的，可以当做是一个固定的query，用来表示这个句子中重要的信息。</p>
<p>维度信息：每个句子只产生一个向量$s_i$，其长度和单个词的BiGRU隐层concat之后的向量$h_{it}$长度相同（不一定等于词向量$w_{it}$的长度）。</p>
<h4 id="Sentence-Encoder"><a href="#Sentence-Encoder" class="headerlink" title="Sentence Encoder"></a>Sentence Encoder</h4><p>句子的encoder也和词的类似，先过bidirectional GRU然后concatenate。</p>
<ol>
<li>forward GRU：$\overset{\rightarrow}{h_{i}}=\overset{\rightarrow}{GRU}(s_{i}),\ i ∈ [1, L]$</li>
<li>backward GRU: $\overset{\leftarrow}{h_{i}}=\overset{\leftarrow}{GRU}(s_{i}),\ i ∈ [L, 1]$</li>
<li>concatenate: $h_{i}=[\overset{\rightarrow}{h_{i}},\overset{\leftarrow}{h_{i}}]$</li>
</ol>
<h4 id="Sentence-Attention"><a href="#Sentence-Attention" class="headerlink" title="Sentence Attention"></a>Sentence Attention</h4><p>这部分也和Word Attention部分一样，只是换了个层次</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}u_{i} &=& tanh(W_sh_{i}+b_s) 
 \tag{FC layer}  
 \\                 
 \\
 \alpha_{i} &=& \frac{exp(u^{T}_{i}u_s)}{\sum_{i}{exp(u^{T}_{i}u_s)}}  
 \tag{measure similarity & normalize}
 \\
 \\
 v &=& \sum_{i}{\alpha_{i}h_{i}}
 \tag{weighted sum}

 \end{eqnarray*}</script><p>这里就将一个文档表示成一个向量$v$， 其长度和单个句子的BiGRU隐层concat之后的向量$h_{i}$长度相同。</p>
<h3 id="Document-Classification"><a href="#Document-Classification" class="headerlink" title="Document Classification"></a>Document Classification</h3><p>这部分很简单，文档向量$v$过softmax，然后用log loss训练。</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}

p &=& softmax(W_cv+b_c) 
 \tag{softmax}  
 \\                 
 \\
L &=& -\sum_{d}{log\ p_{dj}}
 \tag{log loss}

 \end{eqnarray*}</script><p>其中，$j$是文档$d$的标签，只对正确标签计算loss。</p>
<h2 id="Results-and-analysis"><a href="#Results-and-analysis" class="headerlink" title="Results and analysis"></a>Results and analysis</h2><p>  Yelp 2013上的两个文档，左边是给出了5星好评的，右边是0星差评的。模型可以捕捉到那些词重要。</p>
<img src="/2021/06/21/2021-06-21-Hierarchical-Attention/1624323245414_src-1624427147187.JPG" class="" title="显示">

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          
            <a href="/tags/Attention/" rel="tag"># Attention</a>
          
            <a href="/tags/Transformer/" rel="tag"># Transformer</a>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          
            <a href="/tags/%E6%AF%8F%E6%97%A5%E8%AE%BA%E6%96%87/" rel="tag"># 每日论文</a>
          
            <a href="/tags/%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95/" rel="tag"># 经典算法</a>
          
            <a href="/tags/NLP/" rel="tag"># NLP</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/06/22/2021-06-22-Decomposable-Attention/" rel="prev" title="Decomposable Attention Model">
                Decomposable Attention Model <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.png"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">28</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hierarchical-Attention-Networks"><span class="nav-number">2.</span> <span class="nav-text">Hierarchical Attention Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#encoder"><span class="nav-number">2.1.</span> <span class="nav-text">encoder</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hierarchical-Attention"><span class="nav-number">2.2.</span> <span class="nav-text">Hierarchical Attention</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Word-Encoder"><span class="nav-number">2.2.1.</span> <span class="nav-text">Word Encoder</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Word-Attention"><span class="nav-number">2.2.2.</span> <span class="nav-text">Word Attention</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sentence-Encoder"><span class="nav-number">2.2.3.</span> <span class="nav-text">Sentence Encoder</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sentence-Attention"><span class="nav-number">2.2.4.</span> <span class="nav-text">Sentence Attention</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Document-Classification"><span class="nav-number">2.3.</span> <span class="nav-text">Document Classification</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Results-and-analysis"><span class="nav-number">3.</span> <span class="nav-text">Results and analysis</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dongdong Wang</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
