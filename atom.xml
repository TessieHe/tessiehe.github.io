<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>凛冬将至</title>
  
  <subtitle>从简单的例子开始</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wangdongdong122.github.io/"/>
  <updated>2021-08-08T07:50:27.735Z</updated>
  <id>http://wangdongdong122.github.io/</id>
  
  <author>
    <name>Dongdong Wang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://wangdongdong122.github.io/2021/08/08/2021-08-08-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>http://wangdongdong122.github.io/2021/08/08/2021-08-08-线性回归/</id>
    <published>2021-08-08T07:50:27.735Z</published>
    <updated>2021-08-08T07:50:27.735Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>因果推断：the book of why</title>
    <link href="http://wangdongdong122.github.io/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/"/>
    <id>http://wangdongdong122.github.io/2021/08/08/2021-08-08-因果推断-the-book-of-why/</id>
    <published>2021-08-08T01:30:35.000Z</published>
    <updated>2021-08-09T23:49:38.711Z</updated>
    
    <content type="html"><![CDATA[<p>记录学习《因果之书》的笔记。</p><span id="more"></span><h2 id="因果关系介绍"><a href="#因果关系介绍" class="headerlink" title="因果关系介绍"></a>因果关系介绍</h2><h3 id="因果关系"><a href="#因果关系" class="headerlink" title="因果关系"></a>因果关系</h3><p>因果关系的定义一直是个哲学问题，作为一个不可知论者，我一直觉得因果关系涉及最基本的哲学，是<strong>不可知</strong>的。下雨后草木生长，按照唯物主义观点，下雨是因，草木生长是果；但是如果上帝存在，上次可能是希望草木生长所以创造了雨，才会下雨，因果似乎颠倒了。</p><p>我们现实生活中常常也有此类的描述，我们要去吃饭是因为要填饱肚子，填饱肚子是我们要去吃饭的原因。这里的因果似乎也有点奇怪，当存在一个<strong>有意识，有目的，有预测能力</strong>的主体时，其可能会根据因果关系来决定行为，这种情况下“因果关系”（预测结果）是”因”发生的原因。</p><p>​    </p><p>看一下哲学家给出过的定义</p><ul><li>亚里士多德：“质料因”“形式因”“动力因”“目的因”</li><li>休谟：我们可以给一个因下定义说，它是<strong>先行于</strong>、接近于另一个对象的一个对象，而且在这里，凡与前一个对象类似的一切对象都和与后一个对象类似的那些对象处在类似的先行关系和接近关系中。或者，换言之，<strong>假如</strong>没有前一个对象，那么后一个对象就不可能存在。</li></ul><p>​    </p><p><strong>时间先后</strong>的引入可以避免很多问题。很多地方也引入这个约束，比如在信号与系统里，对因果系统的定义是：”零状态响应不出现在激励之前的系统为因果系统”，简单说就是，输入引起的响应不出现在输入之前。因此当时间只能单向流动的规则被打破之后，因果关系开始模糊，变得难以理解。比如星际穿越中，未来的人类掌握了五维空间的黑洞，时间变成一个维度，可以在其中移动。未来的人类放了一个五维黑洞，所以现在的人类可以继续研究，生存下来才会有未来的人类。</p><p>不过本文不讨论<strong>因果发现问题</strong>，只讨论在给定因果关系的假设下，<strong>因果效应的量化</strong>问题和<strong>潜在结果</strong>的计算。</p><p>今年来，因果推断越来越火，相关方向的paper越来越多，业界也开始有越来越多相关的方向。</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210807163727974-1628325552533.png" class="" title="学术热度"><p>​    </p><h3 id="因果与相关"><a href="#因果与相关" class="headerlink" title="因果与相关"></a>因果与相关</h3><p><strong>相关关系不能说明有因果关系</strong>，一个典型的案例是小孩的阅读能力和年龄有关，衣服的大小也有年龄有关，导致衣服大小也与阅读能力有相关性。但两者之间显然没有因果关系，给小孩穿更大的衣服不会提升其阅读能力。</p><p>那么如果给我们10000个小孩的年龄、衣服大小、阅读能力得分，10000行×3列的数据，我们如何只根据数据判断三者之间的因果关系呢？答案是不行，年龄和衣服大小之间的相关性没有方向，如果不结合日常生活的常识，我们无法只通过数据判断谁是因谁是果。</p><ul><li>统计学本身无法告诉哪个是因，哪个是果</li></ul><p><strong>人类的理解世界是以因果关系为基础</strong>而非统计关系，这对应人类做决策判断至关重要。当我们想达到某个结果Y而做一件事X时，实际是因为我们相信做了X，会让Y发生的概率变大，而这正是因果关系而非相关关系。这还有一个可能的原因是<strong>因果关系比相关关系稳健</strong>，相关关系太受各种因素影响，不够稳定，比如观测的范围的偏差、X变量的分布；相对而言，因果关系更多的是直接由客观规律和事情发生的机制直接决定的，接近于<strong>逻辑与规律</strong>的概念，通用性更强。</p><ul><li>人类为什么不一样，人类的直觉是以因果关系而统计关系为组织核心</li><li>深度学习只是让机器具备了高超的能力，而非智能，其致力于拟合出一个函数</li><li>相关性关系并不稳定，但因果关系却更为稳健</li></ul><p>​    </p><h3 id="因果与贝叶斯"><a href="#因果与贝叶斯" class="headerlink" title="因果与贝叶斯"></a>因果与贝叶斯</h3><p>贝叶斯网络并未假设箭头有任何因果意义，只意味着前向概率</p><p>贝叶斯网络和因果图的区别：</p><ul><li>贝叶斯网络并未假设箭头有任何因果意义（所以箭头的方向可以反过来？）</li><li>贝叶斯网络中箭头A-&gt;B，B的概率通过条件概率与A的值相关，且该相关关系是完备的（p144）</li><li>因果图中箭头A-&gt;B，在假设实验角度解释，表示如果我只调整A，就可以看到C的概率发生变化（p145）</li></ul><p>​    </p><h2 id="因果关系的表示"><a href="#因果关系的表示" class="headerlink" title="因果关系的表示"></a>因果关系的表示</h2><h3 id="三节点网络"><a href="#三节点网络" class="headerlink" title="三节点网络"></a>三节点网络</h3><p>三种基本的三节点网络</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808103010446.png" class="" title="三节点网络"><p>​    </p><p><strong>案例</strong></p><p>链式：火灾 → 烟雾 → 警报</p><p>叉式：鞋子尺寸 ← 孩子的年龄 → 阅读能力</p><p>对撞：才华 → 名人 ← 美貌；名人才华与美貌负相关</p><p>​    </p><p><strong>独立性质</strong></p><p>链式：A与C不独立；给定B后，A与C独立，其中B为中介物</p><p>叉式：A与C不独立；给定B后，A与C独立</p><p>对撞：A与C独立；给定B后，A与C不独立</p><p>​    </p><p>注：</p><ul><li><p>上述独立性，建立在三节点网络已经是完备因果图的基础上</p></li><li><p>各个节点都可能还有原因，但这个原因不影响其他变量即可不表示为节点</p></li><li><p>我们不能通过数据区分链式和叉式接合，因为他们具有相同的条件独立性</p></li></ul><p>​    </p><h3 id="独立性质证明"><a href="#独立性质证明" class="headerlink" title="独立性质证明"></a>独立性质证明</h3><p><strong>背景知识</strong></p><p>概率全展开公式</p><script type="math/tex; mode=display">p(x_1,…,x_K)=p(x_K│x_1,…,x_{K−1}),…,p(x_2|x_1)p(x_1)</script><p>该公式对应全连接有向无环图，任意两个节点之间都有连接。</p><p>有向图中：变量（节点）的条件概率与其父节点相关联，且此相关关系是充分的（即其他祖先不会影响这一公式）</p><script type="math/tex; mode=display">p(\boldsymbol x)=\prod_{k=1}^K p(x_k|pa_k)</script><p>其中，$p(x)$表示所有节点的联合分布，k表示第k个节点，$pa_k$表示第k个节点的所有父节点。（PRML，P382）</p><p>​    </p><p><strong>链式证明</strong></p><p>​    </p><h2 id="后门路径"><a href="#后门路径" class="headerlink" title="后门路径"></a>后门路径</h2><h3 id="混杂定义"><a href="#混杂定义" class="headerlink" title="混杂定义"></a>混杂定义</h3><p>关于混杂的定义有很多，这里不再展开解释，给出一个本文的定义</p><ul><li>混杂偏倚（confounding bias）：$p(y|x)≠p(y|do(x))$</li></ul><p>比如给土壤质量差的土地施肥的情况下，肥料和产量之间存在混杂；由于随年龄的变化，人对运动的偏好有明显差异，此时运动和死亡率之间也存在混杂。</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808131455727.png" class="" title="混杂案例"><p>要消除这种混杂，可以做随机测试，抽签决定每块土地是否施肥，此时就可以消除这个场景中的混杂。</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808131717441.png" class="" title="随机实验"><p>这里可以消除混杂是因为抽签和产量之间没有因果关系，在这个实验中应该是没问题的。但在一些医学问题中，由于安慰剂效应，抽签结果可能还是会影响病人康复情况，所以要进行双盲实验。</p><p>​    </p><h3 id="后门路径-1"><a href="#后门路径-1" class="headerlink" title="后门路径"></a>后门路径</h3><p>书中对后门路径的定义是：<strong>X到Y之间所有的路径中，以指向X的箭头开始的路径</strong>。</p><blockquote><p>按照这个定义，包含对撞的路径不算后门路径，这会导致我们需要单独判断对撞是否产生偏倚。个人认为可以将包含<strong>指向X方向的箭头的路径</strong>定义为后门路径，这样就包括了对撞路径，一起判断就可以。</p></blockquote><p>​    </p><p><strong>阻断信息规则</strong>（只针对路径上的信息流动）</p><ol><li>链式（A-&gt;B-&gt;C）、叉式（A&lt;-B-&gt;C）：控制B可阻断A和C间信息流动</li><li>对撞（A-&gt;B&lt;-C）：A和C本身就是阻断的（控制B将导致信息流通）</li><li>控制一个变量的后代节点，将“部分地”控制变量本身</li></ol><p>​    </p><p><strong>去除混杂规则</strong></p><p>阻断了所有的后门路径，则完成了X和Y的去混杂</p><p>去混因子：一个可以阻断干预与结果之间所有后门路径的变量集</p><p>​    </p><p>如果将X和Y之间所有的路径分为三种，对应的<strong>去混杂的原则</strong>如下</p><ol><li>因果路径：反映了X→Y的因果关系，不应该被阻断</li><li>后门路径：产生混杂，应该被阻断，阻断时不应该违反第一条</li><li>对撞路径：原本处于阻断状态，不应该再控制导致混杂，如果已经控制了，则需要再阻断该路径，阻断时不能违反前两条。</li></ol><p>比如下图，第一个，不应该控制Z，第二个和第三个都是Z和M都不应该被控制。从这些案例我们知道，并<strong>不是控制变量越多越好</strong>，基于观察数据的分析，什么变量需要控制，什么变量不需要控制需要弄清楚。</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808133506939.png" class="" title="控制变量"><p>​    </p><h3 id="解释悖论"><a href="#解释悖论" class="headerlink" title="解释悖论"></a>解释悖论</h3><h4 id="相亲对象"><a href="#相亲对象" class="headerlink" title="相亲对象"></a>相亲对象</h4><p>问题：你有没有发现，你的相亲对象要么笨，要么丑！</p><p>因果图：才华 → 和你约会 ← 颜值</p><p>解释：才华和颜值可能没什么相关性，但介绍给你相亲的人中，两者之间可能就有相关性。又笨又丑的多半也不会介绍给你，高富帅、白富美多半也不会。</p><p>​    </p><h4 id="邮件骗局"><a href="#邮件骗局" class="headerlink" title="邮件骗局"></a>邮件骗局</h4><p>问题：如果你收到预测股市涨跌的邮件，连续10次都是准的，第11次预测结果要收费，要不要买呢？</p><p>因果图：预测 → 命中 ← 股市</p><p>解释：可能是每次给10万人发随机的预测结果，这样也会有大概千分之一的人都预测对，这部分人的第11次预测结果和股市涨跌之间并没有什么因果关系。</p><p>​    </p><h4 id="出生体重悖论"><a href="#出生体重悖论" class="headerlink" title="出生体重悖论"></a>出生体重悖论</h4><p>悖论：出生体重轻的婴儿中，母亲吸烟的，死亡率低</p><p>因果图：</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808170719233.png" class="" title="出生体重悖论"><p>解释：控制出生体重导致了偏倚，先天缺陷且母亲吸烟的，可能死亡的概率大很多。</p><p>​    </p><h4 id="辛普森悖论"><a href="#辛普森悖论" class="headerlink" title="辛普森悖论"></a>辛普森悖论</h4><p>悖论：辛普森医生发现一种新药，吃了的人比不吃的人发病率低（0.78 vs 0.83），但这种药似乎对男性和女性都有害，吃了的男性比不吃的男性发病率高（0.93 vs 0.87），吃了药的女性也比不吃药的女性发病率高（0.73 vs 0.69）。</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808145736231.png" class="" title="辛普森悖论-数据"><p>因果图：</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808145524642.png" class="" title="辛普森悖论"><p>解释：男女患病风险不同，对服药的票号也不同。</p><p>扩展：辛普森悖论反映的是整体的统计结果和分层的统计结果可能相反。那么是整体统计结果正确还是分层结果正确呢？不同情况下不一样，需要根据具体研究的问题和因果图来判断。</p><p>​    </p><h4 id="伯克利大学招生悖论"><a href="#伯克利大学招生悖论" class="headerlink" title="伯克利大学招生悖论"></a>伯克利大学招生悖论</h4><p>悖论：1973年，有学者发现伯克利大学招生的时候男女录取比例不一样，男生录取率明显高于女生，男生44%，女生35%。当时公众很关注男女歧视问题，怎么办，伯克利大学的招生是各个系自己定的，所以挨个系查。但是查完就懵了，因为每个系的招生：都有利于女生，实际结果也都是女生录取比例比男生高。</p><p>因果图：</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210809214449045.png" class="" title="伯克利大学招生悖论简化版"><p>解释：也是一个辛普森悖论，女生喜欢申请难录取的院系，但此时院系不是混杂。</p><p>扩展：上图看起来似乎是学校不存在歧视，但实际上如果因果图没画全，院系不仅有性别歧视还有地域歧视。比如说自己的家乡只录取男生，其他地方只录取女生（觉得女生读书就是祸害），如下面的因果图，那也有可能得到完全一样的数据。所以说因果推断的问题不能只从数据中求解，相同的数据，不同的因果假设，得到的结论完全不同。</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808145630481.png" class="" title="伯克利大学招生悖论"><p>​    </p><h4 id="蒙提霍尔悖论"><a href="#蒙提霍尔悖论" class="headerlink" title="蒙提霍尔悖论"></a>蒙提霍尔悖论</h4><p>悖论：有三扇门，门后有车、山羊、山羊。你如果选中有车的门，车就归你。现在你选择了A门，主持人打开了另一扇后面有山羊的B门，问你是否要将你的选择换成C门。</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808145659844.png" class="" title="蒙提霍尔悖论-场景"><p>因果图：</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808145809152.png" class="" title="蒙提霍尔悖论"><p>解释：答案是要换，不换1/3，换了2/3。直觉上理解车子在哪个门后面的概率似乎不会变，都一直是1/3，但实际上，得知主持人打开哪个门之后，你选的门和车子的位置之间是相关的。</p><p>​    </p><h2 id="因果效应量化"><a href="#因果效应量化" class="headerlink" title="因果效应量化"></a>因果效应量化</h2><h3 id="后门标准"><a href="#后门标准" class="headerlink" title="后门标准"></a>后门标准</h3><p><strong>使用条件</strong>：去混因子可观测</p><p>已掌握了变量的一个充分集（包含去混因子）的数据，可以用来阻断干预和结果之间的所有的后门路径。</p><p>​    </p><p><strong>后门调整公式</strong></p><script type="math/tex; mode=display">P(Y|do(X))=∑_ZP(Z=z,X) P(Z=z)</script><blockquote><p>去混因子的各层中的因果效应的趋势是一致的（因为去混因子不影响因果效应，P235）</p></blockquote><p>​    </p><p><strong>做法</strong></p><ol><li>估计去混因子每个水平（分层）上，干预的平均因果效应</li><li>计算各层因果效应的加权平均值，权重为每层在总体中的分布频率</li></ol><ul><li>线性近似将问题大大简化了，每个因果效应都可以用一个数字来表示（P236）</li><li>偏回归系数暗中执行了后门调整（P239）</li></ul><p>​    </p><h3 id="前门标准"><a href="#前门标准" class="headerlink" title="前门标准"></a>前门标准</h3><p>以吸烟为例，假设研究人员可以测量吸烟者肺部的焦油沉积量，且吸烟只通过焦油沉淀引发癌症</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808150116299.png" class="" title="前门路径-吸烟案例"><p>前门调整公式：</p><script type="math/tex; mode=display">P(Y│do(X))=∑_ZP(Z=z,X)∑_XP(Y│X=x,Z=z)P(X=x)</script><p>在吸烟的案例中，X代表“吸烟”，Y代表“癌症”，Z代 表“焦油沉积”，U（在此例中显然没有出现在公式中）代表不可观测的变量，即“吸烟基因”。</p><p>​    </p><p><strong>使用条件</strong>：</p><p>X对Y的因果效应被一组变量C混杂，又被另一组变量M介导，并且中介变量M不受C的影响。（此处笔者认为M也应该不能有其他混杂）</p><p>​    </p><h3 id="do运算"><a href="#do运算" class="headerlink" title="do运算"></a>do运算</h3><blockquote><p>目标：消除do算子，只留下经典的概率表达式，如$P(Y|X)$</p></blockquote><p>do运算<strong>3条法则</strong></p><ol><li><p>如果我们观察到W与Y无关（可在给定其他变量Z的条件下），那么Y的概率分布就不会随W而变</p><script type="math/tex; mode=display">P(Y|do(X),Z,W)=P(Y|do(X),Z)</script><p>如，$P(警报|do(烟雾),火灾)=P(警报|do(烟雾))$</p><p>本法则允许增加或删除某个观察结果。</p></li><li><p>如果变量集Z阻断了从X到Y的所有后门路径，则以Z为条件时，$do(X)$等同于$see(X)$</p><script type="math/tex; mode=display">P(Y|do(X),Z)=P(Y|X,Z)</script><p>本法则允许用观察替换干预，或反之。</p></li><li><p>若X到Y没有因果路径，则可将$do(X)$从$P(Y|do(X))$中移除</p><script type="math/tex; mode=display">P(Y|do(X),Z)=P(Y)</script><p>本法则允许删除或添加干预。</p></li></ol><p>​    </p><p><strong>案例</strong>：</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808150517716.png" class="" title="do运算案例"><script type="math/tex; mode=display">P(Y|do(X))=∑_ZP(Y|do(X),Z)P(Z=z|do(X))                                   =∑_ZP(Y|X,Z=z)P(Z=z)</script><p>​    </p><h2 id="因果图下的新视角"><a href="#因果图下的新视角" class="headerlink" title="因果图下的新视角"></a>因果图下的新视角</h2><blockquote><p>本部分内容存在大量自己总结的内容，可能有误</p></blockquote><p>​    </p><h3 id="工具变量法"><a href="#工具变量法" class="headerlink" title="工具变量法"></a>工具变量法</h3><p><a href="https://zh.wikipedia.org/wiki/%E5%86%85%E7%94%9F%E5%8F%98%E9%87%8F">内生变量</a>：所有与扰动项相关的解释变量都称为“内生变量”。$^{[1]}$</p><p>内生变量导致的问题：OLS得到的估计量不一致。</p><p>工具变量法：</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808154124101.png" class="" title="工具变量法"><p>在线性假设下，$ab=r_{ZY},a=r_{ZX}$，因此，$b=r_{ZY}/r_{ZX}$。其中$r_{ZY}$ 表示Z在Y上回归线的斜率， $a$表示Z增加一个单位的干预将导致X增加 $a$个单位。</p><p>​    </p><h3 id="偏回归"><a href="#偏回归" class="headerlink" title="偏回归"></a>偏回归</h3><p><strong>FWL定理</strong></p><p>主要思想：剔除一个变量（如，月收入）对另一个变量（如，额度）的影响，对参数（如，额度对逾期的影响）进行更为精准的估计</p><p>FWL定理：</p><ul><li>对于多元线性回归模型: $y_i=a+b_1x_{1i}+b_2x_{2i}+b_3x_{3i}+\epsilon _i$</li><li>当$x_1 \leftrightarrow x_2$之间相互影响，会导致估计偏差，解决步骤如下：<ol><li>x1对其他x回归得到误差v：</li><li>y对其他的x回归得到误差w：</li><li>w对v回归得到系数η：</li></ol></li><li>η就是b1的无偏估计</li></ul><p>可理解为，η表示的是“额度中与月收入无关的部分”对“逾期率中与月收入无关的部分”的解释力</p><p><strong>与后门路径之间的关系</strong></p><p>偏回归系数 实际和控制其他变量之后，X对Y的影响 ；实际逻辑后门标准是一致的</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808160721150.png" class="" title="image-20210808160721150"><ul><li>减去均值会影响偏置，但不影响斜率</li><li>该计算方式下，计算得到的相关性系数和后门标准一致：$P(Y│do(X))=∑_ZP(Z=z,X) P(Z=z)$</li><li>如果Z是中介值，偏回归系数应该不对应自然因果效应，而对应直接因果效应。</li></ul><p>​    </p><h2 id="反事实"><a href="#反事实" class="headerlink" title="反事实"></a>反事实</h2><p>本部分介绍如何计算出潜在结果</p><h3 id="潜在结果"><a href="#潜在结果" class="headerlink" title="潜在结果"></a>潜在结果</h3><p>什么是潜在结果(potential outcomes)？定义一个Y的潜在结果，$Y_{X=x}(u)$：假如X的取值为x，那么Y在个体u上的取值（<strong>个体层面</strong>上的定义）。</p><p>如何推断潜在结果？</p><p>给个案例：如果<strong>工资</strong>（S）由<strong>学历</strong>（ED，0：高中，1：大学，2，硕士）和<strong>工作经验</strong>（EX，年数）决定。现在有以下数据，问题是<strong>如果爱丽丝上大学了，工资是多少</strong>？</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210808172100062.png" class="" title="潜在结果-案例"><p>​    </p><h3 id="常见错误做法"><a href="#常见错误做法" class="headerlink" title="常见错误做法"></a>常见错误做法</h3><p><strong>错误的做法是：将因果推断问题看作数据缺失问题</strong>，利用差值法填补空格，或者推断出缺失数据。</p><ul><li>错误方法1：匹配法<ul><li>做法：伯特、卡罗琳工作年限相同 → 伯特的$S_2=9700$，卡罗琳的$S_1=92500$。</li><li>存在问题：没有考虑学历和工作经验之间的影响</li></ul></li><li>错误做法2：线性回归<ul><li>做法：回归结果为：$S=65000+2500EX+5000ED$，因此爱丽丝有大学文凭时（EX=6，ED=1），S=85000</li><li>存在问题：没有考虑学历和工作经验之间的影响</li></ul></li></ul><p>​    </p><h3 id="奈曼-鲁宾因果模型"><a href="#奈曼-鲁宾因果模型" class="headerlink" title="奈曼-鲁宾因果模型"></a>奈曼-鲁宾因果模型</h3><p>先来看下两位大佬的合影（左Pearl，右Robins），后面我也会再写一篇Robin的书的学习笔记，这里只简单介绍一下其<strong>三个假设</strong>。</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210809220700019.png" class="" title="2014年，唐纳德·鲁宾（右）与本书第一作者（资料来源：照片由格雷斯·铉·金提供）"><p>​    </p><h4 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h4><p>单位处理效应稳定：stable unittreatment value assumption，SUTVA</p><p>个体的处理效应稳定不变，和其他个体是否接受处理无关（大部分情况下是合理的）</p><p>​    </p><h4 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h4><p>无论是否主动接受到处理，其效应相同（无安慰剂效应）</p><p>​    </p><h4 id="可交换性"><a href="#可交换性" class="headerlink" title="可交换性"></a>可交换性</h4><p>又称可忽略性，ignorability</p><p>给定某组去混因子Z的值，$Y_X$独立于实际接受的处理X</p><p>​    </p><p>可忽略性假设很难理解</p><h3 id="结构因果模型"><a href="#结构因果模型" class="headerlink" title="结构因果模型"></a>结构因果模型</h3><p>​    </p><h3 id="因果关系细分"><a href="#因果关系细分" class="headerlink" title="因果关系细分"></a>因果关系细分</h3><p>必要因；充分因；充要因</p><p>​    </p><h2 id="中介效应"><a href="#中介效应" class="headerlink" title="中介效应"></a>中介效应</h2><p>中介分析为什么重要呢？因为其对我们弄清楚事情发生的真正机制至关重要。比如说人类对坏血病的认识，就是对其中介物的逐步认识。人们很早就知道柑橘类水果可以避免坏血病，但</p><p>​    </p><h3 id="直接、间接效应"><a href="#直接、间接效应" class="headerlink" title="直接、间接效应"></a>直接、间接效应</h3><p>给定：处理X、结果Y、中介物M，但扰动X而保持M恒定时，得到X对Y的直接效应。</p><p>​    </p><h3 id="受控直接效应"><a href="#受控直接效应" class="headerlink" title="受控直接效应"></a>受控直接效应</h3><p>CDE（controlled direct effect）</p><script type="math/tex; mode=display">CDE(0)=P(Y=1|do(X=1),do(M=0))-P(Y=1|do(X=0),do(M=0))</script><p>同理也有$CDE(1)$。但直接保持中介物恒定，有时是过度对照试验，比如为了判断各个院系是否有性别歧视时，让一个热爱计算机的人去申请考古专业。</p><p>​    </p><h3 id="自然直接效应"><a href="#自然直接效应" class="headerlink" title="自然直接效应"></a>自然直接效应</h3><p>NDE（natural direct effect）</p><script type="math/tex; mode=display">NDE=P(Y_{M=M_0}=1|do(X=1))-P(Y_{M=M_0}=1|do(X=0))</script><p>其中$M_0$表示：$do(X=0)$时，中介物M按其自然状态下的取值。</p><p>案例：伯克利大学招生中，如果一个女生将她的性别报告为“男性”，即$do(X=1)$，并让其申请自己想去的院系$M=M_0$的情况下录取概率相对于其将她的性别报告为“女性”的录取概率差。</p><p>​    </p><h3 id="自然间接效应"><a href="#自然间接效应" class="headerlink" title="自然间接效应"></a>自然间接效应</h3><p>NIE（natural indirect effect）</p><script type="math/tex; mode=display">NIE=P(Y_{M=M_1}=1|do(X=0))-P(Y_{M=M_0}=1|do(X=0))</script><p>其中$M_1$表示：$do(X=1)$后，中介物M按其自然状态下的取值。</p><p>案例：作者朋友收养了一只叫黛西的狗子，天天在家里搞破坏，但主人收养了另外三只小猫之后，黛西不再搞破坏了。在小猫被送回收容所的几天后，黛西故态萌发，又开始搞破坏。在小猫在的时候，黛西长时间地被人密切监视，小猫离开后，就不再密切监督它。那么黛西不搞破坏的原因究竟是什么呢？这个问题中，NIE指的是，第一个概率指不引入其他宠物($X=0$)，但将中介物设置为引入其他宠物时会有的值($M=M_1$)，此时黛西的行为有所改善($Y=1$)的概率，第二个概率指正常情况下不引入其他动物时，黛西不搞破坏的概率。</p><img src="/2021/08/08/2021-08-08-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-the-book-of-why/image-20210809001807145.png" class="" title="黛西"><p>​    </p><h3 id="总效应"><a href="#总效应" class="headerlink" title="总效应"></a>总效应</h3><script type="math/tex; mode=display">总效应（X=0→X=1）=NDE（X=0→X=1）–NIE（X=1→X=0）</script><p>​    </p><p>​    </p><h2 id="我的问题"><a href="#我的问题" class="headerlink" title="我的问题"></a>我的问题</h2><p>记录一下我在学习中想到的问题，以及我的一些想法。</p><p>​     </p><h3 id="随机测试可做因果发现吗"><a href="#随机测试可做因果发现吗" class="headerlink" title="随机测试可做因果发现吗"></a>随机测试可做因果发现吗</h3><p>似乎是可以的，但只能发现处理变量和其他变量之间的因果关系。</p><p>​     </p><h3 id="无法干预时的因果效应"><a href="#无法干预时的因果效应" class="headerlink" title="无法干预时的因果效应"></a>无法干预时的因果效应</h3><p>如果一个变量我们<strong>无法干预，还存在因果关系</strong>吗？这又如何理解？比如年龄→阅读能力，直接<strong>提高年龄会导致阅读能力的提升</strong>吗？</p><p>回答：</p><ul><li><p>这种情况下干预似乎就直接控制了中介因子。但这个是语言的问题，如果大家把年龄看做了自己身份证上的属性，甚至可以直接修改，那就应该把“年龄”替换为“出生年数”，因果关系变成：年龄←出生年数→阅读能力。</p></li><li><p>如果真的是完全没有可能干预呢</p></li></ul><p>​     </p><h3 id="因果图似乎不完备"><a href="#因果图似乎不完备" class="headerlink" title="因果图似乎不完备"></a>因果图似乎不完备</h3><p>在处理交叉影响时，因果图似乎不完备（或有问题）。如，女生更偏好难录取的院系</p><h2 id="新的甘特图功能，丰富你的文章"><a href="#新的甘特图功能，丰富你的文章" class="headerlink" title="新的甘特图功能，丰富你的文章"></a>新的甘特图功能，丰富你的文章</h2><pre class="mermaid">gantt        dateFormat  YYYY-MM-DD        title Adding GANTT diagram functionality to mermaid        section 现有任务        已完成               :done,    des1, 2014-01-06,2014-01-08        进行中               :active,  des2, 2014-01-09, 3d        计划一               :         des3, after des2, 5d        计划二               :         des4, after des3, 5d</pre><ul><li>关于 <strong>甘特图</strong> 语法，参考 [这儿][2],</li></ul><h2 id="UML-图表"><a href="#UML-图表" class="headerlink" title="UML 图表"></a>UML 图表</h2><p>可以使用UML图表进行渲染。 <a href="https://mermaidjs.github.io/">Mermaid</a>. 例如下面产生的一个序列图：:</p><pre class="mermaid">sequenceDiagram张三 ->> 李四: 你好！李四, 最近怎么样?李四-->>王五: 你最近怎么样，王五？李四--x 张三: 我很好，谢谢!李四-x 王五: 我很好，谢谢!Note right of 王五: 李四想了很长时间, 文字太长了<br/>不适合放在一行.李四-->>张三: 打量着王五...张三->>王五: 很好... 王五, 你怎么样?</pre><p>这将产生一个流程图。:</p><pre class="mermaid">graph TBA[长方形] -- 链接 --> B((圆))A --> C(圆角长方形)B --> D{菱形}C --> D</pre><ul><li>关于 <strong>Mermaid</strong> 语法，参考 [这儿][3],</li></ul><h2 id="FLowchart流程图"><a href="#FLowchart流程图" class="headerlink" title="FLowchart流程图"></a>FLowchart流程图</h2><p>我们依旧会支持flowchart的流程图：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: Start|past:&gt;http://www.baidu.com</span><br><span class="line">e=&gt;end: End:&gt;http://www.baidu.com</span><br><span class="line">op1=&gt;operation: My Operation|past</span><br><span class="line">op2=&gt;operation: Stuff|current</span><br><span class="line">sub1=&gt;subroutine: My Subroutine|invalid</span><br><span class="line">cond=&gt;condition: Yes or No?|approved:&gt;http://www.baidu.com</span><br><span class="line">c2=&gt;condition: Good idea|rejected</span><br><span class="line">io=&gt;inputoutput: catch something...|request</span><br><span class="line"></span><br><span class="line">st-&gt;op1(right)-&gt;cond</span><br><span class="line">cond(yes, right)-&gt;c2</span><br><span class="line">cond(no)-&gt;sub1(left)-&gt;op1</span><br><span class="line">c2(yes)-&gt;io-&gt;e</span><br><span class="line">c2(no)-&gt;op2-&gt;e</span><br></pre></td></tr></table></figure><ul><li>关于 <strong>Flowchart流程图</strong> 语法，参考 [这儿][4].</li><li><strong>牢记tag=&gt;type: content:&gt;url</strong></li></ul><h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><p>​      </p><p>​      </p><p>​    </p><p>​    </p><p><strong>参考信息</strong></p><p>[1] 《高级计量经济学及Stata应用》,（第二版），P136</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录学习《因果之书》的笔记。&lt;/p&gt;
    
    </summary>
    
    
      <category term="因果推断" scheme="http://wangdongdong122.github.io/tags/%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD/"/>
    
      <category term="因果之书" scheme="http://wangdongdong122.github.io/tags/%E5%9B%A0%E6%9E%9C%E4%B9%8B%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://wangdongdong122.github.io/2021/08/06/2021-08-06-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%AF%95%E4%B8%80%E4%B8%8B/"/>
    <id>http://wangdongdong122.github.io/2021/08/06/2021-08-06-强化学习试一下/</id>
    <published>2021-08-05T16:04:09.207Z</published>
    <updated>2021-08-05T16:04:09.207Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>tf.function的使用</title>
    <link href="http://wangdongdong122.github.io/2021/08/05/2021-08-05-TensorFlow2.0%E4%BD%BF%E7%94%A8/"/>
    <id>http://wangdongdong122.github.io/2021/08/05/2021-08-05-TensorFlow2.0使用/</id>
    <published>2021-08-05T14:02:38.000Z</published>
    <updated>2021-08-05T16:03:51.165Z</updated>
    
    <content type="html"><![CDATA[<p>@tf.function的用法</p><span id="more"></span><p>TensorFlow中有三种计算图的：静态计算图，动态计算图，以及Autograph。</p><ul><li>在<strong>TensorFlow1中，采用的是静态计算图</strong>，需要先使用TensorFlow的各种算子创建计算图，然后再开启一个会话Session，显式执行计算图</li><li><strong>TensorFlow2默认采用的是动态计算图</strong>，即每使用一个算子后，该算子会被动态加入到隐含的默认计算图中立即执行得到结果。</li></ul><p>对于动态图的好处显而易见，它方便调试程序，让TensorFlow代码的表现和Python原生代码的表现一样，写起来就像写numpy一样，各种日志打印，控制流全部都是可以使用的，当然，这相对于静态图来讲牺牲了些效率，因为使用动态图会有许多次Python进程和TensorFlow的C++进程之间的通信，而静态计算图构建完成之后几乎全部在TensorFlow内核上使用C++代码执行，效率更高。此外静态图会对计算步骤进行一定的优化，剪去和结果无关的计算步骤。</p><p>如果需要<strong>在TensorFlow2.0中使用静态图，可以使用@tf.function装饰器</strong>将普通Python函数转换成对应的TensorFlow计算图构建代码。运行该函数就相当于在TensorFlow1.0中用Session执行代码，使用tf.function构建静态图的方式<strong>叫做 Autograph</strong>。</p><p><strong>参考资料</strong></p><p><a href="https://zhuanlan.zhihu.com/p/344846077">知乎：如何理解TensorFlow计算图？</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;@tf.function的用法&lt;/p&gt;
    
    </summary>
    
    
      <category term="工具使用" scheme="http://wangdongdong122.github.io/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"/>
    
      <category term="TensorFlow2" scheme="http://wangdongdong122.github.io/tags/TensorFlow2/"/>
    
      <category term="非原创" scheme="http://wangdongdong122.github.io/tags/%E9%9D%9E%E5%8E%9F%E5%88%9B/"/>
    
  </entry>
  
  <entry>
    <title>GPU使用中的问题</title>
    <link href="http://wangdongdong122.github.io/2021/08/05/2021-08-05-GPU%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98%E9%9B%86%E9%94%A6/"/>
    <id>http://wangdongdong122.github.io/2021/08/05/2021-08-05-GPU使用问题集锦/</id>
    <published>2021-08-05T05:02:38.000Z</published>
    <updated>2021-08-05T14:05:54.307Z</updated>
    
    <content type="html"><![CDATA[<p>使用GPU训练模型中出现的问题记录</p><span id="more"></span><h2 id="查看GPU状态"><a href="#查看GPU状态" class="headerlink" title="查看GPU状态"></a>查看GPU状态</h2><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="built_in">cmd</span></span><br><span class="line"><span class="built_in">cd</span> C:\Program Files\NVIDIA Corporation\NVSMI</span><br><span class="line">nvidia-smi.exe</span><br></pre></td></tr></table></figure><h2 id="内存溢出"><a href="#内存溢出" class="headerlink" title="内存溢出"></a>内存溢出</h2><p>pycharm报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorflow.python.framework.errors_impl.InternalError: Blas xGEMM launch failed : a.shape=[1,1,100], b.shape=[1,100,12544], m=1, n=12544, k=100 [Op:MatMul]</span><br></pre></td></tr></table></figure><p>原因是内存溢出</p><p>参考<a href="https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed">stackoverflow</a>，增加两行代码后解决</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">physical_devices = tf.config.list_physical_devices(&#x27;GPU&#x27;) </span><br><span class="line">tf.config.experimental.set_memory_growth(physical_devices[0], True)</span><br></pre></td></tr></table></figure><p>设置使用量(暂时没起到作用)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gpus = tf.config.experimental.list_physical_devices(device_type=&#x27;GPU&#x27;)</span><br><span class="line">for gpu in gpus:</span><br><span class="line">    tf.config.experimental.per_process_gpu_memory_fraction = 0.9</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用GPU训练模型中出现的问题记录&lt;/p&gt;
    
    </summary>
    
    
      <category term="bug" scheme="http://wangdongdong122.github.io/tags/bug/"/>
    
      <category term="环境配置" scheme="http://wangdongdong122.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
      <category term="GPU" scheme="http://wangdongdong122.github.io/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>win10配置GPU版TensorFlow.md</title>
    <link href="http://wangdongdong122.github.io/2021/07/30/2021-07-30-win10%E9%85%8D%E7%BD%AEGPU%E7%89%88TensorFlow/"/>
    <id>http://wangdongdong122.github.io/2021/07/30/2021-07-30-win10配置GPU版TensorFlow/</id>
    <published>2021-07-30T05:02:38.000Z</published>
    <updated>2021-08-01T02:16:17.382Z</updated>
    
    <content type="html"><![CDATA[<p>尝试在win10的台式机上，把我的3060用起来。</p><span id="more"></span><h2 id="安装Anaconda"><a href="#安装Anaconda" class="headerlink" title="安装Anaconda"></a>安装Anaconda</h2><p>我已经安装好了anaconda，但还是需要配置环境变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D:\ProgramData\Anaconda3\Scripts</span><br><span class="line">D:\ProgramData\Anaconda3\pkgs\python-3.8.8-hdbf39b2_5</span><br></pre></td></tr></table></figure><h2 id="确认GPU类型"><a href="#确认GPU类型" class="headerlink" title="确认GPU类型"></a>确认GPU类型</h2><p>查看GPU类型</p><p>然后用谷歌搜索“NVIDIA GeForce RTX 3060+SPECIFICATION”，翻到最后在官网查它是否支持CUDA，可以看到其支持的列表，我的既然写了CUDA cores数量应该是支持的。</p><img src="/2021/07/30/2021-07-30-win10%E9%85%8D%E7%BD%AEGPU%E7%89%88TensorFlow/SPECS.png" class="" title="SPECS"><p>在<a href="https://www.tensorflow.org/install/source_windows">TensorFlow官网查询</a>版本和python版本、CUDA等对于关系。</p><h2 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>下载CUDA，去<a href="https://developer.nvidia.com/cuda-toolkit-archive">官网</a>下载并傻瓜式安装。我这里下载的是<a href="https://developer.nvidia.com/cuda-11.0-download-archive">CUDA Toolkit 11.0</a></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><img src="/2021/07/30/2021-07-30-win10%E9%85%8D%E7%BD%AEGPU%E7%89%88TensorFlow/cuda-install.png" class="" title="cuda-install"><p>尝试了一下，在cmd中输入<code>nvcc -V</code>，显示cuda版本为V11，安装成功。</p><img src="/2021/07/30/2021-07-30-win10%E9%85%8D%E7%BD%AEGPU%E7%89%88TensorFlow/cmd.png" class="" title="cmd"><h2 id="安装cuDNN"><a href="#安装cuDNN" class="headerlink" title="安装cuDNN"></a>安装cuDNN</h2><p>依然是去<a href="https://developer.nvidia.com/rdp/cudnn-archive">官网</a>下载，下载之后解压，并将文件夹下的文件拷贝到cuda中与之相对应的<a href="C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.0">文件夹</a>下，即可。</p><h2 id="安装tensorflow"><a href="#安装tensorflow" class="headerlink" title="安装tensorflow"></a>安装tensorflow</h2><p>直接安装tensorflow2.5版即可</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow==2.5</span><br></pre></td></tr></table></figure><p>安装需要的库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install matplotlib</span><br><span class="line">conda install pandas</span><br></pre></td></tr></table></figure><h2 id="测试是否成功"><a href="#测试是否成功" class="headerlink" title="测试是否成功"></a>测试是否成功</h2><p>使用代码测试是否可以调用GPU，运行以下代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">tf.config.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;GPU&#x27;</span>, tf.test.is_gpu_available())</span><br><span class="line"></span><br><span class="line">a = tf.constant(<span class="number">2.0</span>)</span><br><span class="line">b = tf.constant(<span class="number">4.0</span>)</span><br><span class="line"><span class="built_in">print</span>(a + b)</span><br></pre></td></tr></table></figure><p>并没有成功，因为很多dll文件，tensorflow找不到，是环境变量问题。根据报错提示，去<a href="https://www.tensorflow.org/install/gpu">官网</a>看了一下。让我将这些路径加到PATH中。其中cuDNN需要解压后拷贝一下，我这里按他的提示，拷贝到<code>C:\tools\cuda</code>，并增加到系统路径中。</p><p>都加了之后确实大部分dll文件都能找到了，但下面这个<code>cusolver64_11.dll</code>还是找不到，去cuda的文件夹（<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.0</code>）中搜了一下，发现有个<code>cusolver64_10.dll</code>，但没有<code>cusolver64_11.dll</code>。于是我直接粗暴地将这个文件复制一下，新文件命名为<code>cusolver64_11.dll</code>，再测试一下，成功了。</p><img src="/2021/07/30/2021-07-30-win10%E9%85%8D%E7%BD%AEGPU%E7%89%88TensorFlow/test-gpu.png" class="" title="test-gpu">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;尝试在win10的台式机上，把我的3060用起来。&lt;/p&gt;
    
    </summary>
    
    
      <category term="bug" scheme="http://wangdongdong122.github.io/tags/bug/"/>
    
      <category term="环境配置" scheme="http://wangdongdong122.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>强化学习简介</title>
    <link href="http://wangdongdong122.github.io/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"/>
    <id>http://wangdongdong122.github.io/2021/07/29/2021-07-29-强化学习简介/</id>
    <published>2021-07-29T13:56:44.000Z</published>
    <updated>2021-08-07T07:17:40.390Z</updated>
    
    <content type="html"><![CDATA[<p>本篇为学习强化学习笔记，主要是学习李宏毅老师的<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html">课程</a>的笔记。内容是强化学习的简单介绍，了解一下框架。</p><span id="more"></span><h2 id="场景描述"><a href="#场景描述" class="headerlink" title="场景描述"></a>场景描述</h2><p>强化学习的基本场景是Agent和Environment之间交互，Environment给出一个state，Agent看到了这个state（等同于observation，更好理解）并根据这个state做出某个Action，这个Action会影响Environment，state会发生改变，同时Environment会反馈一个Reward。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Scenario-of-Reinforcement-Learning.png" class="" title="Scenario-of-Reinforcement-Learning"><p>强化学习的目的，就是找到一个Actor或者叫Policy，让Reward最大，其输入使observation，输出是Action。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Looking-for-a-Function.png" class="" title="Looking-for-a-Function"><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>以玩游戏为例。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Playing-Video-Game.png" class="" title="Playing-Video-Game"><p>有以下概念：</p><ul><li>state: observation</li><li>玩一局游戏称为一个episode</li></ul><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>根据是否需要建模模拟环境，可以分为Model-free Approach（不需要对环境建模）和Model-based Approach，前者不需要对环境建模，后者需要。</p><p>Model-free Approach中，可以直接学习什么Actor(policy)最好，即Policy-based。也可以学习一个评估函数，来判断不同决策的价值是多少，即可得到每一步最好的Action。如果将两者结合起来则可以综合两方面的优势。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/RL-Outline.png" class="" title="RL-Outline"><h2 id="Policy-based-Approach"><a href="#Policy-based-Approach" class="headerlink" title="Policy-based Approach"></a>Policy-based Approach</h2><h3 id="问题介绍"><a href="#问题介绍" class="headerlink" title="问题介绍"></a>问题介绍</h3><p>前面介绍了Policy-based Approach 就是要学习一个Actor，它会根据看到的情况来判断下一步动作，即输入是state（等同于observation），输出是Action。将神经网络的模型作为一个actor。以上面的游戏为例，其输入就是当前游戏画面，输出是需要进行的游戏操作，用$\pi_{\theta}(s)$来表示。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Neural-network-as-Actor.png" class="" title="Neural-network-as-Actor"><p>要训练这个神经网络模型，关键的问题是，它的训练目标是什么？强化学习的目标就是得到最多的奖励，所以应该用一个Actor所能得到的期望奖励作为评估其好坏的依据，可以通过蒙特卡洛法，多次实验用平均值作为期望值的矩估计。展开一个游戏过程来看，可以将游戏得分作为奖励，同一个Actor玩了很多局游戏，则用每局游戏奖励的平均值<strong>$\overline R_{\theta}$作为评估Actor $\pi_{\theta}(s)$好坏的依据</strong>。所以我们的只要将$\overline R_{\theta}$用$\theta$表示，最大化$\overline R_{\theta}$就可以。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Goodness-of-Actor.png" class="" title="Goodness-of-Actor"><h3 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h3><p>将上面的问题抽象一下，就是找最优$\theta$，最大化$\overline R_{\theta}$。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Problem-statement.png" class="" title="Problem-statement"><p>梯度怎么求呢？这里$\overline R_{\theta}$是由episode的奖励$R(\tau)$和其概率$p(\tau|\theta)$决定，前者和Actor无关。这里对求导做了个变换，目的是为了把概率提出来，这样就可以表示成期望，然后利用蒙特卡洛来用均值代替。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/policy-gredient-define.png" class="" title="policy-gredient-define"><p>注：这里通过乘$p(\tau|\theta)$后再除$p(\tau|\theta)$可以让该项可以表示成期望，但同时也将原来的$\nabla p(\tau|\theta)$变成了$\nabla log\ p(\tau|\theta)$，这会产生什么影响呢？$\nabla log\ p(\tau|\theta)$后面的求导中，还是会变成$1/p(\tau|\theta)$乘$\nabla p(\tau|\theta)$。原本更新$\theta$，按照$p(\tau|\theta)$的梯度反向传导，再用$R(\tau)$作为权重就可以了，前面这个$1/p(\tau|\theta)$是干啥的呢？是为了平衡样本偏差，本来应该完全按照$\tau$所带来的奖励决定其最终的概率，但现在样本是按照$p(\tau|\theta)$采样出来的，所以可能导致一个好的$\tau$在样本里极少出现，而未能对$\theta$的优化产生多大影响，所以$1/p(\tau|\theta)$就刚好是来解决这个问题。即：乘$p(\tau|\theta)$导致了偏差问题，再除$p(\tau|\theta)$有可以解决该问题。</p><p>$\nabla log\ p(\tau|\theta)$怎么求呢？将一局游戏(episode)拆开，可以表示为$\tau =\{s_1,a_1,r_1,s_2,a_2,r_2,···,s_T,a_T,r_T \}$，其似然为给定actor时产生该$\tau$的概率：$P(\tau|\theta)$。对其展开，整个游戏过程可以看做：给定了一个初始的状态$s_1$之后，Actor根据其观测到状态$s_t$和自身参数$\theta$产生一个动作$a_t$，环境根据状态$s_t$和Actore做出的动作$a_t$给出奖励$r_t$和下一各状态$s_{t+1}$。</p><p>$p(s_1)$表示初始状态是$s_1$的概率，由环境决定，不受Actor影响；$p(a_t|s_t,\theta)$表示其观测到状态$s_t$和自身参数$\theta$产生一个动作$a_t$的概率；$p(r_t,s_{t+1}|s_t,a_t)$表示Actor在$s_t$状态下做出动作$a_t$之后，得到的这局游戏中实际观测到的奖励$r_t$和下一个状态$s_{t+1}$的概率，这个概率也由环境决定，不受actor影响。所以<strong>似然中，只有$p(a_t|s_t,\theta)$与要优化的Actor相关</strong>。</p><p>将$p(\tau|\theta)$的计算公式代入$\nabla log\ p(\tau|\theta)$，其中只有$p(a_t|s_t,\theta)$与Actor相关。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/gradient-of-log-p-1627997683506.png" class="" title="gradient-of-log-p"><p>代入$\nabla\overline R_{\theta}$中，得到更新公式</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/gradient-of-R.png" class="" title="gradient-of-R"><h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p>Actor的学习，就是要解决以下问题，我这里用期望代替均值，感觉表述更加准确。</p><script type="math/tex; mode=display">\theta ^* = arg\ \underset{\theta}{max}\ E[R_{\theta}]</script><p>其中$E[R_{\theta}]$可以表示为</p><script type="math/tex; mode=display">E[R_{\theta}] = \sum_{\tau} R(\tau) P(\tau|\theta)</script><p>其导数为</p><script type="math/tex; mode=display">\begin{eqnarray*}\nabla E[R_{\theta}] &=&  \nabla\sum_{\tau} R(\tau) P(\tau|\theta) \\\\&=& \sum_{\tau} R(\tau) \nabla P(\tau|\theta)\tag{$R(\tau)$与$\theta$无关}\\\\&=& \sum_{\tau} R(\tau)P(\tau|\theta) \frac{\nabla P(\tau|\theta)}{P(\tau|\theta)}\tag{增加$P(\tau|\theta)$凑为期望}\\\\&=& \sum_{\tau}P(\tau|\theta) R(\tau) \nabla log P(\tau|\theta)\tag{换为log导数}\\\\&\approx& \frac{1}{N}\sum^N_{n=1}R(\tau^n)\nabla log P(\tau^n|\theta)\tag{期望用均值代替}\end{eqnarray*}</script><p>其中$P(\tau|\theta)$可以展开其生成过程，并对其展开，并求解一下</p><script type="math/tex; mode=display">\begin{eqnarray*}P(\tau|\theta) &=& p(s_1)\prod ^T_{t=1}p(a_t|s_t,\theta)p(r_t,s_{t+1}|s_t,a_t)\\\\log\ P(\tau|\theta) &=& log\ p(s_1) + \sum ^T_{t=1}\left [log\ p(a_t|s_t,\theta) + log \ p(r_t,s_{t+1}|s_t,a_t)\right ]\\\\\nabla log P(\tau|\theta) &=& \sum ^T_{t=1}\nabla log p(a_t|s_t,\theta)\end{eqnarray*}</script><p>因此</p><script type="math/tex; mode=display">\begin{eqnarray*}\nabla E[R_{\theta}] &\approx& \frac{1}{N}\sum^N_{n=1}R(\tau^n)\nabla log P(\tau^n|\theta)\\\\&=& \frac{1}{N}\sum^N_{n=1}\sum ^{T_n}_{t=1}R(\tau^n)\nabla log p(a^n_t|s^n_t,\theta)\tag{仅$p(a_t|s_t,\theta)$与$\theta$相关}\\\\\end{eqnarray*}</script><h3 id="视作多分类"><a href="#视作多分类" class="headerlink" title="视作多分类"></a>视作多分类</h3><p>这其实和多分类问题相同。如果将学习Actor看做一个多分类问题，数据就是在每局游戏中Actor实际根据状态做出的动作。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/classify-data.png" class="" title="classify-data"><p>其中每个$(s,a)$对中，$s$作为输入，$a$作为输出，对应episode的$R(\tau)$作为权重。</p><p>多分类交叉熵为</p><script type="math/tex; mode=display">J_{CE}(\theta)  = -\frac1N \sum^{N}_{i=1}log(\hat y_{iy_i})</script><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/classify-task.png" class="" title="classify-task"><p>此处的$y_{i}$指的就是对应的$a$，$\hat y_{iy_i}$即$p(a^n_t|s^n_t,\theta)$，总样本数量为$N×T$个，权重为$R(\tau)$，则</p><script type="math/tex; mode=display">J(\theta) =-\frac{1}{N×T}\sum^N_{n=1}\sum ^{T}_{t=1}R(\tau^n) log\ p(a^n_t|s^n_t,\theta)</script><p>这里全面的求平均是除$N×T$（实际上这样表示不准确，因为每个episode不一定都是T步），和上面Actor的公式有一点不一样，因为Actor是最大化的一次episode的联合概率，这里是拆解成动作，最大化每个动作的概率。</p><h3 id="BaseLine"><a href="#BaseLine" class="headerlink" title="BaseLine"></a>BaseLine</h3><p>在这个案例中，奖励$R(\tau)$永远是正的，在数据量非常大的时候这样也没什么问题，因为Actor一次做出各种动作的概率和为1，即使较差的动作对应的权重$R(\tau)$也是正的，但应该没有较好的动作权重高，因此最终差的动作概率还是会下降。但实际训练中，数据是采样得到的，有可能真正好的动作没有采样到（下图的a），这样就会导致优秀的动作a的概率下降，差一点的b,c概率上升。解决这个问题，可以给奖励，加一个baseline，低于base line奖励为负。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Add-a-Baseline.png" class="" title="Add-a-Baseline"><h2 id="Value-based-Approach"><a href="#Value-based-Approach" class="headerlink" title="Value-based Approach"></a>Value-based Approach</h2><p>Value-based方法指学习一个Critic来判断Actor的好坏。Critic不决定Action，但可以从Critic得到一个最优的Actor。Critic分为两种：</p><ol><li>$V^{\pi}(s)$ ：在看见状态$s$后，使用Actor $\pi$产生的累积奖励的期望值</li><li>$Q^{\pi}(s,a)$：在看见状态$s$后，先采取Action $a$，然后使用Actor $\pi$产生的累积奖励的期望值</li></ol><p>比如说阿光在下棋的时候，旁边佐为会告诉他，现在的他能驾驭大马步飞了，下大马步飞是好棋，以前太弱不能这么下。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/sai.png" class="" title="sai"><h3 id="estimate-V-pi-s"><a href="#estimate-V-pi-s" class="headerlink" title="estimate $V^{\pi}(s)$"></a>estimate $V^{\pi}(s)$</h3><p>估计$V^{\pi}(s)$ 有两种方法：蒙特卡洛法和差分法</p><h4 id="Monte-Carlo-based-approach"><a href="#Monte-Carlo-based-approach" class="headerlink" title="Monte-Carlo based approach"></a>Monte-Carlo based approach</h4><p>蒙特卡洛法就是让Actor $\pi$玩游戏，产生episode，来训练critic。在看见状态$s_a$之后，直到游戏结束产生的累积奖励为$G_a$。这里的$G$和之前每个episode的总奖赏$R$不同，$G$表示转态$s_a$之后的累计奖励。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Monte-Carlo-based-approach.png" class="" title="Monte-Carlo-based-approach"><h4 id="Temporal-difference-approach"><a href="#Temporal-difference-approach" class="headerlink" title="Temporal-difference approach"></a>Temporal-difference approach</h4><p>差分法，策略$\pi$下产生的episode，相邻状态$s_t$和$s_{t+1}$下的$V$值相差$r_t$，可以以此为目标训练$V^{\pi}(s)$ 。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Temporal-difference-approach.png" class="" title="Temporal-difference-approach"><h4 id="MC-vs-TD"><a href="#MC-vs-TD" class="headerlink" title="MC vs TD"></a>MC vs TD</h4><p>第一点是目标值的方差和偏差的不同。MC法直接预测的是累积奖励$G_a$，方差会更大。而TD法，标签值是单步的$r$，方差相对小，但其用到了$V^{\pi}(s_{t+1})$，这个值一定准。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/MC-vs-TD-1.png" class="" title="MC-vs-TD-1"><p>第二点是基于的假设不同。在下面的数据中，一共有8个episode，不管我们用哪个方法，很明显都能得到$V^{\pi}(s_{b})=3/4$，那么$V^{\pi}(s_{a})$应该等于多少呢。按照MC方法，$V^{\pi}(s_{a})=0$（只有一条数据）；按照TD方法，$V^{\pi}(s_{a})=V^{\pi}(s_{b})+0=3/4$。MC的假设下状态前后之间可能有相互影响。</p><img src="/2021/07/29/2021-07-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/MC-vs-TD-2.png" class="" title="MC-vs-TD-2"><p><strong>问题</strong>：</p><ol><li><p>看起来针对不同的Actor $\pi$有一个模型$V^{\pi}(s)$， Actor如果更新了，V要重新训练吗？</p></li><li><p>得到这个V之后如何使用？</p></li><li><p>MC和TD之间的假设差异如何理解？</p></li></ol><h3 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q-Learning"></a>Q-Learning</h3><p>Q-Learning一样可以用MC和TD方法。学习的目标是$Q^{\pi}(s,a)$</p><h2 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor-Critic"></a>Actor-Critic</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇为学习强化学习笔记，主要是学习李宏毅老师的&lt;a href=&quot;http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html&quot;&gt;课程&lt;/a&gt;的笔记。内容是强化学习的简单介绍，了解一下框架。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://wangdongdong122.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="学习笔记" scheme="http://wangdongdong122.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="强化学习" scheme="http://wangdongdong122.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>win10配置TensorFlow.md</title>
    <link href="http://wangdongdong122.github.io/2021/07/29/2021-07-29-win10%E9%85%8D%E7%BD%AETensorFlow/"/>
    <id>http://wangdongdong122.github.io/2021/07/29/2021-07-29-win10配置TensorFlow/</id>
    <published>2021-07-29T05:02:38.000Z</published>
    <updated>2021-07-29T23:05:07.521Z</updated>
    
    <content type="html"><![CDATA[<p>尝试在win10的台式机上，配置TensorFlow。</p><span id="more"></span><p>看一下当前在哪个环境下</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Anaconda Prompt</span><br><span class="line">conda info --env</span><br></pre></td></tr></table></figure><p>换源，改成清华的（试了一下，虽然有vpn，但还是下不了50M的tensorflow-base-2.3.0）</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Anaconda Prompt</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure><p>直接装<code>tensorflow</code></p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Anaconda Prompt</span><br><span class="line">conda install tensorflow</span><br></pre></td></tr></table></figure><p>试一下</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Anaconda Prompt</span><br><span class="line">python</span><br><span class="line"></span><br><span class="line"># python</span><br><span class="line">import tensorflow</span><br></pre></td></tr></table></figure><p>报错了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AttributeError: type object &#x27;h5py.h5.H5PYConfig&#x27; has no attribute &#x27;__reduce_cython__&#x27;</span><br></pre></td></tr></table></figure><p>安装</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install h5py==<span class="number">2</span>.<span class="number">9</span></span><br></pre></td></tr></table></figure><p>报错了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">error: Microsoft Visual C++ 14.0 or greater is required. Get it with &quot;Microsoft C++ Build Tools&quot;: https://visualstudio.microsoft.com/visual-cpp-build-tools/</span><br></pre></td></tr></table></figure><p>参考<a href="https://blog.csdn.net/zhanghao_0517/article/details/109630391">大佬博客</a>，直接卸载了pip版的h5py即可</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Anaconda Prompt</span><br><span class="line">pip uninstall h5py</span><br><span class="line"></span><br><span class="line"># Anaconda Prompt</span><br><span class="line">python</span><br><span class="line"></span><br><span class="line"># python</span><br><span class="line">import tensorflow</span><br></pre></td></tr></table></figure><p>tip：尽量使用conda安装库</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;尝试在win10的台式机上，配置TensorFlow。&lt;/p&gt;
    
    </summary>
    
    
      <category term="bug" scheme="http://wangdongdong122.github.io/tags/bug/"/>
    
      <category term="环境配置" scheme="http://wangdongdong122.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>迁移学习简介</title>
    <link href="http://wangdongdong122.github.io/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"/>
    <id>http://wangdongdong122.github.io/2021/07/25/2021-07-25-迁移学习简介/</id>
    <published>2021-07-25T13:56:44.000Z</published>
    <updated>2021-08-04T14:28:39.666Z</updated>
    
    <content type="html"><![CDATA[<p>本篇为学习迁移学习笔记，主要是学习李宏毅老师的<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html">课程</a>的笔记，主要图片也都选自其<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/transfer.pdf">课件</a>。内容是迁移学习的简单介绍，了解一下框架。</p><span id="more"></span><h2 id="整体框架"><a href="#整体框架" class="headerlink" title="整体框架"></a>整体框架</h2><p>迁移学习（Transfer Learning）专注于存储已有问题的解决模型，并将其利用在其他不同但相关问题上$^{[1]}$，具体包括了哪些范围，这种概念一向没有精确的范畴，因此就不纠结了。</p><p>按照source data和target data是否有标签，分为4个类型：</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/TransferLearning-1627310686098.png" class="" title="Transfer Learning Overview"><h2 id="S-labeled-amp-T-labeled"><a href="#S-labeled-amp-T-labeled" class="headerlink" title="S labeled &amp; T labeled"></a>S labeled &amp; T labeled</h2><p>都有label了，还需要transfer Learning，一般是source data多，target data少。比如source data是各个人的语音和对应文本，target data是一个特定的人的语音和对应文本。</p><p>那如果目标域的数据足够，Transfer Learning还有增益吗？后面有两个案例可以说明还是可能有增益的。</p><h3 id="Model-Fine-tuning"><a href="#Model-Fine-tuning" class="headerlink" title="Model Fine-tuning"></a>Model Fine-tuning</h3><p>Idea：training a model by source data, then finetune the model by target data </p><p>Challenge: only limited target data, so be <strong>careful about overfitting</strong></p><h4 id="Conservative-Training"><a href="#Conservative-Training" class="headerlink" title="Conservative Training"></a>Conservative Training</h4><p>就是让模型在fine-tuning阶段，<strong>保守地学习</strong>，让模型不会和pre-train的模型差太多。比如增加regularization，使fine-tune和pre-train的模型对相同数据的预测结果接近，或者是fine-tune和pre-train的模型的参数加上l2正则，使其接近。这个有点像终身学习中的做。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/conservative_training.png" class="" title="conservative training"><h4 id="Layer-Transfer"><a href="#Layer-Transfer" class="headerlink" title="Layer Transfer"></a>Layer Transfer</h4><p>做法：将source data上pre-train的模型的大部分层freeze，用target data只fine-tuning模型的其余几层。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/LayerTransfer.png" class="" title="Layer Transfer"><p>这里有一个比较有意思的点，就是不同的任务，可迁移的层（即可以copy的层）不同。</p><ul><li><p>Speech: usually copy the last few layers（前几层是发音方式→说的内容，后几层是说的内容→任务结果）</p></li><li><p>Image: usually copy the first few layers（前几层是基本的线条特征，后几层是和任务比较相关的）</p></li></ul><p>下面这个实验(<a href="https://papers.nips.cc/paper/2014/file/375c71349b295fbe2dcdca9206f20a06-Paper.pdf">How transferable are features in deep neural networks</a>)可以说明Image中前几个层可以transfer，后几个层不行。这个实验很有意思，需要详细介绍一下。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/LayerTransferImage.png" class="" title="Layer Transfer Image"><p>这个实验以ImageNet的数据测试，500类做源域（60万），500类做目标域（60万），<strong>数据量都很充足</strong>。图中横坐标表示transfer了前N层，纵坐标是准确率，越高越好，黑色的水平虚线表示直接用target data训练的效果。第5条线：transfer之后fine-tuning整个模型，能看出来<strong>即使target data充足，加上预训练之后也还是有提升效果的</strong>。第4条线：transfer前几层，只训练后面几层时，只copy前一两层时，效果还有点提升，copy太多了，效果就不行了。第2条线也很有意思，把target data作为预训练，然后transfer前几层，并freeze，只fine-tuning其余层，结果也是copy多了效果反而不好，所以说模型需要前后层相配合才能学习好，但这个结果还是有点诡异，难以解释。</p><p>如果source data和target data差异很大，前几个层还是可以transfer，后面的层不能transfer。黄色的线表示，<strong>如果前面几层random并且freeze，则后面几层怎么train效果也很差</strong>。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/LayerTransferImage2.png" class="" title="Layer Transfer Image 2"><h3 id="Multitask-Learning"><a href="#Multitask-Learning" class="headerlink" title="Multitask Learning"></a>Multitask Learning</h3><p>多任务学习也可以实现迁移学习，如果source data和target data的特征同构，但任务不同，则可以用下图左边的结构，可以用更多的数据学习浅层。如果source data和target data的特征也不同构，任务也不同，但认为其中间层是可以通用的，则可以用右边的结构。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/NNForMultitaskLearning.png" class="" title="NN suitable for multitask learning"><p>比如在多语言语音识别中，可用浅层提取语义信息，然后用多任务，翻译成各个语言。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/MultitaskLearning-MultilingualSpeechRecognitio.png" class="" title="MultitaskLearning-MultilingualSpeechRecognitio"><p>实验中发现，加入其他语言的多任务还是有利于目标语言的预测的。将语言同时输出为欧洲语言也会有助于我们识别普通话的准确率，模型的收敛速度会快一倍。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/MultitaskLearning-Multilingual.png" class="" title="MultitaskLearning-Multilingual"><p>Huang, Jui-Ting, et al. “Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers.” ICASSP, 2013</p><p><strong>Progressive Neural Networks</strong></p><p>上面的多任务学习需要各个任务只有相关，否则有可能起到副作用。这点不是很好把握，所以有作者提出逐步增加任务（<a href="https://arxiv.org/pdf/1606.04671v3.pdf">PNN</a>），将前序任务的模型中间层也输入至后序任务的模型，这样最差前面任务对后面任务没有增益，则transfer的中间层参数为0，也不会起到什么负作用。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/ProgressiveNeuralNetworks.png" class="" title="ProgressiveNeuralNetworks"><p>感觉这个模型不如MMOE更加合理，后者在任务不相关时，也不会起到副作用。</p><h2 id="S-labeled-amp-T-unlabeled"><a href="#S-labeled-amp-T-unlabeled" class="headerlink" title="S labeled &amp; T unlabeled"></a>S labeled &amp; T unlabeled</h2><p>source data有标签，但target data无标签也可以分为几种情况。</p><ul><li>两者的任务相同，输入不匹配，可使用Domain-adversarial training</li><li>两者的任务不同，输入同类型，可使用Zero-shot Learning</li></ul><p>将机器学习任务理解为$f(\boldsymbol X)→y$ 的过程，则本场景下就是要建立起$f(\boldsymbol X_{source})→y_{source}$与$f(\boldsymbol X_{target})→y_{target}$之间的联系。任务相同时，建立特征之间的联系即可，即找到一个表示，使$g(\boldsymbol X_{source})=g(\boldsymbol X_{target})$，后面的任务部分就可以共享了，这是Domain-adversarial training的基本思路。</p><p>如果任务不同，输入类型相同，则需要建立起$y_{source}$和$y_{target}$之间的联系。在Zero-shot Learning中，$g(y_{source})$中不同动物之间的空间关系同样适用于$g(y_{target})$，这往往需要提供y之间关系的信息，比如Attribute和class之间的关系表，或者对y做word embedding所需的文本。</p><h3 id="Domain-adversarial-training"><a href="#Domain-adversarial-training" class="headerlink" title="Domain-adversarial training"></a>Domain-adversarial training</h3><p>source data有标签，但target data无标签的一个典型例子就是黑白的MNIST数据有标签，彩色的MNIST数据无标签。两者的任务相同，但输入是不同类型。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/TaskDescription.png" class="" title="TaskDescription"><p>Domain-adversarial training的方法非常经典，在各个领域都经常看到。通过让source data和target data学到的表示层分布相同，并且最大限度地保留用来预测y的信息，从而实现迁移学习。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Domain-adversarial-training.png" class="" title="Domain-adversarial-training"><p>所谓adversarial，指的是domain label分类任务中，表示层（绿色）和判别层（粉色）之间的对抗。在这部分的梯度下降中，梯度传至特征提取层（绿色）时，会反转梯度，变为梯度上升。</p><p>参考文章：</p><p><a href="http://de.arxiv.org/pdf/1409.7495">Yaroslav Ganin, Victor Lempitsky, Unsupervised Domain Adaptation by Backpropagation, ICML, 2015</a> </p><p><a href="https://arxiv.org/pdf/1505.07818.pdf">Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, Domain-Adversarial Training of Neural Networks, JMLR, 2016</a></p><h3 id="Zero-shot-Learning"><a href="#Zero-shot-Learning" class="headerlink" title="Zero-shot Learning"></a>Zero-shot Learning</h3><p>完全没有想要预测的任务的标签时，还可以用Zero-shot Learning！比如说下面这个任务，source data是猫和狗的图片，以及其对应的标签是猫和狗。target data是草泥马的图片，怎么才能预测出这是草泥马呢？</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Zero-shot-Learning.png" class="" title="Zero-shot-Learning"><p>如果我们能拿到一个database，里面有每种动物对于的属性，且属性的维度多到能够和动物class一一对应。那做法就是，先训练模型预测图片的是否具有各个属性。</p>得到动物的class。<img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Representing-class-by-attributes-test.png" class="" title="Representing-class-by-attributes-test"><h4 id="Attribute-embedding"><a href="#Attribute-embedding" class="headerlink" title="Attribute embedding"></a>Attribute embedding</h4><p>如果Attribute比较复杂，可以做Attribute的embedding，用有标签的数据训练，让$f(图片)$接近于其对应动物的$g(Attribute)$（每个动物有一个$g(Attribute)$）。然后预测时，计算无标签图片的embedding：$f(草泥马图片)$，去匹配和所有动物的$g(Attribute)$，和其最近的$g(Attribute)$对应的动物就是其预测结果。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Attribute-embedding.png" class="" title="Attribute-embedding"><h4 id="Attribute-embedding-word-embedding"><a href="#Attribute-embedding-word-embedding" class="headerlink" title="Attribute embedding + word embedding"></a>Attribute embedding + word embedding</h4><p>上面这种方法需要有Attribute和class之间的关系表，如果没有这个表，可以通过word embedding来对动物embedding。但感觉这个方法精度非常有限，不过也是更人工智能的要求。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Attribute-embedding-word-embedding.png" class="" title="Attribute-embedding-word-embedding"><p>这个方法中的loss挺有意思，可以学习一下。如果直接让$f(\boldsymbol x_i)$和$g(\boldsymbol y_i)$之间的距离最小：</p><script type="math/tex; mode=display">J = \sum^N_{i=1}||f(\boldsymbol x_i)-g(\boldsymbol y_i)||_2</script><p>则会导致模型将所有$i$的$f(\boldsymbol x_i)$和$g(\boldsymbol y_i)$都预测成一样的向量就可以了，所以需要增加一个类间距的约束，此处用内积来度量距离：</p><script type="math/tex; mode=display">J =\sum^N_{i=1}max\left(0,k-f(\boldsymbol x_i)·g(\boldsymbol y_i)+\underset {j\neq i}{max}f(\boldsymbol x_i)·g(\boldsymbol y_j)\right )</script><p>这个公式的含义是$f(\boldsymbol x_i)·g(\boldsymbol y_i)<br>-\underset {j\neq i}{max}f(\boldsymbol x_i)·g(\boldsymbol y_j)=\underset {j\neq i}{min}[-f(\boldsymbol x_i)·g(\boldsymbol y_j)]-(-f(\boldsymbol x_i)·g(\boldsymbol y_i))&gt;k$ 时，即最小的类间距要比类内距大$k$，此时loss为0。否则就加大这个类间距-类内距。</p><h4 id="Convex-Combination-of-Semantic-Embedding"><a href="#Convex-Combination-of-Semantic-Embedding" class="headerlink" title="Convex Combination of Semantic Embedding"></a>Convex Combination of Semantic Embedding</h4><p>也可以连模型都不用训练，找个现成的分类模型，用其在各个类别上的预测结果作为Embedding，然后去和其最近的动物的embedding对应的动物类别（此处已经有了每个动物的embedding）。下图的意思是，对一个输入的图片，预测其属于lion和tiger的概率都是0.5，然后去动物embedding空间中，看离lion和tiger中点最近的embedding对应的动物是什么。这个方法对embedding空间有一定的假设。</p><img src="/2021/07/25/2021-07-25-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/Convex-Combination-of-Semantic-Embedding.png" class="" title="Convex-Combination-of-Semantic-Embedding"><h2 id="S-unlabeled"><a href="#S-unlabeled" class="headerlink" title="S unlabeled"></a>S unlabeled</h2><p>当source data没有label时，可以通过source data学习怎么更好地提取特征，也可以帮助我们的模型。但此时需要用无监督的方式，比如自编码等等。</p><hr><p>注：</p><p>[1]. <a href="https://zh.wikipedia.org/wiki/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0">维基百科</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇为学习迁移学习笔记，主要是学习李宏毅老师的&lt;a href=&quot;http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html&quot;&gt;课程&lt;/a&gt;的笔记，主要图片也都选自其&lt;a href=&quot;http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/transfer.pdf&quot;&gt;课件&lt;/a&gt;。内容是迁移学习的简单介绍，了解一下框架。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://wangdongdong122.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="迁移学习" scheme="http://wangdongdong122.github.io/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="学习笔记" scheme="http://wangdongdong122.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>常见损失函数</title>
    <link href="http://wangdongdong122.github.io/2021/07/24/2021-07-24-%E5%B8%B8%E8%A7%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <id>http://wangdongdong122.github.io/2021/07/24/2021-07-24-常见损失函数/</id>
    <published>2021-07-24T13:56:44.000Z</published>
    <updated>2021-07-25T09:05:25.903Z</updated>
    
    <content type="html"><![CDATA[<p>总结一下常见损失函数</p><span id="more"></span><h2 id="交叉熵损失"><a href="#交叉熵损失" class="headerlink" title="交叉熵损失"></a>交叉熵损失</h2><p><strong>负对数似然（MLE）</strong>是定义在训练集上的经验分布与定义在模型分布上的概率分布之间的<strong>交叉熵</strong>定义如下</p><script type="math/tex; mode=display">H(P,Q) = -E_{X\sim P}[log\ Q(x)]</script><p>将预测概率分布$p_{model}$作为Q，训练集定义的经验分布$\hat p_{data}$作为P，定义交叉熵损失函数如下：</p><script type="math/tex; mode=display">\begin{eqnarray*}J_{CE}(\boldsymbol \theta) &=& -E_{X\sim P}[log\ Q(x)]\\\\&=& -E_{\boldsymbol x,\boldsymbol y\sim \hat p_{data}}[log\ p_{model}(\boldsymbol y|\boldsymbol  x)]\\\\&=& -\frac{1}{N}\sum^{N}_{i=1} log\ p_{model}(\boldsymbol y_i|\boldsymbol  x_i)\tag{$P(Y_i=y_i)=1$}\end{eqnarray*}</script><p>其中，$p_{model}(\boldsymbol y|\boldsymbol  x)$表示按照模型的预测，给定用户特征$\boldsymbol  x$后，目标变量取值为$\boldsymbol y$的概率。在推导中，计算单个样本的$p_{model}(\boldsymbol y_i|\boldsymbol  x_i)$即可代入上面公式。大多数情况下，单个样本预测目标值是标量，因此下文用$p_{model}(y|\boldsymbol  x)$代替$p_{model}(\boldsymbol y|\boldsymbol  x)$推导。</p><h3 id="分类中的交叉熵"><a href="#分类中的交叉熵" class="headerlink" title="分类中的交叉熵"></a>分类中的交叉熵</h3><h4 id="每个类别一个输出单元时"><a href="#每个类别一个输出单元时" class="headerlink" title="每个类别一个输出单元时"></a>每个类别一个输出单元时</h4><p>若共有K个类别，$y_i= 1,2,…,K$表示样本$i$所属的类别。将$y_i$做<strong>one-hot编码</strong>后，$y_{ij}=0,1$表示第$i$个样本是否属于$j$类，对于的预测概率为$\hat y_{ij} \in [0,1]$。则第$i$个样本的交叉熵为</p><script type="math/tex; mode=display">\begin{eqnarray*}E[log\ p_{model}(y_i|\boldsymbol  x_i)]&=&\sum^K_{j=1} P(y_i=j)\ log(p_{model}(y_i=j|\boldsymbol  x_i))\\\\&=&\sum^K_{j=1} y_{ij}\ log(\hat y_{ij})\\\\&=& log(\hat y_{iy_i})\tag{仅$j=y_j$时$y_{ij}$不为0}\end{eqnarray*}</script><p>若共有$N$个样本，对应交叉熵为</p><script type="math/tex; mode=display">\begin{eqnarray*}J_{CE}(\boldsymbol \theta)  &=& -\frac1N \sum^{N}_{i=1}\sum^K_{j=1} y_{ij}\ log(\hat y_{ij})\\\\J_{CE}(\boldsymbol \theta)  &=& -\frac1N \sum^{N}_{i=1}log(\hat y_{iy_i})\end{eqnarray*}</script><h4 id="二分类只用一个单元时（sigmoid）"><a href="#二分类只用一个单元时（sigmoid）" class="headerlink" title="二分类只用一个单元时（sigmoid）"></a>二分类只用一个单元时（sigmoid）</h4><p>当预测值$\hat y \in [0,1]$为概率，真实值$y=0,1$为是否发生时，第$i$个样本的预测概率分别为</p><script type="math/tex; mode=display">\begin{eqnarray*}p_{model}(y=1|\boldsymbol  x_i) &=& \hat y_i\\p_{model}(y=0|\boldsymbol  x_i) &=& 1-\hat y_i\end{eqnarray*}</script><p>此时对于单个样本$i$交叉熵为</p><script type="math/tex; mode=display">\begin{eqnarray*}E[log\ p_{model}(y_i|\boldsymbol  x_i)] &=& P(y_i=1)\ log(p_{model}(y=1|\boldsymbol  x_i))+P(y_i=0)\ log(p_{model}(y=0|\boldsymbol  x_i))\\\\&=& y_i\ ln\ \hat y_i + (1-y_i)\ ln(1-\hat y_i)\end{eqnarray*}</script><p>若共有$N$个样本，可以得到二分类，单输出单元下的交叉熵损失：</p><script type="math/tex; mode=display">J_{CE}(\boldsymbol \theta)  = -\frac1N \sum^{N}_{i=1}[y_i\ ln\ \hat y_i + (1-y_i)\ ln(1-\hat y_i)]</script><h3 id="高斯分布与均方误差损失"><a href="#高斯分布与均方误差损失" class="headerlink" title="高斯分布与均方误差损失"></a>高斯分布与均方误差损失</h3><p>如果真实值服从高斯分布，预测值是高斯分布的均值，即$ p_{model}(y|\boldsymbol  x)=N(y; {\hat  y},1)$,则可以得到均方误差损失。但这并不是要求由均方误差损失求解的${\hat  y}$只能用于预测高斯分布的均值$^{[1]}$。</p><p>对于样本$i$，其真实标签值为$y_i$，预测值为$\hat y_i$，则</p><script type="math/tex; mode=display">p_{model}(y_i|\boldsymbol  x_i) =\frac{1}{\sqrt{2\pi}}e^{-\frac{(y_i-\hat y_i)^2}{2}}</script><p>此时单个样本$i$，有</p><script type="math/tex; mode=display">\begin{eqnarray*}log\ p_{model}(y_i|\boldsymbol  x_i)&=&log\ \left(\frac{1}{\sqrt{2\pi}}e^{-\frac{(y_i-\hat y_i)^2}{2}} \right)\\\\&=& -\frac{(y_i-\hat y_i)^2}{2} +C\end{eqnarray*}</script><p>因此，交叉熵损失等同于均方误差损失：</p><script type="math/tex; mode=display">\begin{eqnarray*}J_{CE}(\boldsymbol \theta)=J_{MSE}(\boldsymbol \theta)=\frac1N \sum^{N}_{i=1}(y_i-\hat y_i)^2\end{eqnarray*}</script><h3 id="拉普拉斯分布到绝对值损失"><a href="#拉普拉斯分布到绝对值损失" class="headerlink" title="拉普拉斯分布到绝对值损失"></a>拉普拉斯分布到绝对值损失</h3><p>如果真实值服从拉普拉斯分布，预测值是拉普拉斯分布的均值，即$ p_{model}(y|\boldsymbol  x)=Laplace(y; {\hat  y},b)$，则对于样本$i$，其真实标签值为$y_i$，预测值为$\hat y_i$，有：</p><script type="math/tex; mode=display">\begin{eqnarray*}p_{model}(y_i|\boldsymbol  x_i) &=&\frac{1}{2b}e^{-\frac{|y_i-\hat y_i|}{b}}\\\\log\ p_{model}(y_i|\boldsymbol  x_i)&=&log\ \left(\frac{1}{2b}e^{-\frac{|y_i-\hat y_i|}{b}} \right)\\\\&=& -\frac{|y_i-\hat y_i|}{b} +C\end{eqnarray*}</script><p>因此此时交叉熵损失为绝对值损失：</p><script type="math/tex; mode=display">J_{CE}(\boldsymbol \theta)=J_{ABS}(\boldsymbol \theta)=\frac1N \sum^{N}_{i=1}|y_i-\hat y_i|</script><h2 id="Hinge损失函数"><a href="#Hinge损失函数" class="headerlink" title="Hinge损失函数"></a>Hinge损失函数</h2><p>用于分类任务，真实值$y=-1,1$，预测值$\hat y \in [-1,1]$，定义如下</p><script type="math/tex; mode=display">J_{Hinge}(\boldsymbol \theta) = max(0,1-y\ \hat y)</script><p>分类正确，即$y=\hat y=1\ or\ y=\hat y=-1$时，损失为0，否则为$1-y\ \hat y$。max的作用是不鼓励$|\hat y|&gt;1$。</p><p>优缺：对异常值的敏感度低，但没有数理统计的理论推导。</p><hr><p>注：</p><p>[1]. 《深度学习》P111</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结一下常见损失函数&lt;/p&gt;
    
    </summary>
    
    
      <category term="基础知识" scheme="http://wangdongdong122.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="损失函数" scheme="http://wangdongdong122.github.io/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>MAP</title>
    <link href="http://wangdongdong122.github.io/2021/07/22/2021-07-22-MAP/"/>
    <id>http://wangdongdong122.github.io/2021/07/22/2021-07-22-MAP/</id>
    <published>2021-07-22T01:30:35.000Z</published>
    <updated>2021-07-24T13:46:24.285Z</updated>
    
    <content type="html"><![CDATA[<p>MAP最大化的是后验概率：$p(\boldsymbol  \theta|\boldsymbol X)$，等同于在MLE的最大化的似然后面再乘先验：$p(\boldsymbol X|\boldsymbol  \theta)p(\boldsymbol  \theta)$。</p><span id="more"></span><h2 id="最大后验概率"><a href="#最大后验概率" class="headerlink" title="最大后验概率"></a>最大后验概率</h2><p>MLE求的是一组使似然函数最大的参数，即</p><script type="math/tex; mode=display">\boldsymbol {\hat\theta}_{MLE}= \underset {\boldsymbol \theta}{argmax} \ p(\boldsymbol X;\boldsymbol  \theta)</script><p>现在问题稍微复杂一点点，假如这个参数 $\boldsymbol  \theta$给定了先验概率呢？比如说，在上面抛硬币的例子，假如我们的经验告诉我们，硬币一般都是匀称的，也就是 $\boldsymbol  \theta  =0.5$的可能性最大， $\boldsymbol  \theta=0.2$ 的可能性比较小，那么参数该怎么估计呢？这就是MAP要考虑的问题。</p><p>给定后验的样本$\boldsymbol {X}$、$\boldsymbol {X}$符合的概率分布类型$p(\boldsymbol {X}|\boldsymbol  \theta)$(函数形式已知，但参数$\boldsymbol  \theta$未知) 、$\boldsymbol  \theta$ 的先验概率$p(\boldsymbol  \theta)$。MAP优化的是一个后验概率，即给定了观测值后使 $\boldsymbol  \theta$ 概率最大：</p><script type="math/tex; mode=display">\begin{eqnarray*}\boldsymbol {\hat\theta}_{MAP} &=&\underset {\boldsymbol  \theta}{argmax} \ p(\boldsymbol  \theta|\boldsymbol X)\\\\&=& \underset {\boldsymbol  \theta}{argmax} \ \frac{p(\boldsymbol X|\boldsymbol  \theta)p(\boldsymbol  \theta)}{p(\boldsymbol X)}\\\\&=& \underset {\boldsymbol  \theta}{argmax} \ p(\boldsymbol X|\boldsymbol  \theta)p(\boldsymbol  \theta)\end{eqnarray*}</script><p>这里的似然$p(\boldsymbol X|\boldsymbol  \theta)$和MLE最大化的$P(\boldsymbol X;\boldsymbol \theta)$表示的是同一个东西，所以MAP最大化的是后验概率，等同于在MLE的最大化的似然后面再乘先验$p(\boldsymbol  \theta)$。</p><h2 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h2><p>和MLE一样，取对数之后，令导数为0，来求解参数</p><script type="math/tex; mode=display">\begin{eqnarray*}\boldsymbol {\hat\theta}_{MAP} &=& \underset {\boldsymbol  \theta}{argmax} \ p(\boldsymbol X|\boldsymbol  \theta)p(\boldsymbol  \theta)\\\\&=&\underset {\boldsymbol  \theta}{argmax} \  log \left ( \prod^{N_X}_{i=1} p(\boldsymbol x_i|\boldsymbol  \theta)p(\boldsymbol  \theta)\right )\tag{取log}\\\\&=&\underset {\boldsymbol  \theta}{argmax} \  \sum ^{N_X}_{i=1} \{log\ p(\boldsymbol x_i|\boldsymbol  \theta)\}+ log\ p(\boldsymbol  \theta)\end{eqnarray*}</script><p>然后根据实际场景给出$p(\boldsymbol x_i|\boldsymbol  \theta)$和先验$p(\boldsymbol  \theta)$，然后令导数为0，求解。</p><p><strong>相关阅读</strong></p><a href="/2021/07/07/2021-07-07-%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/" title="最大似然估计">最大似然估计</a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MAP最大化的是后验概率：$p(\boldsymbol  \theta|\boldsymbol X)$，等同于在MLE的最大化的似然后面再乘先验：$p(\boldsymbol X|\boldsymbol  \theta)p(\boldsymbol  \theta)$。&lt;/p&gt;
    
    </summary>
    
    
      <category term="基础知识" scheme="http://wangdongdong122.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="MAP" scheme="http://wangdongdong122.github.io/tags/MAP/"/>
    
  </entry>
  
  <entry>
    <title>博客符号说明</title>
    <link href="http://wangdongdong122.github.io/2021/07/22/2021-07-22-%E5%8D%9A%E5%AE%A2%E7%AC%A6%E5%8F%B7%E8%AF%B4%E6%98%8E/"/>
    <id>http://wangdongdong122.github.io/2021/07/22/2021-07-22-博客符号说明/</id>
    <published>2021-07-22T01:30:35.000Z</published>
    <updated>2021-07-25T02:08:24.852Z</updated>
    
    <content type="html"><![CDATA[<p>博客的符号统一</p><span id="more"></span><h2 id="模型参数"><a href="#模型参数" class="headerlink" title="模型参数"></a>模型参数</h2><p>模型参数：$\boldsymbol \theta,\boldsymbol  \theta \in \boldsymbol \Theta$</p><p>参数估计值：$\boldsymbol {\hat\theta}$</p><p>不同方法的参数估计值：$\boldsymbol {\hat\theta}_{MLE}$</p><h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><p>代价函数：$J(\boldsymbol \theta)$</p><h2 id="概率"><a href="#概率" class="headerlink" title="概率"></a>概率</h2><p>事件：$A,X=x$</p><p>随机变量：$X,Y,Z$</p><p>概率：$P(A),P(X=x)$</p><p>离散变量上的概率分布：$P(a)$</p><p>连续变量上的概率分布：$p(a)$</p><p>随机变量服从某分布：$a\sim P$</p><h2 id="期望"><a href="#期望" class="headerlink" title="期望"></a>期望</h2><p>$f(x)$关于$P(x)$的期望：$E_{x\sim P}[f(x)]$</p><h2 id="取值范围"><a href="#取值范围" class="headerlink" title="取值范围"></a>取值范围</h2><p>枚举：$x=0,1.$</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;博客的符号统一&lt;/p&gt;
    
    </summary>
    
    
      <category term="文档" scheme="http://wangdongdong122.github.io/tags/%E6%96%87%E6%A1%A3/"/>
    
      <category term="符号" scheme="http://wangdongdong122.github.io/tags/%E7%AC%A6%E5%8F%B7/"/>
    
  </entry>
  
  <entry>
    <title>常见的分布</title>
    <link href="http://wangdongdong122.github.io/2021/07/22/2021-07-22-%E5%B8%B8%E8%A7%81%E7%9A%84%E5%88%86%E5%B8%83/"/>
    <id>http://wangdongdong122.github.io/2021/07/22/2021-07-22-常见的分布/</id>
    <published>2021-07-22T01:30:35.000Z</published>
    <updated>2021-07-25T08:38:09.340Z</updated>
    
    <content type="html"><![CDATA[<p>总结常见的分布</p><span id="more"></span><h2 id="离散型"><a href="#离散型" class="headerlink" title="离散型"></a>离散型</h2><h3 id="二点分布"><a href="#二点分布" class="headerlink" title="二点分布"></a>二点分布</h3><p><strong>表示</strong>：$X\sim b(1,p)$</p><p><strong>别名</strong>：0-1分布；伯努利分布</p><p><strong>分布列</strong>：$P(X=x)=p^x(1-p)^{1-x},x=0,1.$</p><h3 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h3><p><strong>表示</strong>：$X\sim b(n,p)$</p><p><strong>分布列</strong>：</p><script type="math/tex; mode=display">\begin{eqnarray*}P(X=k) &=& \binom{n}{k}p^k(1-p)^{n-k}\tag{$\binom{n}{k}$种可能的概率都是$p^k(1-p)^{n-k}$}\\\\&=&  \frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\end{eqnarray*}</script><p><strong>含义</strong>：n重伯努利实验中成功的次数</p><p><strong>分布特征</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}E(X) &=& \sum^n_{k=0} k\ \binom{n}{k}p^k(1-p)^{n-k}\\\\&=& np \sum^n_{k=1}  \binom{n-1}{k-1}p^{k-1}(1-p)^{(n-1)-(k-1)}\tag{从$C^k_n$中提出n,约掉k}\\\\&=& np[p+(1-p)]^{n-1}\tag{二项定理}\\\\&=& np\\\\Var(X)  &=& E(X^2)-(E(X))^2\\\\&=& np(1-p)\tag{$E(X^2)$证明复杂，省略}\end{eqnarray*}</script><p><strong>二项定理</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}(x+y)^n &=& \sum^n_{k=0} \binom{n}{k} x^{n-k}y^k = \sum^n_{k=0} \binom{n}{k} x^{k}y^{n-k}\\\\\binom{n}{k} &=& C^k_n = \frac{n!}{k!(n-k)!}\end{eqnarray*}</script><p><strong>分布图</strong></p><img src="/2021/07/22/2021-07-22-%E5%B8%B8%E8%A7%81%E7%9A%84%E5%88%86%E5%B8%83/sns.hwcrazy.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg" class="" title="img"><ul><li>位于均值np附近的概率较大</li><li>随着p的增加，分布的峰逐渐右移</li></ul><h3 id="泊松分布"><a href="#泊松分布" class="headerlink" title="泊松分布"></a>泊松分布</h3><h2 id="连续型"><a href="#连续型" class="headerlink" title="连续型"></a>连续型</h2><h3 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a>正态分布</h3><p><strong>表示</strong>：$X\sim N(\mu,\sigma^2)$</p><p><strong>别名</strong>：高斯分布，Normal distribution</p><p><strong>含义</strong>：（中心极限定理）一个随机变量如果是大量微小的，独立的随机因素的叠加结果，则可认为服从正态分布。</p><ul><li>测量误差</li><li>产品重量</li><li>人的身高</li><li>年降雨量</li></ul><p><strong>分布表示</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}p(x) &=&\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}},\ -\infty<x<+\infty\\\\F(x) &=&\frac{1}{\sqrt{2\pi}\sigma} \int^x_{-\infty}e^{-\frac{(t-\mu)^2}{2\sigma^2}}dt,\ -\infty<x<+\infty\end{eqnarray*}</script><p><strong>分布特征</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}E(X)&=&\mu\\\\Var(X)&=&\sigma^2\end{eqnarray*}</script><p><strong>分布图</strong></p><img src="/2021/07/22/2021-07-22-%E5%B8%B8%E8%A7%81%E7%9A%84%E5%88%86%E5%B8%83/Normal_distribution.png" class="" title="Normal_distribution"><h3 id="拉普拉斯分布"><a href="#拉普拉斯分布" class="headerlink" title="拉普拉斯分布"></a>拉普拉斯分布</h3><p><strong>表示</strong>：$X\sim Laplace(\mu,b)$</p><p><strong>别名</strong>：双指数分布，Laplace distribution</p><p><strong>含义</strong>：由两个指数函数组成的</p><p><strong>分布表示</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}p(x) &=& \frac{1}{2b}e^{-\frac{|x-\mu|}{b}}\\\\F(x) &=& \frac12 \left[1+sgn(x-\mu)(1-e^{-\frac{|x-\mu|}{b}})\right ] \end{eqnarray*}</script><p><strong>分布特征</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}E(X)&=&\mu\\\\Var(X)&=&2b^2\end{eqnarray*}</script><p><strong>分布图</strong></p><img src="/2021/07/22/2021-07-22-%E5%B8%B8%E8%A7%81%E7%9A%84%E5%88%86%E5%B8%83/Laplace_distribution.png" class="" title="Laplace_distribution">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结常见的分布&lt;/p&gt;
    
    </summary>
    
    
      <category term="数理统计" scheme="http://wangdongdong122.github.io/tags/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="基础" scheme="http://wangdongdong122.github.io/tags/%E5%9F%BA%E7%A1%80/"/>
    
      <category term="分布" scheme="http://wangdongdong122.github.io/tags/%E5%88%86%E5%B8%83/"/>
    
  </entry>
  
  <entry>
    <title>因果图</title>
    <link href="http://wangdongdong122.github.io/2021/07/22/2021-08-07-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-what-if/"/>
    <id>http://wangdongdong122.github.io/2021/07/22/2021-08-07-因果推断-what-if/</id>
    <published>2021-07-22T01:30:35.000Z</published>
    <updated>2021-08-07T07:39:50.853Z</updated>
    
    <content type="html"><![CDATA[<p>学习《Causal Inference: What If》笔记。</p><span id="more"></span>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;学习《Causal Inference: What If》笔记。&lt;/p&gt;
    
    </summary>
    
    
      <category term="因果推断" scheme="http://wangdongdong122.github.io/tags/%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD/"/>
    
      <category term="学习笔记" scheme="http://wangdongdong122.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="因果之书" scheme="http://wangdongdong122.github.io/tags/%E5%9B%A0%E6%9E%9C%E4%B9%8B%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>hexo疑难杂症</title>
    <link href="http://wangdongdong122.github.io/2021/07/14/2021-07-14-hexo%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"/>
    <id>http://wangdongdong122.github.io/2021/07/14/2021-07-14-hexo疑难杂症/</id>
    <published>2021-07-14T14:34:05.000Z</published>
    <updated>2021-08-04T13:27:24.143Z</updated>
    
    <content type="html"><![CDATA[<p>记录一下博客使用过程中遇到的问题及解决方案。</p><span id="more"></span><h2 id="翻页按钮错误"><a href="#翻页按钮错误" class="headerlink" title="翻页按钮错误"></a>翻页按钮错误</h2><p><strong>问题</strong>：翻页按钮显示为<code>&lt;i class=&quot;fa fa-angle-left&quot;&gt;&lt;/i&gt;</code>和<code>&lt;i class=&quot;fa fa-angle-right&quot;&gt;&lt;/i&gt;</code></p><p><strong>解决办法</strong>：</p><p>打开<code>next &gt; layout &gt; _partials &gt; pagination.swig</code> ，将错误的HTML代码改为‘下一页’和‘上一页’即可！</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if page.prev or page.next %&#125;</span><br><span class="line">  &lt;nav class=&quot;pagination&quot;&gt;</span><br><span class="line">    &#123;&#123;</span><br><span class="line">      paginator(&#123;</span><br><span class="line">        prev_text: &#x27;上一页&#x27;,</span><br><span class="line">        next_text: &#x27;下一页&#x27;,</span><br><span class="line">        mid_size: 1</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;&#125;</span><br><span class="line">  &lt;/nav&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><h2 id="增加微信二维码"><a href="#增加微信二维码" class="headerlink" title="增加微信二维码"></a>增加微信二维码</h2><p>将自己的二维码图片放在<code>source/images</code>中，在<code>\themes\next\layout\_macro\sidebar.swig</code>文件中，<code>&#123;&#123;- next_inject('sidebar') &#125;&#125;</code>之前，增加以下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;div class=&quot;wechat_OA&quot;&gt;</span><br><span class="line">    &lt;span&gt;欢迎加微信讨论&lt;/span&gt;</span><br><span class="line">    &lt;br&gt;</span><br><span class="line">    &lt;!-- 这里添加你的二维码图片 --&gt;</span><br><span class="line">    &lt;img src =&quot;/images/wechat.png&quot; style=&quot;zoom:40%;&quot; /&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><h2 id="TOC展开"><a href="#TOC展开" class="headerlink" title="TOC展开"></a>TOC展开</h2><p>让侧边栏的TOC不要默认是折叠的，都展开方便查看结构</p><p>step1: 打开文件<code>themes/next/source/css/_common/components/sidebar/sidebar-toc.styl</code>,将</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.post-toc .nav .nav-child &#123; display: none; &#125;</span><br></pre></td></tr></table></figure><p>修改为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.post-toc .nav .nav-child &#123; display: block; &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录一下博客使用过程中遇到的问题及解决方案。&lt;/p&gt;
    
    </summary>
    
    
      <category term="bug" scheme="http://wangdongdong122.github.io/tags/bug/"/>
    
      <category term="hexo" scheme="http://wangdongdong122.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>熵</title>
    <link href="http://wangdongdong122.github.io/2021/07/10/2021-07-10-%E7%86%B5/"/>
    <id>http://wangdongdong122.github.io/2021/07/10/2021-07-10-熵/</id>
    <published>2021-07-10T01:30:35.000Z</published>
    <updated>2021-07-25T01:50:54.509Z</updated>
    
    <content type="html"><![CDATA[<p>熵是信息论中的概念，在机器学习中也被广泛应用，比如<strong>交叉熵</strong>、<strong>KL散度</strong>等。本文总结一下各种熵有关的概念，并总结他们的各种形式变种。</p><span id="more"></span><h2 id="热力学中的熵"><a href="#热力学中的熵" class="headerlink" title="热力学中的熵"></a>热力学中的熵</h2><p>直观理解上，熵可以理解为混乱度，混乱度越高，熵越大。熵是来自于热力学的概念，先对这个概念做初步的了解。</p><h3 id="热力学熵"><a href="#热力学熵" class="headerlink" title="热力学熵"></a>热力学熵</h3><p>1856年，克劳修斯推导出的公式：</p><script type="math/tex; mode=display">\Delta S = \frac{\Delta Q}{T}</script><p>其中，S表示熵，Q表示热量，T表示温度，$  \Delta$表示增量。这个公式可以视作“熵”这个字的来源，1924年，我国物理学家胡刚复在翻译德语“entropie”时，创造出来的，在“商”字左边加个“火”，取“热量与温度之商”的意思。该公式有两个问题</p><ol><li>只给了熵的增量的定义，没有给出一个锚点。</li><li>难以直观理解。</li></ol><h3 id="统计熵"><a href="#统计熵" class="headerlink" title="统计熵"></a>统计熵</h3><p>1877年，玻尔兹曼从统计力学角度给出的定义:</p><script type="math/tex; mode=display">S = k_b ln W</script><p>其中，S表示熵，$k_b$是玻尔兹曼常量，W表示微观状态数，即某个系统所处的某个特定的宏观状态，W是符合该系统状态的微观状态总数。所谓宏观状态和微观状态指的是啥？系统的宏观状态有温度、体积、压强、浓度等；微观变量有分子的动量、动能、速度、质量等。</p><h3 id="吉布斯熵"><a href="#吉布斯熵" class="headerlink" title="吉布斯熵"></a>吉布斯熵</h3><p>玻尔兹曼的定义假设了“各微观状态出现的概率相等”，美国物理学家吉布斯在其基础上定义了一般情况下的熵，被称为吉布斯熵：</p><script type="math/tex; mode=display">S = -k_b\sum_i p_i ln\ p_i</script><p>其中$p_i$表示各微观状态出现的概率。</p><h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><h3 id="量化信息的基本思想"><a href="#量化信息的基本思想" class="headerlink" title="量化信息的基本思想"></a>量化信息的基本思想</h3><ul><li>发生概率很大的事件，信息量较少，一定发生的事件则没有信息量</li><li>发生概率很小的事件，信息量较高</li><li>独立事件具有增量的信息</li></ul><p>其实从这些基本的定量关系，我们就能够大概做出一些推导。首先是信息量（用$h(·)$表示）与概率（$p(·)$）相关，概率越小，信息量越大：$h(A)=f(p(A))$，其中$f(·)$是个单调递减函数。</p><p>另外，两个独立事件的信息量等于两个事件的信息量之和：</p><script type="math/tex; mode=display">h(A,B)=h(A)+h(B)=f(p(A))+f(p(B))</script><p>由$h(A)$的定义和独立事件的联合概率等于各自概率乘积可知：</p><script type="math/tex; mode=display">h(A,B) = f(p(A,B))=f(p(A)·p(B)))</script><p>从上面两个式子可知</p><script type="math/tex; mode=display">f(p(A))+f(p(B))=f(p(A)·p(B)))</script><p>不难发现$f(a)+f(b)=f(ab),a&gt;0,b&gt;0$，满足该式子的一定是对数函数（<a href="https://math.stackexchange.com/questions/98673/examples-of-functions-where-fab-fafb">证明</a>）。令$g(x)=f(e^x)$，则</p><script type="math/tex; mode=display">g(x+y)=f(e^{x+y})=f(e^xe^y)=f(e^x)+f(e^y)=g(x)+g(y)</script><p>如果$f(·)$是连续的，则$g$也是连续的，则$g$必然满足：$g(x)=cx$，$c$为某个常数（柯西方程）。因此，</p><script type="math/tex; mode=display">f(e^x)=cx\\f(x)=c\ ln(x)</script><p>即，<strong>如果想让两个独立事件的信息量等于他们的信息量之和，则信息量的计算形式必然是对数函数</strong>。</p><h3 id="自信息"><a href="#自信息" class="headerlink" title="自信息"></a>自信息</h3><p>事件$X=x$的自信息（self-information），公式中的$x$指的是$X=x$这个事件</p><script type="math/tex; mode=display">I(x)=-log\ p(x)</script><p>取值区间：$p(x)=1$时，事件一定发生，自信息为0；$p(x)=0$时，事件不可能发生，自信息为无穷大；</p><p>其物理含义为：</p><ul><li>当底数为2时，其单位为比特（bit）或者香农（shannons）时，1 bit（shannons）是以$\frac{1}{2}$的概率观测到一个事件时获得的信息量</li><li>当底数为e时，其单位为莱特（nats）时，1 nats是以$\frac{1}{e}$的概率观测到一个事件时获得的信息量</li></ul><h3 id="信息熵-1"><a href="#信息熵-1" class="headerlink" title="信息熵"></a>信息熵</h3><p>给定某个概率分布，其香农熵（Shannon Entropy）,量化不确定性。</p><script type="math/tex; mode=display">H(X)=E_{X\sim p(x)}[I(x)]=-E_{X\sim p(x)}[log\ p(x)]</script><p>其含义：</p><ul><li>在事件发生后，表示平均每个事件（或符号）所提供的信息量</li><li>在事件发生前，表示随机变量取值的平均不确定性</li><li>表示随机变量的随机性大小，熵越大，随机性越大</li><li>当事件发生后，其不确定性就被解除，熵是解除随机变量不确定性平均所需信息量。</li></ul><h3 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h3><p>同一个样本空间下，两个单独的概率分布P和Q，在度量两个分布之间差异时，可以使用相对熵（relative entropy）。P相对于Q的相对熵为</p><script type="math/tex; mode=display">D_{KL}(P||Q)=E_{X\sim P}[log\ \frac{P(X)}{Q(X)}]=E_{X\sim P}[log\ P(x)-log\ Q(x)]</script><p>相对熵也称为<strong>交叉熵或K-L距离</strong>。满足以下条件：</p><ul><li>非负性</li><li>当前仅当P=Q时，相对熵为0</li></ul><p><strong>编码解释</strong></p><p>对于概率分布为 P的信源，如果采用编码长度为$I_p(x)=-log \ p(x)$的方式进行编码，则平均码长为:</p><script type="math/tex; mode=display">H(P)=E_{X\sim p(x)}[I(p(x))]=-E_{X\sim p(x)}[log\ p(x)]</script><p>如果采用概率分布Q的码长方式进行编码，那么$x$的编码长度为$I_q(x)=-log \ q(x)$，则平均码长为：</p><script type="math/tex; mode=display">E_{X\sim P}I_q(x)=-E_{X\sim P}log\ q(x)</script><p>那么，由于概率不匹配导致的平均编码长度增加的量，即为相对熵：</p><script type="math/tex; mode=display">-E_{X\sim P}log\ q(x)-[-E_{X\sim p(x)}[log\ p(x)]]=D_{KL}(P||Q)</script><p><strong>最大熵定理</strong></p><p>离散无记忆信源输出M个不同的信息符号，当且仅当各个符号出现概率相等是，熵最大。因为出现任何符号的可能性相等时。不确定性最大。</p><p><strong>交叉熵</strong></p><p>信息论中，称相对熵即为交叉熵、KL散度，但在机器学习中，更常用的交叉熵定义为：</p><script type="math/tex; mode=display">H(P,Q) = H(P)+D_{KL}(P||Q)=-E_{X\sim P}[log\ Q(x)]</script><p>从编码意义上解释，$E_{X\sim P}[log\ Q(x)]$是采用概率分布Q的码长方式概率分布为 P的信源进行编码，得到的平均码长，交叉熵是该码长的负值。</p><p>针对Q最小化交叉熵等价于最小化KL散度or相对熵。</p><h2 id="熵与其他概念关系"><a href="#熵与其他概念关系" class="headerlink" title="熵与其他概念关系"></a>熵与其他概念关系</h2><h3 id="IV值与PSI"><a href="#IV值与PSI" class="headerlink" title="IV值与PSI"></a>IV值与PSI</h3><p><strong>IV值计算公式</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}IV &=& \sum^{n}_{i=1}( \frac{Good_i}{Good_T}-\frac{Bad_i}{Bad_T})×ln(\frac{Good_i}{Good_T}/\frac{Bad_i}{Bad_T})\\\\&=&  \sum^n_{i=1} (\frac{g_i}{g_T}- \frac{b_i}{b_T})ln({\frac{g_i}{g_T}} /\frac{b_i}{b_T})\\\\&=& \sum^n_{i=1} (P^i_g-P^i_b) ln(\frac{P^i_g}{P^i_b})\\\\&=& \sum^n_{i=1} P^i_gln(\frac{P^i_g}{P^i_b}) + \sum^n_{i=1} P^i_bln(\frac{P^i_b}{P^i_g})\\\\&=& KL(P_g||P_b) +KL(P_b||P_g)\end{eqnarray*}</script><p>其中$i$为特征值或模型分分段，共分为$n$段，$P^i_g$和$P^i_b$分别代表好人落在第$i$段上的概率和坏人落在第$i$段的概率。相当于有$n$个样本，每个样本有两个概率$P^i_g$和$P^i_b$，这两个概率的相对熵分别为$KL(P_g||P_b)、KL(P_b||P_g)$，两者的和即为IV值。可以认为是按照特征值（或模型分）分段后，好人的分布与坏人的分布之间的两个顺序的KL散度之和，来度量两者分布的差异。</p><p><strong>PSI计算公式</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}PSI &=&  \sum^{n}_{i=1}(\frac{Actual_i}{Actual_T} - \frac{Expect_i}{Expect_T})×ln(\frac{Actual_i}{Actual_T}/\frac{Expect_i}{Expect_T})\\\\&=& \sum^n_{i=1} (P^i_{Actual}-P^i_{Expect}) ln(\frac{P^i_{Actual}}{P^i_{Expect}})\\\\&=& \sum^n_{i=1} P^i_{Actual}ln(\frac{P^i_{Actual}}{P^i_{Expect}}) + \sum^n_{i=1} P^i_{Expect}ln(\frac{P^i_{Expect}}{P^i_{Actual}})\\\\&=& KL(P_{Actual}||P_{Expect}) +KL(P_{Expect}||P_{Actual})\end{eqnarray*}</script><p>PSI与之一样的道理，将特征值（或模型分）分为$n$段后，$P^i_{Actual}、P^i_{Expect}$分别为样本出现在第$i$段的实际概率和期望概率。PSI是这两个概率的相对熵($KL(P_g||P_b)、KL(P_b||P_g)$)的和。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;熵是信息论中的概念，在机器学习中也被广泛应用，比如&lt;strong&gt;交叉熵&lt;/strong&gt;、&lt;strong&gt;KL散度&lt;/strong&gt;等。本文总结一下各种熵有关的概念，并总结他们的各种形式变种。&lt;/p&gt;
    
    </summary>
    
    
      <category term="基础知识" scheme="http://wangdongdong122.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="交叉熵" scheme="http://wangdongdong122.github.io/tags/%E4%BA%A4%E5%8F%89%E7%86%B5/"/>
    
      <category term="KL散度" scheme="http://wangdongdong122.github.io/tags/KL%E6%95%A3%E5%BA%A6/"/>
    
      <category term="熵" scheme="http://wangdongdong122.github.io/tags/%E7%86%B5/"/>
    
  </entry>
  
  <entry>
    <title>最大似然估计</title>
    <link href="http://wangdongdong122.github.io/2021/07/07/2021-07-07-%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"/>
    <id>http://wangdongdong122.github.io/2021/07/07/2021-07-07-最大似然估计/</id>
    <published>2021-07-07T13:56:44.000Z</published>
    <updated>2021-07-24T14:08:58.434Z</updated>
    
    <content type="html"><![CDATA[<p>最大似然估计是机器学习的核心组件之一，承上启下，和大量知识相关。通过<strong>EM算法</strong>可以求解某些复杂情况下的MLE<sup>[1]</sup>；MLE可以视为<strong>GMM</strong>的一种特例；通过负对数似然是定义在训练集上的经验分布与定义在模型分布上的概率分布之间的<strong>交叉熵</strong>，如<strong>均方误差</strong>是经验分布和高斯分布之间的交叉熵。</p><span id="more"></span><h2 id="最大似然估计基本介绍"><a href="#最大似然估计基本介绍" class="headerlink" title="最大似然估计基本介绍"></a>最大似然估计基本介绍</h2><h3 id="MLE的基本流程"><a href="#MLE的基本流程" class="headerlink" title="MLE的基本流程"></a>MLE的基本流程</h3><ol><li>列出似然函数$L(\boldsymbol \theta)$</li><li>取对数$ln(L(\boldsymbol \theta))$</li><li>令其导数为0</li><li>估计参数$\boldsymbol {\hat\theta}$</li></ol><h3 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h3><p>设总体的概率函数为$P(\boldsymbol X;\boldsymbol \theta), \boldsymbol \theta \in \boldsymbol \Theta$，其中$\boldsymbol \theta$是未知参数向量，$\boldsymbol \Theta$是参数空间。$\boldsymbol x_1,…,\boldsymbol x_n$是来自该总体的样本。</p><p>将样本的联合概率分布函数看成$\boldsymbol \theta$的函数：$L(\boldsymbol \theta;\boldsymbol x_1,…,\boldsymbol x_n)$，记为$L(\boldsymbol \theta)$，称为样本的似然函数：</p><script type="math/tex; mode=display">L(\boldsymbol \theta)=p(\boldsymbol x_1;\boldsymbol \theta)p(\boldsymbol x_2;\boldsymbol \theta)...p(\boldsymbol x_n;\boldsymbol \theta)</script><h3 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h3><p>若$ \hat{\boldsymbol \theta} =\hat{\boldsymbol \theta} (\boldsymbol x_1,…,\boldsymbol x_n)$满足下式，则成$\hat{\boldsymbol \theta}$是$\boldsymbol \theta$的<strong>最大似然估计MLE</strong>(Maximum Likelihood Estimate)。</p><script type="math/tex; mode=display">\begin{eqnarray*}L(\hat{\boldsymbol \theta}) &=& {arg\underset {\boldsymbol \theta \in \boldsymbol \Theta}{\operatorname {max} }}\ L(\boldsymbol \theta)\\\\&=&{arg\underset {\boldsymbol \theta \in \boldsymbol \Theta}{\operatorname {max} }}\prod^m_{i=1}P_{model}(\boldsymbol x_i,\boldsymbol \theta)\end{eqnarray*}</script><p>最大化<strong>对数</strong>似然函数$ln\ L(\boldsymbol \theta)$与最大化$ L(\boldsymbol \theta)$等价。</p><h3 id="用分布表示"><a href="#用分布表示" class="headerlink" title="用分布表示"></a>用分布表示</h3><script type="math/tex; mode=display">\hat{\boldsymbol \theta}={arg\underset {\boldsymbol \theta \in \boldsymbol \Theta}{\operatorname {max} }} \ E_{\boldsymbol X \sim \hat p_{data}}[log\ p_{model}(\boldsymbol X;\boldsymbol \theta)]</script><p>其含义也可以理解为：<strong>最小化经验分布和模型分布之间的交叉熵</strong></p><p>备注</p><ul><li>$ L(\boldsymbol \theta)$可微时，求导是MLE最常用的方法，对$ln\ L(\boldsymbol \theta)$求导更简单，但并不是所有场合求导都有效</li><li>不变性：若$\hat{\boldsymbol \theta}$是$\boldsymbol \theta$的最大似然估计MLE，则对于任意函数$g(\boldsymbol \theta)$，其最大似然估计是$g(\hat{\boldsymbol \theta})$</li></ul><h2 id="推导损失函数"><a href="#推导损失函数" class="headerlink" title="推导损失函数"></a>推导损失函数</h2><p>负对数似然函数等价于交叉熵损失函数，当</p><h2 id="与EM"><a href="#与EM" class="headerlink" title="与EM"></a>与EM</h2><h2 id="与GMM"><a href="#与GMM" class="headerlink" title="与GMM"></a>与GMM</h2><h2 id="推广至MAP"><a href="#推广至MAP" class="headerlink" title="推广至MAP"></a>推广至MAP</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最大似然估计是机器学习的核心组件之一，承上启下，和大量知识相关。通过&lt;strong&gt;EM算法&lt;/strong&gt;可以求解某些复杂情况下的MLE&lt;sup&gt;[1]&lt;/sup&gt;；MLE可以视为&lt;strong&gt;GMM&lt;/strong&gt;的一种特例；通过负对数似然是定义在训练集上的经验分布与定义在模型分布上的概率分布之间的&lt;strong&gt;交叉熵&lt;/strong&gt;，如&lt;strong&gt;均方误差&lt;/strong&gt;是经验分布和高斯分布之间的交叉熵。&lt;/p&gt;
    
    </summary>
    
    
      <category term="基础知识" scheme="http://wangdongdong122.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="代价函数" scheme="http://wangdongdong122.github.io/tags/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/"/>
    
      <category term="MLE" scheme="http://wangdongdong122.github.io/tags/MLE/"/>
    
      <category term="最大似然" scheme="http://wangdongdong122.github.io/tags/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6/"/>
    
  </entry>
  
  <entry>
    <title>代价函数与输出单元</title>
    <link href="http://wangdongdong122.github.io/2021/07/01/2021-07-01-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8E%E8%BE%93%E5%87%BA%E5%8D%95%E5%85%83/"/>
    <id>http://wangdongdong122.github.io/2021/07/01/2021-07-01-激活函数与输出单元/</id>
    <published>2021-07-01T13:56:44.000Z</published>
    <updated>2021-07-07T15:11:01.258Z</updated>
    
    <content type="html"><![CDATA[<p>代价函数和输出单元的选择密切相关，两者都需要根据输出的分布确定。如何选择输出单元，要看预测值的分布，这跟指数族分布和广义线性回归中的结论一致。如何选择代价函数，大多数时候，可以简单地使用<strong>数据分布和模型分布间的交叉熵</strong>，这实际上<strong>等同于最大似然</strong>。本文的主要内容参考花书的第6章。</p><span id="more"></span><h2 id="线性单元-amp-均方误差"><a href="#线性单元-amp-均方误差" class="headerlink" title="线性单元&amp;均方误差"></a>线性单元&amp;均方误差</h2><p>线性单元</p><script type="math/tex; mode=display">\hat {\boldsymbol  y} =\boldsymbol W^T\boldsymbol h + \boldsymbol b</script><p>对应损失函数为均方误差</p><script type="math/tex; mode=display">\begin{eqnarray*}Loss &=& \frac{1}{N} \sum^N_{i=1}(y_i-\hat y_i)^2\\\\&=&\frac{1}{N}||\boldsymbol y-\hat{\boldsymbol y}||^2_2\end{eqnarray*}</script><p>常用来预测高斯分布的均值</p><script type="math/tex; mode=display">\boldsymbol y|\boldsymbol x \sim N(\boldsymbol y;\hat{\boldsymbol y},\boldsymbol I)</script><h2 id="sigmoid单元"><a href="#sigmoid单元" class="headerlink" title="sigmoid单元"></a>sigmoid单元</h2><p>sigmoid单元</p><script type="math/tex; mode=display">\begin{eqnarray*}\hat y &=& \sigma (\boldsymbol W^T\boldsymbol h + \boldsymbol b)\\\\&=& \frac{ 1 }{ 1+e^{−(\boldsymbol W^T\boldsymbol h + \boldsymbol b)} }\end{eqnarray*}</script><p>对应损失函数为<strong>交叉熵</strong></p><script type="math/tex; mode=display">Loss = -\sum^N_{i=1}log\ y_i \hat y_i</script><p>常用来预测Bernoulli分布的概率$p$</p><script type="math/tex; mode=display">y|\boldsymbol x\sim b(1,\hat y|\boldsymbol x)</script><h2 id="softmax单元"><a href="#softmax单元" class="headerlink" title="softmax单元"></a>softmax单元</h2><p>softmax单元</p><script type="math/tex; mode=display">\begin{eqnarray*}\hat {\boldsymbol  y} &=& softmax(\boldsymbol z)\\\\softmax(\boldsymbol z)_k  &=& \frac{exp(z_k)}{\sum_jexp(z_j)}\end{eqnarray*}</script><p>对应损失函数为<strong>交叉熵</strong></p><script type="math/tex; mode=display">loss = -\sum^N_{i=1}\sum^K_{k=1} y_{ik} log(\hat y_{ik})</script><p>其中，N为样本个数，K为类别数。</p><p>用来预测Multinoulli分布的各个类别概率。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;代价函数和输出单元的选择密切相关，两者都需要根据输出的分布确定。如何选择输出单元，要看预测值的分布，这跟指数族分布和广义线性回归中的结论一致。如何选择代价函数，大多数时候，可以简单地使用&lt;strong&gt;数据分布和模型分布间的交叉熵&lt;/strong&gt;，这实际上&lt;strong&gt;等同于最大似然&lt;/strong&gt;。本文的主要内容参考花书的第6章。&lt;/p&gt;
    
    </summary>
    
    
      <category term="基础知识" scheme="http://wangdongdong122.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="激活函数" scheme="http://wangdongdong122.github.io/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    
      <category term="sigmoid" scheme="http://wangdongdong122.github.io/tags/sigmoid/"/>
    
      <category term="代价函数" scheme="http://wangdongdong122.github.io/tags/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/"/>
    
      <category term="softmax" scheme="http://wangdongdong122.github.io/tags/softmax/"/>
    
  </entry>
  
  <entry>
    <title>激活函数</title>
    <link href="http://wangdongdong122.github.io/2021/06/30/2021-06-30-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <id>http://wangdongdong122.github.io/2021/06/30/2021-06-30-激活函数/</id>
    <published>2021-06-29T16:20:53.000Z</published>
    <updated>2021-07-01T13:54:57.483Z</updated>
    
    <content type="html"><![CDATA[<p>在深度学习中，激活函数提供了非线性变换的能力，提高了神经网络的表达能力。根据万能近似定理，这种非线性表达能力赋予了神经网络拟合一切函数的能力！当然也让大多数我们感兴趣的代价函数都变得非凸。</p><span id="more"></span><h2 id="激活函数基本性质"><a href="#激活函数基本性质" class="headerlink" title="激活函数基本性质"></a>激活函数基本性质</h2><p>关于激活函数的一些问题</p><ol><li><p>激活函数的作用</p><p>激活函数是用来加入非线性因素的，提高神经网络对模型的表达能力，解决线性模型所不能解决的问题</p></li><li><p>激活函数一般需要具有的几个性质</p><ul><li>有界</li><li>容易求导</li><li>单调(容易进行凸优化)</li><li>处理简单(计算方面)</li></ul></li></ol><p>参考</p><p><a href="https://www.jiqizhixin.com/articles/2017-10-10-3">机器之心：26种神经网络激活函数可视化</a></p><p><a href="http://arxiv.org/abs/1811.03378v1">Activation Functions: Comparison of trends in Practice and Research for Deep Learning</a></p><h2 id="常见的激活函数"><a href="#常见的激活函数" class="headerlink" title="常见的激活函数"></a>常见的激活函数</h2><img src="/2021/06/30/2021-06-30-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/%E5%87%A0%E7%A7%8D%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0" class="%E5%87%A0%E7%A7%8D%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><h3 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h3><p><strong>函数形式</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}sigmoid(z) &=& \frac{ 1 }{ 1+e^{−z} }\\\\sigmoid′(z) &=& \frac { e^{-z} } { (1+e^{-z})^2 } = sigmoid(z)(1-sigmoid(z)) \tag{一阶导数}\end{eqnarray*}</script><p>经常用$\sigma (·)$表示。</p><p><strong>函数形状</strong></p><p>sigmoid函数形状</p><img src="/2021/06/30/2021-06-30-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/5561420171010093434.png" class="" title="sigmoid及其梯度"><p><strong>作为激活的特点</strong></p><p>输出是0~1之间</p><p>因此，在LSTM的三个门中使用的激活函数就是sigmoid。</p><p><strong>作为激活函数的缺点</strong></p><ol><li>因为sigmoid函数的梯度最大值是0.25，容易梯度消失</li><li>不是0均值，<a href="https://arxiv.org/pdf/1811.03378.pdf">0均值有什么作用</a></li></ol><p><strong>关于sigmoid函数的起源</strong></p><h3 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h3><p><strong>函数形式</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}tanh(x)&=&\frac{e^x-e^{-x}}{e^x+e^{-x}}\\\\tanh^{\prime}(x)&=&\frac{(e^x+e^{-x})(e^x+e^{-x})-(e^x-e^{-x})(e^x-e^{-x})}{(e^x+e^{-x})^2}\\\\&=& 1- \frac{(e^x-e^{-x})^2}{(e^x+e^{-x})^2}\\\\&=& 1- tanh^2(x)\end{eqnarray*}</script><p><strong>函数形状</strong></p><img src="/2021/06/30/2021-06-30-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/8940520171010093544.png" class="" title="img"><p><strong>函数的特点</strong></p><ul><li>优点：0均值</li><li>缺点：梯度消失</li><li>曾应用广泛</li></ul><h3 id="Relu函数"><a href="#Relu函数" class="headerlink" title="Relu函数"></a>Relu函数</h3><p><strong>函数形式</strong></p><script type="math/tex; mode=display">Relu(x) = max(0,x)</script><p><strong>函数形状</strong></p><img src="/2021/06/30/2021-06-30-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/4217520171010093357.png" class="" title="relu及其导数"><p>修正线性单元（Rectified linear unit，ReLU）</p><p><strong>特点</strong></p><ul><li>优点：计算速度快，稀疏，梯度消失缓解</li><li>缺点：神经元会死亡</li><li>应用广泛</li></ul><h3 id="Leaky-Relu"><a href="#Leaky-Relu" class="headerlink" title="Leaky Relu"></a>Leaky Relu</h3><p>带泄露修正线性单元（Leaky ReLU）</p><p><strong>函数形式</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}f(x)&=&\left\{\begin{array}{ll}x&\text{for $x \geq 0$}\\0.01x &\text{for $x<0$}.\end{array}\right.\\ \\f^{\prime}(x)&=&\left\{\begin{array}{ll}1&\text{for $x \geq 0$}\\0.01 &\text{for $x<0$}.\end{array}\right.\end{eqnarray*}</script><p><strong>函数形状</strong></p><img src="/2021/06/30/2021-06-30-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/1601520171010093621.png" class="" title="LeakyReLU"><p><strong>特点</strong></p><ul><li>ReLU的一个变体，减少神经元死亡</li><li>应用较广</li></ul><h3 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h3><p>指数线性单元（Exponential Linear Unit，ELU）</p><p><strong>函数形式</strong></p><script type="math/tex; mode=display">\begin{eqnarray*}f(x)&=&\left\{\begin{array}{ll}x&\text{for $x \geq 0$}\\a(e^x-1) &\text{for $x<0$}.\end{array}\right.\\ \\f^{\prime}(x)&=&\left\{\begin{array}{ll}1&\text{for $x \geq 0$}\\f(x)+a=ae^x &\text{for $x<0$}.\end{array}\right.\end{eqnarray*}</script><p><strong>函数形状</strong></p><img src="/2021/06/30/2021-06-30-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/0169720171010094120.png" class="" title="img"><p><strong>特点</strong></p><ul><li>类似于Leaky ReLU</li><li>计算量稍大</li><li>不会有Dead ReLU问题</li><li>均值接近于0</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在深度学习中，激活函数提供了非线性变换的能力，提高了神经网络的表达能力。根据万能近似定理，这种非线性表达能力赋予了神经网络拟合一切函数的能力！当然也让大多数我们感兴趣的代价函数都变得非凸。&lt;/p&gt;
    
    </summary>
    
    
      <category term="基础知识" scheme="http://wangdongdong122.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="激活函数" scheme="http://wangdongdong122.github.io/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    
      <category term="sigmoid" scheme="http://wangdongdong122.github.io/tags/sigmoid/"/>
    
  </entry>
  
  <entry>
    <title>威尔逊置信区间</title>
    <link href="http://wangdongdong122.github.io/2021/06/27/2021-06-27-%E5%A8%81%E5%B0%94%E9%80%8A%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4/"/>
    <id>http://wangdongdong122.github.io/2021/06/27/2021-06-27-威尔逊置信区间/</id>
    <published>2021-06-27T12:52:53.000Z</published>
    <updated>2021-06-28T15:40:02.688Z</updated>
    
    <content type="html"><![CDATA[<p>二项分布的概率$p$的置信区间、置信度和样本量之间的关系，可以用正态区间来统计，但在样本量较小是正态置信区间往往有准确性较差。因此在小样本下可以用威尔逊置信区间。</p><span id="more"></span><h2 id="正态置信区间"><a href="#正态置信区间" class="headerlink" title="正态置信区间"></a>正态置信区间</h2><p>$p$是伯努利实验的成功率（样本正例比例），$n$是样本数量或实验次数。$z$表示对应某个置信水平的$z$统计量，一般情况下，在95%的置信水平下，$z$统计量的值为1.96</p><div class="table-container"><table><thead><tr><th><strong>置信度</strong></th><th><strong>z分数</strong></th></tr></thead><tbody><tr><td>99%</td><td>2.576</td></tr><tr><td>98%</td><td>2.326</td></tr><tr><td>95%</td><td>1.96</td></tr><tr><td>90%</td><td>1.645</td></tr></tbody></table></div><p>可以看到，当$n$的值足够大时，这个下限值会趋向$\hat p$。如果n非常小（投票人很少），这个下限值会大大小于$\hat p$。</p><script type="math/tex; mode=display">\left[\hat{p}-z\sqrt{\frac{\hat{p}(1-\hat{p})}{n}},\ \ \ \hat{p}+z\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\right]</script><p>但是，它只适用于样本较多的情况（np &gt; 5 且 n(1 − p) &gt; 5），对于小样本，它的准确性很差</p><h2 id="威尔逊区间"><a href="#威尔逊区间" class="headerlink" title="威尔逊区间"></a>威尔逊区间</h2><p>1927年，美国数学家 Edwin Bidwell Wilson提出了一个修正公式，被称为<a href="http://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval">“威尔逊区间”</a>，很好地解决了小样本的准确性问题。</p><script type="math/tex; mode=display">\frac{1}{1+\frac{z^2}{n}}\left[\hat p +\frac{z^2}{2n} \pmz \sqrt{\frac{\hat p (1-\hat p)}{n}+\frac{z^2}{4n^2}}\right]</script><blockquote><p><a href="http://www.evanmiller.org/how-not-to-sort-by-average-rating.html">实际代码</a></p></blockquote><h3 id="应用1特征修正"><a href="#应用1特征修正" class="headerlink" title="应用1特征修正"></a>应用1特征修正</h3><p>在线性模型中，有手工处理特征的条件时，可以使用威尔逊置信区间的下界作为修正后的特征值（实际上是降低置信度低的case的影响）</p><script type="math/tex; mode=display">\frac{1}{1+\frac{z^2}{n}}\left[\hat p +\frac{z^2}{2n} -z \sqrt{\frac{\hat p (1-\hat p)}{n}+\frac{z^2}{4n^2}}\right]</script><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line">p=np.arange(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0.01</span>)</span><br><span class="line">n=np.arange(<span class="number">1</span>, <span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">z=<span class="number">1.96</span></span><br><span class="line">n,p=np.meshgrid(n,p)</span><br><span class="line">y=(p+z**<span class="number">2</span>/(<span class="number">2</span>*n)-z*np.sqrt(p*(<span class="number">1</span>-p)/n + z**<span class="number">2</span>/(<span class="number">4</span>*n**<span class="number">2</span>)))/(<span class="number">1</span>+z/n)</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">ax.plot_surface(n,p,y,cmap=<span class="string">&#x27;rainbow&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>参考：</p><blockquote><p><a href="http://typename.net/statistics/wilson-confidence-interval/">知乎排名算法</a><br><a href="http://www.ruanyifeng.com/blog/2012/03/ranking_algorithm_wilson_score_interval.html">基于用户投票的排名算法</a></p></blockquote><h3 id="应用2评估样本量"><a href="#应用2评估样本量" class="headerlink" title="应用2评估样本量"></a>应用2评估样本量</h3><p>威尔逊置信区间可以在给定数据量n、置信度参数z、统计值$\widehat{p}$ 的情况下给出置信区间。同样的，在给定统计值和能接受的置信度、置信区间的情况下，我们可以评估我们需要的样本量n。</p><script type="math/tex; mode=display">\begin{eqnarray*}\frac {1} {1+ \frac{z^2}{n}} \left[   \widehat{p} + \frac{z^2}{2n} -z     \sqrt{ \frac{\widehat{p}(1-\widehat{p})}{n} + \frac{z^2}{4n^2}}  \right]  = R \cdot \widehat{p}\end{eqnarray*}</script><script type="math/tex; mode=display">\begin{eqnarray*} z     \sqrt{ \frac{\widehat{p}(1-\widehat{p})}{n} + \frac{z^2}{4n^2}}  = R \cdot \widehat{p}\end{eqnarray*}</script><p>其中，$R$为对应设定的置信区间（$R\cdot\widehat{p}$为置信区间下界），z对应设定置信度，$\widehat{p}$ 为统计值，n为需要的样本量，给定$R,z,\widehat{p}$ 时，可以求出 $n=f(R,z,\widehat{p})$（一元二次方程）：</p><script type="math/tex; mode=display">x = \frac{-b \pm \sqrt{\Delta}}{2a} =\frac{-b \pm \sqrt{b^2 -4ac}}{2a}</script><p>需要注意的是，和正态分布置信区间不同，<strong>威尔逊置信区间并不关于 $\widehat{p}$ 对称</strong>。中心点为：</p><script type="math/tex; mode=display">\begin{eqnarray*}\frac {\widehat{p} + \frac{z^2}{2n}} {1+ \frac{z^2}{n}}= \widehat{p} + \frac{ \frac{z^2}{n} \cdot (\frac12 - \widehat{p})}{1+ \frac{z^2}{n}}\end{eqnarray*}</script><p>但 $ \widehat{p}<0.5$ 时，中心位置大于 $ \widehat{p}$ ；当 $ \widehat{p}>0.5$ 时，中心位置小于 $ \widehat{p}$ 。即：<strong>中心会先0.5靠近</strong>。</p><p>因此 $ R \cdot \widehat{p}$并不意味着置信区间为$[R \cdot \widehat{p},(2-R) \cdot \widehat{p}]$</p><blockquote><p>威尔逊置信区间的中心位置是否等同于增加了先验（p=0.5）的map？</p><p>威尔逊置信区间是否相当于贝叶斯</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;二项分布的概率$p$的置信区间、置信度和样本量之间的关系，可以用正态区间来统计，但在样本量较小是正态置信区间往往有准确性较差。因此在小样本下可以用威尔逊置信区间。&lt;/p&gt;
    
    </summary>
    
    
      <category term="基础知识" scheme="http://wangdongdong122.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="数理统计" scheme="http://wangdongdong122.github.io/tags/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"/>
    
  </entry>
  
</feed>
