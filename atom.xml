<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>天气桑的blog</title>
  
  <subtitle>这个人很懒，还没写介绍</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://tessiehe.github.io/"/>
  <updated>2022-03-04T04:05:18.608Z</updated>
  <id>http://tessiehe.github.io/</id>
  
  <author>
    <name>Tenki San</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>hexo_test</title>
    <link href="http://tessiehe.github.io/2022/03/04/hexo-test/"/>
    <id>http://tessiehe.github.io/2022/03/04/hexo-test/</id>
    <published>2022-03-04T04:05:18.000Z</published>
    <updated>2022-03-04T04:05:18.608Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>搜广推技术调研</title>
    <link href="http://tessiehe.github.io/2022/03/04/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%90%9C%E5%B9%BF%E6%8E%A8%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/"/>
    <id>http://tessiehe.github.io/2022/03/04/2_算法相关/搜广推技术调研/</id>
    <published>2022-03-04T03:32:38.000Z</published>
    <updated>2022-03-04T03:55:39.021Z</updated>
    
    <content type="html"><![CDATA[<p>开始前的一些思考：</p><p>搜广推近年来模型越来越复杂，但收益越来越小，可能原因是什么？</p><ol><li>技术水位提高带来的边际收益的降低</li><li>数据处理时的的信息折损。从原始log数据生成各个场景的数据（序列、特征）过程是存在很大的信息折损的，原始数据的信息量是最大的，所以未来的发展模型的输入数据会想原始的方式靠拢。纵观搜广推的技术发展路线，从特征工程到序列建模也是符合这个思路的。</li><li>模型结构和信息传播方式不匹配，导致信息提取的低效。也就是说应该根据业务特征更精巧的设计模型结构，依照先验显式的提取数据中的一些结构化信息，提高信息提取效率，而不是粗暴的加参数加数据。</li></ol><p>第一点确实存在，预估没有ground truth，难以判断天花板在哪。2和3中更偏向于2，因为数据直接决定了模型的天花板，而近年大量paper都是模型方面的工作，数据端的工作是比较被忽视的。</p><span id="more"></span><p>[TOC]</p><h1 id="技术调研"><a href="#技术调研" class="headerlink" title="技术调研"></a>技术调研</h1><h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>深度学习的赋能下，推荐领域主要有<strong>特征交叉、序列建模</strong>两个技术方向，特征交叉以CAN为代表交叉粒度越来越细，向笛卡尔积靠拢。序列建模以阿里的一些列工作为代表，主要有<strong>序列增强</strong>和<strong>模糊序列</strong>两个方向。NLP技术的赋能下越来越多的序列模型落地在推荐领域，受到业界的认可。我们不禁要问，Then what’s next?</p><p>可以参考CV和NLP的发展，各自领域的重大突破都是基于<strong>对数据产生过程的深刻理解</strong>的。CNN捕捉的是图像的平移不变性；bert捕捉的是上下文的交互特点。</p><p>搜索和推荐不同于NLP和CV这些”自然”的数据生成方式，而是人类交互行为产生的数据。这天然决定了数据中存在大量噪音（隐反馈，bias），例如：一个用户点了一个品牌不一定是他就偏好这个品牌，有可能是整个页面都是这个品牌；推荐item同质的场景下点不点击很随机。历史的工作更多的是粗暴的通过大幅度增加数据量，增加模型复杂度来进行低效的<strong>交互和去噪</strong>（基于的假设是噪音数据出现的频率远低于非噪音数据）。业务初期这种方式能快速迭代产生效果，但随着技术水位的提高，这条路边际收益越来越低，需要考虑更高效的数据处理和信息提取形式。推荐场景序列建模是一个比较大的突破，符合用户时间维度的行为模式，一定程度刻画了用户的偏好。</p><p>纵观推荐技术演化方向，我认为未来会<strong>由深度加工数据向原始数据形式（用户反馈数据流）靠拢，更“自然”的融合用户多域/多形式的反馈，且更“柔和”的处理用户的反馈</strong>（而不是非黑即白，如点击就是感兴趣，不点击就是不感兴趣）</p><p><img src alt="draw.io"></p><h2 id="近期工作"><a href="#近期工作" class="headerlink" title="近期工作"></a>近期工作</h2><div class="table-container"><table><thead><tr><th>出处</th><th>要解决的问题</th><th>关键词</th><th>借鉴点</th><th>模型结构</th><th>comment</th></tr></thead><tbody><tr><td>阿里GIN：Graph Intention Network for Click-through Rate Prediction in Sponsored Search，SIGIR19,alibaba</td><td>CTR预估中用户行为稀疏; 跳出用户历史行为的限制探索更多的兴趣</td><td>信息嵌入</td><td>graph&amp;ctr端到端训练可以通过引入各种共现信息来提高信息的流动性</td><td><img src alt="image.jpeg"><img src alt="image.jpeg"></td><td>共现信息生成异构图对用户点击序列的每个item进行邻近节点查找和embed聚合</td></tr><tr><td>阿里Res-embedding for Deep Learning Based Click-Through Rate Prediction Modeling，2019</td><td>现有embedding方式容易产生过拟合。</td><td>信息嵌入</td><td>1、 每个POI的embedding是不是可以表征为区域embedding和独立embedding的和？？</td><td><img src alt="image.jpeg"></td><td>用图中相邻节点的central embedding + 当前item的bias embedding来表征当前item，提高泛化性。\</td><td>\</td><td>bias embed\</td><td>\</td><td>= 0.1*\</td><td>\</td><td>central embed时效果最好\</td><td>\</td><td>量化分析了影响模型泛化能力的变量是GIN的升级版，GIN相当于只用centra embedding</td></tr><tr><td>第四范式TabGNN: Multiplex Graph Neural Network for Tabular Data Prediction,KDD2021,</td><td>通过多重图来建模样本间关系</td><td>信息嵌入</td><td>样本间的关系可以通过图的方式构建图除了通过共现方式构建，也可以通过特征的方式构建（适用于分客群之类的场景）</td><td><img src alt="image.jpeg"></td><td>对于表格特征通过离散化构建多重图。可以理解为每一维特征都可以生成一个 graph layer</td></tr><tr><td>阿里DSGL:Dynamic Sequential Graph Learning for Click-Through Rate Prediction ,2021,aliba,</td><td>用户行为序列受曝光影响动态序列图捕捉用户兴趣变化</td><td>信息嵌入</td><td></td><td><img src alt="image.jpeg"></td><td>1、 图中带时间戳，捕捉时间维度的兴趣变化</td></tr><tr><td>阿里CAN: Feature Co-Action for Click-Through Rate Prediction</td><td>attention等特征交叉方式都是在embed空间的隐式交叉，共现关系不如cartesian方法，但后者参数量太大</td><td>信息融合</td><td></td><td><img src alt="image.jpeg"></td><td>提出一种显示的特征交叉，加入特征笛卡尔积信息，又不会增加太多参数量。用户历史点击过的item的embedding在不同的candidate下有不同的值其实是DIN中attention unit变换成co-action unit，由相似度计算变成了融合的MLP。FM可以看成co-action unit的一种特殊形式。</td></tr><tr><td>新浪FiBiNet ：Feature Importance and Bilinear feature Interaction</td><td>提出通过使用SENET结构动态学习特征的重要性使用双线性函数来更好的建模交叉特征</td><td>信息嵌入</td><td>可通增加embed通道并通过SENET融合各通道。</td><td><img src alt="image.jpeg"><img src alt="image.jpeg"></td><td>结构动态学习特征的重要性以及使用一个双线性函数来更好的建模交叉特征</td></tr><tr><td>腾讯Masked Transformer for Neighhourhood-aware Click-Through Rate Prediction</td><td>主流的CTR模型都是通过用户显示交互的item学习特征的交互和用户兴趣。然而交互行为受推荐系统曝光、用户活跃度限制，简而言之就是信息量不够。通过构建异构图引入邻接节点信息增强信息表征</td><td></td><td></td><td><img src alt="image.jpeg"></td><td>本质上还是通过图的方式引入邻域信息。mask不mask的感觉不重要</td></tr><tr><td>阿里RACP:Modeling Users’ Contextualized Page-wise Feedback for Click-Through Rate Prediction in E-commerce Search</td><td>本文通过加入历史<strong>页面维度的曝光和反馈</strong>做一位用户历史行为序列，提出了一种新的上下文感知的用户行为建模方式。。通过<strong>page-context aware attention</strong> 学习页面内的关系。<strong>recurrent attention</strong>学习页面间的关系</td><td></td><td></td><td><img src alt="image.jpeg"></td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;开始前的一些思考：&lt;/p&gt;
&lt;p&gt;搜广推近年来模型越来越复杂，但收益越来越小，可能原因是什么？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;技术水位提高带来的边际收益的降低&lt;/li&gt;
&lt;li&gt;数据处理时的的信息折损。从原始log数据生成各个场景的数据（序列、特征）过程是存在很大的信息折损的，原始数据的信息量是最大的，所以未来的发展模型的输入数据会想原始的方式靠拢。纵观搜广推的技术发展路线，从特征工程到序列建模也是符合这个思路的。&lt;/li&gt;
&lt;li&gt;模型结构和信息传播方式不匹配，导致信息提取的低效。也就是说应该根据业务特征更精巧的设计模型结构，依照先验显式的提取数据中的一些结构化信息，提高信息提取效率，而不是粗暴的加参数加数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第一点确实存在，预估没有ground truth，难以判断天花板在哪。2和3中更偏向于2，因为数据直接决定了模型的天花板，而近年大量paper都是模型方面的工作，数据端的工作是比较被忽视的。&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
      <category term="调研" scheme="http://tessiehe.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
  </entry>
  
  <entry>
    <title>marginnote</title>
    <link href="http://tessiehe.github.io/2022/03/01/%E6%96%87%E7%8C%AE%E6%9F%A5%E6%89%BETIPS/"/>
    <id>http://tessiehe.github.io/2022/03/01/文献查找TIPS/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-17T03:41:00.884Z</updated>
    
    <content type="html"><![CDATA[<p>文献查找的方法</p><span id="more"></span><h1 id="connected-paper"><a href="#connected-paper" class="headerlink" title="connected paper"></a>connected paper</h1><ol><li>网址：connected paper</li><li>输入文献名称，点击build graph,页面将分为三个部分</li><li>Prior work引用的共同的，之前开创性的文章；  </li><li>derivative work 一些派生文献。</li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.bilibili.com/video/BV1m34y1C72y?-Arouter=story&amp;p=1&amp;share_medium=iphone&amp;share_plat=ios&amp;share_session_id=E531219F-B84B-452C-89A5-F92C67A3C5E7&amp;share_source=WEIXIN&amp;share_tag=s_i&amp;timestamp=1646010472&amp;unique_k=8pBkf0t&amp;share_times=1">AI帮你找文献，让你效率翻倍</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;文献查找的方法&lt;/p&gt;
    
    </summary>
    
      <category term="高效tips" scheme="http://tessiehe.github.io/categories/%E9%AB%98%E6%95%88tips/"/>
    
    
      <category term="高效tips" scheme="http://tessiehe.github.io/tags/%E9%AB%98%E6%95%88tips/"/>
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
  </entry>
  
  <entry>
    <title>2022机器学习会议paper list</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%E4%BC%9A%E8%AE%AEpaper/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/2022会议paper/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-18T03:24:20.716Z</updated>
    
    <content type="html"><![CDATA[<p>各家公司在Cikm2021  wsdm2022上的paper</p><span id="more"></span><p>[TOC]</p><h1 id="cikm2021"><a href="#cikm2021" class="headerlink" title="cikm2021"></a>cikm2021</h1><p><a href="https://www.cikm2021.org/accepted-papers">https://www.cikm2021.org/accepted-papers</a></p><ul><li><h3 id="SimpleX-A-Simple-and-Strong-Baseline-for-Collaborative-Filtering"><a href="#SimpleX-A-Simple-and-Strong-Baseline-for-Collaborative-Filtering" class="headerlink" title="SimpleX: A Simple and Strong Baseline for Collaborative Filtering"></a>SimpleX: A Simple and Strong Baseline for Collaborative Filtering</h3><p>Kelong Mao (Renmin University of China, China), Jieming Zhu (Huawei Noah’s Ark Lab, China), Jinpeng Wang (Tsinghua University, China), Quanyu Dai (Huawei Noah’s Ark Lab, China), Zhenhua Dong (Huawei Noah’s Ark Lab, China), Xi Xiao (Tsinghua University, China), Xiuqiang He (Huawei Noah’s Ark Lab, China)</p></li><li><h3 id="UltraGCN-Ultra-Simplification-of-Graph-Convolutional-Networks-for-Recommendation"><a href="#UltraGCN-Ultra-Simplification-of-Graph-Convolutional-Networks-for-Recommendation" class="headerlink" title="UltraGCN: Ultra Simplification of Graph Convolutional Networks for Recommendation"></a><strong>UltraGCN: Ultra Simplification of Graph Convolutional Networks for Recommendation</strong></h3><p>Kelong Mao (Renmin University of China, China), Jieming Zhu (Huawei Noah’s Ark Lab, China), Xi Xiao (Tsinghua University &amp; Peng Cheng Laboratory, China), Biao Lu (Huawei Noah’s Ark Lab, China), Zhaowei Wang (Huawei Noah’s Ark Lab, China), Xiuqiang He (Huawei Noah’s Ark Lab, China)</p></li><li><h3 id="To-Be-or-not-to-Be-Tail-Labels-in-Extreme-Multi-label-Learning"><a href="#To-Be-or-not-to-Be-Tail-Labels-in-Extreme-Multi-label-Learning" class="headerlink" title="To Be or not to Be, Tail Labels in Extreme Multi-label Learning"></a>To Be or not to Be, Tail Labels in Extreme Multi-label Learning</h3><p>Zhiqi Ge (Jilin University, China), Ximing Li (Jilin University, China)</p></li><li><h3 id="Pre-training-for-Ad-hoc-Retrieval-Hyperlink-is-Also-You-Need"><a href="#Pre-training-for-Ad-hoc-Retrieval-Hyperlink-is-Also-You-Need" class="headerlink" title="Pre-training for Ad-hoc Retrieval: Hyperlink is Also You Need"></a>Pre-training for Ad-hoc Retrieval: Hyperlink is Also You Need</h3><p>Zhengyi Ma (Renmin University of China, China), Zhicheng Dou (Renmin University of China, China), Wei Xu (Renmin University of China, China), Xinyu Zhang (Huawei, China), Hao Jiang (Huawei, China), Zhao Cao (Huawei, China), Ji-Rong Wen (Renmin University of China, China)</p></li><li><h3 id="Pareto-optimal-Community-Search-on-Large-Bipartite-Graphs"><a href="#Pareto-optimal-Community-Search-on-Large-Bipartite-Graphs" class="headerlink" title="Pareto-optimal Community Search on Large Bipartite Graphs"></a><strong>Pareto-optimal Community Search on Large Bipartite Graphs</strong></h3><p>Yuting Zhang (University of New South Wales, Australia), Kai Wang (University of New South Wales, Australia), Wenjie Zhang (University of New South Wales, Australia), Xuemin Lin (University of New South Wales, Australia), Ying Zhang (University of Technology Sydney, Australia)</p></li><li><h3 id="Learning-Implicit-User-Profile-for-Personalized-Retrieval-Based-Chatbot"><a href="#Learning-Implicit-User-Profile-for-Personalized-Retrieval-Based-Chatbot" class="headerlink" title="Learning Implicit User Profile for Personalized Retrieval-Based Chatbot"></a><strong>Learning Implicit User Profile for Personalized Retrieval-Based Chatbot</strong></h3><p>Hongjin Qian (Renmin University of China, China), Zhicheng Dou (Renmin University of China, China), Yutao Zhu (Université de Montréal, Canada), Yueyuan Ma (Renmin University of China, China), Ji-Rong Wen (Renmin University of China &amp; Beijing Key Laboratory of Big Data Management and Analysis Methods, China)</p></li><li><h3 id="Modeling-Heterogeneous-Graph-Network-on-Fraud-Detection-A-Community-based-Framework-with-Attention-Mechanism"><a href="#Modeling-Heterogeneous-Graph-Network-on-Fraud-Detection-A-Community-based-Framework-with-Attention-Mechanism" class="headerlink" title="Modeling Heterogeneous Graph Network on Fraud Detection: A Community-based Framework with Attention Mechanism"></a><strong>Modeling Heterogeneous Graph Network on Fraud Detection: A Community-based Framework with Attention Mechanism</strong></h3><p>Li Wang (JD.com, China), Peipei Li (JD.com, China), Kai Xiong (JD.com, China), Jiashu Zhao (Wilfrid Laurier University, Canada), Rui Lin (JD.com, China)</p></li><li><h3 id="Improving-Chinese-Character-Representation-with-Formation-Graph-Attention-Network"><a href="#Improving-Chinese-Character-Representation-with-Formation-Graph-Attention-Network" class="headerlink" title="Improving Chinese Character Representation with Formation Graph Attention Network"></a><strong>Improving Chinese Character Representation with Formation Graph Attention Network</strong></h3><p>Xiaosu Wang (Fudan University, China), Yun Xiong (Fudan University, China), Hao Niu (Fudan University, China), Jingwen Yue (Fudan University, China), Yangyong Zhu (Fudan University, China), Philip S. Yu (University of Illinois at Chicago, USA)</p></li><li><h3 id="LiteGT-Efficient-and-Lightweight-Graph-Transformers"><a href="#LiteGT-Efficient-and-Lightweight-Graph-Transformers" class="headerlink" title="LiteGT: Efficient and Lightweight Graph Transformers"></a><strong>LiteGT: Efficient and Lightweight Graph Transformers</strong></h3><p>Cong Chen (The University of Hong Kong, China), Chaofan Tao (The University of Hong Kong, Hong Kong), Ngai Wong (The University of Hong Kong, Hong Kong)</p></li><li><h3 id="Top-N-Recommendation-with-Counterfactual-User-Preference-Simulation"><a href="#Top-N-Recommendation-with-Counterfactual-User-Preference-Simulation" class="headerlink" title="Top-N Recommendation with Counterfactual User Preference Simulation"></a><strong>Top-N Recommendation with Counterfactual User Preference Simulation</strong></h3><p>Mengyue Yang (University College London, United Kingdom), Quanyu Dai (Huawei, China), Zhenhua Dong (Huawei, China), Xu Chen (Beijing Key Laboratory of Big Data Management and Analysis Methods &amp; Renmin University of China, China), Xiuqiang He (Huawei, China), Jun Wang (University College London, United Kingdom)</p></li><li><h3 id="Reinforcement-Learning-to-Optimize-Lifetime-Value-in-Cold-Start-Recommendation"><a href="#Reinforcement-Learning-to-Optimize-Lifetime-Value-in-Cold-Start-Recommendation" class="headerlink" title="Reinforcement Learning to Optimize Lifetime Value in Cold-Start Recommendation"></a><strong>Reinforcement Learning to Optimize Lifetime Value in Cold-Start Recommendation</strong></h3><p>Luo Ji (Alibaba Group, China), Qi Qin (Peking University, China), Bingqing Han (Alibaba Group, China), Hongxia Yang (Alibaba Group, China)</p></li><li><h3 id="Zero-Shot-on-the-Cold-Start-Problem-Model-Agnostic-Interest-Learning-for-Recommender-Systems"><a href="#Zero-Shot-on-the-Cold-Start-Problem-Model-Agnostic-Interest-Learning-for-Recommender-Systems" class="headerlink" title="Zero Shot on the Cold-Start Problem: Model-Agnostic Interest Learning for Recommender Systems"></a><strong>Zero Shot on the Cold-Start Problem: Model-Agnostic Interest Learning for Recommender Systems</strong></h3><p>Philip J. Feng (NetEase Inc., China), Pingjun Pan (NetEase Inc., China), Tingting Zhou (NetEase Inc., China), Hongxiang Chen (NetEase Inc., China), Chuanjiang Luo (NetEase Inc., China)</p></li><li><h3 id="Multi-hop-Reading-on-Memory-Neural-Network-with-Selective-Coverage-for-Medication-Recommendation"><a href="#Multi-hop-Reading-on-Memory-Neural-Network-with-Selective-Coverage-for-Medication-Recommendation" class="headerlink" title="Multi-hop Reading on Memory Neural Network with Selective Coverage for Medication Recommendation"></a><strong>Multi-hop Reading on Memory Neural Network with Selective Coverage for Medication Recommendation</strong></h3><p>Yanda Wang (Nanjing University of Aeronautics and Astronautics, China), Weitong Chen (The University of Queensland, Australia), Dechang Pi (Nanjing University of Aeronautics and Astronautics, China), Lin Yue (The University of Queensland, Australia), Miao Xu (The University of Queensland, Australia), Xue Li (The University of Queensland, Australia)</p></li><li><h3 id="DynSTGAT-Dynamic-Spatial-Temporal-Graph-Attention-Network-for-Traffic-Signal-Control"><a href="#DynSTGAT-Dynamic-Spatial-Temporal-Graph-Attention-Network-for-Traffic-Signal-Control" class="headerlink" title="DynSTGAT: Dynamic Spatial-Temporal Graph Attention Network for Traffic Signal Control"></a><strong>DynSTGAT: Dynamic Spatial-Temporal Graph Attention Network for Traffic Signal Control</strong></h3><p>Libing Wu (Wuhan University &amp; Xidian University, China), Min Wang (Wuhan University &amp; Xidian University, China), Dan Wu (University of Windsor, Canada), Jia Wu (Macquarie University, Australia)</p></li><li><h3 id="Are-Negative-Samples-Necessary-in-Entity-Alignment-An-Approach-with-High-Performance-Scalability-and-Robustness"><a href="#Are-Negative-Samples-Necessary-in-Entity-Alignment-An-Approach-with-High-Performance-Scalability-and-Robustness" class="headerlink" title="Are Negative Samples Necessary in Entity Alignment?: An Approach with High Performance, Scalability and Robustness"></a><strong>Are Negative Samples Necessary in Entity Alignment?: An Approach with High Performance, Scalability and Robustness</strong></h3><p>Xin Mao (East China Normal University, China), Wenting Wang (Alibaba Group, Singapore), Yuanbin Wu (East China Normal University, China), Man Lan (East China Normal University, China)</p></li><li><h3 id="Contrastive-Learning-of-User-Behavior-Sequence-for-Context-Aware-Document-Ranking"><a href="#Contrastive-Learning-of-User-Behavior-Sequence-for-Context-Aware-Document-Ranking" class="headerlink" title="Contrastive Learning of User Behavior Sequence for Context-Aware Document Ranking"></a><strong>Contrastive Learning of User Behavior Sequence for Context-Aware Document Ranking</strong></h3><p>Yutao Zhu (University of Montreal, Canada), Jian-Yun Nie (University of Montreal, Canada), Zhicheng Dou (Renmin University of China, China), Zhengyi Ma (Renmin University of China, China), Xinyu Zhang (Distributed and Parallel Software Lab, Huawei, China), Pan Du (University of Montreal, Canada), Xiaochen Zuo (Renmin University of China, China), Hao Jiang (Distributed and Parallel Software Lab, Huawei, China)</p></li><li><h3 id="Deep-Self-Adaptive-Hashing-for-Image-Retrieval"><a href="#Deep-Self-Adaptive-Hashing-for-Image-Retrieval" class="headerlink" title="Deep Self-Adaptive Hashing for Image Retrieval"></a><strong>Deep Self-Adaptive Hashing for Image Retrieval</strong></h3><p>Qinghong Lin (Shenzhen University, China), Xiaojun Chen (Shenzhen University, China), Qin Zhang (Shenzhen University, China), Shangxuan Tian (Tencent, China), Yudong Chen (The University of Queensland, Australia)</p></li><li><h3 id="How-Powerful-is-Graph-Convolution-for-Recommendation"><a href="#How-Powerful-is-Graph-Convolution-for-Recommendation" class="headerlink" title="How Powerful is Graph Convolution for Recommendation"></a><strong>How Powerful is Graph Convolution for Recommendation</strong></h3><p>Yifei Shen (The Hong Kong University of Science and Technology, Hong Kong), Yongji Wu (Duke University, USA), Yao Zhang (Fudan University, China), Caihua Shan (Microsoft Research Asia, China), Jun Zhang (The Hong Kong University of Science and Technology, Hong Kong), B. Khaled Letaief (The Hong Kong University of Science and Technology, Hong Kong), Dongsheng Li (Microsoft Research Asia, China)</p></li><li><h3 id="CBML-A-Cluster-based-Meta-learning-Model-for-Session-based-Recommendation"><a href="#CBML-A-Cluster-based-Meta-learning-Model-for-Session-based-Recommendation" class="headerlink" title="CBML: A Cluster-based Meta-learning Model for Session-based Recommendation"></a><strong>CBML: A Cluster-based Meta-learning Model for Session-based Recommendation</strong></h3><p>Jiayu Song (Soochow University, China), Jiajie Xu (Soochow University, China), Rui Zhou (Swinburne University of Technology, Australia), Lu Chen (Swinburne University of Technology, Australia), Jianxin Li (Deakin University, Australia), Chengfei Liu (Swinburne University of Technology, Australia)</p></li><li><h3 id="AutoIAS-Automatic-Integrated-Architecture-Searcher-for-Click-Trough-Rate-Prediction"><a href="#AutoIAS-Automatic-Integrated-Architecture-Searcher-for-Click-Trough-Rate-Prediction" class="headerlink" title="AutoIAS: Automatic Integrated Architecture Searcher for Click-Trough Rate Prediction"></a><strong>AutoIAS: Automatic Integrated Architecture Searcher for Click-Trough Rate Prediction</strong></h3><p>Zhikun Wei (Tsinghua University, China), Xin Wang (Tsinghua University &amp; Pengcheng Laboratory, China), Wenwu Zhu (Tsinghua University &amp; Pengcheng Laboratory, China)</p></li><li><h3 id="CMML-Contextual-Modulation-Meta-Learning-for-Cold-Start-Recommendation"><a href="#CMML-Contextual-Modulation-Meta-Learning-for-Cold-Start-Recommendation" class="headerlink" title="CMML: Contextual Modulation Meta Learning for Cold-Start Recommendation"></a><strong>CMML: Contextual Modulation Meta Learning for Cold-Start Recommendation</strong></h3><p>Xidong Feng (University College London, United Kingdom), Chen Chen (Noah’s Ark Lab, Huawei, China), Dong Li (Noah’s Ark Lab, Huawei, China), Mengchen Zhao (Noah’s Ark Lab, Huawei, China), Jianye Hao (Noah’s Ark Lab, Huawei, China), Jun Wang (University College London, United Kingdom)</p></li><li><h3 id="Unsupervised-Large-Scale-Social-Network-Alignment-via-Cross-Network-Embedding"><a href="#Unsupervised-Large-Scale-Social-Network-Alignment-via-Cross-Network-Embedding" class="headerlink" title="Unsupervised Large-Scale Social Network Alignment via Cross Network Embedding"></a><strong>Unsupervised Large-Scale Social Network Alignment via Cross Network Embedding</strong></h3><p>Zhehan Liang (Xiamen University, China), Yu Rong (Tencent AI Lab, China), Chenxin Li (Xiamen University, China), Yunlong Zhang (Xiamen University, China), Yue Huang (Xiamen University, China), Tingyang Xu (Tencent AI Lab, China), Xinghao Ding (Xiamen University, China), Junzhou Huang (Tencent AI Lab, China)</p></li><li><h3 id="Learning-Joint-Embedding-with-Modality-Alignments-for-Cross-Modal-Retrieval-of-Recipes-and-Food-Images"><a href="#Learning-Joint-Embedding-with-Modality-Alignments-for-Cross-Modal-Retrieval-of-Recipes-and-Food-Images" class="headerlink" title="Learning Joint Embedding with Modality Alignments for Cross-Modal Retrieval of Recipes and Food Images"></a><strong>Learning Joint Embedding with Modality Alignments for Cross-Modal Retrieval of Recipes and Food Images</strong></h3><p>Zhongwei Xie (Georgia Institute of Technology &amp; Wuhan University of Technology, USA), Ling Liu (Georgia Institute of Technology, USA), Lin Li (Wuhan University of Technology, China), Luo Zhong (Wuhan University of Technology, China)</p></li><li><h3 id="Seq2Bubbles-Region-Based-Embedding-Learning-for-User-Behaviors-in-Sequential-Recommenders"><a href="#Seq2Bubbles-Region-Based-Embedding-Learning-for-User-Behaviors-in-Sequential-Recommenders" class="headerlink" title="Seq2Bubbles: Region-Based Embedding Learning for User Behaviors in Sequential Recommenders"></a><strong>Seq2Bubbles: Region-Based Embedding Learning for User Behaviors in Sequential Recommenders</strong></h3><p>Qitian Wu (Shanghai Jiao Tong University, China), Chenxiao Yang (Shanghai Jiao Tong University, China), Shuodian Yu (Shanghai Jiao Tong University, China), Xiaofeng Gao (Shanghai Jiao Tong University, China), Guihai Chen (Shanghai Jiao Tong University, China)</p></li><li><h3 id="Enhancing-User-Interest-Modeling-with-Knowledge-Enriched-Itemsets-for-Sequential-Recommendation"><a href="#Enhancing-User-Interest-Modeling-with-Knowledge-Enriched-Itemsets-for-Sequential-Recommendation" class="headerlink" title="Enhancing User Interest Modeling with Knowledge-Enriched Itemsets for Sequential Recommendation"></a><strong>Enhancing User Interest Modeling with Knowledge-Enriched Itemsets for Sequential Recommendation</strong></h3><p>Chunyang Wang (Shanghai Jiao Tong University, China), Yanmin Zhu (Shanghai Jiao Tong University, China), Haobing Liu (Shanghai Jiao Tong University, China), Wenze Ma (Shanghai Jiao Tong University, China), Tianzi Zang (Shanghai Jiao Tong University, China), Jiadi Yu (Shanghai Jiao Tong University, China)</p></li><li><h3 id><a href="#" class="headerlink" title="========="></a>=========</h3></li><li><h3 id="Learning-Multiple-Intent-Representations-for-Search-Queries，多表达"><a href="#Learning-Multiple-Intent-Representations-for-Search-Queries，多表达" class="headerlink" title="Learning Multiple Intent Representations for Search Queries，多表达"></a>Learning Multiple Intent Representations for Search Queries，多表达</h3><p>Helia Hashemi (University of Massachusetts Amherst, USA), Hamed Zamani (University of Massachusetts Amherst, USA), W. Bruce Croft (University of Massachusetts Amherst, USA)</p></li></ul><h2 id="阿里"><a href="#阿里" class="headerlink" title="阿里"></a>阿里</h2><ul><li><h3 id="Reinforcement-Learning-to-Optimize-Lifetime-Value-in-Cold-Start-Recommendation-1"><a href="#Reinforcement-Learning-to-Optimize-Lifetime-Value-in-Cold-Start-Recommendation-1" class="headerlink" title="Reinforcement Learning to Optimize Lifetime Value in Cold-Start Recommendation"></a>Reinforcement Learning to Optimize Lifetime Value in Cold-Start Recommendation</h3><p>Luo Ji (Alibaba Group, China), Qi Qin (Peking University, China), Bingqing Han (Alibaba Group, China), Hongxia Yang (Alibaba Group, China)</p></li><li><h3 id="Learning-to-Augment-Imbalanced-Data-for-Re-ranking-Models-‐"><a href="#Learning-to-Augment-Imbalanced-Data-for-Re-ranking-Models-‐" class="headerlink" title="Learning to Augment Imbalanced Data for Re-ranking Models ‐"></a>Learning to Augment Imbalanced Data for Re-ranking Models ‐</h3><p>Zi-Hao Qiu (Nanjing University, China), Ying-Chun Jian (Nanjing University, China), Qing-Guo Chen (Alibaba Group, China), Lijun Zhang (Nanjing University, China)</p></li><li><h3 id="Self-Supervised-Learning-on-Users’-Spontaneous-Behaviors-for-Multi-Scenario-Ranking-in-E-commerce"><a href="#Self-Supervised-Learning-on-Users’-Spontaneous-Behaviors-for-Multi-Scenario-Ranking-in-E-commerce" class="headerlink" title="Self-Supervised Learning on Users’ Spontaneous Behaviors for Multi-Scenario Ranking in E-commerce"></a><strong>Self-Supervised Learning on Users’ Spontaneous Behaviors for Multi-Scenario Ranking in E-commerce</strong></h3><p>Yulong Gu (Alibaba Group, China), Wentian Bao (Alibaba Group, China), Dan Ou (Alibaba Group, China), Xiang Li (Alibaba Group, China), Baoliang Cui (Alibaba Group, China), Biyu Ma (Alibaba Group, China), Haikuan Huang (Alibaba Group, China), Qingwen Liu (Alibaba Group, China), Xiaoyi Zeng (Alibaba Group, China)</p></li><li><h3 id="Heterogeneous-Graph-Neural-Networks-for-Large-Scale-Bid-Keyword-Matching"><a href="#Heterogeneous-Graph-Neural-Networks-for-Large-Scale-Bid-Keyword-Matching" class="headerlink" title="Heterogeneous Graph Neural Networks for Large-Scale Bid Keyword Matching"></a><strong>Heterogeneous Graph Neural Networks for Large-Scale Bid Keyword Matching</strong></h3><p>Zongtao Liu (Alibaba Group, China), Bin Ma (Alibaba Group, China), Quan Liu (Alibaba Group, China), Jian Xu (Alibaba Group, China), Bo Zheng (Alibaba Group, China)</p></li><li><h3 id="Unsupervised-Categorical-Representation-Learning-for-Package-Arrival-Time-Prediction，lbs的特点和eta结合"><a href="#Unsupervised-Categorical-Representation-Learning-for-Package-Arrival-Time-Prediction，lbs的特点和eta结合" class="headerlink" title="Unsupervised Categorical Representation Learning for Package Arrival Time Prediction，lbs的特点和eta结合"></a>Unsupervised Categorical Representation Learning for Package Arrival Time Prediction，lbs的特点和eta结合</h3><p>Yang Li (Alibaba Group, China), Xingyu Wu (Alibaba Group, China), Jinglong Wang (Alibaba Group, China), Yong Liu (Alibaba-NTU Singapore Joint Research Institute, Singapore), Xiaoqing Wang (Alibaba Group, China), Yuming Deng (Alibaba Group, China), Chunyan Miao (Nanyang Technological University, Singapore)</p></li><li><h3 id="Fulfillment-Time-Aware-Personalized-Ranking-for-On-Demand-Food-Recommendation"><a href="#Fulfillment-Time-Aware-Personalized-Ranking-for-On-Demand-Food-Recommendation" class="headerlink" title="Fulfillment-Time-Aware Personalized Ranking for On-Demand Food Recommendation"></a>Fulfillment-Time-Aware Personalized Ranking for On-Demand Food Recommendation</h3><p>Haishuai Wang (Alibaba Group, Fairfield University, China), Zhao Li (Alibaba Group, China), Xuanwu Liu (Alibaba Group, China), Donghui Ding (Alibaba Group, China), Zehong Hu (Alibaba Group, China), Peng Zhang (Guangzhou University, China), Chuan Zhou (Chinese Academy of Sciences, China), Jiajun Bu (Zhejiang University, China)</p></li><li><h3 id="SAR-Net-A-Scenario-Aware-Ranking-Network-for-Personalized-Fair-Recommendation-in-Hundreds-of-Travel-Scenarios"><a href="#SAR-Net-A-Scenario-Aware-Ranking-Network-for-Personalized-Fair-Recommendation-in-Hundreds-of-Travel-Scenarios" class="headerlink" title="SAR-Net: A Scenario-Aware Ranking Network for Personalized Fair Recommendation in Hundreds of Travel Scenarios"></a><strong>SAR-Net: A Scenario-Aware Ranking Network for Personalized Fair Recommendation in Hundreds of Travel Scenarios</strong></h3></li><li><h3 id="SCI-Subspace-Learning-Based-Counterfactual-Inference-for-Individual-Treatment-Effect-Estimation"><a href="#SCI-Subspace-Learning-Based-Counterfactual-Inference-for-Individual-Treatment-Effect-Estimation" class="headerlink" title="SCI: Subspace Learning Based Counterfactual Inference for Individual Treatment Effect Estimation"></a>SCI: Subspace Learning Based Counterfactual Inference for Individual Treatment Effect Estimation</h3><p>Liuyi Yao (Alibaba Group, China), Yaliang Li (Alibaba Group, USA), Sheng Li (University of Georgia, USA), Mengdi Huai (University of Virginia, USA), Jing Gao (Purdue University, USA), Aidong Zhang (University of Virginia, USA)</p></li><li><h3 id="Learning-to-Expand-Reinforced-Response-Expansion-for-Information-seeking-Conversations"><a href="#Learning-to-Expand-Reinforced-Response-Expansion-for-Information-seeking-Conversations" class="headerlink" title="Learning to Expand: Reinforced Response Expansion for Information-seeking Conversations"></a>Learning to Expand: Reinforced Response Expansion for Information-seeking Conversations</h3><p>Haojie Pan (Alibaba Group, China), Cen Chen (East China Normal University, China), Chengyu Wang (Alibaba Group, China), Minghui Qiu (Alibaba Group, Singapore), Liu Yang (University of Massachusetts at Amherst, USA), Feng Ji (Alibaba Group, China), Jun Huang (Alibaba Group, China)</p></li><li><h3 id="Binary-Code-based-Hash-Embedding-for-Web-scale-Applications"><a href="#Binary-Code-based-Hash-Embedding-for-Web-scale-Applications" class="headerlink" title="Binary Code based Hash Embedding for Web-scale Applications"></a>Binary Code based Hash Embedding for Web-scale Applications</h3><p>Bencheng Yan (Alibaba Group, China), Pengjie Wang (Alibaba Group, China), Jinquan Liu (Alibaba Group, China), Wei Lin (Alibaba Group, China), Kuang-Chih Lee (Alibaba Group, China), Jian Xu (Alibaba Group, China), Bo Zheng (Alibaba Group, China)</p></li><li><h3 id="Learning-Effective-and-Efficient-Embedding-via-an-Adaptively-Masked-Twins-based-Layer"><a href="#Learning-Effective-and-Efficient-Embedding-via-an-Adaptively-Masked-Twins-based-Layer" class="headerlink" title="Learning Effective and Efficient Embedding via an Adaptively-Masked Twins-based Layer"></a>Learning Effective and Efficient Embedding via an Adaptively-Masked Twins-based Layer</h3><p>Bencheng Yan (Alibaba Group, China), Pengjie Wang (Alibaba Group, China), Kai Zhang (Alibaba Group, China), Wei Lin (Alibaba Group, China), Kuang-Chih Lee (Alibaba Group, China), Jian Xu (Alibaba Group, China), Bo Zheng (Alibaba Group, China)</p></li><li><h3 id="AutoHERI-Automated-Hierarchical-Representation-Integration-for-Post-Click-Conversion-Rate-Estimation"><a href="#AutoHERI-Automated-Hierarchical-Representation-Integration-for-Post-Click-Conversion-Rate-Estimation" class="headerlink" title="AutoHERI: Automated Hierarchical Representation Integration for Post-Click Conversion Rate Estimation"></a>AutoHERI: Automated Hierarchical Representation Integration for Post-Click Conversion Rate Estimation</h3><p>Penghui Wei (Alibaba Group, China), Weimin Zhang (Alibaba Group, China), Zixuan Xu (Alibaba Group, China), Shaoguo Liu (Alibaba Group, China), Kuang-chih Lee (Alibaba Group, China), Bo Zheng (Alibaba Group, China)</p></li><li><h3 id="SMAD-Scalable-Multi-view-Ad-Retrieval-System-for-E-Commerce-Sponsored-Search"><a href="#SMAD-Scalable-Multi-view-Ad-Retrieval-System-for-E-Commerce-Sponsored-Search" class="headerlink" title="SMAD: Scalable Multi-view Ad Retrieval System for E-Commerce Sponsored Search"></a>SMAD: Scalable Multi-view Ad Retrieval System for E-Commerce Sponsored Search</h3><p>Shiyang Wen (Alibaba Group, China), Yiran Chen (Alibaba Group, China), Zhi Yang (Peking University, China), Yan Zhang (Alibaba Group, China), Di Zhang (Alibaba Group, China), Liang Wang (Alibaba Group, China), Bo Zheng (Alibaba Group, China)</p></li><li><h3 id="From-Community-Search-to-Community-Understanding-A-Multimodal-Community-Query-Engine"><a href="#From-Community-Search-to-Community-Understanding-A-Multimodal-Community-Query-Engine" class="headerlink" title="From Community Search to Community Understanding: A Multimodal Community Query Engine"></a><strong>From Community Search to Community Understanding: A Multimodal Community Query Engine</strong></h3><p>Zhao Li (Alibaba Group, China), Pengcheng Zou (Alibaba Group, China), Xia Chen (Alibaba Group, China), Shichang Hu (Alibaba Group, China), Peng Zhang (Guangzhou University, China), Yumou Zhang (Alibaba Group, China), Bingsheng He (National University of Singapore, Singapore), Yuchen Li (Singapore Management University, Singapore), Xing Tang (Alibaba Group, China)</p></li><li><h3 id="AliMe-MKG-A-Multi-modal-Knowledge-Graph-for-Live-streaming-E-commerce"><a href="#AliMe-MKG-A-Multi-modal-Knowledge-Graph-for-Live-streaming-E-commerce" class="headerlink" title="AliMe MKG: A Multi-modal Knowledge Graph for Live-streaming E-commerce"></a><strong>AliMe MKG: A Multi-modal Knowledge Graph for Live-streaming E-commerce</strong></h3><p>Guohai Xu (Alibaba Group, China), Hehong Chen (Alibaba Group, China), Feng-Lin Li (Alibaba Group, China), Fu Sun (Alibaba Group, China), Yunzhou Shi (Alibaba Group, China), Zhixiong Zeng (Alibaba Group, China), Wei Zhou (Alibaba Group, China), Zhongzhou Zhao (Alibaba Group, China), Ji Zhang (Alibaba Group, China)</p></li><li><h3 id="ECEdgeNet-A-Large-Scale-Edge-Computing-Dataset-in-the-Field-of-E-commerce"><a href="#ECEdgeNet-A-Large-Scale-Edge-Computing-Dataset-in-the-Field-of-E-commerce" class="headerlink" title="ECEdgeNet: A Large Scale Edge Computing Dataset in the Field of E-commerce"></a><strong>ECEdgeNet: A Large Scale Edge Computing Dataset in the Field of E-commerce</strong></h3><p> Liangwei Li (Alibaba Group, China), Chenwei Weng (Alibaba Group, China), Chengfu Huo (Alibaba Group, China), Weijun Ren (Alibaba Group, China)</p></li></ul><h2 id="baidu"><a href="#baidu" class="headerlink" title="baidu"></a>baidu</h2><ul><li><h3 id="Adversarial-Kernel-Sampling-on-Class-imbalanced-Data-Streams"><a href="#Adversarial-Kernel-Sampling-on-Class-imbalanced-Data-Streams" class="headerlink" title="Adversarial Kernel Sampling on Class-imbalanced Data Streams"></a>Adversarial Kernel Sampling on Class-imbalanced Data Streams</h3><p>Peng Yang (Baidu Research, USA), Ping Li (Baidu Research, USA)</p></li><li><h3 id="Efficient-Learning-to-Learn-a-Robust-CTR-Model-for-Web-scale-Online-Sponsored-Search-Advertising"><a href="#Efficient-Learning-to-Learn-a-Robust-CTR-Model-for-Web-scale-Online-Sponsored-Search-Advertising" class="headerlink" title="Efficient Learning to Learn a Robust CTR Model for Web-scale Online Sponsored Search Advertising"></a>Efficient Learning to Learn a Robust CTR Model for Web-scale Online Sponsored Search Advertising</h3><p>Xin Wang (Baidu Research, China), Peng Yang (Baidu Research, USA), Shaopeng Chen (Baidu Sponsored Search (Phoenix Nest), China), Lin Liu (Baidu Sponsored Search (Phoenix Nest), China), Lian Zhao (Baidu Sponsored Search (Phoenix Nest), China), Jiacheng Guo (Baidu Sponsored Search (Phoenix Nest), China), Mingming Sun (Baidu Research, China), Ping Li (Baidu Research, USA)</p></li><li><h3 id="CHASE-Commonsense-Enriched-Advertising-on-Search-Engine-with-Explicit-Knowledge"><a href="#CHASE-Commonsense-Enriched-Advertising-on-Search-Engine-with-Explicit-Knowledge" class="headerlink" title="CHASE: Commonsense-Enriched Advertising on Search Engine with Explicit Knowledge"></a>CHASE: Commonsense-Enriched Advertising on Search Engine with Explicit Knowledge</h3><p>Chao Zhang (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Jingbo Zhou (Baidu Research, China), Xiaoling Zang (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Qing Xu (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Liang Yin (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Xiang He (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Lin Liu (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Haoyi Xiong (Baidu Research, China), Dejing Dou (Baidu Research, China)</p></li><li><h3 id="Multi-modal-Dictionary-BERT-for-Cross-modal-Video-Search-in-Baidu-Advertising"><a href="#Multi-modal-Dictionary-BERT-for-Cross-modal-Video-Search-in-Baidu-Advertising" class="headerlink" title="Multi-modal Dictionary BERT for Cross-modal Video Search in Baidu Advertising"></a>Multi-modal Dictionary BERT for Cross-modal Video Search in Baidu Advertising</h3><p>Tan Yu (Baidu Research, USA), Yi Yang (Baidu Inc., China), Yi Li (Baidu Inc., China), Lin Liu (Baidu Inc., China), Mingming Sun (Baidu Research, China), Ping Li (Baidu Research, USA)</p></li><li><h3 id="MixBERT-for-Image-Ad-Relevance-Scoring-in-Advertising"><a href="#MixBERT-for-Image-Ad-Relevance-Scoring-in-Advertising" class="headerlink" title="MixBERT for Image-Ad Relevance Scoring in Advertising"></a>MixBERT for Image-Ad Relevance Scoring in Advertising</h3><p>Tan Yu (Baidu Research, USA), Xiaokang Li (Baidu Inc., China), Jianwen Xie (Baidu Research, USA), Ruiyang Yin (Baidu Research, China), Qing Xu (Baidu Inc., China), Ping Li (Baidu Research, USA)</p></li></ul><h2 id="腾讯"><a href="#腾讯" class="headerlink" title="腾讯"></a>腾讯</h2><ul><li><h3 id="Fast-Extraction-of-Word-Embedding-from-Q-contexts"><a href="#Fast-Extraction-of-Word-Embedding-from-Q-contexts" class="headerlink" title="Fast Extraction of Word Embedding from Q-contexts"></a>Fast Extraction of Word Embedding from Q-contexts</h3><p>Junsheng Kong (South China University of Technology, China), Weizhao Li (South China University of Technology, China), Zeyi Liu (University of Cambridge, United Kingdom), Ben Liao (Tencent Quantum Lab, China), Jiezhong Qiu (Tsinghua University, China), Chang-Yu Hsieh (Tencent Quantum Lab, China), Yi Cai (School of Software Engineering, South China University of Technology, China), Shengyu Zhang (Tencent Quantum Lab, China)</p></li><li><h3 id="USER-A-Unified-Information-Search-and-Recommendation-Model-based-on-Integrated-Behavior-Sequence"><a href="#USER-A-Unified-Information-Search-and-Recommendation-Model-based-on-Integrated-Behavior-Sequence" class="headerlink" title="USER: A Unified Information Search and Recommendation Model based on Integrated Behavior Sequence"></a><strong>USER: A Unified Information Search and Recommendation Model based on Integrated Behavior Sequence</strong></h3><p>Jing Yao (Renmin University of China &amp; Tencent, China), Zhicheng Dou (Renmin University of China, China), Ruobing Xie (Tencent, China), Yanxiong Lu (Tencent, China), Zhiping Wang (Tencent, China), Ji-Rong Wen (Beijing Key Laboratory of Big Data Management and Analysis Methods &amp; Key Laboratory of Data Engineering and Knowledge Engineering, MOE, China)</p></li><li><h3 id="Dual-Learning-for-Query-Generation-and-Query-Selection-in-Query-Feeds-Recommendation"><a href="#Dual-Learning-for-Query-Generation-and-Query-Selection-in-Query-Feeds-Recommendation" class="headerlink" title="Dual Learning for Query Generation and Query Selection in Query Feeds Recommendation"></a><strong>Dual Learning for Query Generation and Query Selection in Query Feeds Recommendation</strong></h3><p> Kunxun Qi (Sun Yat-sen University&amp;Tencent, China), Ruoxu Wang (Tencent, China), Qikai Lu (University of Alberta, Canada), Xuejiao Wang (Tencent, China), Ning Jing (Tencent, China), Di Niu (University of Alberta, Canada), Haolan Chen (Tencent, China)</p></li><li><h3 id="Influence-Maximization-in-Multi-Relational-Social-Networks"><a href="#Influence-Maximization-in-Multi-Relational-Social-Networks" class="headerlink" title="Influence Maximization in Multi-Relational Social Networks"></a>Influence Maximization in Multi-Relational Social Networks</h3><p> Wei Wang (Tencent Inc. China, China), Haili Yang (Tencent Inc. China, China), Yuanfu Lu (Tencent Inc. China, China), Yuanhang Zou (Tencent Inc. China, China), Xu Zhang (Tencent Inc. China, China), Shuting Guo (Tencent Inc. China, China), Leyu Lin (Tencent Inc. China, China)</p></li><li><h3 id="Spectral-Graph-Attention-Network-with-Fast-Eigen-approximation"><a href="#Spectral-Graph-Attention-Network-with-Fast-Eigen-approximation" class="headerlink" title="Spectral Graph Attention Network with Fast Eigen-approximation"></a><strong>Spectral Graph Attention Network with Fast Eigen-approximation</strong></h3><p>Heng Chang (Tsinghua University, China), Yu Rong (Tencent AI Lab, China), Tingyang Xu (Tencent AI Lab, China), Wenbing Huang (Tsinghua University, China), Somayeh Sojoudi (University of California at Berkeley, USA), Junzhou Huang (Tencent AI Lab, China), Wenwu Zhu (Tsinghua University, China)</p></li></ul><h2 id="Ant-Group"><a href="#Ant-Group" class="headerlink" title="Ant Group"></a>Ant Group</h2><ul><li><h3 id="Conditional-Graph-Attention-Networks-for-Distilling-and-Refining-Knowledge-Graphs-in-Recommendation"><a href="#Conditional-Graph-Attention-Networks-for-Distilling-and-Refining-Knowledge-Graphs-in-Recommendation" class="headerlink" title="Conditional Graph Attention Networks for Distilling and Refining Knowledge Graphs in Recommendation"></a>Conditional Graph Attention Networks for Distilling and Refining Knowledge Graphs in Recommendation</h3><p> Ke Tu (Ant Group, China), Peng Cui (Tsinghua University, China), Daixin Wang (Ant Group, China), Zhiqiang Zhang (Ant Group, China), Jun Zhou (Ant Group, China), Yuan Qi (Ant Group, China), Wenwu Zhu (Tsinghua University, China)</p></li><li><h3 id="Self-supervised-Representation-Learning-on-Dynamic-Graphs"><a href="#Self-supervised-Representation-Learning-on-Dynamic-Graphs" class="headerlink" title="Self-supervised Representation Learning on Dynamic Graphs"></a>Self-supervised Representation Learning on Dynamic Graphs</h3><p>Sheng Tian (Ant Group, China), Ruofan Wu (Ant Group, China), Leilei Shi (Ant Group, China), Liang Zhu (Ant Group, China), Tao Xiong (Ant Group, China)</p></li><li><h3 id="Learning-Representations-of-Inactive-Users-A-Cross-Domain-Approach-with-Graph-Neural-Networks"><a href="#Learning-Representations-of-Inactive-Users-A-Cross-Domain-Approach-with-Graph-Neural-Networks" class="headerlink" title="Learning Representations of Inactive Users: A Cross Domain Approach with Graph Neural Networks"></a>Learning Representations of Inactive Users: A Cross Domain Approach with Graph Neural Networks</h3><p>Ziqi Liu (Ant Group, China), Yue Shen (Ant Group, China), Xiaocheng Cheng (Ant Group, China), Qiang Li (Ant Group, China), Jianping Wei (Ant Group, China), Zhiqiang Zhang (Ant Group, China), Dong Wang (Ant Group, China), Xiaodong Zeng (Ant Group, China), Jinjie Gu (Ant Group, China), Jun Zhou (Ant Group, China)</p></li></ul><h2 id="Microsoft"><a href="#Microsoft" class="headerlink" title="Microsoft"></a>Microsoft</h2><ul><li><h3 id="CoPE-Modeling-Continuous-Propagation-and-Evolution-on-Interaction-Graph"><a href="#CoPE-Modeling-Continuous-Propagation-and-Evolution-on-Interaction-Graph" class="headerlink" title="CoPE: Modeling Continuous Propagation and Evolution on Interaction Graph"></a>CoPE: Modeling Continuous Propagation and Evolution on Interaction Graph</h3><p>Yao Zhang (Fudan University, China), Yun Xiong (Fudan University, China), Dongsheng Li (Microsoft Research Asia, China), Caihua Shan (Microsoft Research Asia, China), Kan Ren (Microsoft Research Asia, China), Yangyong Zhu (Fudan University, China)</p></li><li><h3 id="Improving-Query-Representations-for-Dense-Retrieval-with-Pseudo-Relevance-Feedback"><a href="#Improving-Query-Representations-for-Dense-Retrieval-with-Pseudo-Relevance-Feedback" class="headerlink" title="Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback"></a>Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback</h3><p>HongChien Yu (Carnegie Mellon University, USA), Chenyan Xiong (Microsoft Research, USA), Jamie Callan (Carnegie Mellon University, USA)</p></li><li><h3 id="Is-a-Single-Model-Enough-MuCoS-A-Multi-Model-Ensemble-Learning-Approach-for-Semantic-Code-Search"><a href="#Is-a-Single-Model-Enough-MuCoS-A-Multi-Model-Ensemble-Learning-Approach-for-Semantic-Code-Search" class="headerlink" title="Is a Single Model Enough? MuCoS: A Multi-Model Ensemble Learning Approach for Semantic Code Search"></a>Is a Single Model Enough? MuCoS: A Multi-Model Ensemble Learning Approach for Semantic Code Search</h3><p>Lun Du (Microsoft Research Asia, China), Xiaozhou Shi (Beijing University of Technology, China), Yanlin Wang (Microsoft Research Asia, China), Ensheng Shi (Xi’an Jiaotong University, China), Shi Han (Microsoft Research Asia, China), Dongmei Zhang (Microsoft Research Asia, China)</p></li><li></li><li></li></ul><ul><li></li></ul><h2 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a>Tutorials</h2><ul><li><p><strong>CIKM 2021 Tutorial on Fairness of Machine Learning in Recommender Systems</strong> ‐ Yunqi Li (Rutgers University, USA), Yingqiang Ge (Rutgers University, USA), Yongfeng Zhang (Rutgers University, USA)</p></li><li><p><strong>AutoML: From Methodology to Application</strong> ‐ Yaliang Li (Alibaba Group, USA), Zhen Wang (Alibaba Group, China), Yuexiang Xie (Alibaba Group, China), Bolin Ding (Alibaba Group, USA), Kai Zeng (Alibaba Group, China), Ce Zhang (ETH Zürich, Switzerland)</p></li><li><p><strong>IR From Bag-of-words to BERT and Beyond through Practical Experiments</strong> </p><p><a href="https://github.com/terrier-org/ecir2021tutorial">https://github.com/terrier-org/ecir2021tutorial</a></p><p>Craig Macdonald (University of Glasgow, United Kingdom), Nicola Tonellotto (University of Pisa, Italy), Sean MacAvaney (University of Glasgow, United Kingdom)</p></li></ul><h1 id="wsdm2022"><a href="#wsdm2022" class="headerlink" title="wsdm2022"></a>wsdm2022</h1><p><a href="https://www.wsdm-conference.org/2022/accepted-papers/">https://www.wsdm-conference.org/2022/accepted-papers/</a></p><h2 id="阿里-1"><a href="#阿里-1" class="headerlink" title="阿里"></a>阿里</h2><ul><li><p>A Cooperative-Competitive Multi-Agent Framework for Auto-bidding in Online Advertising</p><p>Chao Wen (Nanjing University of Aeronautics and Astronautics)*; Miao Xu (Alibaba Group); Zhilin Zhang (Alibaba Group); ZHENZHE ZHENG (Shanghai Jiao Tong University); Yuhui Wang (Nanjing University of Aeronautics and Astronautics, China); Xiangyu Liu (Alibaba Group)</p></li><li><p>Learning-To-Ensemble by Contextual Rank Aggregation in E-Commerce</p><p>Xuesi Wang (Alibaba); Guangda Huzhang (Alibaba); Qianying Lin (Alibaba)*; Qing Da (Alibaba Group)</p></li><li><p>Joint Learning of E-commerce Search and Recommendation with A Unified Graph Neural Network</p><p>Kai Zhao (Alibaba Group)*; Yukun Zheng (Alibaba inc.); Tao Zhuang (Alibaba Group); Xiang Li (Alibaba Group); Xiaoyi Zeng (Alibaba Group)</p></li><li><p>Triangle Graph Interest Network for Click-through Rate Prediction</p><p>Wensen Jiang (Alibaba Group)*; Yizhu Jiao (Fudan University); Qingqin Wang (Fudan University); Chuanming Liang (Alibaba Group); Lijie Guo (Alibaba Group); Yao Zhang (Fudan University); Zhijun Sun (Zhejiang Cainiao Supply Chain Management Co Ltd); Yun Xion</p></li><li><p>Modeling Users’ Contextualized Page-wise Feedback for Click-Through Rate Prediction in E-commerce Search</p><p>Zhifang Fan (Alibaba Group)*; Dan Ou (Alibaba Group); Yulong Gu (Alibaba Group); Bairan Fu (Nanjing University); Xiang Li (Alibaba Group); WenTian Bao (alibaba); Xin-yu Dai (Nanjing University); Xiaoyi Zeng (Alibaba Group); Tao Zhuang (Alibaba Group); Qin</p></li><li><p>Leaving No One Behind: A Multi-Scenario Multi-Task Meta Learning Approach for Advertiser Modeling</p><p>qianqian zhang (Alibaba)*; Xinru Liao (Alibaba Group); Quan Liu (Alibaba Group); Jian Xu (Alibaba Group); Bo Zheng (Alibaba Group)</p></li><li><p>An Adaptive Unified Allocation Framework for Guaranteed Display Advertising</p><p>Xiao Cheng (Alibaba); Chuanren Liu (University of Tennessee)*; Liang Dai (Alibaba); Peng Zhang (Alibaba); Zhen Fang (Alibaba); Zhonglin Zu (alibaba)</p></li><li></li></ul><h2 id="Tencent"><a href="#Tencent" class="headerlink" title="Tencent"></a>Tencent</h2><ul><li><p>RecGURU: Adversarial Learning of Generalized User Representations for Cross-Domain Recommendation</p></li><li><p>Personalized Transfer of User Preferences for Cross-domain Recommendation</p><p>Yongchun Zhu (Institute of Computing Technology, Chinese Academy of Sciences)*; Zhenwei Tang (King Abdullah University of Science and Technology); Yudan Liu (WeChat Search Application Department, Tencent); Fuzhen Zhuang (Institute of Artificial Intelligencem, Beihang University)</p></li><li><p>A Peep into the Future: Adversarial Future Encoding in Recommendation</p><p>Ruobing Xie (WeChat Search Application Department, Tencent)*; Shaoliang Zhang (Tencent); Rui Wang (Tencent); Feng Xia (WeChat Search Application Department, Tencent); Leyu Lin (WeChat Search Application Department, Tencent)</p></li><li><p>Efﬁcient two-stage label noise reduction for retrieval-based tasks</p><p>“Mengmeng Kuang (Tencent Holdings Ltd.)*; Weiyan Wang (HKUST); Zhenhong Chen (Tencent Holdings Ltd. ); Lie Kang (Tencent Holdings Ltd. ); Qiang Yan (Tencent)”</p></li></ul><h2 id="baidu-1"><a href="#baidu-1" class="headerlink" title="baidu"></a>baidu</h2><ul><li><p>Fast Semantic Matching via Flexible Contextualized Interaction</p><p>Wenwen Ye (Baidu Inc.)*; Yiding Liu (Baidu Inc.); Lixin Zou (Baidu Inc.); Hengyi Cai (Baidu Inc.); Suqi Cheng (Baidu Inc.); Shuaiqiang Wang (Baidu Inc.); Dawei Yin (Baidu)</p></li><li><p>A GNN-based Multi-task Learning Framework for Personalized Video Search</p><p>Li Zhang (University of Sheffield)*; Lei Shi ( Baidu); Jiashu Zhao (Wilfrid Laurier University); Juan Yang (Baidu); Tianshu Lyv (Baidu); Dawei Yin (Baidu); Haiping Lu (University of Sheffield)</p></li><li></li></ul><ul><li><h2 id="Bytedance"><a href="#Bytedance" class="headerlink" title="Bytedance"></a>Bytedance</h2></li><li><p>Diversified Query Generation Guided by Knowledge Graph</p><p>Xinyao Shen (Fudan University)*; Jiangjie Chen (Fudan University); Jiaze Chen (Bytedance); Chun Zeng (Fudan University); Yanghua Xiao (Fudan University)</p></li></ul><h2 id="kuaishou"><a href="#kuaishou" class="headerlink" title="kuaishou"></a>kuaishou</h2><ul><li><p>C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational Recommender System</p><p>Yuanhang Zhou (Renmin University of China)*; Kun Zhou (Renmin University of China); Wayne Xin Zhao (Renmin University of China); Cheng Wang (Kuaishou Inc); Peng Jiang (Kuaishou Inc.); He Hu (Renmin University of China)</p></li><li></li></ul><h2 id="Ant-Group-1"><a href="#Ant-Group-1" class="headerlink" title="Ant Group"></a>Ant Group</h2><ul><li><h3 id="Scope-aware-Re-ranking-with-Gated-Attention-in-Feed"><a href="#Scope-aware-Re-ranking-with-Gated-Attention-in-Feed" class="headerlink" title="Scope-aware Re-ranking with Gated Attention in Feed"></a>Scope-aware Re-ranking with Gated Attention in Feed</h3><p>Hao Qian (Ant Services Group)*; Qintong Wu (Ant Group ); Kai Zhang (University of Science and Technology of China); Zhiqiang Zhang (Ant Group); Lihong Gu (Ant Group); Xiaodong Zeng (Ant Services Group ); Jun Zhou (Ant Financial); Jinjie Gu (Ant Group)</p></li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li><h3 id="Multi-Resolution-Attention-for-Personalized-Item-Search"><a href="#Multi-Resolution-Attention-for-Personalized-Item-Search" class="headerlink" title="Multi-Resolution Attention for Personalized Item Search"></a>Multi-Resolution Attention for Personalized Item Search</h3><p>Furkan Kocayusufoglu (UC, Santa Barbara)*; Tao Wu (Google Research); Anima Singh (Google); Georgios Roumpos (Google Research); Heng-Tze Cheng (Google Research); Sagar Jain (Google); Ed H. Chi (Google); Ambuj K Singh (UCSB)</p></li><li><p>Supervised Advantage Actor-Critic for Recommender Systems</p><p>Xin Xin (Shandong University); Alexandros Karatzoglou (Google Research)*; Ioannis Arapakis (Telefonica Research); Joemon M Jose ( University of Glasgow)</p></li><li><p>Lightweight Composite Re-Ranking for Efficient Keyword Search with BERT</p><p>Yingrui Yang (University of California, Santa Barbara)*; Yifan Qiao (University of California, Santa Barbara); Jinjin Shao (UCSB); Xifeng Yan (University of California, Santa Barbara); Tao Yang (UC Santa Barbara)</p></li><li><p>Unsupervised Cross-Domain Adaptation for Response Selection Using Self-Supervised and Adversarial Training</p><p>Jia Li (Peking University); Chongyang Tao (Microsoft)*; Huang Hu (Microsoft); Can Xu (microsoft); Yining Chen (Microsoft); Daxin Jiang (Microsoft, Beijing, China)</p></li><li><p>GraSP: Optimizing Graph-based Nearest Neighbor Search with Subgraph Sampling and Pruning</p><p>Minjia Zhang (Microsoft AI and Research)*; Wenhan Wang (Microsoft); Yuxiong He (Microsoft)</p></li><li><p>Learning Multi-granularity Consecutive User Intent Unit for Session-based Recommendation</p><p>Jiayan Guo (Peking University)*; Yaming Yang (MSRA); Xiangchen Song (Carnegie Mellon University); Yuan Zhang (Peking University); Yujing Wang (MSRA); Jing Bai (Microsoft); Yan Zhang (Peking University)</p></li><li><p>MtCut: A Multi-Task Framework for Ranked List Truncation</p><p>Jianxin Li (Beihang University)*; Wang Dong (Beihang University); Tianchen Zhu (Beihang University); Qishan Zhu (Beihang University); Yuxin Wen (Beihang University); Piao Hongming (Beihang University)</p></li><li><p>Improving Session Search by Modeling Multi-Granularity Historical Query Change</p><p>Xiaochen Zuo (Renmin University of China)*; Zhicheng Dou (Remin University of China)</p></li><li><p>Learning Discrete Representations via Constrained Clustering for Effective and Efficient Dense Retrieval</p><p>Jingtao Zhan (Tsinghua University)*; Jiaxin Mao (Renmin University of China); Yiqun LIU (Tsinghua University); Jiafeng Guo (Institute of Computing Technology, Chinese Academy of Sciences); Min Zhang (Tsinghua University); Shaoping Ma (Tsinghua University)</p></li><li><p>ST-GSP: Spatial-Temporal Global Semantic Representation Learning for Urban Flow Prediction</p><p>Liang Zhao (Chongqing University); Min Gao (Chongqing University)*; Zongwei Wang (Chongqing University)</p></li><li><p>Improving Personalized Search with Dual-Feedback Network</p><p>Chenlong Deng (Renmin University of China)*; Yujia Zhou (Renmin University of China); Zhicheng Dou (Remin University of China)</p></li><li><p>Sequential Modeling with Multiple Attributes for Watchlist Recommendation in E-Commerce</p><p>Uriel Singer (Technion, Israel Institute of Technology)*; Haggai Roitman (IBM Research Haifa); yotam eshel (eBay); Alexander Nus (eBay); Ido Guy (eBay); Or Levi (eBay); Idan Hasson (eBay ); Eliyahu Kiperwasser (eBay)</p></li><li><p>Heterogeneous Global Graph Neural Networks for Personalized Session-based Recommendation</p><p>Yitong Pang (Tongji University)*; Lingfei Wu (JD.COM Silicon Valley Research Center); Qi Shen (Tongji University); Yiming Zhang (Tongji University); Zhihua Wei (Tongji University); Fangli Xu (College of William and Mary); Ethan Chang (Middlesex School); B</p></li><li><p>Learning Multi-granularity Consecutive User Intent Unit for Session-based Recommendation</p><p>Jiayan Guo (Peking University)*; Yaming Yang (MSRA); Xiangchen Song (Carnegie Mellon University); Yuan Zhang (Peking University); Yujing Wang (MSRA); Jing Bai (Microsoft); Yan Zhang (Peking University)</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;各家公司在Cikm2021  wsdm2022上的paper&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-17T11:50:19.895Z</updated>
    
    <content type="html"><![CDATA[<p>搜广推领域文献阅读，文献整理来源于git仓库  <a href="https://github.com/TessieHe/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising">Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</a></p><p>【to粗】表示待粗读</p><p>【粗】表示已粗读</p><p>【to精】表示待精读</p><p>【精】表示已精读</p><p>没有标注表示还没看</p><span id="more"></span><p>[TOC]</p><h1 id="Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising"><a href="#Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising" class="headerlink" title="Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising"></a>Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</h1><p>阅读等级：精，粗，to粗</p><p>Keyword：Personalized item search</p><h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><h3 id="2019-Deep-Learning-Based-Recommender-System"><a href="#2019-Deep-Learning-Based-Recommender-System" class="headerlink" title="2019 [Deep Learning Based Recommender System]"></a>2019 [Deep Learning Based Recommender System]</h3><p>Zhang, S.; Yao, L.; Sun, A.; Tay, Y. Deep Learning Based Recommender System: A Survey and New Perspectives. <em>ACM Computing Surveys (CSUR)</em> <strong>2019</strong>, <em>52</em> (1), 1–38.</p><p><strong>简介</strong>：推荐体统的本质是用户与商品的匹配，涉及到两个问题：匹配策略及评判标准</p><p><strong>关键词</strong>：Additional Key Words and Phrases: Recommender System; Deep Learning; Survey</p><ul><li><p>技术层面的分类<img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220311172803323.png" alt="image-20220311172803323" style="zoom:50%;"></p></li><li><p>应用层面的分类</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220311173113403.png" alt="image-20220311173113403" style="zoom:50%;"></p></li></ul><h2 id="Ranking"><a href="#Ranking" class="headerlink" title="Ranking"></a>Ranking</h2><h3 id="【精】2022-Multi-Resolution-Attention-【多时间尺度的attention】"><a href="#【精】2022-Multi-Resolution-Attention-【多时间尺度的attention】" class="headerlink" title="【精】2022[Multi-Resolution Attention] 【多时间尺度的attention】"></a>【精】2022[Multi-Resolution Attention] 【多时间尺度的attention】</h3><p>Kocayusufoglu, F.; Wu, T.; Singh, A.; Roumpos, G.; Cheng, H.-T.; Jain, S.; Chi, E.; Singh, A. Multi-Resolution Attention for Personalized Item Search. In <em>Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</em>; 2022; pp 508–516.</p><p>多分辨率注意力机制</p><p><strong>简介</strong>：用户行为是个性化搜索的基础。用户行为建模存在两个难点：1.并不是所有的行为都和当前决策有关。2.用户行为是非周期性的，他们与当前query的相关性涉及到复杂的时间依赖。本文的方法可以在多个<strong>时空子空间（temporal subspaces (i.e., resolutions)）</strong>捕获<strong>历史行为和当前query的高阶的相关性</strong>。实现方式是通过多头注意力机制+可微分的阈值方式实现时间维度的掩码（masking）。推荐中的很多模型通过attention提取的是序列的信息，而忽略了时间的信息。也有一些工作引入了时间的信息（ [17, 23, 41, 43, 44]）,但大都是推荐场景，不是个性化搜索场景。</p><p><strong>关键词</strong>：item search, personalization, temporal attention, multi-resolution attention, recommender systems</p><ul><li><p>关键思想：在不同时间子空间(时间尺度)计算query和item的相关性</p></li><li><p>个性化搜索领域一般用attention提取历史相关信息，忽略了时间信息；推荐领域今年有考虑序列中的时间信息的工作，但没有query约束。我们的工作是在个性化搜索领域考虑时间信息（umm….）</p></li><li><p>文章先分析了业务场景下用户的交互行为特点，再跟模型结合起来（不同场景有不同的交互行为特点？）数据发现：</p><ol><li>同样的用户在不同品类上的复购周期是有差异的</li><li>同样的品类不同用户的复购周期也是有差异的</li></ol><p>所以提出时间分辨率（temporal resolutions ）的概念，目标是自适应的对不同用户不同品类选取合适的分辨率，并借此计算当前query和历史行为的相关性</p></li></ul><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220314150022595.png" alt="image-20220314150022595" style="zoom:50%;"></p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317165619270.png" alt="image-20220317165619270" style="zoom:50%;"></p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317165638457.png" alt="image-20220317165638457" style="zoom:50%;"></p><ul><li><p>input layer: 对历史序列的item和query进行embedding</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194828763.png" alt="image-20220317194828763" style="zoom:50%;"></p></li><li><p>History Encoding Layer：历史序列的自编码（与query无关）</p></li></ul><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194901838.png" alt="image-20220317194901838" style="zoom:50%;"></p><ul><li>Query-Aware History Encoding Layer： query相关的历史序列多头自编码，每个头有一个时间阈值</li></ul><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194918828.png" alt="image-20220317194918828" style="zoom:50%;"></p><h3 id="【精】2022-CLSR-【自监督-对比学习-长短兴趣表征解耦】"><a href="#【精】2022-CLSR-【自监督-对比学习-长短兴趣表征解耦】" class="headerlink" title="【精】2022[CLSR]【自监督+对比学习=长短兴趣表征解耦】"></a>【精】2022[CLSR]【自监督+对比学习=长短兴趣表征解耦】</h3><p>Cite：Zheng, Y.; Gao, C.; Chang, J.; Niu, Y.; Song, Y.; Jin, D.; Li, Y. Disentangling Long and Short-Term Interests for Recommendation. <em>arXiv preprint arXiv:2202.13090</em> <strong>2022</strong>. </p><p>code: <a href="https://github.com/tsinghua-fib-lab/CLSR">https://github.com/tsinghua-fib-lab/CLSR</a></p><p>CLS：Contrastive learning framework to disentangle Long and Short-term interests for Recommendation (CLSR) with self-supervision.</p><p><strong>简介</strong>：现有工作中用户的长短兴趣大都是耦合建模的，这样会降低准确性和可解释性。本文用对比学习的框架通过自监督的方法解耦了长短兴趣。首先用不同的编码器对长短兴趣(不同时间尺度)进行编码<strong>interest representation</strong>，然后从序列中获取<strong>interest proxies</strong>作为用户兴趣的<strong>伪标签</strong>，然后用pairwise的对比学习任务有监督的学习兴趣表征和相应的interest proxies之间的关系。最后用attention机制融合长短兴趣</p><p><strong>关键词</strong>：Recommendation, Long and Short-Term Interests, Self-supervised Learning, Disentanglement Learning</p><ul><li><p>现有的对用户历史行为的处理有三种方式。1.CF-based的方式，主要处理长期行为。2.sequential model(LSTM,CNN)，主要处理短期行为。3.CF-based + sequential, 缺点是无法保证学习到的长短期行为的准确性，因为没有显示的加入长短期的先验，也就是二者会相互影响。（表示怀疑）</p></li><li><p>长短期行为建模存在3个难点。1.长期行为和短期行为刻画用户的不同时间尺度的信息，公用一个表征是不合适的。2.序列中只有用户的隐反馈，没有标签来区分长短期行为。3.用户不同情况下对长短期行为的依赖是不同的</p></li><li><p><strong>基本思路</strong></p><p>notation</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160528707.png" alt="image-20220310160528707" style="zoom:30%;"></p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161624732.png" alt="image-20220310161624732" style="zoom:50%;"></p><ul><li><p>定义长短期兴趣的query向量（attention中的query概念，并不是真正的query）</p><p>长期行为的query是？？？,短期行为的query是行为序列的RNN输出</p></li></ul><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160613501.png" alt="image-20220310160613501" style="zoom:10%;"></p><ul><li><p>长期兴趣&amp;短期兴趣编码器</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160720224.png" alt="image-20220310160720224" style="zoom:25%;"></p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160739019.png" alt="image-20220310160739019" style="zoom:10%;"></p></li><li><p>自监督的长短期兴趣解耦</p><p>1.不同维度的pooling作为长短期兴趣的伪标签（proxy）；2.用BPR based pairwise loss 或者triplet loss 学习表征</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161821200.png" alt="image-20220310161821200" style="zoom:25%;"></p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310162153666.png" alt="image-20220310162153666" style="zoom:25%;"></p></li><li><p>自适应的兴趣融合</p><p>权重是序列RNN+candidate+长短期兴趣决定的；</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161951289.png" alt="image-20220310161951289" style="zoom:25%;"></p></li></ul></li><li><p><strong>启发</strong></p><ul><li>后续可跟进的方向：伪标签的构造方法可以更复杂。作者说目前这种avg pooling的方法出于简单，效果又足够好。后续可以优化</li><li>在预估任务中加入伪标签+对比学习框架通过自监督约束表征（representation）是一个指的研究的方向，其实是通过伪标签的形式加入了更多的模糊的先验知识。</li></ul></li><li><p><strong>几个有意思的结论</strong>：</p><ul><li>所有数据集上短期兴趣模型（如DIEN）基本都比长期兴趣（DIN）模型要好——-&gt;太长序列的增益很有限？</li><li>短期行为序列的增长带来的增益会递减，ctr任务上递减的速度高于cvr任务——-&gt; 短期序列更重要</li><li>长短期行为联合训练不一定会更有优：因为长短期行为的耦合增加了模型的内部依赖性（ internal dependency ）,会降低模型表现</li><li>固定的长短期兴趣融合策略（concat/固定权重）没有自适应的权重好：不同场景下长短兴趣的重要性是不同的</li><li>高客单价/购买场景对长期兴趣的依赖性高于低客单价/点击场景</li><li>由于作者认为长短兴趣也有重叠的部分，所以没有像其他解耦任务一样增加正则项，强制两个表征不相似</li></ul></li><li><p><strong>引用文献</strong></p><ul><li>【推荐中的解耦】FrancescoLocatello,StefanBauer,MarioLucic,GunnarRaetsch,SylvainGelly, Bernhard Schölkopf, and Olivier Bachem. 2019. Challenging common assump- tions in the unsupervised learning of disentangled representations. In interna- tional conference on machine learning. PMLR, 4114–4124.</li><li>【推荐中的解耦】Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua. 2020. Disentangled graph collaborative filtering. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 1001–1010.</li></ul></li></ul><h3 id="【精】2022-RACP-【页面维度信息-负反馈】"><a href="#【精】2022-RACP-【页面维度信息-负反馈】" class="headerlink" title="【精】2022 [RACP]【页面维度信息+负反馈】"></a>【精】2022 [RACP]【页面维度信息+负反馈】</h3><p>2022 (Alibaba) (WSDM)(ZhifangFan)[RACP]Modeling Users’ Contextualized Page-wise Feedback for Click-Through Rate Prediction in E-commerce Search</p><p>简介：建模用户的历史行为对个性化搜索和推荐都很重要，现有方法主要是对用户历史正反馈的建模（点击序列），忽略了产生反馈的上下文信息。本文通过加入历史<strong>页面维度的曝光和反馈</strong>做一位用户历史行为序列，提出了一种新的上下文感知的用户行为建模方式。通过捕捉页面内的信息和页面间的演化可以更详细的学习用户的偏好。 RACP(Recurrent Attention over Contextualized Page sequence)模型通过<strong>page-context aware attention</strong> 学习页面内的关系。<strong>recurrent attention</strong>学习页面间的关系</p><ul><li><p>模型结构：</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228121702691.png" alt="image-20220228121702691" style="zoom:50%;"></p></li><li><p>quote</p><ul><li>“However, they treat users’ positive and negative feedback separately, and rep- resent users’ feedback as a clicked item sequence and a non-clicked item sequence, which cannot generate the mutual context between clicks and non-clicks and ignores other page context information in the page-sequence” 历史工作很少考虑负反馈，即便考虑也是和正反馈分开处理的，这忽略了<strong>正负反馈之间的相互作用</strong></li><li>页面信息的增益：1）<strong>正反馈是有噪音的</strong>，避免过拟合。一个用户点了一个品牌不一定是他就偏好这个品牌，有可能是整个页面都是这个品牌 2) 用户对item的行为受曝光的其他item影响</li><li>页面间的增益：搜索场景下用户的行为和意图是一个逐渐收敛的过程。例如：搜索—-曝光—-点击—-搜索—-曝光—-点击—-购买</li><li>“Recently, some pioneering work (<strong>DFN</strong> [33], <strong>DSTN</strong> [25]) high- light the importance of modeling both users’ positive and negative feedback for CTR prediction.” 一些负反馈的工作</li><li><strong>DFN</strong> [33]: DFN treats click behaviors as strong feedback to guide the positive preference extraction from unclicked behavior sequence.</li><li><strong>DSTN</strong> [25]: DSTN considers the clicked and unclicked be- haviors as heterogeneous auxiliary data to help the user preference modeling.</li><li>item画像：item id,品类id,shop id,统计类（成单量等）</li><li>query画像：query id,字符串，分词，类别</li><li><strong>页内的attention聚合+页间兴趣回溯(GRU，由下一个page表征当前的query) + 页间兴趣融合(attention)</strong></li></ul></li><li></li></ul><h3 id="【粗】2021-ETA-【长期行为-SimHash相似度】"><a href="#【粗】2021-ETA-【长期行为-SimHash相似度】" class="headerlink" title="【粗】2021[ETA]【长期行为+SimHash相似度】"></a>【粗】2021[ETA]【长期行为+SimHash相似度】</h3><p>2021(Alibaba)(ArXiv)[ETA]End-to-End User Behavior Retrieval in Click-Through Rate Prediction Model</p><p>简介：用户的长期行为对CTR预估很重要，但由于性能的约束，超长期用户行为通常是通过两段式训练进行处理的。第一阶段通过长期行为召回topK,第二阶段结合短期行为进行排序。两阶段由于优化目标不一致降低了长期用户行为带来的CTR增益。本文通过<strong>locality- sensitive hashing (LSH)</strong>方法提出端到端的ETA模型，使得满足训练和推理性能要求的前提下端到端训练的长期用户行为ctr模型。主要是通过<strong>SimHash</strong>的方法计算相似度，使得相似度的计算复杂度由O(L<em> B </em> d)变为O(L*B)，其中L是序列长度，B是candidate梳理，d是embedding维度</p><ul><li><p>模型结构：</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228145221827.png" alt="image-20220228145221827" style="zoom:50%;"></p></li></ul><h3 id="【粗】2021-ZEUS-【预测下一个query-微调】"><a href="#【粗】2021-ZEUS-【预测下一个query-微调】" class="headerlink" title="【粗】2021  [ZEUS]【预测下一个query + 微调】"></a>【粗】2021  [ZEUS]【预测下一个query + 微调】</h3><p>2021 (Alibaba) (CIKM) [ZEUS] Self-Supervised Learning on Users’ Spontaneous Behaviors for Multi-Scenario Ranking in E-commerce</p><p>Gu, Y.; Bao, W.; Ou, D.; Li, X.; Cui, B.; Ma, B.; Huang, H.; Liu, Q.; Zeng, X. Self-Supervised Learning on Users’ Spontaneous Behaviors for Multi-Scenario Ranking in E-Commerce. In <em>Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</em>; ACM: Virtual Event Queensland Australia, 2021; pp 3828–3837. <a href="https://doi.org/10.1145/3459637.3481953">https://doi.org/10.1145/3459637.3481953</a>.</p><p>关键词：Learning to Rank; Multi-Scenario; Intent Recommendation; Rec- ommender System; E-commerce</p><p>简介：多场景下用户<strong>自发行为</strong>的<strong>自监督</strong>学习。搜广推场景下排序模块都非常重要，目前大部分工作聚焦于单场景建模。我们认为多场景面对以下两个挑战：1) Feedback Loop. 模型的训练数据是由模型产生的 2)多场景样本不足。模型包括用户自发行为（如主动搜索，指不受推荐系统影响的行为）的预训练，和用户隐反馈上的微调</p><ul><li>电子商务中的排序根据上下文和排序对象的不同可以分为三类：1)商品推荐，对象是商品; 2)意图推荐，对象是query; 3)商品搜索，对象是商品，上下文是query</li><li>relate work包含4个领域：<strong>learn to rank; 多场景学习(multi-senario LTR) ；自监督学习;意图推荐(intent reommendation)</strong></li><li>预训练任务：预测下一个搜索词。微调任务：各个场景的CTR任务。微调先是用全场景的点击作为y进行第一阶段微调，再用各自场景的点击进行第二阶段微调。微调时商品和query的embedding向量是固定的，其他特征是可变的</li></ul><h3 id="【to粗】2021-DUMN-【加入负反馈-显反馈对隐反馈去噪】"><a href="#【to粗】2021-DUMN-【加入负反馈-显反馈对隐反馈去噪】" class="headerlink" title="【to粗】2021[DUMN]【加入负反馈+显反馈对隐反馈去噪】"></a>【to粗】2021[DUMN]【加入负反馈+显反馈对隐反馈去噪】</h3><p>2021(Alibaba)(ACM)[DUMN]Denoising User-aware Memory Network for Recommendation</p><p>简介：最近推荐领域非常多的工作聚焦在用户行为建模。用户的反馈包含显式和隐式的，大部分工作忽略了<strong>隐式反馈的噪音</strong>（用显示反馈对隐式反馈进行去噪），这会导致对于用户兴趣的有偏理解，本文1）通过正交映射( orthogonal mapping)对隐反馈进行去噪  2)基于内存的用户长期行为建模  3)短期行为和长期行为的融合。输入包括4个部分，<strong>显示反馈：喜欢，不喜欢 ；隐式反馈：点击，未点击</strong></p><ul><li>外卖场景下的显示隐式反馈是什么？？？<img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228150641871.png" alt="image-20220228150641871" style="zoom:50%;"></li></ul><h3 id="【to粗】2020-CIKM-DMT"><a href="#【to粗】2020-CIKM-DMT" class="headerlink" title="【to粗】2020(CIKM)[DMT]"></a>【to粗】2020(CIKM)[DMT]</h3><p>2020(CIKM)(JD)[DMT]Deep Multifaceted Transformers for Multi-objective Ranking in Large- Scale E-commerce Recommender Systems</p><p>Gu, Y.; Ding, Z.; Wang, S.; Zou, L.; Liu, Y.; Yin, D. Deep Multifaceted Transformers for Multi-Objective Ranking in Large-Scale E-Commerce Recommender Systems. In <em>Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>; ACM: Virtual Event Ireland, 2020; pp 2493–2500. <a href="https://doi.org/10.1145/3340531.3412697">https://doi.org/10.1145/3340531.3412697</a>.</p><h2 id="【粗】"><a href="#【粗】" class="headerlink" title="【粗】"></a>【粗】</h2><h2 id="Post-Ranking"><a href="#Post-Ranking" class="headerlink" title="Post_Ranking"></a>Post_Ranking</h2><h2 id="Multi-task"><a href="#Multi-task" class="headerlink" title="Multi-task"></a>Multi-task</h2><h2 id="Graph-Neural-Network"><a href="#Graph-Neural-Network" class="headerlink" title="Graph_Neural_Network"></a>Graph_Neural_Network</h2><h2 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer_Learning"></a>Transfer_Learning</h2><h2 id="Reignforcement-Learning"><a href="#Reignforcement-Learning" class="headerlink" title="Reignforcement_Learning"></a>Reignforcement_Learning</h2><h2 id="Self-Supervised-Learning"><a href="#Self-Supervised-Learning" class="headerlink" title="Self_Supervised_Learning"></a>Self_Supervised_Learning</h2><h2 id="Corporation"><a href="#Corporation" class="headerlink" title="Corporation"></a>Corporation</h2><h2 id="New-Papers"><a href="#New-Papers" class="headerlink" title="New_Papers"></a>New_Papers</h2><h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><h2 id="Maching"><a href="#Maching" class="headerlink" title="Maching"></a>Maching</h2><h2 id><a href="#" class="headerlink" title=" "></a> </h2><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p> <a href="https://github.com/guyulongcs/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising">Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</a></p><p><a href="https://mp.weixin.qq.com/s/lOCcPexEs9xRwcnfGIdXVw">WSDM2022推荐系统论文集锦</a></p><p><a href="https://mp.weixin.qq.com/s/hRLq9Q3NBZcj16uSKHPQaA">WWW 2022 推荐系统和广告相关论文整理分类</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;搜广推领域文献阅读，文献整理来源于git仓库  &lt;a href=&quot;https://github.com/TessieHe/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising&quot;&gt;Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;【to粗】表示待粗读&lt;/p&gt;
&lt;p&gt;【粗】表示已粗读&lt;/p&gt;
&lt;p&gt;【to精】表示待精读&lt;/p&gt;
&lt;p&gt;【精】表示已精读&lt;/p&gt;
&lt;p&gt;没有标注表示还没看&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
      <category term="Learning to Rank" scheme="http://tessiehe.github.io/tags/Learning-to-Rank/"/>
    
      <category term="Multi-Scenario" scheme="http://tessiehe.github.io/tags/Multi-Scenario/"/>
    
      <category term="Intent Recommendation" scheme="http://tessiehe.github.io/tags/Intent-Recommendation/"/>
    
      <category term="Recommender System" scheme="http://tessiehe.github.io/tags/Recommender-System/"/>
    
      <category term="E-commerce" scheme="http://tessiehe.github.io/tags/E-commerce/"/>
    
  </entry>
  
  <entry>
    <title>FM</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/FM/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/FM/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T03:59:30.994Z</updated>
    
    <content type="html"><![CDATA[<p>FM</p><span id="more"></span><h1 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h1><h1 id="为什么时间复杂度是O-kn"><a href="#为什么时间复杂度是O-kn" class="headerlink" title="为什么时间复杂度是O(kn)"></a>为什么时间复杂度是O(kn)</h1><p>我们考虑二次项</p><p>哇塞，这么复杂的公式怎么看得懂，我们一步步来，其实很简单。</p><p>第一步，拆解过程如图</p><p> 拆解</p><p>第二步，向量点乘</p><p>第三步，将k求和提出来</p><p>第四步，左边i和j式子相同，可以认为两者相等，直接得出平方</p><p>到此，很明显，它的计算复杂度为O(kn)，左边求和之后平方，右边平方后求和，没有出现</p><p>接下来我们看看FM如何收敛，照常使用SGD，计算FM的梯度是：</p><p>求Xi的梯度，令Xj固定，则第三项左边求和是一个定值，与Xi无关。时间复杂度为O(kn)</p><p>FM也可以扩展到更高阶的形式</p><p>到这，我们可以推断，FM能够在O(kn)时间复杂度处理特征间关联问题。</p><p>作者：邹金伟</p><p>链接：</p><p><a href="https://www.jianshu.com/p/67b4f7ec919e">https://www.jianshu.com/p/67b4f7ec919e</a></p><p>来源：简书</p><p>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h1 id="为什么能处理稀疏矩阵"><a href="#为什么能处理稀疏矩阵" class="headerlink" title="为什么能处理稀疏矩阵"></a>为什么能处理稀疏矩阵</h1><blockquote><ul><li>用$<v_i,v_j>$代替$W$,理论依据是任何一个正定阵$W$都可表视为  $W=V\cdot V^T$, 其中$W \in (n<em>n),V\in (n</em>k)$, 只要k足够大。</v_i,v_j></li><li>FM中通过选定一个较小的超参k可捕捉交叉特征稀疏空间的联</li></ul></blockquote><p>​                        </p><p>那么，这和SVM相比有什么优势呢，SVM通过相应的核函数也能做到。还记得我们开头说的吗，相比SVM，FM能够胜任稀疏矩阵。</p><p>首先我们来看一下SVM如何处理特征间关联问题。SVM的公式是：</p><p>选用合适的核函数，这里我们设d=2， 例如</p><p>展开后公式可得</p><p>通过大量的数据训练，我们也能够得出对应的Weight。但是，如果特征i，和特征j没有同时出现呢。例如，从来没有一个人既买过啤酒，又买过烧鸭，那么你能认为某个人买完啤酒后不会再买烧鸭吗？这就是数据稀疏时候出现的问题，这时候Wi,j没有对应的x值训练。FM通过Vi *  Vj来确定W，那么只要其他记录有Vi，和Vj，不用同时出现，就可以分别对其进行训练，最后通过点乘来确定值。这牺牲了Wi,j一点自由度，却能够很好的处理稀疏矩阵的问题。</p><p>链接：</p><p><a href="https://www.jianshu.com/p/67b4f7ec919e">https://www.jianshu.com/p/67b4f7ec919e</a></p><p>来源：简书</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;FM&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>LDA算法</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/LDA%E7%AE%97%E6%B3%95/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/LDA算法/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T03:59:30.994Z</updated>
    
    <content type="html"><![CDATA[<p>LDA算法</p><span id="more"></span><h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>PLSA </p><p>每篇文章有个<script type="math/tex">\theta_i</script>确定每篇文章到topic的概率分布</p><p>每个topic_j有个<script type="math/tex">\phi_j</script>确定每篇文章到词的概率分布</p><p>求解theta_i，phi_j</p><p>LDA</p><p>每篇文i章有个alpha（对每篇文章都一样，是依靠先验人工设置的） 确定的地理克雷分布确定theta_i，由theta_i确定文章i到topic的概率分布</p><p>每个topic_j有个beta（对每个词都一样，是依靠先验人工设置的） 确定的地理克雷分布确定 phi_j, 由phi_j 确定topic_j到词的概率分布</p><p>求解theta_i，phi_j</p><h1 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h1><p>LDA</p><ol><li>每篇文i章有个alpha（对每篇文章都一样，是依靠先验人工设置的） 确定的地理克雷分布确定theta_i，由theta_i确定文章i到topic的概率分布</li></ol><script type="math/tex; mode=display">\theta_i=P_d(\alpha) \\P(j|i) = P_{mult}(\theta_i) \\文章i到各个topic_j的分布由\theta_i确定,其中P_d是狄利克雷分布，P_{mult}是多项式分布</script><ol><li>每个topic_j有个beta（对每个词都一样，是依靠先验人工设置的） 确定的地理克雷分布确定 phi_j, 由phi_j 确定topic_j到词的概率分布</li></ol><script type="math/tex; mode=display">\phi_j=P_d(\beta) \\P(k|j) = P_{mult}(\phi_j) \\topic_j到词k的分布由\phi_j确定,其中P_d是狄利克雷分布，P_{mult}是多项式分布</script><ol><li>求解theta_i，phi_j</li></ol><h1 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;LDA算法&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>Learning to Rank：Point-wise、Pair-wise 和 List-wise区别</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Learning%20to%20Rank%EF%BC%9APoint-wise%E3%80%81Pair-wise%20%E5%92%8C%20List-wise%E5%8C%BA%E5%88%AB/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/Learning to Rank：Point-wise、Pair-wise 和 List-wise区别/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T03:59:30.984Z</updated>
    
    <content type="html"><![CDATA[<p>Learning to Rank：Point-wise、Pair-wise 和 List-wise区别</p><span id="more"></span><h1 id="Learning-to-Rank：Point-wise、Pair-wise-和-List-wise区别"><a href="#Learning-to-Rank：Point-wise、Pair-wise-和-List-wise区别" class="headerlink" title="Learning to Rank：Point-wise、Pair-wise 和 List-wise区别"></a>Learning to Rank：Point-wise、Pair-wise 和 List-wise区别</h1><p><img src="https://csdnimg.cn/release/phoenix/template/new_img/reprint.png" alt="img"></p><p><a href="https://me.csdn.net/weixin_34005042">weixin_34005042</a> 2018-09-29 15:19:00 <img src="https://csdnimg.cn/release/phoenix/template/new_img/articleRead.png" alt="img"> 4131 <img src="https://csdnimg.cn/release/phoenix/template/new_img/tobarCollectionActive.png" alt="img"> 已收藏 4</p><p> 机器学习的 ranking 技术——learning2rank，包括 pointwise、pairwise、listwise 三大类型。</p><p> <img src="https://img2018.cnblogs.com/blog/818082/201809/818082-20180929163323836-2075825354.png" alt="img"></p><p><a href="https://stackoverflow.com/questions/17411986/what-is-the-difference-between-point-wise-and-pair-wise-ranking-in-machine-learn">【Ref-1】</a>给出的：</p><Point wise ranking 类似于回归><p>Point wise ranking is analogous to regression. Each point has an associated rank score, and you want to predict that rank score. So your labeled data set will have a feature vector and associated rank score given a query</p><p>IE: {d1, r1} {d2, r2} {d3, r3} {d4, r4}</p><p>where r1 &gt; r2 &gt; r3 &gt;r4</p><Pairwise ranking 类似于分类><p>Pairwise ranking is analogous to classification. Each data point is associated with another data point, and the goal is to learn a classifier which will predict which of the two is “more” relevant to a given query.</p><p>IE: {d1 &gt; d2} {d2 &gt; d3} {d3 &gt; d4}</p><h1 id="1、Pointwise-Approach"><a href="#1、Pointwise-Approach" class="headerlink" title="\1、Pointwise Approach**"></a><strong><em>\</em>1、Pointwise Approach**</strong></h1><h2 id="1-1-特点"><a href="#1-1-特点" class="headerlink" title="　　*\*1.1 特点****"></a>　　<strong>*\</strong>*1.1 特点**<em>**</em></h2><p>　　Pointwise 类方法，其 L2R 框架具有以下特征：</p><ul><li>输入空间中样本是单个 doc（和对应 query）构成的特征向量；</li><li>输出空间中样本是单个 doc（和对应 query）的相关度；</li><li>假设空间中样本是打分函数；</li><li>损失函数评估单个 doc 的预测得分和真实得分之间差异。</li></ul><p>　　这里讨论下，关于人工标注标签怎么转换到 pointwise 类方法的输出空间：</p><ol><li>如果标注直接是相关度 s_j，则 doc x_j 的真实标签定义为 y_j=s_j</li><li>如果标注是 pairwise preference s_{u,v}，则 doc x_j 的真实标签可以利用该 doc 击败了其他 docs 的频次</li><li>如果标注是整体排序 π，则 doc x_j 的真实标签可以利用映射函数，如将 doc 的排序位置序号当作真实标签</li></ol><h2 id="1-2-根据使用的-ML-方法不同，pointwise-类可以进一步分成三类：基于回归的算法、基于分类的算法，基于有序回归的算法。"><a href="#1-2-根据使用的-ML-方法不同，pointwise-类可以进一步分成三类：基于回归的算法、基于分类的算法，基于有序回归的算法。" class="headerlink" title="　　1.2 根据使用的 ML 方法不同，pointwise 类可以进一步分成三类：基于回归的算法、基于分类的算法，基于有序回归的算法。"></a>　　1.2 根据使用的 ML 方法不同，pointwise 类可以进一步分成三类：基于回归的算法、基于分类的算法，基于有序回归的算法。</h2><p>　　（1）基于回归的算法</p><p>　　　　此时，输出空间包含的是实值相关度得分。采用 ML 中传统的回归方法即可。</p><p>　　（2）基于分类的算法</p><p>　　　　此时，输出空间包含的是无序类别。对于二分类，SVM、LR 等均可；对于多分类，提升树等均可。</p><p>　　（3）基于有序回归的算法</p><p>　　　　此时，输出空间包含的是有序类别。通常是找到一个打分函数，然后用一系列阈值对得分进行分割，得到有序类别。采用 PRanking、基于 margin 的方法都可以。</p><h2 id="1-3-缺陷"><a href="#1-3-缺陷" class="headerlink" title="　　1.3 缺陷"></a>　　1.3 缺陷</h2><p>　　　　回顾概述中提到的评估指标应该基于 query 和 position，</p><ul><li>ranking 追求的是排序结果，并不要求精确打分，只要有相对打分即可。</li><li>pointwise 类方法并没有考虑同一个 query 对应的 docs 间的内部依赖性。一方面，导致输入空间内的样本不是 IID 的，违反了 ML 的基本假设，另一方面，没有充分利用这种样本间的结构性。其次，当不同 query 对应不同数量的 docs 时，整体 loss 将会被对应 docs 数量大的 query 组所支配，前面说过应该每组 query 都是等价的。</li><li>损失函数也没有 model 到预测排序中的位置信息。因此，损失函数可能无意的过多强调那些不重要的 docs，即那些排序在后面对用户体验影响小的 doc。</li></ul><h2 id="1-4-改进"><a href="#1-4-改进" class="headerlink" title="　　1.4 改进"></a>　　1.4 改进</h2><p>　　　　如在 loss 中引入基于 query 的正则化因子的 RankCosine 方法。</p><h1 id="2、Pairwise-Approach"><a href="#2、Pairwise-Approach" class="headerlink" title="2、Pairwise Approach"></a>2、Pairwise Approach</h1><h2 id="2-1-特点"><a href="#2-1-特点" class="headerlink" title="　  2.1 特点"></a>　  2.1 特点</h2><p>　　Pairwise 类方法，其 L2R 框架具有以下特征：</p><ul><li>输入空间中样本是（同一 query 对应的）两个 doc（和对应 query）构成的两个特征向量；</li><li>输出空间中样本是 pairwise preference；</li><li>假设空间中样本是二变量函数；</li><li>损失函数评估 doc pair 的预测 preference 和真实 preference 之间差异。</li></ul><p>　　这里讨论下，关于人工标注标签怎么转换到 pairwise 类方法的输出空间：</p><ol><li>如果标注直接是相关度 s_j，则 doc pair (x_u,x_v) 的真实标签定义为 y_{u,v}=2*I_{s_u&gt;s_v}-1</li><li>如果标注是 pairwise preference s_{u,v}，则 doc pair (x_u,x_v) 的真实标签定义为y_{u,v}=s_{u,v}</li><li>如果标注是整体排序 π，则 doc pair (x_u,x_v) 的真实标签定义为y_{u,v}=2*I_{π_u,π_v}-1</li></ol><h2 id="2-2-基于二分类的算法"><a href="#2-2-基于二分类的算法" class="headerlink" title="　　2.2 基于二分类的算法　　"></a>　　2.2 基于二分类的算法　　</h2><p>　　Pairwise 类方法基本就是使用二分类算法即可。</p><p>　　经典的算法有 基于 NN 的 SortNet，基于 NN 的 RankNet，基于 fidelity loss 的 FRank，基于 AdaBoost 的 RankBoost，基于 SVM 的 RankingSVM，基于提升树的 GBRank。</p><h2 id="2-3-缺陷"><a href="#2-3-缺陷" class="headerlink" title="　　2.3 缺陷"></a>　　2.3 缺陷</h2><p>　　虽然 pairwise 类相较 pointwise 类 model 到一些 doc pair 间的相对顺序信息，但还是存在不少问题，回顾概述中提到的评估指标应该基于 query 和 position，</p><ul><li>如果人工标注给定的是第一种和第三种，即已包含多有序类别，那么转化成 pairwise preference 时必定会损失掉一些更细粒度的相关度标注信息。</li><li>doc pair 的数量将是 doc 数量的二次，从而 pointwise 类方法就存在的 query 间 doc 数量的不平衡性将在 pairwise 类方法中进一步放大。</li><li>pairwise 类方法相对 pointwise 类方法对噪声标注更敏感，即一个错误标注会引起多个 doc pair 标注错误。</li><li>pairwise 类方法仅考虑了 doc pair 的相对位置，损失函数还是没有 model 到预测排序中的位置信息。</li><li>pairwise 类方法也没有考虑同一个 query 对应的 doc pair 间的内部依赖性，即输入空间内的样本并不是 IID 的，违反了 ML 的基本假设，并且也没有充分利用这种样本间的结构性。</li></ul><h2 id="2-4-改进"><a href="#2-4-改进" class="headerlink" title="　　2.4 改进"></a>　　2.4 改进</h2><p>　　　pairwise 类方法也有一些尝试，去一定程度解决上述缺陷，比如：</p><ul><li>Multiple hyperplane ranker，主要针对前述第一个缺陷</li><li>magnitude-preserving ranking，主要针对前述第一个缺陷</li><li>IRSVM，主要针对前述第二个缺陷</li><li>采用 Sigmoid 进行改进的 pairwise 方法，主要针对前述第三个缺陷</li><li>P-norm push，主要针对前述第四个缺陷</li><li>Ordered weighted average ranking，主要针对前述第四个缺陷</li><li>LambdaRank，主要针对前述第四个缺陷</li><li>Sparse ranker，主要针对前述第四个缺陷</li></ul><p> 　<strong><em>\</em>3、Listwise Approach**</strong></p><h2 id="3-1-特点"><a href="#3-1-特点" class="headerlink" title="　　3.1 特点　　"></a>　　3.1 特点　　</h2><p>　　Listwise 类方法，其 L2R 框架具有以下特征：</p><ul><li>输入空间中样本是（同一 query 对应的）所有 doc（与对应的 query）构成的多个特征向量（列表）；</li><li>输出空间中样本是这些 doc（和对应 query）的相关度排序列表或者排列；</li><li>假设空间中样本是多变量函数，对于 docs 得到其排列，实践中，通常是一个打分函数，根据打分函数对所有 docs 的打分进行排序得到 docs 相关度的排列；</li><li>损失函数分成两类，一类是直接和评价指标相关的，还有一类不是直接相关的。具体后面介绍。</li></ul><p>　　这里讨论下，关于人工标注标签怎么转换到 listwise 类方法的输出空间：</p><ol><li>如果标注直接是相关度 s_j，则 doc set 的真实标签可以利用相关度 s_j 进行比较构造出排列</li><li>如果标注是 pairwise preference s_{u,v}，则 doc set 的真实标签也可以利用所有 s_{u,v} 进行比较构造出排列</li><li>如果标注是整体排序 π，则 doc set 则可以直接得到真实标签</li></ol><h2 id="3-2-根据损失函数构造方式的不同，listwise-类可以分成两类直接基于评价指标的算法，间接基于评价指标的算法。"><a href="#3-2-根据损失函数构造方式的不同，listwise-类可以分成两类直接基于评价指标的算法，间接基于评价指标的算法。" class="headerlink" title="　　3.2 根据损失函数构造方式的不同，listwise 类可以分成两类直接基于评价指标的算法，间接基于评价指标的算法。"></a>　　3.2 根据损失函数构造方式的不同，listwise 类可以分成两类直接基于评价指标的算法，间接基于评价指标的算法。</h2><p>　　　（1）直接基于评价指标的算法</p><p>　　直接取优化 ranking 的评价指标，也算是 listwise 中最直观的方法。但这并不简单，因为前面说过评价指标都是离散不可微的，具体处理方式有这么几种：</p><ul><li>优化基于评价指标的 ranking error 的连续可微的近似，这种方法就可以直接应用已有的优化方法，如SoftRank，ApproximateRank，SmoothRank</li><li>优化基于评价指标的 ranking error 的连续可微的上界，如 SVM-MAP，SVM-NDCG，PermuRank</li><li>使用可以优化非平滑目标函数的优化技术，如 AdaRank，RankGP</li></ul><p>　　上述方法的优化目标都是直接和 ranking 的评价指标有关。现在来考虑一个概念，informativeness。通常认为一个更有信息量的指标，可以产生更有效的排序模型。而多层评价指标（NDCG）相较二元评价（AP）指标通常更富信息量。因此，有时虽然使用信息量更少的指标来评估模型，但仍然可以使用更富信息量的指标来作为 loss 进行模型训练。</p><p>　　  （2）非直接基于评价指标的算法</p><p>　　这里，不再使用和评价指标相关的 loss 来优化模型，而是设计能衡量模型输出与真实排列之间差异的 loss，如此获得的模型在评价指标上也能获得不错的性能。<br>　　经典的如 ，ListNet，ListMLE，StructRank，BoltzRank。</p><h2 id="3-3-缺陷"><a href="#3-3-缺陷" class="headerlink" title="　　3.3 缺陷"></a>　　3.3 缺陷</h2><p>listwise 类相较 pointwise、pairwise 对 ranking 的 model 更自然，解决了 ranking 应该基于 query 和 position 问题。</p><p>listwise 类存在的主要缺陷是：一些 ranking 算法需要基于排列来计算 loss，从而使得训练复杂度较高，如 ListNet和 BoltzRank。此外，位置信息并没有在 loss 中得到充分利用，可以考虑在 ListNet 和 ListMLE 的 loss 中引入位置折扣因子。</p><h2 id="3-4-改进"><a href="#3-4-改进" class="headerlink" title="　　3.4 改进"></a>　　3.4 改进</h2><p>　　　pairwise 类方法也有一些尝试，去一定程度解决上述缺陷，比如：</p><ul><li>Multiple hyperplane ranker，主要针对前述第一个缺陷</li><li>magnitude-preserving ranking，主要针对前述第一个缺陷</li><li>IRSVM，主要针对前述第二个缺陷</li><li>采用 Sigmoid 进行改进的 pairwise 方法，主要针对前述第三个缺陷</li><li>P-norm push，主要针对前述第四个缺陷</li><li>Ordered weighted average ranking，主要针对前述第四个缺陷</li><li>LambdaRank，主要针对前述第四个缺陷</li><li>Sparse ranker，主要针对前述第四个缺陷</li></ul><p>以上，<strong>这三大类方法主要区别在于损失函数。不同的损失函数决定了不同的模型学习过程和输入输出空间。</strong></p><p>rating数据集：</p><p>：所以关于这个问题，是要使用topN=1的对吗？并把指标改为 AUC和 NDCG对吗？</p><p>——是这样，这个是一个rating数据集。</p><p>如果是按照pairwise ranking的正确率，应该是我们的oPR和oMRR，PR和MAP都是没有用的。</p><p>如果不按照pairwise，（按照listwise），就是AUC和NDCG，所以我让你算那个。</p><p>当然还有就是按照数值，（按照pointwise），RMSE，不过我们的没法计算RMSE。</p><p>：啊这个“不按照pairwise”，没太明白，还是按照原来的思路，用的 winner 和 loser 比较对呀。尤其在这个rating数据集，是每个比较对当成一个session，这点还是不变的吧？？</p><p>——这不就是pairwise吗？</p><p>rating是可以按照每个用户得到一个排序的，这是listwise，也就是算出NDCG，AUC的指标。</p><p>还可以按照pointwise，每个分数预测的怎么样，就是RMSE。</p><p>【Reference】</p><p>1、<a href="https://stackoverflow.com/questions/17411986/what-is-the-difference-between-point-wise-and-pair-wise-ranking-in-machine-learn">What is the difference between point-wise and pair-wise ranking in machine learning</a></p><p>2、<a href="https://blog.csdn.net/lipengcn/article/details/80373744">学习排序 Learning to Rank：从 pointwise 和 pairwise 到 listwise，经典模型与优缺点</a></p><p>3、<a href="https://cloud.tencent.com/developer/news/135904">基于 Pairwise 和 Listwise 的排序学习</a></p></Pairwise></Point>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Learning to Rank：Point-wise、Pair-wise 和 List-wise区别&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>Uplift Modeling</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Uplift%20Modeling/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/Uplift Modeling/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T03:59:30.990Z</updated>
    
    <content type="html"><![CDATA[<p>Uplift Modeling</p><span id="more"></span><p>Uplift Modeling</p><h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>增量模型，用于预估某种干预对结果的因果关系（ITE，Individual Treatment Effect），即预测：</p><h1 id="基本假设"><a href="#基本假设" class="headerlink" title="基本假设"></a>基本假设</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Uplift Modeling&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>Exact-K Recommendation</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%5Bcomment%5DExact-K%20Recommendation/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/[comment]Exact-K Recommendation/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T04:02:16.574Z</updated>
    
    <content type="html"><![CDATA[<p>Exact-K Recommendation</p><span id="more"></span><p>Exact-K Recommendation via Maximal Clique Optimization</p><h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><blockquote><ol><li>传统的top k推荐基于的假设是要把点击概率最高的商品排在前面</li><li>exact-K目标是通过排序优化K个商品的联合概率</li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Exact-K Recommendation&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>XGBOOST文献</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%5Bcomment%5DXGBOOST%E6%96%87%E7%8C%AE/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/[comment]XGBOOST文献/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T04:02:26.966Z</updated>
    
    <content type="html"><![CDATA[<p>XGBOOST文献</p><span id="more"></span><h1 id="XGBOOST文献笔记"><a href="#XGBOOST文献笔记" class="headerlink" title="XGBOOST文献笔记"></a>XGBOOST文献笔记</h1><p><a href="http://delivery.acm.org/10.1145/2940000/2939785/p785-chen.pdf?ip=111.200.23.13&amp;id=2939785&amp;acc=CHORUS&amp;key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;__acm__=1536805596_740dd7db7cc67a94ca9b28d83bd32678">http://delivery.acm.org/10.1145/2940000/2939785/p785-chen.pdf?ip=111.200.23.13&amp;id=2939785&amp;acc=CHORUS&amp;key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;__acm__=1536805596_740dd7db7cc67a94ca9b28d83bd32678</a></p><h2 id="决策相关知识点"><a href="#决策相关知识点" class="headerlink" title="决策相关知识点"></a>决策相关知识点</h2><ul><li><p>输入特征是连续特征&amp;离散特征</p><p>连续特征可直接输入，算法处理时暴力选择改特征划分点 或者按照该特征值的分布选择候选划分点</p><p>离散特征要进过one-hot后输入</p></li><li><p>输出是连续值（回归）&amp;离散值（分类）</p><p>回归：损失函数用均方误差</p><p>分类：损失函数用基尼值之类的</p></li><li><p>如何数值计算导数</p><p>$\frac{\partial J}{\partial \theta} = \lim_{\varepsilon \to 0} \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon} $</p></li></ul><h1 id="XGBoost-A-Scalable-Tree-Boosting-System"><a href="#XGBoost-A-Scalable-Tree-Boosting-System" class="headerlink" title="XGBoost: A Scalable Tree Boosting System"></a>XGBoost: A Scalable Tree Boosting System</h1><ul><li>字母解释</li></ul><p>$n:样本数 \\  m: 特征维度 \\  K:数的颗数 \\ D: 样本空间 \\ F:cart树空间 \\q:每棵树的结构\\ T：每棵树的叶子 \\ w:叶子权重 $</p><h2 id="与gradient-boosting相比改进的地方"><a href="#与gradient-boosting相比改进的地方" class="headerlink" title="与gradient boosting相比改进的地方"></a>与gradient boosting相比改进的地方</h2><blockquote><ol><li>增加正则项，防止过拟合。类似的方法用在RGF上</li><li>算每一颗数的loss时用$L_{t}=L_{t-1}+\Delta L\\  $，$\Delta L用L对\hat{y}_{t}$的二阶泰勒展开代替</li><li>优化时逐棵树优化，每棵树只在上一棵树的基础上分裂一次</li><li>叶子节点分裂时先对样本进行排序，分箱，再按分箱值进行分裂并筛选合适的分裂值。这样一方面能减少运算量，一方面可减轻过拟合, 为了保证每个分箱产生的loss均一，用残差的二阶导作为分箱依据（Weighted Quantile）</li></ol></blockquote><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>$\hat{y_i}=\sum_{i=1}^{K}w_i$</p><p>当正则项为0时，目标函数就跟传统的gradient tree boosting一样</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>低t轮迭代时（第t棵树），对于第i个样本，用一阶倒数近似就是$y_i^{t}=y_i^{t-1}+f_t(x_i)$，损失函数就是</p><p>第二棵树开始，每棵树预测残差</p><p>只要确定了树结构，二阶近似有以上的最优解。但实际上无法确定树结构，即无法全局优化，所以采用贪婪地逐个叶子优化：</p><p>其中$L_{split}$是一个节点分裂前的loss-分裂后的loss，$L_{split}$越大越好</p><h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><p>解读：</p><p>首先对将全量样本分别按照各个特征排序，分箱（百分位数），箱值即为之后树分裂会用到的值；</p><p>假设前一颗数有两个叶子节点，生成第三棵树时：</p><ol><li>对第一个叶子节点上的sample<ol><li>计算各个分箱值时score，取使得score最大的分箱值</li><li>同样的方法遍历所有特征，得到各个特征在第一个节点上的最佳分裂值及score</li><li>选择score最大的特征及对应分分裂值</li></ol></li><li>同样的方式得到第二个叶子节点上的sample最佳分裂特征和分裂值</li><li>比较score，选择score最大的节点及特征及分裂值</li></ol><blockquote><p>分箱方法有两个：global variant 和 local variant</p><p>global variant是全局分箱，计算量少，但需要数据量大，分箱粒度大，不适合太深的树</p><p>local variant是每个叶子节点上的数据进行分箱</p></blockquote><h2 id="weighted-quantile"><a href="#weighted-quantile" class="headerlink" title="weighted quantile"></a>weighted quantile</h2><p>解读：</p><p>不是按特征值大小排序，按百分位分箱，而是构造特征排序函数r，其中h是残差在特征x上的二阶导。</p><p>推导：</p><p>loss函数$\sum_{i=1}^n=\sum_{k=1}^k\sum_{i\in z_j}\frac{h_i}{2}（f_t-\frac{g_i}{h_i}）+  ….$</p><p>rankz函数$r_k$的构造可以保证每个分箱上的loss的高阶系数是均一的，这样能加速优化</p><h2 id="Sparsity-aware-Split-Finding-空值"><a href="#Sparsity-aware-Split-Finding-空值" class="headerlink" title="Sparsity-aware Split Finding(空值)"></a>Sparsity-aware Split Finding(空值)</h2><p>处理每一个分支时默认空值朝左或者朝右，找到最合适的方向</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;XGBOOST文献&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning based Recommender System A Survey and New Perspectives</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%5Bcomment%5DDeep%20Learning%20based%20Recommender%20System%20A%20Survey%20and%20New%20Perspectives/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/[comment]Deep Learning based Recommender System A Survey and New Perspectives/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T04:02:12.188Z</updated>
    
    <content type="html"><![CDATA[<p>Deep Learning based Recommender System A Survey and New Perspectives</p><span id="more"></span><h1 id="【PAPER-COMMENT】Deep-Learning-based-Recommender-System-A-Survey-and-New-Perspectives"><a href="#【PAPER-COMMENT】Deep-Learning-based-Recommender-System-A-Survey-and-New-Perspectives" class="headerlink" title="【PAPER COMMENT】Deep Learning based Recommender System: A Survey and New Perspectives"></a>【PAPER COMMENT】Deep Learning based Recommender System: A Survey and New Perspectives</h1><p>high-profile conferences ： NIPS, ICML, ICLR,KDD,WWW, SIGIR, WSDM, RecSys,<br>[TOC]</p><h2 id="2-OVERVIEW-OF-RECOMMENDER-SYSTEMS-AND-DEEP-LEARNING"><a href="#2-OVERVIEW-OF-RECOMMENDER-SYSTEMS-AND-DEEP-LEARNING" class="headerlink" title="2 OVERVIEW OF RECOMMENDER SYSTEMS AND DEEP LEARNING"></a>2 OVERVIEW OF RECOMMENDER SYSTEMS AND DEEP LEARNING</h2><h3 id="2-1-Rrecommendation-System"><a href="#2-1-Rrecommendation-System" class="headerlink" title="2.1 Rrecommendation System"></a>2.1 Rrecommendation System</h3><ul><li>recommendation system classification:<ul><li>CF(Interaction pnly): learning from user-item historical interactions, including explicit and implicit feedback</li><li>Content based: learning from auxiliary information( feature engineering)</li><li>Hybrid<h3 id="2-2-Deep-Learning-Techniques"><a href="#2-2-Deep-Learning-Techniques" class="headerlink" title="2.2 Deep Learning Techniques"></a>2.2 Deep Learning Techniques</h3>deep learning: <em>deep representation</em></li></ul></li><li><code>Multilayer Perceptiron(MLP)</code> :多层感知机 learning hierarchical feature representations</li><li><code>Autoencoder(AE)</code>: bottleneck  layer (the middle-most layer) is used as a salient feature representation of the input<br>data.</li><li><code>CNN</code>:It performs well in processing data with grid-like topology (网络拓扑结构的data)</li><li><code>RNN,LSTM, GRU</code></li><li><em><code>Restricted Boltzman Machine(RBM)</code></em></li><li><code>Adversarial Networks (AN)</code></li><li><code>Atentional Models</code></li><li><p><code>Deep Reinforcement Learning(DRL)</code>:consists of agents, environments, states, actions and rewards</p><h3 id="2-3-Why-DNN-for-Recommendation"><a href="#2-3-Why-DNN-for-Recommendation" class="headerlink" title="2.3 Why DNN for Recommendation"></a>2.3 Why DNN for Recommendation</h3><p>the sequential structure of session or click-logs are highly suitable for the inductive<br>biases provided by recurrent/convolutional models</p></li><li><p>Conten Bsed: When dealing with textual data (reviews, tweets ), image data (social posts, product images), CNNs/RNNs become indispensable neural building blocks.traditional alternative (designing modality-specific features etc.) becomes significantly less atractive and consequently </p></li><li>Interaction Only:  deep neural networks are justied when there is a huge amount of complexity or when there is<br><em>a large number of training instances</em> (用SGD的思想优化矩阵分解过程，可使用online数据，也可减少运算量，狭义的深度学习不适合）</li><li>ADVANTAGES：Nonlinear Transformation.（非线性拟合能力），Representation Learning（特征提取），Sequence Modelling(序列性特征)，Flexibility.(深度学习框架的模块化开发)<h2 id="3-DEEP-LEARNING-BASED-RECOMMENDATION-STATE-OF-THE-ART"><a href="#3-DEEP-LEARNING-BASED-RECOMMENDATION-STATE-OF-THE-ART" class="headerlink" title="3 DEEP LEARNING BASED RECOMMENDATION: STATE-OF-THE-ART"></a>3 DEEP LEARNING BASED RECOMMENDATION: STATE-OF-THE-ART</h2><h3 id="3-1-Categories-of-deep-learning-based-recommendation-models"><a href="#3-1-Categories-of-deep-learning-based-recommendation-models" class="headerlink" title="3.1 Categories of deep learning based recommendation models"></a>3.1 Categories of deep learning based recommendation models</h3></li><li>Recommendation with Neural Building Blocks：<code>MLP, AE, CNNs, RNNs, RBM, NADE,AM, AN and DRL based recommender system</code>。 <em>MLP</em> can easily model the non-linear interactions between users and items; <em>CNNs</em> are capable of extracting local and global representations from heterogeneous data(CNN 可用于异质的特征融合) sources such as textual and visual information; <em>RNNs</em>  enable the recommender system to model the temporal dynamics and sequential evolution of content information</li><li>Recommendation with Deep Hybrid Models:</li></ul><h3 id="3-2-MLP"><a href="#3-2-MLP" class="headerlink" title="3.2 MLP"></a>3.2 MLP</h3><ul><li><p><strong>Neural Extension of Traditional Recommendation Methods</strong>：<code>Neural Network Matrix Factorization (NNMF)</code>  and <code>Neural Collaborative Filtering(NCF)</code></p></li><li><p><strong>Feature Representation Learning with MLP.</strong> </p></li></ul><p><code>wide &amp; deep</code>wide 部分负责memorization，使用人工特征，deep部分负generalization（泛化），使用id特征（用户id，item id）。<a href="https://blog.csdn.net/u010352603/article/details/80590129#22-wide-part">https://blog.csdn.net/u010352603/article/details/80590129#22-wide-part</a></p><h3 id="3-3-Auto-encoder"><a href="#3-3-Auto-encoder" class="headerlink" title="3.3 Auto encoder"></a>3.3 Auto encoder</h3><h3 id="3-4-CNN"><a href="#3-4-CNN" class="headerlink" title="3.4 CNN"></a>3.4 CNN</h3><p>Tang et al. [143] presented sequential recommendation (with user identier) with CNNs, where two CNNs (hierarchical and vertical) are used to model the union-level sequential paerns and skip behaviors for sequence-aware recommendation</p><h3 id="3-5-RNN"><a href="#3-5-RNN" class="headerlink" title="3.5 RNN"></a>3.5 RNN</h3><ul><li>Session-Based（基于会话的推荐）<h2 id="4-Future-Rsearch-Directions-and-Open-Issues"><a href="#4-Future-Rsearch-Directions-and-Open-Issues" class="headerlink" title="4 Future Rsearch Directions and Open Issues"></a>4 Future Rsearch Directions and Open Issues</h2><h3 id="4-1-Joint-Representation-Learning-from-User-and-Item-Content-Information"><a href="#4-1-Joint-Representation-Learning-from-User-and-Item-Content-Information" class="headerlink" title="4.1 Joint Representation Learning from User and Item Content Information"></a>4.1 Joint Representation Learning from User and Item Content Information</h3>多种异质性信息的联合学习，如图片，text，side infomation <h3 id="4-2-Explainable-Recommendation-with-Deep-Leadrning"><a href="#4-2-Explainable-Recommendation-with-Deep-Leadrning" class="headerlink" title="4.2 Explainable Recommendation with Deep Leadrning"></a>4.2 Explainable Recommendation with Deep Leadrning</h3></li></ul><ol><li>to ussers: explainable prediction</li><li>to practitioner(从业者)： explainable weight<br><code>attention model</code> ： action weights give insights about the inner work of the model.<br>research dirextion:  <code>pre deep learning</code> <h3 id="4-3-Going-Deeper-for-Recommendation"><a href="#4-3-Going-Deeper-for-Recommendation" class="headerlink" title="4.3 Going Deeper for Recommendation"></a>4.3 Going Deeper for Recommendation</h3><h3 id="4-4-Machine-Reasoning-for-Recommendation"><a href="#4-4-Machine-Reasoning-for-Recommendation" class="headerlink" title="4.4 Machine Reasoning for Recommendation"></a>4.4 Machine Reasoning for Recommendation</h3><code>Machine Reasoning</code> 机理学习，通常用于文本和图像理解，很少用于推荐系统。担忧共通点，都是信息检索。interaction-only recommendation 跟<code>reasoning over meta-paths</code>很相似<h3 id="4-5-Cross-Domain-Recommendation-with-Deep-Neural-Networks"><a href="#4-5-Cross-Domain-Recommendation-with-Deep-Neural-Networks" class="headerlink" title="4.5 Cross Domain Recommendation with Deep Neural Networks"></a>4.5 Cross Domain Recommendation with Deep Neural Networks</h3>融合多个场景特征，可解决冷启动<br><code>transfer learning</code><h3 id="4-6-Deep-Multi-Task-Learning-for-Recommendation"><a href="#4-6-Deep-Multi-Task-Learning-for-Recommendation" class="headerlink" title="4.6 Deep Multi-Task Learning for Recommendation"></a>4.6 Deep Multi-Task Learning for Recommendation</h3>优点：<br>(1) learning several tasks at a time can prevent overfing by generalizing the shared hidden representations;减少过拟合，增加泛化<br>(2) auxiliary task provides interpretable output for explaining the recommendation;附加任务可增加可解释信<br>(3) multi-task provides an implicit data augmentation for alleviating the sparsity problem.减轻稀疏问题<h3 id="4-7-Scalability-of-Deep-Neural-Networks-for-Recommendation"><a href="#4-7-Scalability-of-Deep-Neural-Networks-for-Recommendation" class="headerlink" title="4.7 Scalability of Deep Neural Networks for Recommendation"></a>4.7 Scalability of Deep Neural Networks for Recommendation</h3>改进方向：<br>(1) incremental learning for non-stationary and streaming data such as large volume of incoming users<br>and items; 使用流式数据增量训练<br>(2) computation eficiency for high-dimensional tensors and multimedia data sources高维张量的计算效率<br>(3) balancing of the model complexity and scalability with the exponential growth of parameters<br>可能的解决方案：<br>(1) the key idea is to train a <code>smaller student</code> model that absorbs knowledge from the large<code>teacher model</code>.<br>(2) the high-dimensional input data can be compressed to compact embedding to reduce the space and computation time during model learning 压缩或者embedding稀疏编码</li></ol><h3 id="4-8-The-Field-Needs-Beer-More-Unified-and-Harder-Evaluation"><a href="#4-8-The-Field-Needs-Beer-More-Unified-and-Harder-Evaluation" class="headerlink" title="4.8 The Field Needs Beer, More Unified and Harder Evaluation"></a>4.8 The Field Needs Beer, More Unified and Harder Evaluation</h3><p>学术界没有统一的数据集，没有统一的评价标准，paper结果难以复现</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Deep Learning based Recommender System A Survey and New Perspectives&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>airbnb embedding</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%5Bcomment%5Dairbnb%20embedding/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/[comment]airbnb embedding/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T04:02:09.151Z</updated>
    
    <content type="html"><![CDATA[<p>[comment]</p><span id="more"></span><p>Real-time Personalization using Embeddings for Search<br>Ranking at Airbnb</p><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><ul><li>airbnb是租客与房东双向预测 -&gt; 解决方法：用pair wise的loss（每一对样本有正反馈和负反馈）</li></ul><h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><h2 id="Listing-Embedding"><a href="#Listing-Embedding" class="headerlink" title="Listing Embedding"></a>Listing Embedding</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[comment]&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>silk_road</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%5Bcomment%5Dsilk_road/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/[comment]silk_road/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T04:02:21.603Z</updated>
    
    <content type="html"><![CDATA[<p>silk_road</p><span id="more"></span><h1 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h1><p>基于购买行为的information domain 和 基于社交关系的 social domain联合推荐，最终实现对social domain中的用户进行item预</p><p>特点：</p><ol><li><p>info domain中用pooling的办法把交互特征和side information 融合在一起；</p><ol><li>bridge 用户很少；</li><li>两个网络时异质的</li></ol></li></ol><h2 id="名词解释："><a href="#名词解释：" class="headerlink" title="名词解释："></a>名词解释：</h2><h3 id="info-domain"><a href="#info-domain" class="headerlink" title="info-domain"></a>info-domain</h3><p>包括有交互特征$Y$和side info $G$ 。用户的G指的是一些tag标签，如喜欢自然，喜欢欧洲，一共有$v_u$个tag。item的G指的是item的一些标签（与用户标签对应的），如自然，欧洲，一共有$v_i$ 个tag。</p><script type="math/tex; mode=display">\begin{split}User_1&:&U_1&={\{u_t}\}_{t=1}^{M_1}  \\Item_1&:&I_1&=\{i_t\}_{t=1}^{m}  \\Interaction&:&Y&=\{y_{ij}\} \\Arttibute&:& \\&&G_u&=\{g_1^u,g_2^u\quad ...\quad g_{v_u}^u\} \\&&G_i&=\{g_1^i,g_1^i \quad ... \quad g_{v_i}^i\}\end{split}</script><h3 id="social-domain"><a href="#social-domain" class="headerlink" title="social-domain"></a>social-domain</h3><script type="math/tex; mode=display">User_2:U_2=\{u_t^{'}\}_{t=1}^{M_2} \\Interaction: S=\{s_{u{'},u^{''}}\}</script><h1 id="Solution-NSCR"><a href="#Solution-NSCR" class="headerlink" title="Solution: NSCR"></a>Solution: NSCR</h1><p>Neural Social Collaborative Ranking (NSCR)</p><h2 id="info-domain-1"><a href="#info-domain-1" class="headerlink" title="info-domain"></a>info-domain</h2><h3 id="pairwise-pooling"><a href="#pairwise-pooling" class="headerlink" title="pairwise pooling"></a>pairwise pooling</h3><h3 id="pairwise-loss"><a href="#pairwise-loss" class="headerlink" title="pairwise loss"></a>pairwise loss</h3><p>其中$y_{u,i}=1,t_{u,j}=0$</p><h3 id="forward-propagation"><a href="#forward-propagation" class="headerlink" title="forward propagation"></a>forward propagation</h3><p>prediction:</p><h2 id="social-domain-1"><a href="#social-domain-1" class="headerlink" title="social-domain"></a>social-domain</h2><p>两个约束作为loss：</p><h3 id="平滑约束（smothness）"><a href="#平滑约束（smothness）" class="headerlink" title="平滑约束（smothness）"></a>平滑约束（smothness）</h3><p>$s_{u^{‘’},u^{‘’}} 越大，p_{u^{‘}},p_{u^{‘’}}就$</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;silk_road&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>中文分词</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/中文分词/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T03:59:30.981Z</updated>
    
    <content type="html"><![CDATA[<p>中文分词</p><span id="more"></span><p>[TOC]</p><h1 id="jieba分词"><a href="#jieba分词" class="headerlink" title="jieba分词"></a>jieba分词</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_corpus</span>(<span class="params">f_corpus</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param f_corpus: txt</span></span><br><span class="line"><span class="string">    :return: list</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(f_corpus, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;f_corpus lines: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(lines)))</span><br><span class="line">    <span class="built_in">print</span>(lines[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> lines</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stopwords</span>(<span class="params">f_stopwords</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param f_stopwords: txt</span></span><br><span class="line"><span class="string">    :return: list</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(f_stopwords, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        stopwords = f.readlines()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;stop words lines: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(stopwords)))</span><br><span class="line">    <span class="keyword">return</span> stopwords</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_keyword_dict</span>(<span class="params">filename</span>):</span></span><br><span class="line">    <span class="built_in">dict</span> = &#123;&#125;</span><br><span class="line">    keys = []</span><br><span class="line">    num=<span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        line = f.readline()</span><br><span class="line">        <span class="keyword">while</span> line :</span><br><span class="line">            num +=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> num % <span class="number">10000</span> ==<span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;line &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(num))</span><br><span class="line">            word = line.strip()</span><br><span class="line">            word = get_keyword(word).strip(<span class="string">&#x27;【&#x27;</span>).strip(<span class="string">&#x27;】&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> keys:</span><br><span class="line">                keys.append(word)</span><br><span class="line">                <span class="built_in">dict</span>[word] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">dict</span>[word] += <span class="number">1</span></span><br><span class="line">            line = f.readline()</span><br><span class="line">    <span class="built_in">dict</span> = <span class="built_in">sorted</span>(<span class="built_in">dict</span>.items(),key=<span class="keyword">lambda</span> s:s[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">dict</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main_count</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    统计词频</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    f_corpus = <span class="string">&#x27;part1.txt&#x27;</span></span><br><span class="line">    f_stopwords = <span class="string">&#x27;stopwords.txt&#x27;</span></span><br><span class="line">    f_count_words = <span class="string">&#x27;wordsCount_part1.txt&#x27;</span></span><br><span class="line">    corpus=get_corpus(f_corpus) <span class="comment">#list</span></span><br><span class="line">    stopwords=get_stopwords(f_stopwords) <span class="comment">#list</span></span><br><span class="line">    word_dic=count_word(corpus,stopwords) <span class="comment">#list</span></span><br><span class="line">    <span class="built_in">print</span> (word_dic)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(f_count_words):</span><br><span class="line">        os.system(<span class="string">r&quot;touch &#123;&#125;&quot;</span>.<span class="built_in">format</span>(f_count_words))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(f_count_words,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> word_dic:</span><br><span class="line">            res = i[<span class="number">0</span>].strip()+<span class="string">&#x27;\t&#x27;</span>+<span class="built_in">str</span>(i[<span class="number">1</span>])</span><br><span class="line">            f.write(res+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;done!&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;中文分词&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>吴恩达卷积神经网络笔记</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/吴恩达卷积神经网络笔记/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T03:59:30.987Z</updated>
    
    <content type="html"><![CDATA[<p>吴恩达卷积神经网络笔记</p><span id="more"></span><p>[TOC]</p><h1 id="第一周-卷积神经网络"><a href="#第一周-卷积神经网络" class="headerlink" title="第一周 卷积神经网络"></a>第一周 卷积神经网络</h1><h2 id="计算及视觉要解决的问题"><a href="#计算及视觉要解决的问题" class="headerlink" title="计算及视觉要解决的问题"></a>计算及视觉要解决的问题</h2><ul><li>Image Classification</li><li>Object detection<h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2></li><li>图像计算数据量非常大</li><li>所以需要通过卷积减少参数量</li></ul><h2 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h2><ul><li>valid padding: 不填充</li><li>same padding：输出和输入一样的size。步长为1时 p=(f-1)/2 ,f为卷积核的大小</li></ul><h2 id="stride（步长）"><a href="#stride（步长）" class="headerlink" title="stride（步长）"></a>stride（步长）</h2><ul><li>输出图像大小：floor[(n+2p-f)/s]+1<h2 id="多通道卷积"><a href="#多通道卷积" class="headerlink" title="多通道卷积"></a>多通道卷积</h2></li><li>卷积核的通道数=输入的通道数</li><li>一个卷积核将输入映射为单通道图片</li><li>卷积核的数量=输出图片的通道数</li><li>每个卷积核的bias是一个数<h2 id="pooling-池化"><a href="#pooling-池化" class="headerlink" title="pooling(池化)"></a>pooling(池化)</h2></li><li>max pooling: 只要过滤器检测到了特征，就保留下来<ul><li>输出的size和padding计算方法一致</li><li>pooling前后通道数目不变（跟卷积核不一样的地方）</li><li>没有参数需要学习<h2 id="使用卷积的意义"><a href="#使用卷积的意义" class="headerlink" title="使用卷积的意义"></a>使用卷积的意义</h2></li></ul></li><li>参数共享(parameter sharing):<ul><li>卷积核(过滤器)可通用语图片的各个位置</li></ul></li><li>稀疏连接(sparsity of connections)<ul><li>卷积后的图片每个像素点只与输入中卷集合大小的像素点有关，与其他像素点无关。这保证图片有平移不变性，即原始图片平移几个像素不太会导致结果的变化</li></ul></li></ul><h1 id="第二周-深度卷积网络：实例探究"><a href="#第二周-深度卷积网络：实例探究" class="headerlink" title="第二周 深度卷积网络：实例探究"></a>第二周 深度卷积网络：实例探究</h1><h2 id="经典网络"><a href="#经典网络" class="headerlink" title="经典网络"></a>经典网络</h2><ul><li>LeNet-5 (1998)</li><li>AlexNet</li><li>VGG</li><li>ResNet</li><li>Inception</li></ul><h2 id="LeNet-5-（1998）"><a href="#LeNet-5-（1998）" class="headerlink" title="LeNet-5 （1998）"></a>LeNet-5 （1998）</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-11 下午3.00.23.png" alt="屏幕快照 2019-11-11 下午3.00.23"></p><p>6w 参数</p><h2 id="AlexNet（2012）"><a href="#AlexNet（2012）" class="headerlink" title="AlexNet（2012）"></a>AlexNet（2012）</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-11 下午8.11.06.png" alt></p><p>6kw 参数</p><h2 id="VGG-2015"><a href="#VGG-2015" class="headerlink" title="VGG(2015)"></a>VGG(2015)</h2><p>用同样大小的卷积核（3*3 ， s=1, padding=same），同样的池化策略</p><h2 id="ResNet-2015"><a href="#ResNet-2015" class="headerlink" title="ResNet(2015)"></a>ResNet(2015)</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-11 下午8.20.45.png" alt="屏幕快照 2019-11-11 下午8.20.45"></p><p>随着层数增加，理论上来说损失会减少，但是实际上随着层数增加，对优化算法的要求越高，导致损失上升。</p><p>ResNet: $a_{l+1}=g(z(l+1)+a_l)$</p><h2 id="1-1卷积核"><a href="#1-1卷积核" class="headerlink" title="1*1卷积核"></a>1*1卷积核</h2><p>输入图片用1个1*1的卷积核座卷积意义是：输入图片各个通道加权成一个通道</p><h2 id="Inception-Network-2014"><a href="#Inception-Network-2014" class="headerlink" title="Inception Network(2014)"></a>Inception Network(2014)</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-11 下午8.40.29.png" alt="屏幕快照 2019-11-11 下午8.40.29"></p><h2 id="迁移学习-transfer-learning"><a href="#迁移学习-transfer-learning" class="headerlink" title="迁移学习 transfer learning"></a>迁移学习 transfer learning</h2><p>冻结前面几层，只训练最后一层全连接层。实现方案之一为：输入通过冻结的几层得到预计算输出，写入硬盘。之后每次从硬盘读入数据，训练最后几层网络，这样不需要每次迭代时都进行前面的计算。</p><p>或者只把下载的权重作为初始化，训练整个网络。</p><h2 id="数据扩充-data-augmentation"><a href="#数据扩充-data-augmentation" class="headerlink" title="数据扩充 data augmentation"></a>数据扩充 data augmentation</h2><p>当数据量不够时。</p><ul><li>镜像对称</li><li>随机剪裁</li><li>色彩转换 color shifting(PCA增强)</li></ul><h2 id="计算机视觉现状"><a href="#计算机视觉现状" class="headerlink" title="计算机视觉现状"></a>计算机视觉现状</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-11 下午8.56.18.png" alt="屏幕快照 2019-11-11 下午8.56.18"></p><p>数据量越少，人工特征提取越重要。</p><h1 id="第三周-目标检测"><a href="#第三周-目标检测" class="headerlink" title="第三周 目标检测"></a>第三周 目标检测</h1><h2 id="目标定位-localization-and-detection"><a href="#目标定位-localization-and-detection" class="headerlink" title="目标定位 localization and detection"></a>目标定位 localization and detection</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-12 下午6.32.06.png" alt="屏幕快照 2019-11-12 下午6.32.06"></p><ul><li><p>目标定位：图片中只有一个目标，要定位目标并识别目标。</p><p> 实现方法：输出除了类别向量外还有四个数：中心点x,y值，box长度，box高度</p></li><li><p>定义Y</p><p> 假设检测目标有三种，图片中最多只会有一个目标物体，则y为：</p><script type="math/tex; mode=display">\left[\begin{matrix}p_c\\b_x\\b_y\\b_h\\b_w\\c_1\\c_2\\c_3\end{matrix}\right]</script><p> 其中如果图片中有三种中的一种，则$p_c=1 $，$c_1,c_2,c_3$为对应的onehot向量。如果图片中没有目标种类的则$p_c=0$,其他数字为任意值</p></li><li><p>loss</p><script type="math/tex; mode=display">loss=\left\{\begin{matrix} \sum_{i=1}^8(y_i-\hat{y_i})^2,\quad if  \quad p_c=1\\ (y_i-\hat{y_i})^2,\quad else \end{matrix}\right.</script><p> 即如果图片中有目标物体，则loss包含每个y的分量误差。如果没有，则loss只计算$p_c$和预测值的误差。实际上y不同的部分可采用不同的误差，如$p_c$用logistic误差，b用均方误差，c用softmax误差</p></li></ul><h2 id="特征点检测"><a href="#特征点检测" class="headerlink" title="特征点检测"></a>特征点检测</h2><p>在图片分类的基础上做改造：y第一个元素实$p_c$,其他元素实特征点的坐标值。</p><p>体态检测也是一样，只不过特征点是关节点的坐标。要注意的实特征点的顺序需要是一致的。</p><h2 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h2><ul><li><p>滑动窗口 sliding window detection</p><ol><li>针对被检测物体（如车）训练图片分类网络</li><li><p>用不同大小的box扫过目标图片，并输出相应位置的概率</p><p>计算成本很大</p></li></ol></li></ul><h2 id="卷积的滑动窗口实现"><a href="#卷积的滑动窗口实现" class="headerlink" title="卷积的滑动窗口实现"></a>卷积的滑动窗口实现</h2><ul><li><p>FC层可用卷积实现，具体操作就是卷积核大小与输入相同，卷积核数量与FC的输出层相同。这种卷积表示与全连接的数学实现是一样的</p></li><li><p>将滑动窗口并卷积得到不同box的预测值—&gt;将整张图片进行卷积，最后输出的就是哥哥box对应的概率</p></li><li><p>问题：该方法隐式的预测bounding box的位置，结果不是很准确</p><p> 由于box的size是一定的（卷积网络的第一层卷积核大小），移动步长也是一定的(卷积网络的移动步长)</p></li></ul><h2 id="bounding-box预测"><a href="#bounding-box预测" class="headerlink" title="bounding box预测"></a>bounding box预测</h2><ul><li><p>YOLO (you only look once) 2015</p><p> 将问题简化为子图上的目标定位问题</p><ol><li>将图片分割，假设分割成3*3的小图</li><li>按照目标定位的方法对每个小图标定8维向量y，由于有9个小图，最终Y为3<em>3 </em> 8 的矢量</li><li>按照一般的方法进行训练。</li><li><p>预测时看每$\hat{Y}$的第一个分量，为1的地方就表示对应的子图有目标物体，对应的$b_i$即为box位置, 对应的$c_i$就是目标物体的种类</p><p>注意：</p></li><li><p>标定物体的时候如果物体横跨多个子图，物体只会被分配到一个图上。</p></li><li>标定$b_i$的时候用的是子图的相对比例坐标。$b_x,b_y$一定小于等于1，$b_x,b_y$可以大于1</li></ol></li><li><p>好处：</p><ol><li>bounding box大小和位置不受限制</li><li>只进行单词卷积，而非滑动多次卷积。这是由于滑动卷积过程中有很多计算实可以共享的</li></ol></li></ul><h2 id="交并比-intersection-over-union"><a href="#交并比-intersection-over-union" class="headerlink" title="交并比 intersection over union"></a>交并比 intersection over union</h2><p>用来评价目标检测模型好坏。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;吴恩达卷积神经网络笔记&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>时间序列模型</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/时间序列模型/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T03:59:30.977Z</updated>
    
    <content type="html"><![CDATA[<p>时间序列模型</p><span id="more"></span><hr><h2 id="typora-copy-images-to-image"><a href="#typora-copy-images-to-image" class="headerlink" title="typora-copy-images-to: ./image"></a>typora-copy-images-to: ./image</h2><h1 id="时间序列模型"><a href="#时间序列模型" class="headerlink" title="时间序列模型"></a>时间序列模型</h1><h2 id="WEEK1"><a href="#WEEK1" class="headerlink" title="WEEK1"></a>WEEK1</h2><ul><li><p>符号解释</p><p>$x^{(i)<t>}$:  第i个样本的第t维分量</t></p><p>$T_x^{(i)}$ : 第i个样本x的维度</p></li><li><p>主体抓取</p><ol><li><p>多对多模型</p></li><li><p>不能用全连接，因为输入和输出的长度不定，而且输入矩阵太大</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/E36DF04F-C0BD-42D3-9A0D-CA2F2B1C7DE9.png" alt="E36DF04F-C0BD-42D3-9A0D-CA2F2B1C7DE9"></p></li></ol></li></ul><p>$a^{<0>} = \vec{0}$</0></p><p>$a^{<1>} = g(W_{aa}a^{<0>} +W_{ax}x^{<1>} +b_a)$</1></0></1></p><p>$\hat{y}^{<1>} = g(W_{ya}a^{<1>}+b_y)$</1></1></p><ul><li>Forward propagation</li></ul><p>$a^{<t>} = g(W_{aa}a^{<t-1>} +W_{ax}x^{<t-1>}+b_a)$</t-1></t-1></t></p><p>$\hat{y^{<t>}} = g(W_{ya}a^{<t>}+b_y)$</t></t></p><p>为了简化模型，可把$W_{ax},W_{aa}$横向排列成为$W_a$，$a^{<t-1>},x^{t}$纵向排列</t-1></p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/D71818E3-4031-4EF4-99F4-BD47FC6BD0C5.png" alt="D71818E3-4031-4EF4-99F4-BD47FC6BD0C5"></p><ul><li><p>Back propagation</p><p>$L^{<t>} (\hat{y}^{<t>},y^{t}) = -y^{<t>}log(\hat{y})-(1-y^{<t>})log(1-\hat{y}^{<t>})$</t></t></t></t></t></p><p>$L(\hat{y},y) = \sum_{t=1}^{T_x}L^{<t>}(\hat{y}^{<t>},y^{<t>})$</t></t></t></p></li><li><p>Different types of RNN</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/FF3C6BD2-518A-480C-ADE5-3B71224C7DDB.png" alt="FF3C6BD2-518A-480C-ADE5-3B71224C7DDB"></p></li><li><p>Language model</p><ul><li><p>tokenize (one hot)</p></li><li><p><UNK>来编码非常用单词</UNK></p></li><li><p>目标：判断一个句子的概率</p><ul><li><p>训练：</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/FC45A4AF-B524-425F-8C28-14FF8C16B802.png" alt="ßFC45A4AF-B524-425F-8C28-14FF8C16B802"></p></li></ul></li></ul></li><li><p>Sample a sequence model from trained RNN</p><ul><li>初始化输入（零向量）</li><li>按照预测softmax后的概率sample出一个词</li><li>以新词作为输入，softmax预测下一个词的概率，按照概率分布sample出第二个词</li></ul></li><li><p>RNN的梯度消失</p><p>梯度爆炸可使用gradient clipping</p></li><li><p>GRU（Gradient Recurrent Unit）</p><ul><li><p>c:memory cell</p><p>$c^{<t>} = a^{<t>}$</t></t></p><p>$\hat{c}^{<t>}=tanh(W_c[c^{<t-1>},x^{<t>}]+b_c)$</t></t-1></t></p><p>$\Gamma_u=\sigma(W_u[c^{<t-1>},x^{<t>}]+b_u)$   (u: update,$\Gamma$ 约为0或1)</t></t-1></p><p>$c^{<t>} = \Gamma_u\hat{c}^{<t>} +(1-\Gamma_u)c^{<t-1>}$  （$\Gamma$维度和c一样；elemet wise multiply）</t-1></t></t></p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/05728660-E7EF-4289-9665-45E6653B03F5.png" alt="05728660-E7EF-4289-9665-45E6653B03F5"></p></li><li><p>Full GRU</p><p>$\hat{c}^{<t>} = tanh(Wc[\Gamma_r*c^{<t-1>},x^{<t>}]+b_c)$</t></t-1></t></p><p>$\Gamma_r=\sigma(W_r[c^{<t-1>},x^{t}]+b_c)$</t-1></p><p>$\Gamma _u=\sigma(W_u[c^{<t-1>},x^{<t>}]+b_u)$</t></t-1></p><p>$c^{<t>} = \Gamma_u<em>\hat{c}^{<t>}+(1-\Gamma_u)</t></em>c^{<t-1>}$</t-1></t></p><p>$a^{<t>} = c^{<t>}$</t></t></p><p>​</p></li></ul></li><li><p>LSTM (Long Short Term Memory)</p><p>$\hat{c}^{<t>} = tanh(W_c[a^{<t-1>},x^{<t>}]+b_c)$</t></t-1></t></p><p>$\Gamma_u=\sigma(W_u[a^{<t-1>},x^{<t>}]+b_u)$</t></t-1></p><p>$\Gamma_f=\sigma(W_f[a^{<t-1>},x^{<t>}]+b_f)$</t></t-1></p><p>$\Gamma_o=\sigma(W_o[a^{<t-1>},x^{<t>}]+b_o)$</t></t-1></p><p>$c^{<t>}=\Gamma_u<em>\hat{c}^{<t>}+\Gamma_f</t></em>c^{<t-1>}$</t-1></t></p><p>$a^{<t>}=\Gamma_o*c^{<t>}$</t></t></p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/C9ED60FC-BEA6-49F4-A735-90C7B76F782D.png" alt="C9ED60FC-BEA6-49F4-A735-90C7B76F782D"></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;时间序列模型&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>机器学习基础</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/机器学习基础/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T03:59:30.976Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习基础</p><span id="more"></span><p>[TOC]</p><h1 id="Woe"><a href="#Woe" class="headerlink" title="Woe"></a>Woe</h1><p>WOE的全称是“weight of evidence”，即证据权重, WOE表示的含义即是”<strong>当前分组中响应客户占所有响应客户的比例”和”当前分组中没有响应的客户占所有没有响应客户的比例</strong>“的差异。先把分析变量进行分箱，每个分箱内的$w_{oe}$为</p><script type="math/tex; mode=display">woe_i=\frac{当前分组中响应客户占所有响应客户的比例}{当前分组中没有响应的客户占所有没有响应客户的比例}=ln\frac{P_{y_i}}{P_{n_i}}=ln\frac{y_1/y_2}{n_i/n_s}</script><script type="math/tex; mode=display">woe_i=\frac{sum(y_i)/sum(y_s)}{sum(1-y_i)/sum(1-y_s)}</script><p>该值绝对值越大说明变量区分能力越强</p><h1 id="IV"><a href="#IV" class="headerlink" title="IV"></a>IV</h1><p>IV衡量的是某一个变量的信息量，从公式来看的话，相当于是自变量WOE值的一个加权求和，其值的大小决定了自变量对于目标变量的影响程度</p><script type="math/tex; mode=display">IV_i=(P_{y_i}-P_{n_i})*woe_i</script><p>WOE 和 IV 都能表达某个分组对目标变量的预测能力。但实际中，我们通常选择 IV 而不是 WOE 的和来衡量变量预测的能力，这是为什么呢？首先，因为我们在衡量一个变量的预测能力时，我们所使用的指标值不应该是负数。从这意义上来说，IV 比 WOE 多乘以前面那个因子，就保证了它不会是负数；然后，乘以(Pyi−Pni)这个因子，体现出了变量当前分组中个体的数量占整体的比例，从而很好考虑了这个分组中样本占整体的比例，比例越低，这个分组对变量整体预测能力的贡献越低。相反，如果直接用 WOE 的绝对值加和，会因为该分组出现次数偏少的影响而得到一个很高的指标。</p><h1 id="AUC-amp-KS"><a href="#AUC-amp-KS" class="headerlink" title="AUC &amp; KS"></a>AUC &amp; KS</h1><h1 id="信息熵（information-entropy）"><a href="#信息熵（information-entropy）" class="headerlink" title="信息熵（information entropy）"></a>信息熵（information entropy）</h1><p>衡量样本纯度，熵越小越纯,样本D有K类样本，其信息熵为</p><script type="math/tex; mode=display">Ent(D)=-\sum_{k=1}^{K}p_klog_2p_k</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;机器学习基础&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅强化学习笔记</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/李宏毅强化学习笔记/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T03:59:30.983Z</updated>
    
    <content type="html"><![CDATA[<p>李宏毅强化学习笔记</p><span id="more"></span><p>[TOC]</p><h1 id="PART1"><a href="#PART1" class="headerlink" title="PART1"></a>PART1</h1><p><strong>什么是强化学习</strong></p><p>强化学习决策过程包括4个环节：agent观察环境（observation）—-agent做出动作（action）——动作会引起环境的变化 —- agent得到奖励（reward）—-agent再次观察环境（observation）。强化学习就是通过学习实现agent的决策序列收益（reward）最大。</p><p><strong>强化学习的分类</strong></p><p>policy based, grade based, model based。 这三种方式其实是不同的reward方式</p><h1 id="PART-2"><a href="#PART-2" class="headerlink" title="PART 2"></a>PART 2</h1><h1 id="PART-3"><a href="#PART-3" class="headerlink" title="PART 3"></a>PART 3</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;李宏毅强化学习笔记&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>深度学习笔记</title>
    <link href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://tessiehe.github.io/2022/03/01/2_算法相关/深度学习笔记/</id>
    <published>2022-03-01T03:32:38.000Z</published>
    <updated>2022-03-01T03:59:30.989Z</updated>
    
    <content type="html"><![CDATA[<p>深度学习笔记</p><span id="more"></span><h1 id="深度学习笔记"><a href="#深度学习笔记" class="headerlink" title="深度学习笔记"></a>深度学习笔记</h1><h2 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h2><ul><li><p>基本思想：</p><p>深度网络对输入的分布式敏感的，若采用mini-batch方法训练模型，则每次样本分布式不同的。不仅第一层如此，由于非线性的变换，后面每一层的输入（即前一层的输出）的分布都是不一样的，不符合IID独立同分布假设，模型训练也会越来越困难，也就是所谓的internal covariate shift问题。所以考虑在每一层的线下变换后，非线性变化之前，将输出强制变换为0-1分布。</p><p>这样做是受图像处理中的白化（whiten）操作的启发：就是对输入数据分布变换到0均值，单位方差的正态分布</p><p>所以本质就是：<strong>对于每个隐层神经元，把逐渐向非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0方差为1的比较标准的正态分布，使得非线性变换函数的输入值落入对输入比较敏感的区域，以此避免梯度消失问题。</strong> </p><p>但是，都通过BN，那么不就跟把非线性函数替换成线性函数效果相同了？这意味着什么？我们知道，如果是多层的线性函数变换其实这个深层是没有意义的，因为多层线性网络跟一层线性网络是等价的。这意味着网络的<strong>表达能力</strong>下降了，这也意味着深度的意义就没有了。<strong>所以BN为了保证非线性的获得，对变换后的满足均值为0方差为1的x又进行了scale加上shift操作(y=scale*x+shift)</strong>，每个神经元增加了两个参数scale和shift参数，这两个参数是通过训练学习到的，意思是通过scale和shift把这个值从标准正态分布左移或者右移一点并长胖一点或者变瘦一点，每个实例挪动的程度不一样，这样等价于非线性函数的值从正中心周围的线性区往非线性区动了动。核心思想应该是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠非线性区两头使得网络收敛速度太慢。 </p></li><li><p>流程：</p><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1541386887738.png" alt="1541386887738"></p></li><li><p>inference过程：</p><p>由于inference过程只有一个实例，无法获得期望和方差，可用全局方差代替。具体来说就是记住每一个mini-batch的方差和期望，然后统计出全局统计量</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;深度学习笔记&lt;/p&gt;
    
    </summary>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
    
      <category term="default" scheme="http://tessiehe.github.io/tags/default/"/>
    
      <category term="算法相关" scheme="http://tessiehe.github.io/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/"/>
    
  </entry>
  
</feed>
