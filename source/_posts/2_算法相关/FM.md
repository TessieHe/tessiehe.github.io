---
title: FM
date: 2022-03-01 11:32:38
tags:
    - 算法相关
    - default
categories: 
    - 算法相关
---

FM

<!-- more -->


# 模型介绍

![1571637924127](FM.assets/1571637924127.png)

# 为什么时间复杂度是O(kn)

我们考虑二次项



![img](FM.assets/11944360-479d4c5f93627025.webp)



哇塞，这么复杂的公式怎么看得懂，我们一步步来，其实很简单。

第一步，拆解过程如图



![img](FM.assets/11944360-adafd0f533517322.webp)

 拆解

第二步，向量点乘

第三步，将k求和提出来

第四步，左边i和j式子相同，可以认为两者相等，直接得出平方

到此，很明显，它的计算复杂度为O(kn)，左边求和之后平方，右边平方后求和，没有出现



![img](FM.assets/11944360-c69f278cdaf982b5.webp)



接下来我们看看FM如何收敛，照常使用SGD，计算FM的梯度是：



![img](FM.assets/11944360-019eef148af27cb3.webp)



求Xi的梯度，令Xj固定，则第三项左边求和是一个定值，与Xi无关。时间复杂度为O(kn)

FM也可以扩展到更高阶的形式



![img](FM.assets/11944360-fe15425d75e7f0cc.webp)



到这，我们可以推断，FM能够在O(kn)时间复杂度处理特征间关联问题。

作者：邹金伟

链接：

https://www.jianshu.com/p/67b4f7ec919e

来源：简书

著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

# 为什么能处理稀疏矩阵



> - 用$<v_i,v_j>$代替$W$,理论依据是任何一个正定阵$W$都可表视为  $W=V\cdot V^T$, 其中$W \in (n*n),V\in (n*k)$, 只要k足够大。
> - FM中通过选定一个较小的超参k可捕捉交叉特征稀疏空间的联

​                        

那么，这和SVM相比有什么优势呢，SVM通过相应的核函数也能做到。还记得我们开头说的吗，相比SVM，FM能够胜任稀疏矩阵。

首先我们来看一下SVM如何处理特征间关联问题。SVM的公式是：



![img](FM.assets/11944360-2f4397b3680dc239.webp)



选用合适的核函数，这里我们设d=2， 例如



![img](FM.assets/11944360-f0de213892c4d1c6.webp)



展开后公式可得



![img](FM.assets/11944360-a70478586c11ed6f.webp)



通过大量的数据训练，我们也能够得出对应的Weight。但是，如果特征i，和特征j没有同时出现呢。例如，从来没有一个人既买过啤酒，又买过烧鸭，那么你能认为某个人买完啤酒后不会再买烧鸭吗？这就是数据稀疏时候出现的问题，这时候Wi,j没有对应的x值训练。FM通过Vi *  Vj来确定W，那么只要其他记录有Vi，和Vj，不用同时出现，就可以分别对其进行训练，最后通过点乘来确定值。这牺牲了Wi,j一点自由度，却能够很好的处理稀疏矩阵的问题。

链接：

https://www.jianshu.com/p/67b4f7ec919e

来源：简书

