<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>hexo_test</title>
    <url>/2022/03/04/hexo-test/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>marginnote</title>
    <url>/2022/03/01/%E6%96%87%E7%8C%AE%E6%9F%A5%E6%89%BETIPS/</url>
    <content><![CDATA[<p>文献查找的方法</p>
<span id="more"></span>
<h1 id="connected-paper"><a href="#connected-paper" class="headerlink" title="connected paper"></a>connected paper</h1><ol>
<li>网址：connected paper</li>
<li>输入文献名称，点击build graph,页面将分为三个部分</li>
<li>Prior work引用的共同的，之前开创性的文章；  </li>
<li>derivative work 一些派生文献。</li>
</ol>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.bilibili.com/video/BV1m34y1C72y?-Arouter=story&amp;p=1&amp;share_medium=iphone&amp;share_plat=ios&amp;share_session_id=E531219F-B84B-452C-89A5-F92C67A3C5E7&amp;share_source=WEIXIN&amp;share_tag=s_i&amp;timestamp=1646010472&amp;unique_k=8pBkf0t&amp;share_times=1">AI帮你找文献，让你效率翻倍</a></p>
]]></content>
      <categories>
        <category>高效tips</category>
      </categories>
      <tags>
        <tag>高效tips</tag>
        <tag>default</tag>
      </tags>
  </entry>
  <entry>
    <title>01_日期操作</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/01_%E6%97%A5%E6%9C%9F%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<p>sql相关的日期操作</p>
<span id="more"></span>
<h2 id="一、日期运算"><a href="#一、日期运算" class="headerlink" title="一、日期运算"></a>一、日期运算</h2><h3 id="1-date-add"><a href="#1-date-add" class="headerlink" title="1. date_add"></a>1. date_add</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> date_add(<span class="string">&#x27;2017-09-15&#x27;</span>,<span class="number">1</span>) ;</span><br></pre></td></tr></table></figure>
<h3 id="2-date-sub"><a href="#2-date-sub" class="headerlink" title="2. date_sub"></a>2. date_sub</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> date_sub(<span class="string">&#x27;2017-09-15&#x27;</span>,<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<h3 id="3-datediff"><a href="#3-datediff" class="headerlink" title="3. datediff"></a>3. datediff</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> datediff(<span class="string">&#x27;2017-09-15&#x27;</span>,<span class="string">&#x27;2017-09-01&#x27;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="4-add-months"><a href="#4-add-months" class="headerlink" title="4. add_months"></a>4. add_months</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> add_months(<span class="string">&#x27;2017-02-27&#x27;</span>,<span class="number">-1</span>);</span><br><span class="line"><span class="comment">-- 2017-01-27</span></span><br><span class="line"><span class="keyword">select</span> add_months(<span class="string">&#x27;2017-02-01&#x27;</span>,<span class="number">-1</span>);</span><br><span class="line"><span class="comment">-- 2017-01-01</span></span><br><span class="line"><span class="keyword">select</span> add_months(<span class="string">&#x27;2017-02-28&#x27;</span>,<span class="number">-1</span>);</span><br><span class="line"><span class="comment">-- 2017-01-31</span></span><br></pre></td></tr></table></figure>
<h3 id="5-last-day"><a href="#5-last-day" class="headerlink" title="5. last_day"></a>5. last_day</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select last_day(&#x27;2018-09-22&#x27;);</span><br></pre></td></tr></table></figure>
<h3 id="6-months-between"><a href="#6-months-between" class="headerlink" title="6. months_between"></a>6. months_between</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> months_between(<span class="string">&#x27;2018-09-22&#x27;</span>,<span class="string">&#x27;2018-08-02&#x27;</span>);</span><br></pre></td></tr></table></figure>
<h2 id="二、日期转换"><a href="#二、日期转换" class="headerlink" title="二、日期转换"></a>二、日期转换</h2><h3 id="1-to-date"><a href="#1-to-date" class="headerlink" title="1. to_date"></a>1. to_date</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> to_date(<span class="string">&#x27;2017-09-15 11:12:00&#x27;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="2-from-unixtime"><a href="#2-from-unixtime" class="headerlink" title="2. from_unixtime"></a>2. from_unixtime</h3><p>时间戳转日期</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--时间戳转日期</span></span><br><span class="line"><span class="keyword">select</span> from_unixtime(<span class="number">1505456567</span>); </span><br><span class="line"><span class="keyword">select</span> from_unixtime(<span class="number">1505456567</span>,<span class="string">&#x27;yyyyMMdd&#x27;</span>); </span><br><span class="line"><span class="keyword">select</span> from_unixtime(<span class="number">1505456567</span>,<span class="string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>); </span><br><span class="line"><span class="keyword">select</span> from_unixtime(unix_timestamp(),<span class="string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>); <span class="comment">--获取系统当前时间</span></span><br></pre></td></tr></table></figure>
<p>方法1: from_unixtime+ unix_timestamp<br>—20171205转成2017-12-05<br>select from_unixtime(unix_timestamp(‘20171205’,’yyyymmdd’),’yyyy-mm-dd’) from dual;</p>
<p>—2017-12-05转成20171205<br>select from_unixtime(unix_timestamp(‘2017-12-05’,’yyyy-mm-dd’),’yyyymmdd’) from dual;</p>
<p>方法2: substr + concat<br>—20171205转成2017-12-05<br>select concat(substr(‘20171205’,1,4),’-‘,substr(‘20171205’,5,2),’-‘,substr(‘20171205’,7,2)) from dual;</p>
<p>—2017-12-05转成20171205<br>select concat(substr(‘2017-12-05’,1,4),substr(‘2017-12-05’,6,2),substr(‘2017-12-05’,9,2)) from dual;</p>
<p>————————————————<br>版权声明：本文为CSDN博主「开心果汁」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/u013421629/article/details/80068090">https://blog.csdn.net/u013421629/article/details/80068090</a></p>
<h2 id="三、自动获取日期"><a href="#三、自动获取日期" class="headerlink" title="三、自动获取日期"></a>三、自动获取日期</h2><h3 id="1-current-date"><a href="#1-current-date" class="headerlink" title="1. current_date"></a>1. current_date</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--其他日期函数</span></span><br><span class="line"><span class="comment">--查询当前系统时间(包括毫秒数): </span></span><br><span class="line"><span class="keyword">select</span> <span class="built_in">current_timestamp</span>;  </span><br><span class="line"><span class="comment">-- 查询当月第几天: </span></span><br><span class="line"><span class="keyword">select</span> dayofmonth(<span class="built_in">current_date</span>);</span><br><span class="line"><span class="comment">-- 月末</span></span><br><span class="line"><span class="keyword">select</span> last_day(<span class="built_in">current_date</span>);</span><br><span class="line"><span class="comment">-- 当月第1天</span></span><br><span class="line"><span class="keyword">select</span> date_sub(<span class="built_in">current_date</span>,dayofmonth(<span class="built_in">current_date</span>)<span class="number">-1</span>);</span><br><span class="line"><span class="comment">-- 下个月第1天</span></span><br><span class="line"><span class="keyword">select</span> add_months(date_sub(<span class="built_in">current_date</span>,dayofmonth(<span class="built_in">current_date</span>)<span class="number">-1</span>),<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<h3 id="2-sysdate"><a href="#2-sysdate" class="headerlink" title="2. sysdate"></a>2. sysdate</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> sysdate(<span class="number">-2</span>) ;</span><br></pre></td></tr></table></figure>
<h3 id="3-unix-timestamp"><a href="#3-unix-timestamp" class="headerlink" title="3. unix_timestamp"></a>3. unix_timestamp</h3><p>时间戳函数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--日期转时间戳：从1970-01-01 00:00:00 UTC到指定时间的秒数</span></span><br><span class="line"><span class="keyword">select</span> unix_timestamp(); <span class="comment">--获得当前时区的UNIX时间戳</span></span><br><span class="line"><span class="keyword">select</span> unix_timestamp(<span class="string">&#x27;2017-09-15 14:23:00&#x27;</span>); </span><br><span class="line"><span class="keyword">select</span> unix_timestamp(<span class="string">&#x27;2017-09-15 14:23:00&#x27;</span>,<span class="string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>);</span><br><span class="line"><span class="keyword">select</span> unix_timestamp(<span class="string">&#x27;20170915 14:23:00&#x27;</span>,<span class="string">&#x27;yyyyMMdd HH:mm:ss&#x27;</span>); </span><br></pre></td></tr></table></figure>
<h3 id="4-年月日"><a href="#4-年月日" class="headerlink" title="4. 年月日"></a>4. 年月日</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select year(dt),month(dt),day(dt),hour(dt),minute(dt),second(dt),weekofyear(dt);</span><br></pre></td></tr></table></figure>
<h3 id="5-trunc"><a href="#5-trunc" class="headerlink" title="5. trunc"></a>5. trunc</h3><p>获取月初、年初</p>
<p>&gt;</p>
<blockquote>
<p>trunc(date,format)  format:MONTH/MON/MM, YEAR/YYYY/YY</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> trunc(<span class="string">&#x27;2018-09-27&#x27;</span>,<span class="string">&#x27;YY&#x27;</span>) <span class="keyword">as</span> date_time,trunc(<span class="string">&#x27;2018-09-27 21:16:13&#x27;</span>,<span class="string">&#x27;MM&#x27;</span>) <span class="keyword">as</span> date_time1;</span><br><span class="line"></span><br><span class="line"><span class="comment">--date_time       date_time1</span></span><br><span class="line"><span class="comment">--2018-01-01      2018-09-01</span></span><br></pre></td></tr></table></figure>
<h3 id="6-next-day"><a href="#6-next-day" class="headerlink" title="6. next_day"></a>6. next_day</h3><p>当前日期下个星期X的日期</p>
<p>&gt;</p>
<blockquote>
<p>next_day(date,formate) format:英文星期几的缩写或者全拼</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> next_day(<span class="string">&#x27;2018-09-27&#x27;</span>,<span class="string">&#x27;TH&#x27;</span>) <span class="keyword">as</span> date_time,next_day(<span class="string">&#x27;2018-09-27 21:16:13&#x27;</span>,<span class="string">&#x27;TU&#x27;</span>) <span class="keyword">as</span> date_time1;</span><br><span class="line"><span class="comment">-- date_time       date_time1</span></span><br><span class="line"><span class="comment">-- 2018-10-04      2018-10-02</span></span><br></pre></td></tr></table></figure>
<pre><code> 2018-10-02
</code></pre><p>```</p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建hexo博客</title>
    <url>/2021/06/23/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/2021-06-23-%E6%90%AD%E5%BB%BAhexo%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<p>搭建hexo博客</p>
<span id="more"></span>
<p>[TOC]</p>
<pre><code>- 博客配置
</code></pre><hr>
<p>记录一下搭建博客的过程。</p>
<!-- more -->
<h2 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h2><p>参考内容：<a href="https://www.jianshu.com/p/9bbae1d105be">https://www.jianshu.com/p/9bbae1d105be</a></p>
<h2 id="配置hexo与更换Next主题"><a href="#配置hexo与更换Next主题" class="headerlink" title="配置hexo与更换Next主题"></a>配置hexo与更换Next主题</h2><p><strong>下载主题</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/theme-next/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>
<p>由于github被墙，使用代理科学上网后，clone经常报<code>OpenSSL SSL_connect</code>的错，因此我直接在网页上下载的zip包，解压到<code>themes/next</code>文件夹。</p>
<p><strong>页面报错</strong></p>
<p>跟换主题后重新<code>hexo s</code>，页面无法显示内容，提示以下信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% extends &#x27;_layout.swig&#x27; %&#125; &#123;% import &#x27;_macro/post.swig&#x27; as post_template %&#125; &#123;% import &#x27;_macro/sidebar.swig&#x27; as sidebar_template %&#125; &#123;% block title %&#125;&#123;&#123; page.title &#125;&#125; | &#123;&#123; config.title &#125;&#125;&#123;% endblock %&#125; &#123;% block page_class %&#125;page-post-detail&#123;% endblock %&#125; &#123;% block content %&#125;</span><br><span class="line">&#123;&#123; post_template.render(page) &#125;&#125;</span><br><span class="line">&#123;% if theme.jiathis %&#125; &#123;% include &#x27;_partials/share/jiathis.swig&#x27; %&#125; &#123;% elseif theme.baidushare %&#125; &#123;% include &#x27;_partials/share/baidushare.swig&#x27; %&#125; &#123;% elseif theme.add_this_id %&#125; &#123;% include &#x27;_partials/share/add-this.swig&#x27; %&#125; &#123;% elseif theme.duoshuo_shortname and theme.duoshuo_share %&#125; &#123;% include &#x27;_partials/share/duoshuo_share.swig&#x27; %&#125; &#123;% endif %&#125;</span><br><span class="line">&#123;% endblock %&#125; &#123;% block sidebar %&#125; &#123;&#123; sidebar_template.render(true) &#125;&#125; &#123;% endblock %&#125; &#123;% block script_extra %&#125; &#123;% include &#x27;_scripts/pages/post-details.swig&#x27; %&#125; &#123;% endblock %&#125;</span><br></pre></td></tr></table></figure>
<p>根据<a href="https://blog.csdn.net/qq_39898645/article/details/109181736">博客</a>介绍，原因是hexo在5.0之后把swig给删除了需要自己手动安装，安装后解决了该问题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm i hexo-renderer-swig</span><br></pre></td></tr></table></figure>
<p><strong>显示公式</strong></p>
<p>由于我的博客中有大量公式，页面中无法显示。参考<a href="https://www.jianshu.com/p/9b9c241146bc">博客</a>解决了该问题，问题的核心是配置好两个因素：mathjax和kramed。</p>
<p>添加mathjax</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-math --save</span><br><span class="line">npm install hexo-renderer-mathjax --save</span><br></pre></td></tr></table></figure>
<p>换渲染引擎</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure>
<p>由于我之前瞎试，装过pandoc，也要一起卸掉：<code>npm uninstall hexo-renderer-pandoc --save</code></p>
<p>修改渲染引擎的bug：到博客根目录下，找到node_modules\kramed\lib\rules\inline.js，第11行的 escape 变量：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,</span><br><span class="line">escape: /^\\([`*\[\]()#$+\-.!_&gt;])/,</span><br></pre></td></tr></table></figure>
<p>第20行的em变量：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br><span class="line">em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br></pre></td></tr></table></figure>
<p>配置.\themes\next\_config.yml</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># MathJax Support</span><br><span class="line">mathjax:</span><br><span class="line">  enable: true</span><br><span class="line">  per_page: true</span><br><span class="line">  engine: mathjax</span><br><span class="line">  cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML</span><br></pre></td></tr></table></figure>
<p>在文章的Front-matter里打开mathjax开关</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">title: Hierarchical Attention Networks for Document Classification</span><br><span class="line">date: 2021-06-23 09:26:17</span><br><span class="line">tags:</span><br><span class="line">    - 深度学习</span><br><span class="line">    - Attention</span><br><span class="line">    - Transformer</span><br><span class="line">    - 机器学习</span><br><span class="line">    - 每日论文</span><br><span class="line">    - 经典算法</span><br><span class="line">    - NLP</span><br><span class="line">mathjax: true</span><br></pre></td></tr></table></figure>
<p>重启以下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>
<p>到这里我的公式一部分能显示，一部分不能显示。继续查了查，发现别人也有这个情况，比如多行公式的时候显示不了，是因为不能出现连续的大括号<code>&#123;&#123;</code>​。我怀疑我的也是类似的问题，于是试了一下在我的<code>:公式</code>的结构中，把冒号删了，居然所有公式都正常显示了，然后我又把冒号加回去，还是都可以显示！！！不知道上面那堆设置需要时间起作用还是我的修改触发了什么，总之问题解决了。</p>
<p>后面有查了一些博客之后，推测更有可能是浏览器缓存导致的改动生效的延迟，刷新网页的时候应该<code>ctrl+F5</code>。</p>
<p>操作完这套后，<a href="http://localhost:4000">本地预览</a>可以正常显示公式，但github.io上却不行（有可能是我clean&amp;generate没有放在最后一步）。根据<a href="https://segmentfault.com/q/1010000007410421">大佬</a>的指示，我去查了一下github.io页面，确实有报错！</p>
<p>1 error</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Error with Permissions-Policy header: Unrecognized feature: &#x27;interest-cohort&#x27;.</span><br><span class="line"></span><br><span class="line">Mixed Content: The page at &#x27;https://wangdongdong122.github.io/&#x27; was loaded over HTTPS, but requested an insecure script &#x27;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#x27;. This request has been blocked; the content must be served over HTTPS.</span><br></pre></td></tr></table></figure>
<p>2 page errors</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Mixed content: load all resources via HTTPS to improve the security of your site</span><br><span class="line">Even though the initial HTML page is loaded over a secure HTTPS connection, some resources like images, stylesheets or scripts are being accessed over an insecure HTTP connection. Usage of insecure resources is restricted to strengthen the security of your entire site.</span><br><span class="line">To resolve this issue, load all resources over a secure HTTPS connection.</span><br><span class="line">1 request</span><br><span class="line">MathJax.js?config=TeX-AMS-MML_HTMLorMML</span><br><span class="line">1 resource</span><br><span class="line">Name	Restriction Status</span><br><span class="line">MathJax.js?config=TeX-AMS-MML_HTMLorMML	blocked</span><br></pre></td></tr></table></figure>
<p>google了一下错误内容，终于找到了<a href="https://github.com/github/pages-gem/issues/307">解决方案</a>，原来只是<code>node_modules/hexo-renderer-mathjax/mathjax.html</code>中的 <code>&lt;script&gt;</code> 少了个type，终于搞定了！！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Just if someone else face the same problem, you should use this:</span><br><span class="line"></span><br><span class="line">&lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure>
<p>最后再重启一次</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo clean #删除渲染</span><br><span class="line">hexo generate #由source渲染成静态网页</span><br><span class="line">hexo s #部署本地服务</span><br><span class="line">hexo d ##推送到远程</span><br></pre></td></tr></table></figure>
<h1 id="github备份blog源文件"><a href="#github备份blog源文件" class="headerlink" title="github备份blog源文件"></a>github备份blog源文件</h1><p>参考 <a href="https://zhuanlan.zhihu.com/p/122948913?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=810832757881208832">https://zhuanlan.zhihu.com/p/122948913?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=810832757881208832</a></p>
<h1 id="各种配置"><a href="#各种配置" class="headerlink" title="各种配置"></a>各种配置</h1><p><a href="https://blog.csdn.net/as480133937/article/details/100138838">Hexo-Next 主题博客个性化配置超详细，超全面(两万字)</a></p>
<h1 id="图片路径问题"><a href="#图片路径问题" class="headerlink" title="图片路径问题"></a>图片路径问题</h1><p><a href="https://www.npmjs.com/package/hexo-asset-image-for-hexo5">hexo插入图片的路径嵌套</a> ：markdown中图片插入方法,但是图片的文件夹必须和同名md文件在同一层级</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;img src=&quot;Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228150641871.png&quot; alt=&quot;image-20220228150641871&quot; style=&quot;zoom:50%;&quot; /&gt;</span><br></pre></td></tr></table></figure>
<h1 id="加粗字体高亮"><a href="#加粗字体高亮" class="headerlink" title="加粗字体高亮"></a>加粗字体高亮</h1><p><a href="https://blog.csdn.net/landada123/article/details/106111348">通过配置文件更改Typora的字体颜色</a></p>
<p>参考上面的，hexo是修改主题文件夹下 source/css/_common/scaffolding/normalize.styl中的strong配置</p>
<p><img src="/2021/06/23/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/2021-06-23-%E6%90%AD%E5%BB%BAhexo%E5%8D%9A%E5%AE%A2/image-20220304124934364.png" alt="image-20220304124934364" style="zoom:50%;"></p>
<h1 id="文章加密"><a href="#文章加密" class="headerlink" title="文章加密"></a>文章加密</h1><p><a href="https://www.jianshu.com/p/44e211829447">hexo文章加密</a></p>
<p>其实是修改 yourblogsite/themes/next/layout/_layout.swig</p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>配置环境&amp;安装工具</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言学习</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/C%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>C语言入门</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="环境与入门"><a href="#环境与入门" class="headerlink" title="环境与入门"></a>环境与入门</h1><h2 id="实例代码"><a href="#实例代码" class="headerlink" title="实例代码"></a>实例代码</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="comment">/* 我的第一个 C 程序 */</span></span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;Hello, World! \n&quot;</span>);</span><br><span class="line">   </span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>程序的第一行 <em>#include <stdio.h></stdio.h></em> 是<strong>预处理器指令</strong>，告诉 C 编译器在实际编译之前要包含 stdio.h 文件。</li>
<li>下一行 <em>int main()</em> 是主函数，程序从这里开始执行。</li>
<li>下一行 /<em>…</em>/ 将会被编译器忽略，这里放置程序的注释内容。它们被称为程序的注释。</li>
<li>下一行 <em>printf(…)</em> 是 C 中另一个可用的函数，会在屏幕上显示消息 “Hello, World!”。</li>
<li>下一行 <strong>return 0;</strong> 终止 main() 函数，并返回值 0。</li>
</ol>
<h2 id="编译-amp-执行C程序"><a href="#编译-amp-执行C程序" class="headerlink" title="编译&amp;执行C程序"></a>编译&amp;执行C程序</h2><ol>
<li>开一个文本编辑器，添加上述代码。</li>
<li>保存文件为 <em>hello.c</em>。</li>
<li>打开命令提示符，进入到保存文件所在的目录。</li>
<li>键入 <em>gcc hello.c</em>，输入回车，编译代码。</li>
<li>如果代码中没有错误，命令提示符会跳到下一行，并生成 <em>a.out</em> 可执行文件。</li>
<li>现在，键入 <em>a.out</em> 来执行程序。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gcc hello.c</span><br><span class="line">./a.out</span><br></pre></td></tr></table></figure>
<p>如果是多个 c 代码的源码文件，编译方法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc test1.c test2.c -o main.out</span><br><span class="line">$ ./main.out</span><br></pre></td></tr></table></figure>
<p>test1.c 与 test2.c 是两个源代码文件</p>
<h1 id="C语言基本语法"><a href="#C语言基本语法" class="headerlink" title="C语言基本语法"></a>C语言基本语法</h1><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//单行注释</span></span><br><span class="line"><span class="comment">/* 单行注释 */</span></span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment"> 多行注释</span></span><br><span class="line"><span class="comment"> 多行注释</span></span><br><span class="line"><span class="comment"> 多行注释</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>
<p>必须以分号结尾</p>
<h2 id="printf"><a href="#printf" class="headerlink" title="printf"></a>printf</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;打印整数 ： %d \n&quot;</span>,<span class="number">2</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">格式字符</th>
<th style="text-align:left">意义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">d</td>
<td style="text-align:left">以十进制形式输出带符号整数(正数不输出符号)</td>
</tr>
<tr>
<td style="text-align:left">o</td>
<td style="text-align:left">以八进制形式输出无符号整数(不输出前缀0)</td>
</tr>
<tr>
<td style="text-align:left">x,X</td>
<td style="text-align:left">以十六进制形式输出无符号整数(不输出前缀Ox)</td>
</tr>
<tr>
<td style="text-align:left">u</td>
<td style="text-align:left">以十进制形式输出无符号整数</td>
</tr>
<tr>
<td style="text-align:left">f</td>
<td style="text-align:left">以小数形式输出单、双精度实数</td>
</tr>
<tr>
<td style="text-align:left">e,E</td>
<td style="text-align:left">以指数形式输出单、双精度实数</td>
</tr>
<tr>
<td style="text-align:left">g,G</td>
<td style="text-align:left">以%f或%e中较短的输出宽度输出单、双精度实数</td>
</tr>
<tr>
<td style="text-align:left">c</td>
<td style="text-align:left">输出单个字符</td>
</tr>
<tr>
<td style="text-align:left">s</td>
<td style="text-align:left">输出字符串</td>
</tr>
<tr>
<td style="text-align:left">p</td>
<td style="text-align:left">输出指针地址</td>
</tr>
<tr>
<td style="text-align:left">lu</td>
<td style="text-align:left">32位无符号整数</td>
</tr>
<tr>
<td style="text-align:left">llu</td>
<td style="text-align:left">64位无符号整数</td>
</tr>
</tbody>
</table>
</div>
<h2 id="C数据类型"><a href="#C数据类型" class="headerlink" title="C数据类型"></a>C数据类型</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">序号</th>
<th style="text-align:left">类型与描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left"><strong>基本类型：</strong> 它们是算术类型，包括两种类型：整数类型和浮点类型。</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left"><strong>枚举类型：</strong> 它们也是算术类型，被用来定义在程序中只能赋予其一定的离散整数值的变量。</td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:left"><strong>void 类型：</strong> 类型说明符 <em>void</em> 表明没有可用的值。</td>
</tr>
<tr>
<td style="text-align:left">4</td>
<td style="text-align:left"><strong>派生类型：</strong> 它们包括：指针类型、数组类型、结构类型、共用体类型和函数类型。</td>
</tr>
</tbody>
</table>
</div>
<p>一个bite占8bit</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">类型</th>
<th style="text-align:left">存储大小</th>
<th style="text-align:left">值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">char</td>
<td style="text-align:left">1 字节</td>
<td style="text-align:left">-128 到 127 或 0 到 255</td>
</tr>
<tr>
<td style="text-align:left">int</td>
<td style="text-align:left">2 或 4 字节</td>
<td style="text-align:left">-32,768 到 32,767 或 -2,147,483,648 到 2,147,483,647</td>
</tr>
<tr>
<td style="text-align:left">short</td>
<td style="text-align:left">2 字节</td>
<td style="text-align:left">-32,768 到 32,767</td>
</tr>
<tr>
<td style="text-align:left">long</td>
<td style="text-align:left">4 字节</td>
<td style="text-align:left">-2,147,483,648 到 2,147,483,647</td>
</tr>
<tr>
<td style="text-align:left">float</td>
<td style="text-align:left">4 字节</td>
<td style="text-align:left">1.2E-38 到 3.4E+38</td>
</tr>
<tr>
<td style="text-align:left">double</td>
<td style="text-align:left">8 字节</td>
<td style="text-align:left">2.3E-308 到 1.7E+308</td>
</tr>
<tr>
<td style="text-align:left">long double</td>
<td style="text-align:left">16 字节</td>
<td style="text-align:left">3.4E-4932 到 1.1E+4932</td>
</tr>
</tbody>
</table>
</div>
<h2 id="变量的定义"><a href="#变量的定义" class="headerlink" title="变量的定义"></a>变量的定义</h2><p>变量只不过是程序可操作性的存储区的名称，每个变量有特定的类型，类型决定了变量存储的大小和布局</p>
<p>变量定义就是告诉编译器在何处创建变量的存储，以及如何创建变量的存储。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i,j,k;</span><br></pre></td></tr></table></figure>
<h2 id="变量的声明"><a href="#变量的声明" class="headerlink" title="变量的声明"></a>变量的声明</h2><p>变量声明向编译器保证变量以指定的类型和名称存在，这样编译器在不需要知道变量完整细节的情况下也能继续进一步的编译。变量声明只在编译时有它的意义，在程序连接时编译器需要实际的变量声明。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">int</span> i; <span class="comment">//声明，不是定义</span></span><br><span class="line"><span class="keyword">int</span> i; <span class="comment">//声明，也是定义</span></span><br></pre></td></tr></table></figure>
<p>变量的声明有两种情况：</p>
<ul>
<li><p>1、一种是需要建立存储空间的。例如：int a 在声明的时候就已经建立了存储空间。</p>
</li>
<li><p>2、另一种是不需要建立存储空间的，通过使用extern关键字声明变量名而不定义它。 例如：extern int a 其中变量 a 可以在别的文件中定义的。</p>
<p>除非有extern关键字，否则都是变量的定义。</p>
</li>
</ul>
<blockquote>
<p>如果需要在一个源文件中引用另外一个源文件中定义的变量，我们只需在引用的文件中将变量加上 extern 关键字的声明即可。</p>
</blockquote>
<ul>
<li><p>C 中有两种类型的表达式：</p>
<ol>
<li><strong>左值（lvalue）：</strong>指向内存位置的表达式被称为左值（lvalue）表达式。左值可以出现在赋值号的左边或右边。</li>
<li><strong>右值（rvalue）：</strong>术语右值（rvalue）指的是存储在内存中某些地址的数值。右值是不能对其进行赋值的表达式，也就是说，右值可以出现在赋值号的右边，但不能出现在赋值号的左边。</li>
</ol>
<p>变量是左值，因此可以出现在赋值号的左边。数值型的字面值是右值，因此不能被赋值，不能出现在赋值号的左边。  </p>
</li>
</ul>
<h2 id="整数常量"><a href="#整数常量" class="headerlink" title="整数常量"></a>整数常量</h2><p>整数常量可以是十进制、八进制或十六进制的常量。前缀指定基数：0x 或 0X 表示十六进制，0 表示八进制，不带前缀则默认表示十进制。</p>
<p>整数常量也可以带一个后缀，后缀是 U 和 L 的组合，U 表示无符号整数（unsigned），L 表示长整数（long）。后缀可以是大写，也可以是小写，U 和 L 的顺序任意</p>
<blockquote>
<p>85         /<em> 十进制 </em>/<br>0213       /<em> 八进制 </em>/<br>0x4b       /<em> 十六进制 </em>/<br>30         /<em> 整数 </em>/<br>30u        /<em> 无符号整数 </em>/<br>30l        /<em> 长整数 </em>/<br>30ul       /<em> 无符号长整数 </em>/</p>
</blockquote>
<h2 id="浮点常量"><a href="#浮点常量" class="headerlink" title="浮点常量"></a>浮点常量</h2><h2 id="定义常量"><a href="#定义常量" class="headerlink" title="定义常量"></a>定义常量</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> L1 10; <span class="comment">//使用的覅额与处理器</span></span></span><br><span class="line">count <span class="keyword">int</span> a=<span class="number">10</span> ;</span><br></pre></td></tr></table></figure>
<h2 id="存储类"><a href="#存储类" class="headerlink" title="存储类"></a>存储类</h2><p>存储类定义 C 程序中变量/函数的范围（可见性）和生命周期。这些说明符放置在它们所修饰的类型之前。下面列出 C 程序中可用的存储类：auto , register, static , extern</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="keyword">auto</span> <span class="keyword">int</span> mount;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="auto-存储类"><a href="#auto-存储类" class="headerlink" title="auto 存储类"></a>auto 存储类</h3><p>auto存储类是所有局部变量默认的存储类，只能修饰局部变量</p>
<h3 id="register-存储类"><a href="#register-存储类" class="headerlink" title="register 存储类"></a>register 存储类</h3><p><strong>register</strong> 存储类用于定义存储在寄存器中而不是 RAM 中的局部变量。这意味着变量的最大尺寸等于寄存器的大小（通常是一个词），且不能对它应用一元的 ‘&amp;’ 运算符（因为它没有内存位置）。</p>
<blockquote>
<p>寄存器只用于需要快速访问的变量，比如计数器</p>
</blockquote>
<h3 id="static-存储类"><a href="#static-存储类" class="headerlink" title="static 存储类"></a>static 存储类</h3><p><strong>static</strong> 存储类指示编译器在程序的生命周期内保持局部变量的存在，而不需要在每次它进入和离开作用域时进行创建和销毁。因此，</p>
<blockquote>
<p>使用 static 修饰局部变量可以在函数调用之间保持局部变量的值。(只初始化一次)</p>
</blockquote>
<p>static 修饰符也可以应用于全局变量。当 static 修饰全局变量时，会使变量的作用域限制在声明它的文件内。</p>
<blockquote>
<p>全局声明的一个 static 变量或方法可以被任何函数或方法调用，只要这些方法出现在跟 static 变量或方法同一个文件中。</p>
</blockquote>
<h3 id="extern-存储类"><a href="#extern-存储类" class="headerlink" title="extern 存储类"></a>extern 存储类</h3><p><strong>extern</strong> 存储类用于提供一个全局变量的引用，全局变量对所有的程序文件都是可见的。当您使用 <strong>extern</strong> 时，对于无法初始化的变量，会把变量名指向一个之前定义过的存储位置。</p>
<p>当您有多个文件且定义了一个可以在其他文件中使用的全局变量或函数时，可以在其他文件中使用 <em>extern</em> 来得到已定义的变量或函数的引用。可以这么理解，</p>
<blockquote>
<p><em>extern</em> 是用来在另一个文件中声明一个全局变量或函数。</p>
</blockquote>
<p>extern 修饰符通常用于当有两个或多个文件共享相同的全局变量或函数的时候，如下所示：</p>
<h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><h3 id="算数运算符"><a href="#算数运算符" class="headerlink" title="算数运算符"></a>算数运算符</h3><div class="table-container">
<table>
<thead>
<tr>
<th>/</th>
<th>分子除以分母，向下取整</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>a++ 先赋值后运算 ； ++ a 先运算后赋值</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h3 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h3><p>&amp;&amp;   ， ||  ， ！</p>
<h3 id="杂项运算符"><a href="#杂项运算符" class="headerlink" title="杂项运算符"></a>杂项运算符</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">运算符</th>
<th style="text-align:left">描述</th>
<th style="text-align:left">实例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">sizeof()</td>
<td style="text-align:left">返回变量的大小。</td>
<td style="text-align:left">sizeof(a) 将返回 4，其中 a 是整数。</td>
</tr>
<tr>
<td style="text-align:left">&amp;</td>
<td style="text-align:left">返回变量的地址。</td>
<td style="text-align:left">&a; 将给出变量的实际地址。</td>
</tr>
<tr>
<td style="text-align:left">*</td>
<td style="text-align:left">指向一个变量。</td>
<td style="text-align:left"><em>a; 将指向一个变量。（a为地址，</em>*a为该地址的变量）</td>
</tr>
<tr>
<td style="text-align:left">? :</td>
<td style="text-align:left">条件表达式</td>
<td style="text-align:left">如果条件为真 ? 则值为 X : 否则值为 Y</td>
</tr>
</tbody>
</table>
</div>
<h2 id="判断"><a href="#判断" class="headerlink" title="判断"></a>判断</h2><p>if , if…else ,  switch</p>
<p>C 语言把任何<strong>非零</strong>和<strong>非空</strong>的值假定为 <strong>true</strong>，把<strong>零</strong>或 <strong>null</strong> 假定为 <strong>false</strong>。</p>
<blockquote>
<p>运算符(三元运算符):  Exp1 ? Exp2 : Exp3;</p>
<p>如果exp1为真 则运行exp2，否则运行exp3</p>
</blockquote>
<h2 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h2><p>while ,  do … while , for</p>
<blockquote>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> ( init; condition; increment )</span><br><span class="line">&#123;</span><br><span class="line">   statement(s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="comment">/* for 循环执行 */</span></span><br><span class="line">   <span class="keyword">for</span>( <span class="keyword">int</span> a = <span class="number">10</span>; a &lt; <span class="number">20</span>; a = a + <span class="number">1</span> )</span><br><span class="line">   &#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">&quot;a 的值： %d\n&quot;</span>, a);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="循环控制语句"><a href="#循环控制语句" class="headerlink" title="循环控制语句"></a>循环控制语句</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">控制语句</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="https://www.runoob.com/cprogramming/c-break-statement.html">break 语句</a></td>
<td style="text-align:left">终止<strong>循环</strong>或 <strong>switch</strong> 语句，程序流将继续执行紧接着循环或 switch 的下一条语句。</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.runoob.com/cprogramming/c-continue-statement.html">continue 语句</a></td>
<td style="text-align:left">告诉一个循环体立刻停止本次循环迭代，重新开始下次循环迭代。</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.runoob.com/cprogramming/c-goto-statement.html">goto 语句</a></td>
<td style="text-align:left">将控制转移到被标记的语句。但是不建议在程序中使用 goto 语句。</td>
</tr>
</tbody>
</table>
</div>
<p>无限循环</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (;;)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;一直执行&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>每个 C 程序都至少有一个函数，即主函数 <strong>main()</strong> </p>
<p>函数还有很多叫法，比如方法、子例程或程序，等等。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">return_type <span class="title">function_name</span><span class="params">( parameter <span class="built_in">list</span> )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   body of the function</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在 C 语言中，函数由一个函数头和一个函数主体组成。下面列出一个函数的所有组成部分：</p>
<h3 id="函数声明"><a href="#函数声明" class="headerlink" title="函数声明"></a>函数声明</h3><p>在函数调用之前要进行声明</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">return_type <span class="title">function_name</span><span class="params">( parameter <span class="built_in">list</span> )</span></span>;</span><br></pre></td></tr></table></figure>
<p>针对上面定义的函数 max()，以下是函数声明：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int max(int num1, int num2);</span><br></pre></td></tr></table></figure>
<p>在函数声明中，参数的名称并不重要，只有参数的类型是必需的，因此下面也是有效的声明：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int max(int, int);</span><br></pre></td></tr></table></figure>
<h3 id="函数调用"><a href="#函数调用" class="headerlink" title="函数调用"></a>函数调用</h3><p>传值调用，引用调用</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/* 函数声明 */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> *x, <span class="keyword">int</span> *y)</span></span>; </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="comment">/* 局部变量定义 */</span></span><br><span class="line">   <span class="keyword">int</span> a = <span class="number">100</span>;</span><br><span class="line">   <span class="keyword">int</span> b = <span class="number">200</span>;</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;交换前，a 的值： %d\n&quot;</span>, a );</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;交换前，b 的值： %d\n&quot;</span>, b );</span><br><span class="line">   <span class="comment">/* 调用函数来交换值</span></span><br><span class="line"><span class="comment">    * &amp;a 表示指向 a 的指针，即变量 a 的地址</span></span><br><span class="line"><span class="comment">    * &amp;b 表示指向 b 的指针，即变量 b 的地址</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">   swap(&amp;a, &amp;b);</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;交换后，a 的值： %d\n&quot;</span>, a );</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;交换后，b 的值： %d\n&quot;</span>, b );</span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="作用域规则"><a href="#作用域规则" class="headerlink" title="作用域规则"></a>作用域规则</h2><p><strong>全局变量与局部变量在内存中的区别</strong>：</p>
<ul>
<li>全局变量保存在内存的全局存储区中，占用静态的存储单元；</li>
<li>局部变量保存在栈中，只有在所在函数被调用时才动态地为变量分配存储单元。</li>
</ul>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>VPN搭建</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/VPN%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>科学搭建~~~</p>
<span id="more"></span>
<p> VPN搭建</p>
<p>[TOC]</p>
<p><a href="https://zoomyale.com/2016/vultr_and_ss/"><strong>https://zoomyale.com/2016/vultr_and_ss/</strong></a></p>
<h1 id="配置服务器shadowsocks"><a href="#配置服务器shadowsocks" class="headerlink" title="配置服务器shadowsocks"></a>配置服务器shadowsocks</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh <span class="comment">#从github下载脚本（点击github对应文件raw，新网页的链接）</span></span><br><span class="line"></span><br><span class="line">chmod +x shadowsocks-all.sh  <span class="comment">#给执行权限</span></span><br><span class="line">./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log</span><br></pre></td></tr></table></figure>
<p><a href="https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh">repositry 链接</a></p>
<ul>
<li>用python版本安装</li>
<li>不使用混淆插件</li>
<li>info在/etc/shadowsocks-python文件夹下</li>
<li>修改端口后要 检查服务器shadowsocks是否运行</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/shadowsocks-libev status</span><br></pre></td></tr></table></figure>
<p>置信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nano /etc/shadowsocks-libev/config.json</span><br></pre></td></tr></table></figure>
<h1 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h1><p>如果某天你的 ss 突然无法使用了，很可能就是端口被封了。</p>
<p>这时你可以直接在这里，将端口修改为 1-65535 间任意其他数字。编辑完成后，按 Ctrl + X ，再输入 Y 并回车确认退出。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nano /etc/shadowsocks-libev/config.json</span><br></pre></td></tr></table></figure>
<p>需注意的是，如果你更新了配置文件，得重启 ss 才能生效。重启命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/shadowsocks-libev restart</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>XGB</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/XGB/</url>
    <content><![CDATA[<p>xgb包函数</p>
<span id="more"></span>
<h1 id="xgboost-sklearn-XGBClassifier"><a href="#xgboost-sklearn-XGBClassifier" class="headerlink" title="xgboost.sklearn.XGBClassifier"></a>xgboost.sklearn.XGBClassifier</h1><h2 id="f-score"><a href="#f-score" class="headerlink" title="f_score"></a>f_score</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost.sklearn <span class="keyword">import</span> XGBClassifier</span><br><span class="line"></span><br><span class="line">model = XGBClassifier(**params)</span><br><span class="line">model.fit(x_train, y_train, eval_set=watchlist,  <span class="comment"># 训练模型</span></span><br><span class="line">          eval_metric=<span class="string">&quot;logloss&quot;</span>,</span><br><span class="line">          early_stopping_rounds=<span class="number">30</span>,</span><br><span class="line">          verbose=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># feature importance 方法一</span></span><br><span class="line">importance =model.get_booster().get_fscore()  <span class="comment">#返回字典</span></span><br></pre></td></tr></table></figure>
<p>结果（特征分叉次数）：</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/XGB/XGB.assets/1565232108098.png" alt="1565232108098"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">impo=model.feature_importances_ <span class="comment">#返回array</span></span><br></pre></td></tr></table></figure>
<p>结果（特征分叉次数占比）：</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/XGB/XGB.assets/1565232794674.png" alt="1565232794674"></p>
<h1 id="xgboost"><a href="#xgboost" class="headerlink" title="xgboost"></a>xgboost</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">xgb_model = xgb.train (params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># feature importance</span></span><br><span class="line">importance =xgb_model.get_fscore() <span class="comment">#返回字典</span></span><br></pre></td></tr></table></figure>
<p>结果：</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/XGB/XGB.assets/1565232255682.png" alt="1565232255682"></p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>AWK语法</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/awk/</url>
    <content><![CDATA[<p>AWK工具书</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="AWK"><a href="#AWK" class="headerlink" title="AWK"></a>AWK</h1><h2 id="1-格式"><a href="#1-格式" class="headerlink" title="1. 格式"></a>1. 格式</h2><h3 id="1-命令形式"><a href="#1-命令形式" class="headerlink" title="1). 命令形式"></a>1). 命令形式</h3><p><code>awk [-F|-f|-v] ‘BEGIN&#123;&#125; //&#123;command1; command2&#125; END&#123;&#125;’ file</code></p>
<blockquote>
<p>BEGIN{ 这里面放的是执行前的语句 } ，其中的语句只会运行一次<br>END {这里面放的是处理完所有的行后要执行的语句 } 。其中的语句也只会运行一次<br>{这里面放的是处理每一行时要执行的语句} ，这里的语句会读文件的每行都运行一次</p>
</blockquote>
<p> [-F|-f|-v]   大参数，-F指定分隔符，-f调用脚本，-v定义变量 var=value</p>
<p>‘  ‘          引用代码块</p>
<p>BEGIN   初始化代码块，在对每一行进行处理之前，初始化代码，主要是引用全局变量，设置FS分隔符</p>
<p>//           匹配代码块，可以是字符串或正则表达式</p>
<p>{}           命令代码块，包含一条或多条命令</p>
<p>；          多条命令使用分号分隔</p>
<p>END      结尾代码块，在对每一行进行处理之后再执行的代码块，主要是进行最终计算或输出结尾摘要信息</p>
<h3 id="2-特殊要点"><a href="#2-特殊要点" class="headerlink" title="2). 特殊要点"></a>2). 特殊要点</h3><p><a href="https://www.cnblogs.com/chengmo/archive/2010/10/06/1844818.html">linux awk 内置变量使用介绍</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>特殊符号</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>$0</td>
<td>表示整个当前行</td>
</tr>
<tr>
<td>$1</td>
<td>每行第一个字段</td>
</tr>
<tr>
<td>NF</td>
<td>字段数量变量</td>
</tr>
<tr>
<td>NR</td>
<td>每行的记录号，多文件记录递增</td>
</tr>
<tr>
<td>FNR</td>
<td>与NR类似，不过多文件记录不递增，每个文件都从1开始</td>
</tr>
<tr>
<td>\t</td>
<td>制表符</td>
</tr>
<tr>
<td>\n</td>
<td>换行符</td>
</tr>
<tr>
<td>FS</td>
<td>BEGIN时定义分隔符，输入字段分隔符 默认是空格</td>
</tr>
<tr>
<td>RS</td>
<td>输入的记录分隔符， 默认为换行符(即文本是按一行一行输入)</td>
</tr>
<tr>
<td>~</td>
<td>匹配，与==相比不是精确比较</td>
</tr>
<tr>
<td>!~</td>
<td>不匹配，不精确比较</td>
</tr>
<tr>
<td>==</td>
<td>等于，必须全部相等，精确比较</td>
</tr>
<tr>
<td>!=</td>
<td>不等于，精确比较</td>
</tr>
<tr>
<td>&amp;&amp;</td>
<td>逻辑与</td>
</tr>
<tr>
<td>\</td>
<td>\</td>
<td></td>
<td>逻辑或</td>
</tr>
<tr>
<td>+</td>
<td>匹配时表示1个或1个以上</td>
</tr>
<tr>
<td>/[0-9][0-9]+/</td>
<td>两个或两个以上数字</td>
</tr>
<tr>
<td>/[0-9][0-9]*/</td>
<td>一个或一个以上数字</td>
</tr>
<tr>
<td>FILENAME</td>
<td>文件名</td>
</tr>
<tr>
<td>OFS</td>
<td>输出字段分隔符， 默认也是空格，可以改为制表符等</td>
</tr>
<tr>
<td>ORS</td>
<td>输出的记录分隔符，默认为换行符,即处理结果也是一行一行输出到屏幕</td>
</tr>
<tr>
<td>-F’[:#/]’</td>
<td>定义三个分隔符</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-内置函数"><a href="#2-内置函数" class="headerlink" title="2. 内置函数"></a>2. 内置函数</h2><p><a href="https://www.cnblogs.com/chengmo/archive/2010/10/08/1845913.html">linux awk 内置函数详细介绍</a></p>
<blockquote>
<p>这篇博客的函数都写在begin{}中</p>
</blockquote>
<h3 id="1-算术函数"><a href="#1-算术函数" class="headerlink" title="1). 算术函数"></a>1). 算术函数</h3><div class="table-container">
<table>
<thead>
<tr>
<th><strong>函数名</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>atan2( y, x )</td>
<td>返回 y/x 的反正切。</td>
</tr>
<tr>
<td>cos( x )</td>
<td>返回 x 的余弦；x 是弧度。</td>
</tr>
<tr>
<td>sin( x )</td>
<td>返回 x 的正弦；x 是弧度。</td>
</tr>
<tr>
<td>exp( x )</td>
<td>返回 x 幂函数。</td>
</tr>
<tr>
<td>log( x )</td>
<td>返回 x 的自然对数。</td>
</tr>
<tr>
<td>sqrt( x )</td>
<td>返回 x 平方根。</td>
</tr>
<tr>
<td>int( x )</td>
<td>返回 x 的截断至整数的值。</td>
</tr>
<tr>
<td>rand( )</td>
<td>返回任意数字 n，其中 0 &lt;= n &lt; 1。</td>
</tr>
<tr>
<td>srand( [Expr] )</td>
<td>将 rand 函数的种子值设置为 Expr 参数的值。返回先前的种子值。</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># OFMT 设置输出数据格式是保留3位小数</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;OFMT=&quot;%.3f&quot;;fs=sin(1);fe=exp(10);fl=log(10);fi=int(3.1415);print fs,fe,fl,fi;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 0.841 22026.466 2.303 3 </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获得随机数：</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;srand();fr=int(100*rand());print fr;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 78</span></span><br></pre></td></tr></table></figure>
<h3 id="2-字符串函数"><a href="#2-字符串函数" class="headerlink" title="2). 字符串函数"></a>2). 字符串函数</h3><div class="table-container">
<table>
<thead>
<tr>
<th><strong>函数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>gsub( Ere, Repl, [ In ] )</td>
<td>除了正则表达式所有具体值被替代这点，它和 sub 函数完全一样地执行，。</td>
</tr>
<tr>
<td>sub( Ere, Repl, [ In ] )</td>
<td>用 Repl 参数指定的字符串替换 In 参数指定的字符串中的由 Ere  参数指定的扩展正则表达式的第一个具体值。sub 函数返回替换的数量。出现在 Repl 参数指定的字符串中的 &amp;（和符号）由 In  参数指定的与 Ere 参数的指定的扩展正则表达式匹配的字符串替换。如果未指定 In 参数，缺省值是整个记录（$0 记录变量）。</td>
</tr>
<tr>
<td>index( String1, String2 )</td>
<td>在由 String1 参数指定的字符串（其中有出现 String2 指定的参数）中，返回位置，从 1 开始编号。如果 String2 参数不在 String1 参数中出现，则返回 0（零）。</td>
</tr>
<tr>
<td>length [(String)]</td>
<td>返回 String 参数指定的字符串的长度（字符形式）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。</td>
</tr>
<tr>
<td>blength [(String)]</td>
<td>返回 String 参数指定的字符串的长度（以字节为单位）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。</td>
</tr>
<tr>
<td>substr( String, M, [ N ] )</td>
<td>返回具有 N 参数指定的字符数量子串。子串从 String  参数指定的字符串取得，其字符以 M 参数指定的位置开始。M 参数指定为将 String 参数中的第一个字符作为编号 1。如果未指定 N  参数，则子串的长度将是 M 参数指定的位置到 String 参数的末尾 的长度。</td>
</tr>
<tr>
<td>match( String, Ere )</td>
<td>在 String 参数指定的字符串（Ere  参数指定的扩展正则表达式出现在其中）中返回位置（字符形式），从 1 开始编号，或如果 Ere 参数不出现，则返回 0（零）。RSTART  特殊变量设置为返回值。RLENGTH 特殊变量设置为匹配的字符串的长度，或如果未找到任何匹配，则设置为 -1（负一）。</td>
</tr>
<tr>
<td>split( String, A, [Ere] )</td>
<td>将 String 参数指定的参数分割为数组元素 A[1], A[2], . .  ., A[n]，并返回 n 变量的值。此分隔可以通过 Ere 参数指定的扩展正则表达式进行，或用当前字段分隔符（FS  特殊变量）来进行（如果没有给出 Ere 参数）。除非上下文指明特定的元素还应具有一个数字值，否则 A 数组中的元素用字符串值来创建。</td>
</tr>
<tr>
<td>tolower( String )</td>
<td>返回 String 参数指定的字符串，字符串中每个大写字符将更改为小写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。</td>
</tr>
<tr>
<td>toupper( String )</td>
<td>返回 String 参数指定的字符串，字符串中每个小写字符将更改为大写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。</td>
</tr>
<tr>
<td>sprintf(Format, Expr, Expr, . . . )</td>
<td>根据 Format 参数指定的 <a href="http://www.cnblogs.com/chengmo/admin/zh_CN/libs/basetrf1/printf.htm#a8zed0gaco">printf</a> 子例程格式字符串来格式化 Expr 参数指定的表达式并返回最后生成的字符串。</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>Ere都可以是正则表达式</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在 info中查找满足正则表达式，/[0-9]+/ 用””替换，并且替换后的值，赋值给info 未给info值，默认是$0</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;info=&quot;this is a test2010test!&quot;;gsub(/[0-9]+/,&quot;!&quot;,info);print info&#125;&#x27;</span> </span><br><span class="line"><span class="comment"># this is a test!test!</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找字符串（index使用）</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;info=&quot;this is a test2010test!&quot;;print index(info,&quot;test&quot;)?&quot;ok&quot;:&quot;no found&quot;;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># ok</span></span><br><span class="line"><span class="comment"># 未找到，返回0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 正则表达式匹配查找(match使用）</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;info=&quot;this is a test2010test!&quot;;print match(info,/[0-9]+/)?&quot;ok&quot;:&quot;no found&quot;;&#125;&#x27;</span>   <span class="comment"># ok </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 截取字符串(substr使用）</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;info=&quot;this is a test2010test!&quot;;print substr(info,4,10);&#125;&#x27;</span></span><br><span class="line"><span class="comment"># s is a tes</span></span><br><span class="line"><span class="comment"># 从第 4个 字符开始，截取10个长度字符串</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串分割（split使用）</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;info=&quot;this is a test&quot;;split(info,tA,&quot; &quot;);print length(tA);for(k in tA)&#123;print k,tA[k];&#125;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 4</span></span><br><span class="line"><span class="comment"># 4 test</span></span><br><span class="line"><span class="comment"># 1 this</span></span><br><span class="line"><span class="comment"># 2 is</span></span><br><span class="line"><span class="comment"># 3 a</span></span><br><span class="line"><span class="comment"># 分割info,动态创建数组tA,这里比较有意思，awk for …in 循环，是一个无序的循环。 并不是从数组下标1…n ，因此使用时候需要注意。</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>awk for …in 循环，是一个无序的循环。 并不是从数组下标1…n ，因此使用时候需要注意</p>
<p>应该是因为awk中数组其实是字段。</p>
</blockquote>
<p><strong>格式化字符串输出（sprintf使用）</strong></p>
<p>格式化字符串包括两部分内容: 一部分是正常字符, 这些字符将按原样输出; 另一部分是格式化规定字符, 以”%”开始, 后跟一个或几个规定字符,用来确定输出内容格式。 </p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>格式符</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>%d</td>
<td>十进制有符号整数</td>
</tr>
<tr>
<td>%u</td>
<td>十进制无符号整数</td>
</tr>
<tr>
<td>%f</td>
<td>浮点数</td>
</tr>
<tr>
<td>%s</td>
<td>字符串</td>
</tr>
<tr>
<td>%c</td>
<td>单个字符</td>
</tr>
<tr>
<td>%p</td>
<td>指针的值</td>
</tr>
<tr>
<td>%e</td>
<td>指数形式的浮点数</td>
</tr>
<tr>
<td>%x</td>
<td>%X 无符号以十六进制表示的整数</td>
</tr>
<tr>
<td>%o</td>
<td>无符号以八进制表示的整数</td>
</tr>
<tr>
<td>%g</td>
<td>自动选择合适的表示法</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;BEGIN&#123;n1=124.113;n2=-1.224;n3=1.2345; printf(&quot;%.2f,%.2u,%.2g,%X,%o\n&quot;,n1,n2,n3,n1,n1);&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 124.11,18446744073709551615,1.2,7C,174 </span></span><br></pre></td></tr></table></figure>
<h3 id="3-时间函数"><a href="#3-时间函数" class="headerlink" title="3). 时间函数"></a>3). 时间函数</h3><div class="table-container">
<table>
<thead>
<tr>
<th><strong>函数名</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>mktime( YYYY MM DD HH MM SS[ DST])</td>
<td>生成时间格式</td>
</tr>
<tr>
<td>strftime([format [, timestamp]])</td>
<td>格式化时间输出，将时间戳转为时间字符串  具体格式，见下表.</td>
</tr>
<tr>
<td>systime()</td>
<td>得到时间戳,返回从1970年1月1日开始到当前时间(不计闰年)的整秒数</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建指定时间(mktime使用）</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;tstamp=mktime(&quot;2001 01 01 12 12 12&quot;);print strftime(&quot;%c&quot;,tstamp);&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 2001年01月01日 星期一 12时12分12秒 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 求2个时间段中间时间差,介绍了strftime使用方法 </span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;tstamp1=mktime(&quot;2001 01 01 12 12 12&quot;);tstamp2=mktime(&quot;2001 02 01 0 0 0&quot;);print tstamp2-tstamp1;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 2634468 </span></span><br><span class="line"></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;tstamp1=mktime(&quot;2001 01 01 12 12 12&quot;);tstamp2=systime();print tstamp2-tstamp1;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 308201392 </span></span><br></pre></td></tr></table></figure>
<p><strong>strftime日期和时间格式说明符</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>格式</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>%a</td>
<td>星期几的缩写(Sun)</td>
</tr>
<tr>
<td>%A</td>
<td>星期几的完整写法(Sunday)</td>
</tr>
<tr>
<td>%b</td>
<td>月名的缩写(Oct)</td>
</tr>
<tr>
<td>%B</td>
<td>月名的完整写法(October)</td>
</tr>
<tr>
<td>%c</td>
<td>本地日期和时间</td>
</tr>
<tr>
<td>%d</td>
<td>十进制日期</td>
</tr>
<tr>
<td>%D</td>
<td>日期 08/20/99</td>
</tr>
<tr>
<td>%e</td>
<td>日期，如果只有一位会补上一个空格</td>
</tr>
<tr>
<td>%H</td>
<td>用十进制表示24小时格式的小时</td>
</tr>
<tr>
<td>%I</td>
<td>用十进制表示12小时格式的小时</td>
</tr>
<tr>
<td>%j</td>
<td>从1月1日起一年中的第几天</td>
</tr>
<tr>
<td>%m</td>
<td>十进制表示的月份</td>
</tr>
<tr>
<td>%M</td>
<td>十进制表示的分钟</td>
</tr>
<tr>
<td>%p</td>
<td>12小时表示法(AM/PM)</td>
</tr>
<tr>
<td>%S</td>
<td>十进制表示的秒</td>
</tr>
<tr>
<td>%U</td>
<td>十进制表示的一年中的第几个星期(星期天作为一个星期的开始)</td>
</tr>
<tr>
<td>%w</td>
<td>十进制表示的星期几(星期天是0)</td>
</tr>
<tr>
<td>%W</td>
<td>十进制表示的一年中的第几个星期(星期一作为一个星期的开始)</td>
</tr>
<tr>
<td>%x</td>
<td>重新设置本地日期(08/20/99)</td>
</tr>
<tr>
<td>%X</td>
<td>重新设置本地时间(12：00：00)</td>
</tr>
<tr>
<td>%y</td>
<td>两位数字表示的年(99)</td>
</tr>
<tr>
<td>%Y</td>
<td>当前月份</td>
</tr>
<tr>
<td>%Z</td>
<td>时区(PDT)</td>
</tr>
<tr>
<td>%%</td>
<td>百分号(%)</td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-一般函数"><a href="#4-一般函数" class="headerlink" title="4). 一般函数"></a>4). 一般函数</h3><div class="table-container">
<table>
<thead>
<tr>
<th><strong>函数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>close( Expression )</td>
<td>用同一个带字符串值的 Expression 参数来关闭由 print 或  printf 语句打开的或调用 getline 函数打开的文件或管道。如果文件或管道成功关闭，则返回  0；其它情况下返回非零值。如果打算写一个文件，并稍后在同一个程序中读取文件，则 close 语句是必需的。</td>
</tr>
<tr>
<td>system(Command )</td>
<td>执行 Command 参数指定的命令，并返回退出状态。等同于 <a href="http://www.cnblogs.com/chengmo/admin/zh_CN/libs/basetrf2/system.htm#a181929c">system</a> 子例程。</td>
</tr>
<tr>
<td>Expression \</td>
<td>getline [ Variable ]</td>
<td>从来自 Expression 参数指定的命令的输出中通过管道传送的流中读取一个输入记录，并将该记录的值指定给 Variable 参数指定的变量。如果当前未打开将 Expression 参数的值作为其命令名称的流，则创建流。创建的流等同于调用 <a href="http://www.cnblogs.com/chengmo/admin/zh_CN/libs/basetrf1/popen.htm#sk62b0shad">popen</a>  子例程，此时 Command 参数取 Expression 参数的值且 Mode 参数设置为一个是 r 的值。只要流保留打开且  Expression 参数求得同一个字符串，则对 getline 函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0  记录变量和 NF 特殊变量设置为从流读取的记录。</td>
</tr>
<tr>
<td>getline [ Variable ] &lt; Expression</td>
<td>从 Expression 参数指定的文件读取输入的下一个记录，并将  Variable 参数指定的变量设置为该记录的值。只要流保留打开且 Expression 参数对同一个字符串求值，则对 getline  函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置为从流读取的记录。</td>
</tr>
<tr>
<td>getline [ Variable ]</td>
<td>将 Variable 参数指定的变量设置为从当前输入文件读取的下一个输入记录。如果未指定 Variable 参数，则 $0 记录变量设置为该记录的值，还将设置 NF、NR 和 FNR 特殊变量。</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 打开外部文件（close用法）</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;while(&quot;cat /etc/passwd&quot;|getline)&#123;print $0;&#125;;close(&quot;/etc/passwd&quot;);&#125;&#x27;</span></span><br><span class="line"><span class="comment"># root:x:0:0:root:/root:/bin/bash</span></span><br><span class="line"><span class="comment"># bin:x:1:1:bin:/bin:/sbin/nologin</span></span><br><span class="line"><span class="comment"># daemon:x:2:2:daemon:/sbin:/sbin/nologin </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 逐行读取外部文件(getline使用方法）</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;while(getline &lt; &quot;/etc/passwd&quot;)&#123;print $0;&#125;;close(&quot;/etc/passwd&quot;);&#125;&#x27;</span></span><br><span class="line"><span class="comment"># root:x:0:0:root:/root:/bin/bash</span></span><br><span class="line"><span class="comment"># bin:x:1:1:bin:/bin:/sbin/nologin</span></span><br><span class="line"><span class="comment"># daemon:x:2:2:daemon:/sbin:/sbin/nologin </span></span><br><span class="line"></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;print &quot;Enter your name:&quot;;getline name;print name;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># Enter your name:</span></span><br><span class="line"><span class="comment"># wangdongdong</span></span><br><span class="line"><span class="comment"># wangdongdong</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用外部应用程序(system使用方法）</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;b=system(&quot;python helloworld.py&quot;);print b;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># helloworld</span></span><br><span class="line"><span class="comment"># 0</span></span><br></pre></td></tr></table></figure>
<h2 id="3-数组"><a href="#3-数组" class="headerlink" title="3. 数组"></a>3. 数组</h2><p><a href="https://www.cnblogs.com/chengmo/archive/2010/10/08/1846190.html">linux awk数组操作详细介绍</a></p>
<h2 id="4-案例"><a href="#4-案例" class="headerlink" title="4. 案例"></a>4. 案例</h2><h3 id="1-print"><a href="#1-print" class="headerlink" title="1). print"></a>1). print</h3><p>print 是awk打印指定内容的主要命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;&#123;print&#125;&#x27;</span> /etc/passwd == awk <span class="string">&#x27;&#123;print $0&#125;&#x27;</span> /etc/passwd </span><br><span class="line">awk <span class="string">&#x27;&#123;print &quot; &quot;&#125;&#x27;</span> /etc/passwd <span class="comment">#不输出passwd的内容，而是输出相同个数的空行，进一步解释了awk是一行一行处理文本</span></span><br><span class="line">awk <span class="string">&#x27;&#123;print &quot;a&quot;&#125;&#x27;</span> /etc/passwd <span class="comment">#输出相同个数的a行，一行只有一个a字母</span></span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> /etc/passwd </span><br><span class="line">awk -F: <span class="string">&#x27;&#123;print $1; print $2&#125;&#x27;</span> /etc/passwd <span class="comment">#将每一行的前二个字段，分行输出，进一步理解一行一行处理文本</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;print $1,$3,$6&#125;&#x27;</span> OFS=<span class="string">&quot;\t&quot;</span> /etc/passwd <span class="comment">#输出字段1,3,6，以制表符作为分隔符</span></span><br></pre></td></tr></table></figure>
<h3 id="2-f指定脚本文件"><a href="#2-f指定脚本文件" class="headerlink" title="2). -f指定脚本文件"></a>2). -f指定脚本文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk -f script.awk  file</span><br><span class="line"></span><br><span class="line"><span class="comment"># script.awk内容如下：</span></span><br><span class="line">BEGIN&#123;</span><br><span class="line">FS=<span class="string">&quot;:&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">&#123;<span class="built_in">print</span> <span class="variable">$1</span>&#125;   <span class="comment">#效果与awk -F&quot;:&quot; &#x27;&#123;print $1&#125;&#x27;相同,只是分隔符使用FS在代码自身中指定</span></span><br><span class="line"></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;X=0&#125; /^$/&#123; X+=1 &#125; END&#123;print &quot;I find&quot;,X,&quot;blank lines.&quot;&#125;&#x27;</span> <span class="built_in">test</span> </span><br><span class="line"><span class="comment"># I find 4 blank lines.</span></span><br><span class="line"></span><br><span class="line">ls -l|awk <span class="string">&#x27;BEGIN&#123;sum=0&#125; !/^d/&#123;sum+=$5&#125; END&#123;print &quot;total size is&quot;,sum&#125;&#x27;</span> <span class="comment">#计算文件大小 </span></span><br><span class="line"><span class="comment">#total size is 17487</span></span><br></pre></td></tr></table></figure>
<h3 id="3-F指定分隔符"><a href="#3-F指定分隔符" class="headerlink" title="3). -F指定分隔符"></a>3). -F指定分隔符</h3><p>$1 指指定分隔符后，第一个字段，$3第三个字段， \t是制表符</p>
<p>一个或多个连续的空格或制表符看做一个定界符，即多个空格看做一个空格</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>  /etc/passwd</span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;print $1 $3&#125;&#x27;</span>  /etc/passwd <span class="comment">#$1与$3相连输出，不分隔</span></span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;print $1,$3&#125;&#x27;</span>  /etc/passwd <span class="comment">#多了一个逗号，$1与$3使用空格分隔</span></span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;print $1 &quot; &quot; $3&#125;&#x27;</span>  /etc/passwd <span class="comment">#$1与$3之间手动添加空格分隔</span></span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;print &quot;Username:&quot; $1 &quot;\t\t Uid:&quot; $3 &#125;&#x27;</span> /etc/passwd <span class="comment">#自定义输出  </span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;print NF&#125;&#x27;</span> /etc/passwd <span class="comment">#显示每行有多少字段</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;print $NF&#125;&#x27;</span> /etc/passwd <span class="comment">#将每行第NF个字段的值打印出来</span></span><br><span class="line">awk -F: <span class="string">&#x27;NF==4 &#123;print &#125;&#x27;</span> /etc/passwd <span class="comment">#显示只有4个字段的行</span></span><br><span class="line">awk -F: <span class="string">&#x27;NF&gt;2&#123;print $0&#125;&#x27;</span> /etc/passwd <span class="comment">#显示每行字段数量大于2的行</span></span><br><span class="line">awk <span class="string">&#x27;&#123;print NR,$0&#125;&#x27;</span> /etc/passwd <span class="comment">#输出每行的行号</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;print NR,NF,$NF,&quot;\t&quot;,$0&#125;&#x27;</span> /etc/passwd <span class="comment">#依次打印行号，字段数，最后字段值，制表符，每行内容</span></span><br><span class="line">awk -F: <span class="string">&#x27;NR==5&#123;print&#125;&#x27;</span>  /etc/passwd <span class="comment">#显示第5行</span></span><br><span class="line">awk -F: <span class="string">&#x27;NR==5 || NR==6&#123;print&#125;&#x27;</span>  /etc/passwd <span class="comment">#显示第5行和第6行</span></span><br><span class="line">route -n|awk <span class="string">&#x27;NR!=1&#123;print&#125;&#x27;</span> <span class="comment">#不显示第一行</span></span><br></pre></td></tr></table></figure>
<h3 id="4-IF语句"><a href="#4-IF语句" class="headerlink" title="4). IF语句"></a>4). IF语句</h3><p>必须用在{}中，且比较内容用()扩起来</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk -F: <span class="string">&#x27;&#123;if($1~/mail/) print $1&#125;&#x27;</span> /etc/passwd <span class="comment">#简写</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;if($1~/mail/) &#123;print $1&#125;&#125;&#x27;</span> /etc/passwd <span class="comment">#全写</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;if($1~/mail/) &#123;print $1&#125; else &#123;print $2&#125;&#125;&#x27;</span> /etc/passwd <span class="comment">#if...else...</span></span><br><span class="line"></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;if($3&gt;100) print &quot;large&quot;; else print &quot;small&quot;&#125;&#x27;</span> /etc/passwd</span><br><span class="line">awk -F: <span class="string">&#x27;BEGIN&#123;A=0;B=0&#125; &#123;if($3&gt;100) &#123;A++; print &quot;large&quot;&#125; else &#123;B++; print &quot;small&quot;&#125;&#125; END&#123;print A,&quot;\t&quot;,B&#125;&#x27;</span> /etc/passwd  <span class="comment">#ID大于100,A加1，否则B加1</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;if($3&lt;100) next; else print&#125;&#x27;</span> /etc/passwd <span class="comment">#小于100跳过，否则显示</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;print ($3&gt;100 ? &quot;yes&quot;:&quot;no&quot;)&#125;&#x27;</span>  /etc/passwd </span><br><span class="line">awk -F: <span class="string">&#x27;&#123;print ($3&gt;100 ? $3&quot;:\tyes&quot;:$3&quot;:\tno&quot;)&#125;&#x27;</span>  /etc/passwd</span><br></pre></td></tr></table></figure>
<h3 id="5-条件表达式"><a href="#5-条件表达式" class="headerlink" title="5). 条件表达式"></a>5). 条件表达式</h3><p><strong>==   !=   &gt;   &gt;=</strong> </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;$1==&quot;mysql&quot;&#123;print $3&#125;&#x27;</span> /etc/passwd  </span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;if($1==&quot;mysql&quot;) print $3&#125;&#x27;</span> /etc/passwd <span class="comment">#与上面相同 </span></span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;$1!=&quot;mysql&quot;&#123;print $3&#125;&#x27;</span> /etc/passwd <span class="comment">#不等于</span></span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;$3&gt;1000&#123;print $3&#125;&#x27;</span> /etc/passwd <span class="comment">#大于</span></span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;$3&gt;=100&#123;print $3&#125;&#x27;</span> /etc/passwd <span class="comment">#大于等于</span></span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;$3&lt;1&#123;print $3&#125;&#x27;</span> /etc/passwd <span class="comment">#小于</span></span><br><span class="line">awk -F<span class="string">&quot;:&quot;</span> <span class="string">&#x27;$3&lt;=1&#123;print $3&#125;&#x27;</span> /etc/passwd <span class="comment">#小于等于</span></span><br></pre></td></tr></table></figure>
<h3 id="6-逻辑运算符"><a href="#6-逻辑运算符" class="headerlink" title="6). 逻辑运算符"></a>6). 逻辑运算符</h3><p><strong>&amp;&amp;　||</strong> </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk -F: <span class="string">&#x27;$1~/mail/ &amp;&amp; $3&gt;8 &#123;print &#125;&#x27;</span> /etc/passwd <span class="comment">#逻辑与，$1匹配mail，并且$3&gt;8</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;if($1~/mail/ &amp;&amp; $3&gt;8) print &#125;&#x27;</span> /etc/passwd</span><br><span class="line">awk -F: <span class="string">&#x27;$1~/mail/ || $3&gt;1000 &#123;print &#125;&#x27;</span> /etc/passwd <span class="comment">#逻辑或</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;if($1~/mail/ || $3&gt;1000) print &#125;&#x27;</span> /etc/passwd </span><br></pre></td></tr></table></figure>
<h3 id="7-数值运算"><a href="#7-数值运算" class="headerlink" title="7). 数值运算"></a>7). 数值运算</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk -F: <span class="string">&#x27;$3 &gt; 100&#x27;</span> /etc/passwd    </span><br><span class="line">awk -F: <span class="string">&#x27;$3 &gt; 100 || $3 &lt; 5&#x27;</span> /etc/passwd  </span><br><span class="line">awk -F: <span class="string">&#x27;$3+$4 &gt; 200&#x27;</span> /etc/passwd</span><br><span class="line">awk -F: <span class="string">&#x27;/mysql|mail/&#123;print $3+10&#125;&#x27;</span> /etc/passwd <span class="comment">#第三个字段加10打印 </span></span><br><span class="line">awk -F: <span class="string">&#x27;/mysql/&#123;print $3-$4&#125;&#x27;</span> /etc/passwd <span class="comment">#减法</span></span><br><span class="line">awk -F: <span class="string">&#x27;/mysql/&#123;print $3*$4&#125;&#x27;</span> /etc/passwd <span class="comment">#求乘积</span></span><br><span class="line">awk <span class="string">&#x27;/MemFree/&#123;print $2/1024&#125;&#x27;</span> /proc/meminfo <span class="comment">#除法</span></span><br><span class="line">awk <span class="string">&#x27;/MemFree/&#123;print int($2/1024)&#125;&#x27;</span> /proc/meminfo <span class="comment">#取整</span></span><br></pre></td></tr></table></figure>
<h3 id="8-输出分隔符OFS"><a href="#8-输出分隔符OFS" class="headerlink" title="8). 输出分隔符OFS"></a>8). 输出分隔符OFS</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;$6 ~ /FIN/ || NR==1 &#123;print NR,$4,$5,$6&#125;&#x27;</span> OFS=<span class="string">&quot;\t&quot;</span> netstat.txt</span><br><span class="line">awk <span class="string">&#x27;$6 ~ /WAIT/ || NR==1 &#123;print NR,$4,$5,$6&#125;&#x27;</span> OFS=<span class="string">&quot;\t&quot;</span> netstat.txt        </span><br><span class="line"><span class="comment">#输出字段6匹配WAIT的行，其中输出每行行号，字段4，5,6，并使用制表符分割字段</span></span><br></pre></td></tr></table></figure>
<h3 id="9-输出处理结果到文件"><a href="#9-输出处理结果到文件" class="headerlink" title="9). 输出处理结果到文件"></a>9). 输出处理结果到文件</h3><p>①在命令代码块中直接输出 route -n|awk ‘NR!=1{print &gt; “./fs”}’   </p>
<p>②使用重定向进行输出  route -n|awk ‘NR!=1{print}’  &gt; ./fs</p>
<h3 id="10-格式化输出"><a href="#10-格式化输出" class="headerlink" title="10). 格式化输出"></a>10). 格式化输出</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -anp|awk <span class="string">&#x27;&#123;printf &quot;%-8s %-8s %-10s\n&quot;,$1,$2,$3&#125;&#x27;</span> </span><br></pre></td></tr></table></figure>
<p>printf表示格式输出</p>
<p>%格式化输出分隔符</p>
<p>-8长度为8个字符</p>
<p>s表示字符串类型</p>
<p>打印每行前三个字段，指定第一个字段输出字符串类型(长度为8)，第二个字段输出字符串类型(长度为8),</p>
<p>第三个字段输出字符串类型(长度为10)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -anp|awk <span class="string">&#x27;$6==&quot;LISTEN&quot; || NR==1 &#123;printf &quot;%-10s %-10s %-10s \n&quot;,$1,$2,$3&#125;&#x27;</span></span><br><span class="line">netstat -anp|awk <span class="string">&#x27;$6==&quot;LISTEN&quot; || NR==1 &#123;printf &quot;%-3s %-10s %-10s %-10s \n&quot;,NR,$1,$2,$3&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="11-数组"><a href="#11-数组" class="headerlink" title="11). 数组"></a>11). 数组</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -anp|awk <span class="string">&#x27;NR!=1&#123;a[$6]++&#125; END&#123;for (i in a) print i,&quot;\t&quot;,a[i]&#125;&#x27;</span></span><br><span class="line">netstat -anp|awk <span class="string">&#x27;NR!=1&#123;a[$6]++&#125; END&#123;for (i in a) \</span></span><br><span class="line"><span class="string">  printf &quot;%-20s %-10s %-5s \n&quot;, i,&quot;\t&quot;,a[i]&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="12-其他应用"><a href="#12-其他应用" class="headerlink" title="12). 其他应用"></a>12). 其他应用</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk -F: <span class="string">&#x27;&#123;print NF&#125;&#x27;</span> helloworld.sh <span class="comment">#输出文件每行有多少字段</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;print $1,$2,$3,$4,$5&#125;&#x27;</span> helloworld.sh <span class="comment">#输出前5个字段</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;print $1,$2,$3,$4,$5&#125;&#x27;</span> OFS=<span class="string">&#x27;\t&#x27;</span> helloworld.sh <span class="comment">#输出前5个字段并使用制表符分隔输出</span></span><br><span class="line">awk -F: <span class="string">&#x27;&#123;print NR,$1,$2,$3,$4,$5&#125;&#x27;</span> OFS=<span class="string">&#x27;\t&#x27;</span> helloworld.sh <span class="comment">#制表符分隔输出前5个字段，并打印行号</span></span><br><span class="line">awk -F<span class="string">&#x27;[:#]&#x27;</span> <span class="string">&#x27;&#123;print NF&#125;&#x27;</span>  helloworld.sh <span class="comment">#指定多个分隔符: #，输出每行多少字段</span></span><br><span class="line">awk -F<span class="string">&#x27;[:#]&#x27;</span> <span class="string">&#x27;&#123;print $1,$2,$3,$4,$5,$6,$7&#125;&#x27;</span> OFS=<span class="string">&#x27;\t&#x27;</span> helloworld.sh <span class="comment">#制表符分隔输出多字段</span></span><br><span class="line">awk -F<span class="string">&#x27;[:#/]&#x27;</span> <span class="string">&#x27;&#123;print NF&#125;&#x27;</span> helloworld.sh <span class="comment">#指定三个分隔符，并输出每行字段数</span></span><br><span class="line">awk -F<span class="string">&#x27;[:#/]&#x27;</span> <span class="string">&#x27;&#123;print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12&#125;&#x27;</span> hi.sh <span class="comment">#制表符分隔输出多字段</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#计算/home目录下，普通文件的大小，使用KB作为单位</span></span><br><span class="line">ls -l|awk <span class="string">&#x27;BEGIN&#123;sum=0&#125; !/^d/&#123;sum+=$5&#125; END&#123;print &quot;total size is:&quot;,sum/1024,&quot;KB&quot;&#125;&#x27;</span></span><br><span class="line">ls -l|awk <span class="string">&#x27;BEGIN&#123;sum=0&#125; !/^d/&#123;sum+=$5&#125; END&#123;print &quot;total size is:&quot;,int(sum/1024),&quot;KB&quot;&#125;&#x27;</span> <span class="comment">#int是取整的意思</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#统计netstat -anp 状态为LISTEN和CONNECT的连接数量分别是多少</span></span><br><span class="line">netstat -anp|awk <span class="string">&#x27;$6~/LISTEN|CONNECTED/&#123;sum[$6]++&#125; END&#123;for (i in sum) printf &quot;%-10s %-6s %-3s \n&quot;, i,&quot; &quot;,sum[i]&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#统计/home目录下不同用户的普通文件的总数是多少？</span></span><br><span class="line">ls -l|awk <span class="string">&#x27;NR!=1 &amp;&amp; !/^d/&#123;sum[$3]++&#125; END&#123;for (i in sum) printf &quot;%-6s %-5s %-3s \n&quot;,i,&quot; &quot;,sum[i]&#125;&#x27;</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment">#统计/home目录下不同用户的普通文件的大小总size是多少？</span></span><br><span class="line">ls -l|awk <span class="string">&#x27;NR!=1 &amp;&amp; !/^d/&#123;sum[$3]+=$5&#125; END&#123;for (i in sum) printf &quot;%-6s %-5s %-3s %-2s \n&quot;,i,&quot; &quot;,sum[i]/1024/1024,&quot;MB&quot;&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输出成绩表</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN&#123;math=0;eng=0;com=0;printf &quot;Lineno.   Name    No.    Math   English   Computer    Total\n&quot;;printf &quot;------------------------------------------------------------\n&quot;&#125;&#123;math+=$3; eng+=$4; com+=$5;printf &quot;%-8s %-7s %-7s %-7s %-9s %-10s %-7s \n&quot;,NR,$1,$2,$3,$4,$5,$3+$4+$5&#125; END&#123;printf &quot;------------------------------------------------------------\n&quot;;printf &quot;%-24s %-7s %-9s %-20s \n&quot;,&quot;Total:&quot;,math,eng,com;printf &quot;%-24s %-7s %-9s %-20s \n&quot;,&quot;Avg:&quot;,math/NR,eng/NR,com/NR&#125;&#x27;</span> <span class="built_in">test</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="13-Vlookup"><a href="#13-Vlookup" class="headerlink" title="13). Vlookup"></a>13). Vlookup</h3><p><a href="https://www.jianshu.com/p/01906e4b7af7">awk实现excel vlookup</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据</span></span><br><span class="line">$ cat a.txt </span><br><span class="line">1       abc</span><br><span class="line">2       def</span><br><span class="line">3       ghi</span><br><span class="line">4       jlm</span><br><span class="line">$ cat b.txt </span><br><span class="line">3       shit</span><br><span class="line">1       rubb</span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">awk <span class="string">&#x27;NR==FNR&#123;a[$1]=$2;next&#125;NR&gt;FNR&#123;if($1 in a)print $0&quot;\t&quot;a[$1]&#125;&#x27;</span> a.txt b.txt </span><br><span class="line"><span class="comment"># 3       shit    ghi</span></span><br><span class="line"><span class="comment"># 1       rubb    abc</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：a是一个字典，<code>NR==FNR</code>时在第一个文件，<code>NR&gt;FNR</code>时在读b.txt</p>
<p><code>NR==FNR&#123;a[$1]=$2;next&#125;</code>是使用第一个文件<code>a.txt</code>初始化字典，将其每行<code>$1</code>作为key，<code>$2</code>作为value</p>
<p><code>if($1 in a)</code>指序号<code>$1</code>是否在a的key中，如果在打印的<code>a[$1]</code>为key：<code>$1</code>对于的value</p>
<p>查看字典：<code>awk &#39;NR==FNR&#123;a[$1]=$2;next&#125;END&#123;for(k in a)&#123;print k,a[k]&#125;&#125;&#39; a.txt b.txt</code></p>
</blockquote>
<h3 id="14-group-by"><a href="#14-group-by" class="headerlink" title="14). group by"></a>14). group by</h3><p><a href="http://www.cppblog.com/datouwang/articles/45582.html">总结一下awk的group by功能</a></p>
<p>通过数组的key作为作为on的条件，value进行聚合运算</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据</span></span><br><span class="line">cat c.txt</span><br><span class="line">06 01 06 30      2.700         81.000</span><br><span class="line">06 01 06 45      3.900        175.500</span><br><span class="line">06 01 07 00      2.400          0.000</span><br><span class="line">06 01 07 15      0.160          2.400</span><br><span class="line">06 01 08 00      0.380          0.000</span><br><span class="line">06 01 08 15      0.300          4.500</span><br><span class="line">06 01 08 30      3.900        117.000</span><br><span class="line">06 01 08 45      5.520        248.400</span><br><span class="line">06 01 09 00      6.600          0.000</span><br><span class="line">06 01 09 15      9.600        144.000</span><br><span class="line">06 01 09 30      3.300         99.000</span><br><span class="line">06 01 09 45      2.300        103.500</span><br><span class="line">06 01 10 15      7.880        118.200</span><br><span class="line">06 01 10 30     10.820        324.600</span><br><span class="line">06 01 10 45      7.360        331.200</span><br><span class="line">06 01 11 00     11.940          0.000</span><br><span class="line">06 01 11 15      4.200         63.000</span><br><span class="line">06 01 11 30      3.180         95.400</span><br><span class="line">06 01 11 45      1.800         81.000</span><br><span class="line">06 01 12 00     30.970          0.000</span><br><span class="line"><span class="comment"># 实现</span></span><br><span class="line"><span class="comment"># 单列group by单列聚合</span></span><br><span class="line">awk <span class="string">&#x27;&#123;a[$2]+=$5&#125;END&#123;for(i in a) printf &quot;%s %10.3f\n&quot;,i,a[i]&#125;&#x27;</span> c.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单列group by多列聚合</span></span><br><span class="line">awk <span class="string">&#x27;&#123;a[$2]+=$5;b[$2]+=$6&#125;END&#123;for(i in a) printf &quot;%s %10.3f %14.3f\n&quot;,i,a[i],b[i]&#125;&#x27;</span> c.txt </span><br><span class="line"></span><br><span class="line"><span class="comment"># 多列group by单列聚合</span></span><br><span class="line">awk <span class="string">&#x27;&#123;a[$2&quot; &quot;$3]+=$5&#125;END&#123;for(i in a) printf &quot;%s %10.3f\n&quot;,i,a[i]&#125;&#x27;</span> c.txt <span class="comment"># 求和</span></span><br><span class="line">awk <span class="string">&#x27;&#123;a[$2&quot; &quot;$3]+=1&#125;END&#123;for(i in a) printf &quot;%s %10.3f\n&quot;,i,a[i]&#125;&#x27;</span> c.txt <span class="comment"># 计数</span></span><br><span class="line">awk <span class="string">&#x27;&#123;s[$2&quot; &quot;$3]+=$5;n[$2&quot; &quot;$3]+=1&#125;END&#123;for(i in s)&#123;avg_v=s[i]/n[i];printf &quot;%s %10.3f\n&quot;,i,avg_v&#125;&#125;&#x27;</span> c.txt <span class="comment"># 平均</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 多列group by多列聚合：多来一个数组</span></span><br><span class="line">awk <span class="string">&#x27;&#123;a[$2&quot; &quot;$3]+=$5;b[$2&quot; &quot;$3]+=$6&#125;END&#123;for(i in a) printf &quot;%s %14.3f %14.3f\n&quot;,i,a[i],b[i]&#125;&#x27;</span> c.txt</span><br></pre></td></tr></table></figure>
<p>awk -F’ ‘ ‘/from/{print}’</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">awk &#x27;&#123;for(i=0;++i&lt;=NF;)a[i]=a[i]?a[i] FS $i:$i&#125;END&#123;for(i=0;i++&lt;NF;)printf a[i]&quot;\b \n&quot;&#125;&#x27; </span><br></pre></td></tr></table></figure>
<h2 id="5-正则表达式"><a href="#5-正则表达式" class="headerlink" title="5. 正则表达式"></a>5. 正则表达式</h2><p><a href="https://www.cnblogs.com/myyan/p/4765683.html">awk 正则表达式、正则运算符详细介绍</a></p>
<p><a href="https://www.cnblogs.com/chengmo/archive/2010/10/10/1847287.html">linux shell 正则表达式(BREs,EREs,PREs)差异比较</a></p>
<h3 id="1"><a href="#1" class="headerlink" title="1). +"></a>1). +</h3><p>指定如果<strong>一个或多个字符</strong>或扩展正则表达式的具体值（在 +（加号）前）在这个字符串中，则字符串匹配。</p>
<p>命令行：<code>awk &#39;/smith+ern/&#39; testfile</code></p>
<p>将包含字符 smit，后跟一个或多个 h 字符，并以字符 ern 结束的字符串的任何记录打印至标准输出。</p>
<p>此示例中的输出是：smithern, harry smithhern, anne</p>
<h3 id="2"><a href="#2" class="headerlink" title="2). ?"></a>2). ?</h3><p>指定如果<strong>零个或一个字符</strong>或扩展正则表达式的具体值（在 ?（问号）之前）在字符串中，则字符串匹配。</p>
<p>命令行： <code>awk &#39;/smith?/&#39; testfile</code></p>
<p>将包含字符 <code>smit</code>，后跟零个或一个 <code>h</code> 字符的实例的所有记录打印至标准输出。</p>
<p>此示例中的输出是：smith, alan smithern, harry smithhern, anne smitters, alexis</p>
<h3 id="3"><a href="#3" class="headerlink" title="3). |"></a>3). |</h3><p>指定如果以 |（垂直线）隔开的字符串的<strong>任何一个在字符串中</strong>，则字符串匹配。</p>
<p>命令行：<code>awk &#39;/allen | alan /&#39; testfile</code></p>
<p>将包含字符串 allen 或 alan 的所有记录打印至标准输出。</p>
<p>此示例中的输出是：smiley, allen smith, alan</p>
<h3 id="4"><a href="#4" class="headerlink" title="4). ()"></a>4). ()</h3><p>在正则表达式中将字符串组合在一起。</p>
<p>命令行： <code>awk &#39;/a(ll)?(nn)?e/&#39; testfile</code></p>
<p>将具有字符串 <code>ae</code> 或 <code>alle</code> 或 <code>anne</code> 或 <code>allnne</code> 的所有记录打印至标准输出。</p>
<p>此示例中的输出是：smiley, allen smithhern, anne</p>
<h3 id="5-m"><a href="#5-m" class="headerlink" title="5). {m}"></a>5). {m}</h3><p>指定如果<strong>正好有 m 个模式的具体值位于字符串中</strong>，则字符串匹配。</p>
<p>命令行：awk ‘/l{2}/‘ testfile</p>
<p>打印至标准输出：smiley, allen</p>
<h3 id="6-m"><a href="#6-m" class="headerlink" title="6). {m,}"></a>6). {m,}</h3><p>指定如果<strong>至少 m 个模式的具体值在字符串中</strong>，则字符串匹配。</p>
<p>命令行：<code>awk &#39;/t&#123;2,&#125;/&#39; testfile</code></p>
<p>打印至标准输出：smitters, alexis</p>
<h3 id="7-m-n"><a href="#7-m-n" class="headerlink" title="7). {m, n}"></a>7). {m, n}</h3><p>指定如果 <strong>m 和 n 之间（包含的 m 和 n）个模式</strong>的具体值在字符串中（其中m&lt;= n），则字符串匹配。</p>
<p>命令行：<code>awk &#39;/er&#123;1, 2&#125;/&#39; testfile</code></p>
<p>打印至标准输出：smithern, harry smithern, anne smitters, alexis</p>
<h3 id="8-String"><a href="#8-String" class="headerlink" title="8). [String]"></a>8). [String]</h3><p>指定正则表达式与方括号内 <strong>String 变量指定的任何字符匹配</strong>。</p>
<p>命令行：<code>awk &#39;/sm[a-h]/&#39; testfile</code></p>
<p>将具有 <code>sm</code> 后跟以字母顺序从 <code>a</code> 到 <code>h</code> 排列的任何字符的所有记录打印至标准输出。</p>
<p>此示例的输出是：smawley, andy</p>
<h3 id="9-String"><a href="#9-String" class="headerlink" title="9). [^ String]"></a>9). [^ String]</h3><p>在 [ ]（方括号）和在指定字符串开头的 ^ (插入记号) 指明<strong>正则表达式与方括号内的任何字符不匹配。</strong></p>
<p>命令行：<code>awk &#39;/sm\[^a-h]/&#39; testfile</code></p>
<p>打印至标准输出：smiley, allen smith, alan smithern, harry smithhern, anne smitters, alexis</p>
<h3 id="10"><a href="#10" class="headerlink" title="10). ~, !~"></a>10). ~, !~</h3><p>表示<strong>指定变量与正则表达式**</strong>匹配<strong>（~）或</strong>不匹配**（!~）的条件语句。</p>
<p>命令行：<code>awk &#39;$1 ~ /n/&#39; testfile</code></p>
<p>将第一个字段包含字符 <code>n</code> 的所有记录打印至标准输出。</p>
<p>此示例中的输出是：smithern, harry smithhern, anne</p>
<h3 id="11"><a href="#11" class="headerlink" title="11). ^"></a>11). ^</h3><p><strong>指定</strong>字段或记录的<strong>开头</strong>。</p>
<p>命令行： awk ‘$2 ~ /^h/‘ testfile</p>
<p>将把字符 <code>h</code> 作为第二个字段的第一个字符的所有记录打印至标准输出。</p>
<p>此示例中的输出是：smithern, harry</p>
<h3 id="12"><a href="#12" class="headerlink" title="12). $"></a>12). $</h3><p><strong>指定</strong>字段或记录的<strong>末尾</strong>。</p>
<p>命令行： awk ‘$2 ~ /y$/‘ testfile</p>
<p>将把字符 <code>y</code> 作为第二个字段的最后一个字符的所有记录打印至标准输出。</p>
<p>此示例中的输出是：smawley, andy smithern, harry</p>
<h3 id="13-（句号）"><a href="#13-（句号）" class="headerlink" title="13). .（句号）"></a>13). .（句号）</h3><p><strong>表示</strong>除了在空白末尾的终端换行字符以外的<strong>任何一个字符</strong>。</p>
<p>命令行： awk ‘/a..e/‘ testfile</p>
<p>将具有以两个字符隔开的字符 <code>a</code> 和 e 的所有记录打印至标准输出。</p>
<p>此示例中的输出是：smawley, andy smiley, allen smithhern, anne</p>
<h3 id="14-（星号）"><a href="#14-（星号）" class="headerlink" title="14). *（星号）"></a>14). *（星号）</h3><p>表示<strong>零个或更多的任意字符。</strong></p>
<p>命令行： awk ‘/a.*e/‘ testfile</p>
<p>将具有以零个或更多字符隔开的字符 <code>a</code> 和 e 的所有记录打印至标准输出。</p>
<p>此示例中的输出是：smawley, andy smiley, allen smithhern, anne smitters, alexis</p>
<h3 id="15-反斜杠"><a href="#15-反斜杠" class="headerlink" title="15). \ (反斜杠)"></a>15). \ (反斜杠)</h3><p>转义字符。当位于在扩展正则表达式中具有特殊含义的任何字符之前时，转义字符除去该字符的任何特殊含义。</p>
<p>例如，命令行： /a\/\//</p>
<p>将与模式 a // 匹配，因为反斜杠否定斜杠作为正则表达式定界符的通常含义。要将反斜杠本身指定为字符，则使用双反斜杠。有关反斜杠及其使用的更多信息，请参阅以下关于转义序列的内容。</p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>final_cut_pro基础知识</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/final_cut_pro%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<p>最常用的FCP操作</p>
<span id="more"></span>
<p>快捷键：</p>
<p>i</p>
<p>o</p>
<p>e</p>
<p>d</p>
<p>B:切割</p>
<p>A：选择</p>
<p>T：修建</p>
<p>cmmand+-</p>
<p>shif+z:自动缩放</p>
<p>ctrl+T: 基本字幕</p>
<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><ul>
<li>资源库：最高文件夹</li>
<li>事件</li>
<li>项目：影片名字</li>
</ul>
<h1 id="插入快捷键"><a href="#插入快捷键" class="headerlink" title="插入快捷键"></a>插入快捷键</h1><p>选择素材，按快捷键</p>
<p>Q: 插到时间轴所在位置,有视频的话会在新时间线</p>
<p>W:插到当前事件轴位置，分隔</p>
<p><strong>E</strong>：插到时间线最后</p>
<p>D：覆盖到时间轴位置</p>
<h1 id="精修快捷键"><a href="#精修快捷键" class="headerlink" title="精修快捷键"></a>精修快捷键</h1><p>B: 切割</p>
<p>A：选择</p>
<p>shif：连续多选</p>
<p>右键生成复合片段：合并片段</p>
<h1 id="多轨道剪辑"><a href="#多轨道剪辑" class="headerlink" title="多轨道剪辑"></a>多轨道剪辑</h1><p><strong>主序列片段只有一个，移动主序列片段时会影响其他序列的片段</strong></p>
<h1 id="转场"><a href="#转场" class="headerlink" title="转场"></a>转场</h1><p>直接拖到两个片段之间，呈灰色即转场成功</p>
<p>可在检查器设置转场参数</p>
<h1 id="字幕"><a href="#字幕" class="headerlink" title="字幕"></a>字幕</h1><p>基本字幕</p>
<h1 id="音画匹配"><a href="#音画匹配" class="headerlink" title="音画匹配"></a>音画匹配</h1><ul>
<li>右键—&gt; 分离音频</li>
</ul>
<h1 id="关键帧"><a href="#关键帧" class="headerlink" title="关键帧"></a>关键帧</h1><pre><code>- 对某个属性打两个关键帧，可实现该属性过度
</code></pre><h1 id="速率和方向"><a href="#速率和方向" class="headerlink" title="速率和方向"></a>速率和方向</h1><p>contrl+option+r: 调整速度</p>
<h1 id="聚焦-抠像-遮罩"><a href="#聚焦-抠像-遮罩" class="headerlink" title="聚焦 抠像 遮罩"></a>聚焦 抠像 遮罩</h1><p>聚焦：模糊分类中</p>
<h1 id="主要情节"><a href="#主要情节" class="headerlink" title="主要情节"></a>主要情节</h1><p>主要时间轴：右键—&gt; 从故事情节提取</p>
<p>非主要-》主要：右键—&gt; 覆盖至主要故事情节</p>
<h1 id="声音"><a href="#声音" class="headerlink" title="声音"></a>声音</h1><ul>
<li>合成异常</li>
<li>No</li>
</ul>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>git基础操作笔记</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>git工具书</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="git-worktree"><a href="#git-worktree" class="headerlink" title="git worktree"></a>git worktree</h1><p><a href="https://zhuanlan.zhihu.com/p/92906230">Git屠龙技：使用Git Worktree并行开发测试</a></p>
<p>Git worktree严格意义上说已经不是一个新的功能了，它推出也已经好几年了，是在2015年7月发布的2.5版引入的。Worktree是链接到统一仓库的多个工作区（目录，树）。一个git仓库可以支持多个工作树，分别对应不同的分支。我们在git中通过”git init”或”git clone”创建一个（主）工作区（树）（main working tree）。<br>同理，我们使用git worktree创建一个（和工作区）不同目录的工作区（树），我们称之为为”链接工作区（树）（linked working tree）”。git仓库有一个主工作树（裸库）和零个或多个链接工作树。与重建的孤立的目录不同，链接工作树和主仓库直接就行分支一样是有机关联的，任何一个链接工作树的变更提交都在仓库内部。链接工作树用完后，可以直接通过git worktree remove删除。</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/image-20220402155722383.png" alt="image-20220402155722383" style="zoom:50%;"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git worktree add ../工作树目录 分支(commits ID)  <span class="comment">#在../工作树目录下，创建一套完整分支工作区</span></span><br><span class="line"></span><br><span class="line">git worktree list <span class="comment">#列出所有工作树  --porcelain 选项，可以列出更完整的哈希值和分支信息</span></span><br><span class="line"></span><br><span class="line">git worktree remove ... <span class="comment">#删除工作树，但只能删除干净的工作树（没有未跟踪文件）</span></span><br><span class="line"></span><br><span class="line">git worktree prune <span class="comment">#删除工作树信息，🙅不要轻易使用</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="强制回滚到某个commit版本"><a href="#强制回滚到某个commit版本" class="headerlink" title="强制回滚到某个commit版本"></a>强制回滚到某个commit版本</h1><p>1 git log —stat 查找到某个commit 的版本号</p>
<p>2 git reset —hard 版本号 （本地执行回滚命令，回滚到某个commit版本）</p>
<p>3 git push origin HEAD —force （远端同步回滚）</p>
<h1 id="merge时产生冲突"><a href="#merge时产生冲突" class="headerlink" title="merge时产生冲突"></a>merge时产生冲突</h1>
<h1 id="git删除远程文件或者文件夹"><a href="#git删除远程文件或者文件夹" class="headerlink" title="git删除远程文件或者文件夹"></a>git删除远程文件或者文件夹</h1><p>git删除远程文件夹或文件的方法</p>
<p><a href="https://www.cnblogs.com/xusir/p/4111723.html">https://www.cnblogs.com/xusir/p/4111723.html</a></p>
<p>由于本地修改了文件夹大全名大小写的原因，同步到git上并不区分大小写，造成了一些文件同步不了，所以要先把git远程库上文件夹删除掉，然后再重新同步</p>
<p>如下，我把src里的全部移除，但是本地文件还保留。</p>
<p>git rm -r -n —cached  <em>/src/\</em>      //-n：加上这个参数，执行命令时，是不会删除任何文件，而是展示此命令要删除的文件列表预览。</p>
<p>git rm -r —cached  <em>/src/\</em>      //最终执行命令. </p>
<p>git commit -m”移除src目录下所有文件的版本控制”    //提交 </p>
<p>git push origin master   //提交到远程服务器</p>
<p>若用git status命令查看，则/src/目录下文件出现在结果列表里， 我们不希望这个目录下的文件出现，则在项目根目录下，和.git 同级目录下，新建一个.gitignore文件，</p>
<p>把.gitignore提交到远程服务器。 则/src目录就不会被提交了。</p>
<h1 id="git基础操作"><a href="#git基础操作" class="headerlink" title="git基础操作"></a>git基础操作</h1><p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/git基础操作笔记.assets\1541381811863.png" alt="1541381811863"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git init #在现有目录中初始化仓库</span><br><span class="line">git diff #查看已暂存和未暂存的修改</span><br><span class="line">git log #查看提交历史</span><br><span class="line">git reset HEAD [file] #取消暂存的文件</span><br><span class="line">git checkout --[file] #撤消对文件的修改</span><br><span class="line">git branch testing #建立分支</span><br><span class="line">git checkout testing #切换分支</span><br><span class="line">git merge #分支合并</span><br><span class="line">git remote #查看远程仓库名称</span><br><span class="line">git branch -r #查看远程分支的名称</span><br></pre></td></tr></table></figure>
<h2 id="crontab同步git仓库"><a href="#crontab同步git仓库" class="headerlink" title="crontab同步git仓库"></a>crontab同步git仓库</h2><p>添加远程仓库的时候使用https,并加入用户名、密码<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote add origin http://hetianqi:htq0625HTQ%24@git.jd.com/jd_git/monitors.git</span><br></pre></td></tr></table></figure></p>
<h2 id="gitignore"><a href="#gitignore" class="headerlink" title="gitignore"></a>gitignore</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 忽略子目录</span><br><span class="line">**/log/*</span><br><span class="line"></span><br><span class="line"># 忽略*.o和*.a文件</span><br><span class="line">*.[oa] </span><br><span class="line"></span><br><span class="line"># 忽略*.b和*.B文件，my.b除外</span><br><span class="line">*.[bB]</span><br><span class="line">!my.b</span><br><span class="line"></span><br><span class="line"># 忽略dbg文件和dbg目录(只要)</span><br><span class="line">dbg</span><br><span class="line"></span><br><span class="line"># 只忽略dbg目录，不忽略dbg文件</span><br><span class="line">dbg/</span><br><span class="line"></span><br><span class="line"># 只忽略dbg文件，不忽略dbg目录</span><br><span class="line">dbg</span><br><span class="line">!dbg/</span><br><span class="line"></span><br><span class="line"># 只忽略当前目录下的dbg文件和目录，子目录的dbg不在忽略范围内</span><br><span class="line"></span><br><span class="line">/dbg</span><br><span class="line"></span><br><span class="line"># 以&#x27;#&#x27;开始的行，被视为注释.</span><br><span class="line"></span><br><span class="line"> * ？：代表任意的一个字符</span><br><span class="line">    * ＊：代表任意数目的字符</span><br><span class="line">    * &#123;!ab&#125;：必须不是此类型</span><br><span class="line">    * &#123;ab,bb,cx&#125;：代表ab,bb,cx中任一类型即可</span><br><span class="line">    * [abc]：代表a,b,c中任一字符即可</span><br><span class="line">    * [ ^abc]：代表必须不是a,b,c中任一字符</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> mac配置全局gitignore</span></span><br><span class="line">git config --global core.excludesfile ~/.gitignore_global</span><br><span class="line"></span><br><span class="line">vim ~/.gitignore_global</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">for</span> Mac OS X System Files</span></span><br><span class="line">.DS_Store</span><br><span class="line">Thumbs.db</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">for</span> emacs</span></span><br><span class="line">*~</span><br><span class="line"><span class="meta">[#</span><span class="bash">]*[<span class="comment">#]</span></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">for</span> Eclipse</span></span><br><span class="line">*.project</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">for</span> Logs and databases</span></span><br><span class="line">*.log</span><br><span class="line">*.dat</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> remove SVN</span></span><br><span class="line">.svn</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">for</span> Xcode</span></span><br><span class="line">.*.swp</span><br><span class="line">.clang_complete</span><br><span class="line">*.xcodeproj/project.xcworkspace/</span><br><span class="line">*.xcodeproj/xcuserdata/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">for</span> IDEA</span></span><br><span class="line">**/build/*</span><br><span class="line">.idea/*</span><br><span class="line">*.iml</span><br><span class="line">**/out/*</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">for</span> PYCHARM</span></span><br><span class="line">**/__pycache__/*</span><br><span class="line">**/.ipynb_checkpoints/*</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="fetch-和-pull的区别"><a href="#fetch-和-pull的区别" class="headerlink" title="fetch 和 pull的区别"></a>fetch 和 pull的区别</h2><p><a href="https://www.cnblogs.com/runnerjack/p/9342362.html">https://www.cnblogs.com/runnerjack/p/9342362.html</a><br>git fetch 命令：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git fetch &lt;远程主机名&gt; //这个命令将某个远程主机的更新全部取回本地</span></span><br><span class="line">如果只想取回特定分支的更新，可以指定分支名：</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git fetch &lt;远程主机名&gt; &lt;分支名&gt; //注意之间有空格</span></span><br><span class="line">最常见的命令如取回origin 主机的master 分支：</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git fetch origin master</span></span><br><span class="line">取回更新后，会返回一个FETCH_HEAD ，指的是某个branch在服务器上的最新状态，我们可以在本地通过它查看刚取回的更新信息：</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">log</span> -p FETCH_HEAD</span></span><br><span class="line">前面提到，git pull 的过程可以理解为：</span><br><span class="line"></span><br><span class="line">git fetch origin master //从远程主机的master分支拉取最新内容 </span><br><span class="line">git merge FETCH_HEAD    //将拉取下来的最新内容合并到当前所在的分支中</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">即将远程主机的某个分支的更新取回，并与本地指定的分支合并，完整格式可表示为：</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;</span></span><br><span class="line">如果远程分支是与当前分支合并，则冒号后面的部分可以省略：</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git pull origin next</span></span><br></pre></td></tr></table></figure></p>
<h2 id="按后缀添加文件"><a href="#按后缀添加文件" class="headerlink" title="按后缀添加文件"></a>按后缀添加文件</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -name &#x27;*.py&#x27; -exec git add &#123;&#125; \;</span><br><span class="line">find . -name &#x27;*.sh&#x27; -exec git add &#123;&#125; \;</span><br><span class="line">find . -name &#x27;*.sql&#x27; -exec git add &#123;&#125; \;</span><br><span class="line"></span><br><span class="line">find . -name &#x27;*.dump&#x27; -exec git add &#123;&#125; \;</span><br><span class="line">find . -name &#x27;*.ipynb&#x27; -exec git add &#123;&#125; \;</span><br><span class="line">find . -name &#x27;*.model&#x27; -exec git add &#123;&#125; \;</span><br><span class="line">find . -name &#x27;*.model&#x27; -exec git checkout &#123;&#125; </span><br><span class="line"></span><br><span class="line">find . -name &#x27;*.model&#x27; -exec git add &#123;&#125; \;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">find ./ -regex .*transform_5k/.*meta -exec git add &#123;&#125; \;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">find /notebook/rta_cvr_git/3_tfModels/application/MMOE/transform_5k/ -name &#x27;*&#x27; -exec git add &#123;&#125; \;</span><br></pre></td></tr></table></figure>
<h2 id="git切换关联的远程仓库"><a href="#git切换关联的远程仓库" class="headerlink" title="git切换关联的远程仓库"></a>git切换关联的远程仓库</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 先删除关联</span><br><span class="line">git remote rm origin</span><br><span class="line">// 再关联新的地址</span><br><span class="line">git remote add origin XXXXXXXXXXXXX</span><br></pre></td></tr></table></figure>
<h2 id="删除某些已经存在的索引及文件"><a href="#删除某些已经存在的索引及文件" class="headerlink" title="删除某些已经存在的索引及文件"></a>删除某些已经存在的索引及文件</h2><p>原理：对所有文件的commit log进行重写，排除掉某些文件即可。<br>命令如下：</p>
<ol>
<li>删除远程和本地索引</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git filter-branch -f --tree-filter &#x27;rm -rf */.ipynb_checkpoints/*&#x27; HEAD</span><br></pre></td></tr></table></figure>
<p>当然，如果你还需要push到远端，就</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git push --set-upstream origin master  --force #也可以是别的分支</span><br></pre></td></tr></table></figure>
<ol>
<li>删除远程文件：IDE里直接删除并commit</li>
<li>pull</li>
</ol>
<p>注意</p>
<p>1、其他分支也需要删除commit索引</p>
<h2 id="强制覆盖本地的代码"><a href="#强制覆盖本地的代码" class="headerlink" title="强制覆盖本地的代码"></a>强制覆盖本地的代码</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git fetch --all</span><br><span class="line"><span class="meta">#</span><span class="bash">然后，你有两个选择：</span></span><br><span class="line">git reset --hard origin/master</span><br><span class="line"><span class="meta">#</span><span class="bash">或者如果你在其他分支上：</span></span><br><span class="line">git reset --hard origin/&lt;branch_name&gt;</span><br><span class="line"></span><br><span class="line">git pull</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">说明：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">git fetch从远程下载最新的，而不尝试合并或rebase任何东西。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">然后git reset将主分支重置为您刚刚获取的内容。 --hard选项更改工作树中的所有文件以匹配origin/master中的文件。</span></span><br></pre></td></tr></table></figure>
<h2 id="git-push"><a href="#git-push" class="headerlink" title="git push"></a>git push</h2><p>  git push的一般形式为 git push &lt;远程主机名&gt; &lt;本地分支名&gt;  &lt;远程分支名&gt; ，例如 git push origin master：refs/for/master ，即是将本地的master分支推送到远程主机origin上的对应master分支， origin 是远程主机名， 第一个master是本地分支名，第二个master是远程分支名。</p>
<p><strong>Git push</strong></p>
<p>​        在使用git commit命令将修改从暂存区提交到本地版本库后，只剩下最后一步将本地版本库的分支推送到远程服务器上对应的分支了，如果不清楚版本库的构成，可以查看我的另一篇，git 仓库的基本结构。</p>
<p>​    git push的一般形式为 git push &lt;远程主机名&gt; &lt;本地分支名&gt;  &lt;远程分支名&gt; ，例如 git push origin master：refs/for/master ，即是将本地的master分支推送到远程主机origin上的对应master分支， origin 是远程主机名，</p>
<p>​    第一个master是本地分支名，第二个master是远程分支名。</p>
<p>​    <strong>1.1 git push origin master</strong></p>
<p>​        如果远程分支被省略，如上则表示将本地分支推送到与之存在追踪关系的远程分支（通常两者同名），如果该远程分支不存在，则会被新建</p>
<p>​     <strong>1.2</strong> <strong>git push origin ：refs/for/master</strong> </p>
<p>　　如果省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支，等同于 git push origin —delete master</p>
<p>​    <strong>1.3</strong> <strong>git push origin</strong></p>
<p>　　 如果当前分支与远程分支存在追踪关系，则本地分支和远程分支都可以省略，将当前分支推送到origin主机的对应分支 </p>
<p>　<strong>1.4 git push</strong></p>
<p>　　如果当前分支只有一个远程分支，那么主机名都可以省略，形如 git push，可以使用git branch -r ，查看远程的分支名</p>
<p>　<strong>1.5 git push 的其他命令</strong></p>
<p>　　这几个常见的用法已足以满足我们日常开发的使用了，还有几个扩展的用法，如下：</p>
<p>　　　　（1） git push -u origin master 如果当前分支与多个主机存在追踪关系，则可以使用 -u 参数指定一个默认主机，这样后面就可以不加任何参数使用git push，</p>
<p>　　　　　　不带任何参数的git push，默认只推送当前分支，这叫做simple方式，还有一种matching方式，会推送所有有对应的远程分支的本地分支， Git 2.0之前默认使用matching，现在改为simple方式</p>
<p>　　　　　　如果想更改设置，可以使用git config命令。git config —global push.default matching OR git config —global push.default simple；可以使用git config -l 查看配置</p>
<p>　　　　（2） git push —all origin 当遇到这种情况就是不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要 -all 选项</p>
<p>　　　　（3） git push —force origin git push的时候需要本地先git pull更新到跟服务器版本一致，如果本地版本库比远程服务器上的低，那么一般会提示你git pull更新，如果一定要提交，那么可以使用这个命令。</p>
<p>　　　　（4） git push origin —tags //git push 的时候不会推送分支，如果一定要推送标签的话那么可以使用这个命令</p>
<h2 id="本地repository关联到远程"><a href="#本地repository关联到远程" class="headerlink" title="本地repository关联到远程"></a>本地repository关联到远程</h2><h3 id="1-打开在你的项目文件夹，输入下面的命令"><a href="#1-打开在你的项目文件夹，输入下面的命令" class="headerlink" title="1. 打开在你的项目文件夹，输入下面的命令"></a>1. 打开在你的项目文件夹，输入下面的命令</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/643024-20161117105613529-1331892400.png" alt="img"></p>
<p> 输完上面的命令，文件夹中会出现一个.git文件夹，如下图所示，其他的的文件也会出现蓝色小问号的标志</p>
<p> <img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/643024-20161020175232498-1872971817.png" alt="img"></p>
<h3 id="2-添加所有文件"><a href="#2-添加所有文件" class="headerlink" title="2. 添加所有文件"></a>2. 添加所有文件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git add .</span><br></pre></td></tr></table></figure>
<p>注意最后的点是有用的哦</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/643024-20161117105642248-437211863.png" alt="img"></p>
<p> 输入完成后，文件夹如下所示</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/643024-20161020175721045-34264600.png" alt="img"></p>
<h3 id="3-提交所有文件"><a href="#3-提交所有文件" class="headerlink" title="3. 提交所有文件"></a>3. 提交所有文件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git commit -m &quot;这里是备注信息&quot; -a</span><br></pre></td></tr></table></figure>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/git基础操作笔记.assets\643024-20161117105723982-456456864.png" alt="img"></p>
<p> 完成后，文件夹显示如下</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/643024-20161020180119123-417194644.png" alt="img"></p>
<p>都会出现绿色的小对勾</p>
<h3 id="4-连接到远程仓库"><a href="#4-连接到远程仓库" class="headerlink" title="4. 连接到远程仓库"></a>4. 连接到远程仓库</h3><p>提前在你的github中新建一个仓库，操作如下</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/643024-20161020180953357-871156867.png" alt="img"></p>
<p>建好后，取好项目名称，点击create repository按钮，完成仓库的建立</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/643024-20161020180830388-1568291414.png" alt="img"></p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/643024-20161026120125703-263387261.png" alt="img"></p>
<p>点击红色框出的小按钮，复制链接 </p>
<h3 id="5-连接远程仓库"><a href="#5-连接远程仓库" class="headerlink" title="5. 连接远程仓库"></a>5. 连接远程仓库</h3><p>在本地的命令框中输入下面的命令，即连接到了名为poster的仓库上</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git remote add origin https://github.com/OliveKong/poster.git </span><br></pre></td></tr></table></figure>
<p> <img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/643024-20161117105800279-1083550297.png" alt="img"></p>
<h3 id="6-把本地项目推送到远程仓库"><a href="#6-把本地项目推送到远程仓库" class="headerlink" title="6.把本地项目推送到远程仓库"></a>6.把本地项目推送到远程仓库</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git push -u origin master </span><br></pre></td></tr></table></figure>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/git%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/643024-20161117105822107-1011418356.png" alt="img"></p>
<h2 id="git-ignore"><a href="#git-ignore" class="headerlink" title="git ignore"></a>git ignore</h2><p>.gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。</p>
<p>解决方法就是先把本地缓存删除（改变成未track状态），然后再提交:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git rm -r --cached .</span><br><span class="line">git add .</span><br><span class="line">git commit -m &#x27;update .gitignore&#x27;</span><br></pre></td></tr></table></figure>
<h1 id="git-工作流程"><a href="#git-工作流程" class="headerlink" title="git 工作流程"></a>git 工作流程</h1><p><a href="https://blog.csdn.net/zyw0713/article/details/80083431">https://blog.csdn.net/zyw0713/article/details/80083431</a></p>
<h2 id="主master分支"><a href="#主master分支" class="headerlink" title="主master分支"></a>主master分支</h2><h2 id="开发分支develop"><a href="#开发分支develop" class="headerlink" title="开发分支develop"></a>开发分支develop</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Git创建Develop分支的命令</span></span><br><span class="line">git checkout -b develop master  <span class="comment">#相当于 创建新分支：git branch branchName 切换到新分支：git checkout branchName</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将Develop分支发布到Master分支的命令</span></span><br><span class="line">git checkout master</span><br><span class="line">git merge --no-ff develop</span><br></pre></td></tr></table></figure>
<p>—no-ff参数：默认情况下，Git执行”快进式合并”，会直接将Master分支指向Develop分支。强推。少用！！</p>
<h2 id="临时分支（功能feature，预发布release，fixbug）"><a href="#临时分支（功能feature，预发布release，fixbug）" class="headerlink" title="临时分支（功能feature，预发布release，fixbug）"></a>临时分支（功能feature，预发布release，fixbug）</h2><p>前面讲到版本库的两条主要分支：Master和Develop。前者用于正式发布，后者用于日常开发。其实，常设分支只需要这两条就够了，不需要其他了。</p>
<p>但是，除了常设分支以外，还有一些临时性分支，用于应对一些特定目的的版本开发。临时性分支主要有三种：</p>
<ul>
<li><p>功能分支 （feature）</p>
</li>
<li><p>预发布分支 (release)</p>
</li>
<li><p>修补bug分支 (fixbug)</p>
</li>
</ul>
<p>这三种分支都属于临时性需要，使用完以后，应该删除，使得代码库的常设分支始终只有Master和Develop。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建一个功能分支</span></span><br><span class="line">git checkout -b feature-x develop</span><br><span class="line"><span class="comment">#合并到develop分支</span></span><br><span class="line">git checkout develop</span><br><span class="line">git merge --no-ff feature-x</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#删除feature分支</span></span><br><span class="line">git branch -d feature-x</span><br></pre></td></tr></table></figure>
<h2 id="克隆其他分支"><a href="#克隆其他分支" class="headerlink" title="克隆其他分支"></a>克隆其他分支</h2><p>假设要clone dev分支：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> ........ <span class="comment">#把项目从远程clone到本地，默认clonemaster分支</span></span><br><span class="line">git pull origin dev:dev  <span class="comment">#把远程的dev分支拉到本地的dev分支。冒号前是远程分支名，冒号后是本地分支名</span></span><br></pre></td></tr></table></figure>
<h1 id="注释规范"><a href="#注释规范" class="headerlink" title="注释规范"></a>注释规范</h1><p>Added (新加入的需求)</p>
<p>　　Fixed： (修复bug )</p>
<p>　　Changed ：(完成的任务)</p>
<p>　　Updated： (完成的任务，或者由于第三方模块变化而做的变化)</p>
<p>　　Mod: 修改（Modify）</p>
<p>　　Add: a new module to have faster process, 表示新增（Add）</p>
<p>　　Rem: deprecate unused modules, 表示移除（Remove）</p>
<p>　　Ref: improved the implementation of module X, 表示重构（Refactory）</p>
<p>假如有 Issues 系统，其中可以包含 Issue 的 ID。比如：Issue #123456</p>
<h1 id="上传大文件失败"><a href="#上传大文件失败" class="headerlink" title="上传大文件失败"></a>上传大文件失败</h1><p>参考： <a href="https://blog.csdn.net/quiet_girl/article/details/79487966">https://blog.csdn.net/quiet_girl/article/details/79487966</a></p>
<p>git push 时，存在大文件会报错，即使删除大文件后，还会报错。主要是因为大文件存在没有被提交的commit记录里面。</p>
<p><strong>解决方案：删除有大文件的commit记录即可</strong></p>
<p>1、git status 查看未被传送到远程代码库的提交状态</p>
<p>2、git cherry -v 查看未被传送到远程代码库的提交描述和说明</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cc@lcc MyDoc$ git cherry -v </span><br><span class="line">+ 0bd8c12c3b44c5d16ff6e9ce84d00230561b7f12 kafka console消费失败</span><br><span class="line">+ 0f535fa58f413913c2c5ce37b85bf0803ea88f0b kafka console消费失败</span><br><span class="line">+ 3342e8c5db5c8d4533a70c80cf2a480ef0dd94f8 kafka console消费失败</span><br><span class="line">+ de978a99704e1bec6d2e81fcfd24900e6be43d8e kafka console消费失败</span><br><span class="line">+ f96a7d270c8d6a253530309a9f485a8d2a84befe kafka console消费失败</span><br><span class="line">+ 8ebe1f4d47845ddf21e7f14c031e73ec4f786722 drui io</span><br><span class="line">+ f8e4b51169d00242fff77aae182097cecbbff95a drui io</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>3、git reset commit_id 撤销未被传送到远程代码库的提交</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">这里我选择第一个</span><br><span class="line">cc@lcc MyDoc$ git reset 0bd8c12c3b44c5d16ff6e9ce84d00230561b7f12</span><br><span class="line">Unstaged changes after reset:</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>移除大文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lcc@lcc MyDoc$ git rm --cached *.pdf</span><br><span class="line"><span class="comment">#这里我直接移除所有的pdf文件。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#然后备份这些pdf文件 </span></span><br><span class="line">lcc@lcc MyDoc$ mv ./*/*.pdf ~/Downloads/</span><br></pre></td></tr></table></figure>
<h2 id="【git】全局配置和单个仓库的用户名邮箱配置"><a href="#【git】全局配置和单个仓库的用户名邮箱配置" class="headerlink" title="【git】全局配置和单个仓库的用户名邮箱配置"></a>【git】全局配置和单个仓库的用户名邮箱配置</h2><p>Git全局配置和单个仓库的用户名邮箱配置</p>
<p>学习git的时候, 大家刚开始使用之前都配置了一个全局的用户名和邮箱</p>
<p>$ git config —global user.name “github’s Name”</p>
<p>$ git config —global user.email “github@xx.com”</p>
<p>$ git config —list</p>
<p>如果你公司的项目是放在自建的gitlab上面, 如果你不进行配置用户名和邮箱的话, 则会使用全局的, 这个时候是错误的, 正确的做法是针对公司的项目, 在项目根目录下进行单独配置</p>
<p>$ git config user.name “gitlab’s Name”</p>
<p>$ git config user.email “gitlab@xx.com”</p>
<p>$ git config —list</p>
<p> git config —list查看当前配置, 在当前项目下面查看的配置是全局配置+当前项目的配置, 使用的时候会优先使用当前项目的配置</p>
<h1 id="问题集锦"><a href="#问题集锦" class="headerlink" title="问题集锦"></a>问题集锦</h1><h2 id="not-staged"><a href="#not-staged" class="headerlink" title="not staged"></a>not staged</h2>
<p>解决：如果已add .之后还是报这个问题，就是这几个目录下有git文件（这些git文件没有add）</p>
<h2 id="Please-commit-your-changes-or-stash-them-before-you-merge"><a href="#Please-commit-your-changes-or-stash-them-before-you-merge" class="headerlink" title="Please commit your changes or stash them before you merge."></a>Please commit your changes or stash them before you merge.</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git stash</span><br><span class="line">git pull</span><br></pre></td></tr></table></figure>
<h2 id="fatal-refusing-to-merge-unrelated-histories"><a href="#fatal-refusing-to-merge-unrelated-histories" class="headerlink" title="fatal: refusing to merge unrelated histories"></a>fatal: refusing to merge unrelated histories</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git pull origin master --allow-unrelated-histories</span><br></pre></td></tr></table></figure>
<h2 id="中文显示乱码"><a href="#中文显示乱码" class="headerlink" title="中文显示乱码"></a>中文显示乱码</h2><p><a href="https://blog.csdn.net/u012145252/article/details/81775362">https://blog.csdn.net/u012145252/article/details/81775362</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config --global core.quotepath false</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>hdfs常用命令</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/hdfs%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>hdfs常用操作</p>
<span id="more"></span>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html</span><br><span class="line">1.hdfs命令行</span><br><span class="line">    （1）查看帮助</span><br><span class="line">        hdfs dfs -help </span><br><span class="line">        </span><br><span class="line">    （2）查看当前目录信息</span><br><span class="line">        hdfs dfs -ls /</span><br><span class="line">        </span><br><span class="line">    （3）上传文件</span><br><span class="line">        hdfs dfs -put /本地路径 /hdfs路径</span><br><span class="line">        </span><br><span class="line">    （4）剪切文件</span><br><span class="line">        hdfs dfs -moveFromLocal a.txt /aa.txt</span><br><span class="line">        </span><br><span class="line">    （5）下载文件到本地</span><br><span class="line">        hdfs dfs -get /hdfs路径 /本地路径</span><br><span class="line">        </span><br><span class="line">    （6）合并下载</span><br><span class="line">        hdfs dfs -getmerge /hdfs路径文件夹 /合并后的文件</span><br><span class="line">        </span><br><span class="line">    （7）创建文件夹</span><br><span class="line">        hdfs dfs -mkdir /hello</span><br><span class="line">        </span><br><span class="line">    （8）创建多级文件夹</span><br><span class="line">        hdfs dfs -mkdir -p /hello/world</span><br><span class="line">        </span><br><span class="line">    （9）移动hdfs文件</span><br><span class="line">        hdfs dfs -mv /hdfs路径 /hdfs路径</span><br><span class="line">        </span><br><span class="line">    （10）复制hdfs文件</span><br><span class="line">        hdfs dfs -cp /hdfs路径 /hdfs路径</span><br><span class="line">        </span><br><span class="line">    （11）删除hdfs文件</span><br><span class="line">        hdfs dfs -rm /aa.txt</span><br><span class="line">        </span><br><span class="line">    （12）删除hdfs文件夹</span><br><span class="line">        hdfs dfs -rm -r /hello</span><br><span class="line">        </span><br><span class="line">    （13）查看hdfs中的文件</span><br><span class="line">        hdfs dfs -cat /文件</span><br><span class="line">        hdfs dfs -tail -f /文件</span><br><span class="line">        </span><br><span class="line">    （14）查看文件夹中有多少个文件</span><br><span class="line">        hdfs dfs -count /文件夹</span><br><span class="line">        </span><br><span class="line">    （15）查看hdfs的总空间</span><br><span class="line">        hdfs dfs -df /</span><br><span class="line">        hdfs dfs -df -h /</span><br><span class="line">        </span><br><span class="line">    （16）修改副本数    </span><br><span class="line">        hdfs dfs -setrep 1 /a.txt</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>anaconda+tensorflow安装教程</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/anaconda+tensorflow%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>anaconda+tensorflow安装教程</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="安装pip-conda-tensorflow"><a href="#安装pip-conda-tensorflow" class="headerlink" title="安装pip,conda,tensorflow"></a>安装pip,conda,tensorflow</h1><ol>
<li><p>安装pip</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip --version #check id exists</span><br><span class="line"></span><br><span class="line">sudo easy_install pip #安装pip</span><br></pre></td></tr></table></figure>
<p>1    q官网下载并安装anaconda,安装时勾选添加环境变量【非常重要，不然后续会出错】</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> anaconda path 如果忘记勾选了，要配置环境变量</span></span><br><span class="line">vim ~/.bash_proflw</span><br><span class="line">export PATH=$PATH:/Users/hetianqi/opt/anaconda3/bin/</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>cmd中确认conda安装正确</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda -V</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建新的虚拟环境</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> <span class="comment">#windows 的tensorflow只支持python3以上，3.6稳定，3.7和3.8都不稳定</span></span><br><span class="line">conda create -n python3.6 python=3.6 </span><br><span class="line">conda info -e</span><br><span class="line">conda env list</span><br><span class="line">conda activate python3.6  </span><br></pre></td></tr></table></figure>
</li>
<li><p>安装tensorflow</p>
<p><a href="https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/tensorflow/">https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/tensorflow/</a> 清华镜像，可查询tensorflow版本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pip+清华镜像</span></span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple tensorflow==2.0.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># pip+豆瓣镜像</span></span><br><span class="line">pip install -i https://pypi.douban.com/simple tensorflow==2.0.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># conda + </span></span><br><span class="line">conda install --channel https://conda.anaconda.org/anaconda tensorflow=2.0.0</span><br><span class="line"></span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pandas</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>在jupyterlab中使用tf</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source activate 环境 #激活环境</span><br><span class="line">conda install ipykernel</span><br><span class="line">conda install ipython</span><br><span class="line">conda install jupyterlab</span><br><span class="line">ipython kernelspec install-self ––user</span><br><span class="line">python -m ipykernel install --user --name 环境名称 --display-name “环境名称” </span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>安装xgboost</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple XGBoost  <span class="comment">#win10</span></span><br><span class="line">conda install py-xgboost <span class="comment">#mac</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>安装torch</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">pip install torch===1.3.0 torchvision===0.4.1 -f https://download.pytorch.org/whl/torch_stable.html -i  https://pypi.mirrors.ustc.edu.cn/simple/</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="安装scala-pyspark"><a href="#安装scala-pyspark" class="headerlink" title="安装scala,pyspark"></a>安装scala,pyspark</h1><ol>
<li><p>安装brew</p>
<p>在网上搜了很多brew安装方式，包括使用官网的方式都安装报错<br>Failed to connect to raw.githubusercontent.com port 443: Connection refused</p>
<p>可使用一下源</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/bin/zsh -c &quot;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装scala</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">brew search scala #查看可安装版本</span><br><span class="line">brew instal scala@2.12</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改~/.bash_profile</span></span><br><span class="line">export PATH=&quot;/usr/local/opt/scala@2.11/bin:$PATH</span><br><span class="line">scala -version #check是否安装成功</span><br></pre></td></tr></table></figure>
<p>报错： Error opening archive: Failed to open ‘/Users/hetianqi/Library/Caches/Homebrew/downloads/d1650a0762f1f057c43d5600d72a18d9aaa0c5da3cd172cac87ae9fcb6439bc0—openjdk-16.0.1.big_sur.bottle.tar.gz’</p>
<p>解决方法：export HOMEBREW_BOTTLE_DOMAIN=’’ </p>
<p>详细解释参考 <a href="https://zhuanlan.zhihu.com/p/383707713">https://zhuanlan.zhihu.com/p/383707713</a></p>
<blockquote>
<p>如果scala交互模式下方向键乱码，则在~/.bash_profile中添加</p>
<p>export TERM=xterm-color</p>
</blockquote>
</li>
<li><p>安装spark</p>
<p>a) 下载安装包 <a href="http://spark.apache.org/downloads.html">http://spark.apache.org/downloads.html</a></p>
</li>
</ol>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/anaconda+tensorflow%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/anaconda+tensorflow安装教程/image-20211013142113102.png" alt="image-20211013142113102" style="zoom:50%;"></p>
<p>​        b) 解压安装包，复制到路径 /usr/local/Cellar/</p>
<p>​        c) 修改~/.bash_profile</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">	</span><br><span class="line">export SPARK_HOME=/usr/local/Cellar/spark/</span><br><span class="line">export PATH=$SPARK_HOME:$SPARK_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>​        d) check是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-shell</span><br></pre></td></tr></table></figure>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/anaconda+tensorflow%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/anaconda+tensorflow安装教程/image-20211013142621551.png" alt="image-20211013142621551" style="zoom:50%;"></p>
<ol>
<li>安装pyspark</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install pyspark</span><br></pre></td></tr></table></figure>
<ol>
<li><p>配置idea for scala and spark</p>
<p>Step1：建空maven项目</p>
<p>Step2:  建scala目录并mark as source</p>
<p>Step3: 下载scala插件：preference —&gt; pluging —&gt;scala</p>
<p>Step4: 增加框架支持：右击工程—&gt; add framework —&gt; scala</p>
<p>Step5: 添加apache jars: 右击工程 —&gt; open module settings —&gt; libraries —&gt; + java —&gt; browes —&gt; /usr/local/Cellar/spark/jars  (finder看不见这个文件夹可以 commmand + shift + G)</p>
</li>
</ol>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>hive</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/hive/</url>
    <content><![CDATA[<p>hive 常用操作</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h1><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> tb_name</span><br><span class="line">(a string comment <span class="string">&#x27;a&#x27;</span>,b string comment <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="type">row</span> format delimited</span><br><span class="line">fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> textfile;</span><br></pre></td></tr></table></figure>
<h1 id="增加map数量"><a href="#增加map数量" class="headerlink" title="增加map数量"></a>增加map数量</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set mapred.max.split.size=10000000; -- 决定每个map处理的最大的文件大小，单位为B</span><br><span class="line">set mapred.min.split.size.per.node=10000000; -- 节点中可以处理的最小的文件大小</span><br><span class="line">set mapred.min.split.size.per.rack=10000000; -- 机架中可以处理的最小的文件大小</span><br><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;---实现map中的数据合并需要设置下面的参数，集群默认就是这个格式</span><br></pre></td></tr></table></figure>
<h1 id="查询log"><a href="#查询log" class="headerlink" title="查询log"></a>查询log</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yarn logs -applicationId=application_1556066424096_26253 | less</span><br></pre></td></tr></table></figure>
<h1 id="设置变量"><a href="#设置变量" class="headerlink" title="设置变量"></a>设置变量</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#hivevar</span></span><br><span class="line">hive -d name=hetianqi -f temp.sql</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> name;</span><br><span class="line"><span class="comment">--set name=hetinaiq;</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> name<span class="operator">=</span>$&#123;name&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Hive中Create-table…-as-和-Create-table-…-like-的区别和使用注意"><a href="#Hive中Create-table…-as-和-Create-table-…-like-的区别和使用注意" class="headerlink" title="Hive中Create table… as 和 Create table … like 的区别和使用注意"></a>Hive中Create table… as 和 Create table … like 的区别和使用注意</h1><p><a href="https://blog.csdn.net/lzw2016/article/details/97811799">https://blog.csdn.net/lzw2016/article/details/97811799</a></p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>mac使用rz sz</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/mac%E4%BD%BF%E7%94%A8rz%20sz/</url>
    <content><![CDATA[<p>mac配置rz sz</p>
<span id="more"></span>
<p>一、安装brew<br> <code>/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</code><br> 二、安装iterm2<br> <code>brew cask install iterm2</code><br> 三、安装lrzsz<br> <code>sudo brew install lrzsz</code><br> 四、将下面2个脚本保存到 <code>/usr/local/bin/</code>下<br> 1.iterm2-recv-zmodem.sh</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># Author: Matt Mastracci (matthew@mastracci.com)</span></span><br><span class="line"><span class="comment"># AppleScript from http://stackoverflow.com/questions/4309087/cancel-button-on-osascript-in-a-bash-script</span></span><br><span class="line"><span class="comment"># licensed under cc-wiki with attribution required </span></span><br><span class="line"><span class="comment"># Remainder of script public domain</span></span><br><span class="line"></span><br><span class="line">osascript -e <span class="string">&#x27;tell application &quot;iTerm2&quot; to version&#x27;</span> &gt; /dev/null 2&gt;&amp;1 &amp;&amp; NAME=iTerm2 || NAME=iTerm</span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$NAME</span> = <span class="string">&quot;iTerm&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    FILE=`osascript -e <span class="string">&#x27;tell application &quot;iTerm&quot; to activate&#x27;</span> -e <span class="string">&#x27;tell application &quot;iTerm&quot; to set thefile to choose folder with prompt &quot;Choose a folder to place received files in&quot;&#x27;</span> -e <span class="string">&quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;</span>`</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    FILE=`osascript -e <span class="string">&#x27;tell application &quot;iTerm2&quot; to activate&#x27;</span> -e <span class="string">&#x27;tell application &quot;iTerm2&quot; to set thefile to choose folder with prompt &quot;Choose a folder to place received files in&quot;&#x27;</span> -e <span class="string">&quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;</span>`</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$FILE</span> = <span class="string">&quot;&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> Cancelled.</span><br><span class="line">    <span class="comment"># Send ZModem cancel</span></span><br><span class="line">    <span class="built_in">echo</span> -e \\x18\\x18\\x18\\x18\\x18</span><br><span class="line">    sleep 1</span><br><span class="line">    <span class="built_in">echo</span></span><br><span class="line">    <span class="built_in">echo</span> \<span class="comment"># Cancelled transfer</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">cd</span> <span class="string">&quot;<span class="variable">$FILE</span>&quot;</span></span><br><span class="line">    /usr/<span class="built_in">local</span>/bin/rz -E -e -b</span><br><span class="line">    sleep 1</span><br><span class="line">    <span class="built_in">echo</span></span><br><span class="line">    <span class="built_in">echo</span></span><br><span class="line">    <span class="built_in">echo</span> \<span class="comment"># Sent \-\&gt; $FILE</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>2.iterm2-send-zmodem.sh</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># Author: Matt Mastracci (matthew@mastracci.com)</span></span><br><span class="line"><span class="comment"># AppleScript from http://stackoverflow.com/questions/4309087/cancel-button-on-osascript-in-a-bash-script</span></span><br><span class="line"><span class="comment"># licensed under cc-wiki with attribution required </span></span><br><span class="line"><span class="comment"># Remainder of script public domain</span></span><br><span class="line"></span><br><span class="line">osascript -e <span class="string">&#x27;tell application &quot;iTerm2&quot; to version&#x27;</span> &gt; /dev/null 2&gt;&amp;1 &amp;&amp; NAME=iTerm2 || NAME=iTerm</span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$NAME</span> = <span class="string">&quot;iTerm&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    FILE=`osascript -e <span class="string">&#x27;tell application &quot;iTerm&quot; to activate&#x27;</span> -e <span class="string">&#x27;tell application &quot;iTerm&quot; to set thefile to choose file with prompt &quot;Choose a file to send&quot;&#x27;</span> -e <span class="string">&quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;</span>`</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    FILE=`osascript -e <span class="string">&#x27;tell application &quot;iTerm2&quot; to activate&#x27;</span> -e <span class="string">&#x27;tell application &quot;iTerm2&quot; to set thefile to choose file with prompt &quot;Choose a file to send&quot;&#x27;</span> -e <span class="string">&quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;</span>`</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$FILE</span> = <span class="string">&quot;&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> Cancelled.</span><br><span class="line">    <span class="comment"># Send ZModem cancel</span></span><br><span class="line">    <span class="built_in">echo</span> -e \\x18\\x18\\x18\\x18\\x18</span><br><span class="line">    sleep 1</span><br><span class="line">    <span class="built_in">echo</span></span><br><span class="line">    <span class="built_in">echo</span> \<span class="comment"># Cancelled transfer</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    /usr/<span class="built_in">local</span>/bin/sz <span class="string">&quot;<span class="variable">$FILE</span>&quot;</span> -e -b</span><br><span class="line">    sleep 1</span><br><span class="line">    <span class="built_in">echo</span></span><br><span class="line">    <span class="built_in">echo</span> \<span class="comment"># Received $FILE</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>五、添加iTerm2 trigger</p>
<p>Item-profile-advanced-edit-default-add</p>
<p><img src="/Users/hetianqi/Library/Application Support/typora-user-images/image-20200403193423571.png" alt="image-20200403193423571"></p>
<blockquote>
<p>注意！！！</p>
<p>paramers一定要加绝对路径！！！</p>
</blockquote>
<p>配置项：</p>
<p>Regular expression      　　Action      　　　　　　　Parameters</p>
<p>/<em>/</em>B0100　　　　　　　　Run Silent Coprocess　　/usr/local/bin/iterm2-send-zmodem.sh</p>
<p>/<em>/</em>B00000000000000　  Run Silent Coprocess　　/usr/local/bin/iterm2-recv-zmodem.sh</p>
<p> 六：sudo</p>
<p>sudo chmod 777 /usr/local/bin/iterm2-*</p>
<p>配置完重启即可使用rz 和sz命令。</p>
<p>作者：小黑胖_<br>链接：<a href="https://www.jianshu.com/p/c23896b96b6c">https://www.jianshu.com/p/c23896b96b6c</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>mathtype破解教程</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/mathtype%E7%A0%B4%E8%A7%A3%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>如题</p>
<span id="more"></span>
<ol>
<li><code>Windows + R</code> 然后输入<code>regedit.exe</code> 后确定，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190426093524662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hvdXdhbmxl,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
<li>来到目录<code>HKEY_CURRENT_USER\Software\Install Options</code> 下，删除图片中红线标出来的文件：<br><img src="https://img-blog.csdnimg.cn/20190426094144337.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hvdXdhbmxl,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
<li>操作完上面的步骤后，重新打开MathType，又可以试用30天啦~</li>
</ol>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>numpy</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/numpy/</url>
    <content><![CDATA[<p>numpy常用操作</p>
<span id="more"></span>
<h1 id="增加行或列"><a href="#增加行或列" class="headerlink" title="增加行或列"></a>增加行或列</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#增加列</span></span><br><span class="line">a=np.random.randn(<span class="number">4</span>,<span class="number">2</span>)</span><br><span class="line">b=np.random.randn(<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">c=np.column_stack((a,b))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#增加行</span></span><br><span class="line">a=np.random.randn(<span class="number">4</span>,<span class="number">2</span>)</span><br><span class="line">b=np.random.randn(<span class="number">4</span>,<span class="number">2</span>)</span><br><span class="line">c=np.row_stack((a,b))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>pandas</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/pandas/</url>
    <content><![CDATA[<p>pandas常用操作</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="python调用shell"><a href="#python调用shell" class="headerlink" title="python调用shell"></a>python调用shell</h1><p>在python程序中调用shell命令，是件很酷且常用的事情……</p>
<p><a href="https://www.cnblogs.com/pengdonglin137/articles/8093409.html">https://www.cnblogs.com/pengdonglin137/articles/8093409.html</a></p>
<h2 id="os-system-command"><a href="#os-system-command" class="headerlink" title="os.system(command)"></a>os.system(command)</h2><p>  此函数会启动子进程，在子进程中执行command，并返回command命令执行完毕后的退出状态，如果command有执行内容，会在标准输出显示。这实际上是使用C标准库函数system()实现的。</p>
<blockquote>
<p>缺点：这个函数在执行command命令时需要重新打开一个终端，并且无法保存command命令的执行结果。<br>实例：os.system(‘ls -l *’)</p>
<h2 id="os-popen-command-mode"><a href="#os-popen-command-mode" class="headerlink" title="os.popen(command,mode)"></a>os.popen(command,mode)</h2></blockquote>
<p>打开一个与command进程之间的管道。这个函数的返回值是一个文件对象，可以读或者写(由mode决定，mode默认是’r’)。如果mode为’r’，可以使用此函数的返回值调用read()来获取command命令的执行结果。</p>
<p>os.system(cmd)或os.popen(cmd)，前者返回值是脚本的退出状态码，后者的返回值是脚本执行过程中的输出内容。实际使用时视需求情况而选择。</p>
<p>实例：tmp = os.popen(‘ls -l *’).readlines()</p>
<h1 id="同时写入多个sheet"><a href="#同时写入多个sheet" class="headerlink" title="同时写入多个sheet"></a>同时写入多个sheet</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_excel_pd</span>(<span class="params">file, sheet, data</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    excel title: name /  age</span></span><br><span class="line"><span class="string">        df1 = &#123;</span></span><br><span class="line"><span class="string">        &#x27;name&#x27;: [1, 2, 3],</span></span><br><span class="line"><span class="string">        &#x27;age&#x27;: [1, 2, 3]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    pandas DataFrame  write to excel</span></span><br><span class="line"><span class="string">    :param file:  file_path + file_name</span></span><br><span class="line"><span class="string">    :param sheet: type：list</span></span><br><span class="line"><span class="string">    :param data: type: list  DataFrame</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    writer = pd.ExcelWriter(file)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sheet)):</span><br><span class="line">        df = pd.DataFrame(data[i])</span><br><span class="line">        df.to_excel(excel_writer=writer, sheet_name=sheet[i])</span><br><span class="line">    writer.save()</span><br><span class="line">    writer.close()</span><br><span class="line">    log.info(<span class="string">&#x27;写入数据完成！&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="按条件过滤行"><a href="#按条件过滤行" class="headerlink" title="按条件过滤行"></a>按条件过滤行</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[df[A] &gt; <span class="number">0</span>] <span class="comment">#选出A列&gt;0的行</span></span><br><span class="line">df[df[A]。isin([<span class="number">0</span>,<span class="number">1</span>])] <span class="comment">#选出A列中是0或1的行</span></span><br></pre></td></tr></table></figure>
<h1 id="读入"><a href="#读入" class="headerlink" title="读入"></a>读入</h1><p>import pandas as pd<br>df=pd.read_table(‘dddd.txt’,header=0,index_col=0,error_bad_lines=False,delimiter=’\t’)</p>
<h1 id="列名"><a href="#列名" class="headerlink" title="列名"></a>列名</h1><p>df.columns</p>
<h1 id="删除列"><a href="#删除列" class="headerlink" title="删除列"></a>删除列</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.drop([<span class="string">&#x27;k&#x27;</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>) <span class="comment">#删除k列</span></span><br></pre></td></tr></table></figure>
<h1 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h1><p>values={}<br>with open(‘fill_na.txt’) as f:<br>    for line in f:<br>        line = line.strip().split(‘:’)<br>        values[line[0]] = int(line[1])<br>df = df.fillna(value=values)<br>df = df.dropna(axis=0,how=’any’) #删除含有NULL的行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#删除指定列有空值的行</span></span><br><span class="line">df_ios_tmp=df_ios.dropna(subset=[列名],how=<span class="string">&#x27;all&#x27;</span>,inplace=<span class="literal">False</span>) <span class="comment">#how=all 或者 any</span></span><br></pre></td></tr></table></figure>
<h1 id="shuffle"><a href="#shuffle" class="headerlink" title="shuffle"></a>shuffle</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h1 id="数据检查"><a href="#数据检查" class="headerlink" title="数据检查"></a>数据检查</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#datafram 每一列值unique数</span></span><br><span class="line">data_idfa.info(verbose=<span class="literal">True</span>, null_counts=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#每一列均值 方差等</span></span><br><span class="line">data_idfa.describe()</span><br></pre></td></tr></table></figure>

<h1 id="group-by"><a href="#group-by" class="headerlink" title="group by"></a>group by</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_ios.groupby([<span class="string">&#x27;y_flag&#x27;</span>], as_index=<span class="literal">False</span>)[<span class="string">&#x27;dt&#x27;</span>].count() <span class="comment">#聚合函数除了count还有sum,min,max等</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_ios.groupby([<span class="string">&#x27;dt_m&#x27;</span>,<span class="string">&#x27;y_flag&#x27;</span>], as_index=<span class="literal">False</span>)[<span class="string">&#x27;pin&#x27;</span>].count()</span><br></pre></td></tr></table></figure>

<h1 id="截取时间前几位"><a href="#截取时间前几位" class="headerlink" title="截取时间前几位"></a>截取时间前几位</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_ios[<span class="string">&#x27;dt_m&#x27;</span>]=df_ios[<span class="string">&#x27;dt&#x27;</span>].<span class="built_in">str</span>[<span class="number">0</span>:<span class="number">7</span>]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>pandas常用命令</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/pandas%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>10 minutes to pandas</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="10-minutes-to-pandas"><a href="#10-minutes-to-pandas" class="headerlink" title="10 minutes to pandas"></a>10 minutes to pandas</h1><p>This is a short introduction to pandas, geared mainly for new users. You can see more complex recipes in the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html#cookbook">Cookbook</a>.</p>
<p>Customarily, we import as follows:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [1]: import numpy as np</span><br><span class="line"></span><br><span class="line">In [2]: import pandas as pd</span><br></pre></td></tr></table></figure>
<h2 id="Object-creation"><a href="#Object-creation" class="headerlink" title="Object creation"></a>Object creation</h2><p>See the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dsintro">Data Structure Intro section</a>.</p>
<p>Creating a <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series"><code>Series</code></a> by passing a list of values, letting pandas create a default integer index:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [3]: s = pd.Series([1, 3, 5, np.nan, 6, 8])</span><br><span class="line"></span><br><span class="line">In [4]: s</span><br><span class="line">Out[4]: </span><br><span class="line">0    1.0</span><br><span class="line">1    3.0</span><br><span class="line">2    5.0</span><br><span class="line">3    NaN</span><br><span class="line">4    6.0</span><br><span class="line">5    8.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<p>Creating a <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame"><code>DataFrame</code></a> by passing a NumPy array, with a datetime index and labeled columns:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [5]: dates = pd.date_range(&#x27;20130101&#x27;, periods=6)</span><br><span class="line"></span><br><span class="line">In [6]: dates</span><br><span class="line">Out[6]: </span><br><span class="line">DatetimeIndex([&#x27;2013-01-01&#x27;, &#x27;2013-01-02&#x27;, &#x27;2013-01-03&#x27;, &#x27;2013-01-04&#x27;,</span><br><span class="line">               &#x27;2013-01-05&#x27;, &#x27;2013-01-06&#x27;],</span><br><span class="line">              dtype=&#x27;datetime64[ns]&#x27;, freq=&#x27;D&#x27;)</span><br><span class="line"></span><br><span class="line">In [7]: df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(&#x27;ABCD&#x27;))</span><br><span class="line"></span><br><span class="line">In [8]: df</span><br><span class="line">Out[8]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401</span><br><span class="line">2013-01-06 -0.673690  0.113648 -1.478427  0.524988</span><br></pre></td></tr></table></figure>
<p>Creating a <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame"><code>DataFrame</code></a> by passing a dict of objects that can be converted to series-like.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [9]: df2 = pd.DataFrame(&#123;&#x27;A&#x27;: 1.,</span><br><span class="line">   ...:                     &#x27;B&#x27;: pd.Timestamp(&#x27;20130102&#x27;),</span><br><span class="line">   ...:                     &#x27;C&#x27;: pd.Series(1, index=list(range(4)), dtype=&#x27;float32&#x27;),</span><br><span class="line">   ...:                     &#x27;D&#x27;: np.array([3] * 4, dtype=&#x27;int32&#x27;),</span><br><span class="line">   ...:                     &#x27;E&#x27;: pd.Categorical([&quot;test&quot;, &quot;train&quot;, &quot;test&quot;, &quot;train&quot;]),</span><br><span class="line">   ...:                     &#x27;F&#x27;: &#x27;foo&#x27;&#125;)</span><br><span class="line">   ...: </span><br><span class="line"></span><br><span class="line">In [10]: df2</span><br><span class="line">Out[10]: </span><br><span class="line">     A          B    C  D      E    F</span><br><span class="line">0  1.0 2013-01-02  1.0  3   test  foo</span><br><span class="line">1  1.0 2013-01-02  1.0  3  train  foo</span><br><span class="line">2  1.0 2013-01-02  1.0  3   test  foo</span><br><span class="line">3  1.0 2013-01-02  1.0  3  train  foo</span><br></pre></td></tr></table></figure>
<p>The columns of the resulting <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame"><code>DataFrame</code></a> have different <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#basics-dtypes">dtypes</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [11]: df2.dtypes</span><br><span class="line">Out[11]: </span><br><span class="line">A           float64</span><br><span class="line">B    datetime64[ns]</span><br><span class="line">C           float32</span><br><span class="line">D             int32</span><br><span class="line">E          category</span><br><span class="line">F            object</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure>
<p>If you’re using IPython, tab completion for column names (as well as public attributes) is automatically enabled. Here’s a subset of the attributes that will be completed:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [12]: df2.&lt;TAB&gt;  # noqa: E225, E999</span><br><span class="line">df2.A                  df2.bool</span><br><span class="line">df2.abs                df2.boxplot</span><br><span class="line">df2.add                df2.C</span><br><span class="line">df2.add_prefix         df2.clip</span><br><span class="line">df2.add_suffix         df2.columns</span><br><span class="line">df2.align              df2.copy</span><br><span class="line">df2.all                df2.count</span><br><span class="line">df2.any                df2.combine</span><br><span class="line">df2.append             df2.D</span><br><span class="line">df2.apply              df2.describe</span><br><span class="line">df2.applymap           df2.diff</span><br><span class="line">df2.B                  df2.duplicated</span><br></pre></td></tr></table></figure>
<p>As you can see, the columns <code>A</code>, <code>B</code>, <code>C</code>, and <code>D</code> are automatically tab completed. <code>E</code> and <code>F</code> are there as well; the rest of the attributes have been truncated for brevity.</p>
<h2 id="Viewing-data"><a href="#Viewing-data" class="headerlink" title="Viewing data"></a>Viewing data</h2><p>See the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#basics">Basics section</a>.</p>
<p>Here is how to view the top and bottom rows of the frame:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [13]: df.head()</span><br><span class="line">Out[13]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401</span><br><span class="line"></span><br><span class="line">In [14]: df.tail(3)</span><br><span class="line">Out[14]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401</span><br><span class="line">2013-01-06 -0.673690  0.113648 -1.478427  0.524988</span><br></pre></td></tr></table></figure>
<p>Display the index, columns:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [15]: df.index</span><br><span class="line">Out[15]: </span><br><span class="line">DatetimeIndex([&#x27;2013-01-01&#x27;, &#x27;2013-01-02&#x27;, &#x27;2013-01-03&#x27;, &#x27;2013-01-04&#x27;,</span><br><span class="line">               &#x27;2013-01-05&#x27;, &#x27;2013-01-06&#x27;],</span><br><span class="line">              dtype=&#x27;datetime64[ns]&#x27;, freq=&#x27;D&#x27;)</span><br><span class="line"></span><br><span class="line">In [16]: df.columns</span><br><span class="line">Out[16]: Index([&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;], dtype=&#x27;object&#x27;)</span><br></pre></td></tr></table></figure>
<p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"><code>DataFrame.to_numpy()</code></a> gives a NumPy representation of the underlying data. Note that this can be an expensive operation when your <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame"><code>DataFrame</code></a> has columns with different data types, which comes down to a fundamental difference between pandas and NumPy: <strong>NumPy arrays have one dtype for the entire array, while pandas DataFrames have one dtype per column</strong>. When you call <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"><code>DataFrame.to_numpy()</code></a>, pandas will find the NumPy dtype that can hold <em>all</em> of the dtypes in the DataFrame. This may end up being <code>object</code>, which requires casting every value to a Python object.</p>
<p>For <code>df</code>, our <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame"><code>DataFrame</code></a> of all floating-point values, <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"><code>DataFrame.to_numpy()</code></a> is fast and doesn’t require copying data.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [17]: df.to_numpy()</span><br><span class="line">Out[17]: </span><br><span class="line">array([[ 0.4691, -0.2829, -1.5091, -1.1356],</span><br><span class="line">       [ 1.2121, -0.1732,  0.1192, -1.0442],</span><br><span class="line">       [-0.8618, -2.1046, -0.4949,  1.0718],</span><br><span class="line">       [ 0.7216, -0.7068, -1.0396,  0.2719],</span><br><span class="line">       [-0.425 ,  0.567 ,  0.2762, -1.0874],</span><br><span class="line">       [-0.6737,  0.1136, -1.4784,  0.525 ]])</span><br></pre></td></tr></table></figure>
<p>For <code>df2</code>, the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame"><code>DataFrame</code></a> with multiple dtypes, <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"><code>DataFrame.to_numpy()</code></a> is relatively expensive.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [18]: df2.to_numpy()</span><br><span class="line">Out[18]: </span><br><span class="line">array([[1.0, Timestamp(&#x27;2013-01-02 00:00:00&#x27;), 1.0, 3, &#x27;test&#x27;, &#x27;foo&#x27;],</span><br><span class="line">       [1.0, Timestamp(&#x27;2013-01-02 00:00:00&#x27;), 1.0, 3, &#x27;train&#x27;, &#x27;foo&#x27;],</span><br><span class="line">       [1.0, Timestamp(&#x27;2013-01-02 00:00:00&#x27;), 1.0, 3, &#x27;test&#x27;, &#x27;foo&#x27;],</span><br><span class="line">       [1.0, Timestamp(&#x27;2013-01-02 00:00:00&#x27;), 1.0, 3, &#x27;train&#x27;, &#x27;foo&#x27;]],</span><br><span class="line">      dtype=object)</span><br></pre></td></tr></table></figure>
<p>Note</p>
<p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy"><code>DataFrame.to_numpy()</code></a> does <em>not</em> include the index or column labels in the output.</p>
<p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe"><code>describe()</code></a> shows a quick statistic summary of your data:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [19]: df.describe()</span><br><span class="line">Out[19]: </span><br><span class="line">              A         B         C         D</span><br><span class="line">count  6.000000  6.000000  6.000000  6.000000</span><br><span class="line">mean   0.073711 -0.431125 -0.687758 -0.233103</span><br><span class="line">std    0.843157  0.922818  0.779887  0.973118</span><br><span class="line">min   -0.861849 -2.104569 -1.509059 -1.135632</span><br><span class="line">25%   -0.611510 -0.600794 -1.368714 -1.076610</span><br><span class="line">50%    0.022070 -0.228039 -0.767252 -0.386188</span><br><span class="line">75%    0.658444  0.041933 -0.034326  0.461706</span><br><span class="line">max    1.212112  0.567020  0.276232  1.071804</span><br></pre></td></tr></table></figure>
<p>Transposing your data:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [20]: df.T</span><br><span class="line">Out[20]: </span><br><span class="line">   2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06</span><br><span class="line">A    0.469112    1.212112   -0.861849    0.721555   -0.424972   -0.673690</span><br><span class="line">B   -0.282863   -0.173215   -2.104569   -0.706771    0.567020    0.113648</span><br><span class="line">C   -1.509059    0.119209   -0.494929   -1.039575    0.276232   -1.478427</span><br><span class="line">D   -1.135632   -1.044236    1.071804    0.271860   -1.087401    0.524988</span><br></pre></td></tr></table></figure>
<p>Sorting by an axis:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [21]: df.sort_index(axis=1, ascending=False)</span><br><span class="line">Out[21]: </span><br><span class="line">                   D         C         B         A</span><br><span class="line">2013-01-01 -1.135632 -1.509059 -0.282863  0.469112</span><br><span class="line">2013-01-02 -1.044236  0.119209 -0.173215  1.212112</span><br><span class="line">2013-01-03  1.071804 -0.494929 -2.104569 -0.861849</span><br><span class="line">2013-01-04  0.271860 -1.039575 -0.706771  0.721555</span><br><span class="line">2013-01-05 -1.087401  0.276232  0.567020 -0.424972</span><br><span class="line">2013-01-06  0.524988 -1.478427  0.113648 -0.673690</span><br></pre></td></tr></table></figure>
<p>Sorting by values:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [22]: df.sort_values(by=&#x27;B&#x27;)</span><br><span class="line">Out[22]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-06 -0.673690  0.113648 -1.478427  0.524988</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401</span><br></pre></td></tr></table></figure>
<h2 id="Selection"><a href="#Selection" class="headerlink" title="Selection"></a>Selection</h2><p>Note</p>
<p>While standard Python / Numpy expressions for selecting and setting are intuitive and come in handy for interactive work, for production code, we recommend the optimized pandas data access methods, <code>.at</code>, <code>.iat</code>, <code>.loc</code> and <code>.iloc</code>.</p>
<p>See the indexing documentation <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing">Indexing and Selecting Data</a> and <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#advanced">MultiIndex / Advanced Indexing</a>.</p>
<h3 id="Getting"><a href="#Getting" class="headerlink" title="Getting"></a>Getting</h3><p>Selecting a single column, which yields a <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series"><code>Series</code></a>, equivalent to <code>df.A</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [23]: df[&#x27;A&#x27;]</span><br><span class="line">Out[23]: </span><br><span class="line">2013-01-01    0.469112</span><br><span class="line">2013-01-02    1.212112</span><br><span class="line">2013-01-03   -0.861849</span><br><span class="line">2013-01-04    0.721555</span><br><span class="line">2013-01-05   -0.424972</span><br><span class="line">2013-01-06   -0.673690</span><br><span class="line">Freq: D, Name: A, dtype: float64</span><br></pre></td></tr></table></figure>
<p>Selecting via <code>[]</code>, which slices the rows.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [24]: df[0:3]</span><br><span class="line">Out[24]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br><span class="line"></span><br><span class="line">In [25]: df[&#x27;20130102&#x27;:&#x27;20130104&#x27;]</span><br><span class="line">Out[25]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br></pre></td></tr></table></figure>
<h3 id="Selection-by-label"><a href="#Selection-by-label" class="headerlink" title="Selection by label"></a>Selection by label</h3><p>See more in <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-label">Selection by Label</a>.</p>
<p>For getting a cross section using a label:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [26]: df.loc[dates[0]]</span><br><span class="line">Out[26]: </span><br><span class="line">A    0.469112</span><br><span class="line">B   -0.282863</span><br><span class="line">C   -1.509059</span><br><span class="line">D   -1.135632</span><br><span class="line">Name: 2013-01-01 00:00:00, dtype: float64</span><br></pre></td></tr></table></figure>
<p>Selecting on a multi-axis by label:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [27]: df.loc[:, [&#x27;A&#x27;, &#x27;B&#x27;]]</span><br><span class="line">Out[27]: </span><br><span class="line">                   A         B</span><br><span class="line">2013-01-01  0.469112 -0.282863</span><br><span class="line">2013-01-02  1.212112 -0.173215</span><br><span class="line">2013-01-03 -0.861849 -2.104569</span><br><span class="line">2013-01-04  0.721555 -0.706771</span><br><span class="line">2013-01-05 -0.424972  0.567020</span><br><span class="line">2013-01-06 -0.673690  0.113648</span><br></pre></td></tr></table></figure>
<p>Showing label slicing, both endpoints are <em>included</em>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [28]: df.loc[&#x27;20130102&#x27;:&#x27;20130104&#x27;, [&#x27;A&#x27;, &#x27;B&#x27;]]</span><br><span class="line">Out[28]: </span><br><span class="line">                   A         B</span><br><span class="line">2013-01-02  1.212112 -0.173215</span><br><span class="line">2013-01-03 -0.861849 -2.104569</span><br><span class="line">2013-01-04  0.721555 -0.706771</span><br></pre></td></tr></table></figure>
<p>Reduction in the dimensions of the returned object:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [29]: df.loc[&#x27;20130102&#x27;, [&#x27;A&#x27;, &#x27;B&#x27;]]</span><br><span class="line">Out[29]: </span><br><span class="line">A    1.212112</span><br><span class="line">B   -0.173215</span><br><span class="line">Name: 2013-01-02 00:00:00, dtype: float64</span><br></pre></td></tr></table></figure>
<p>For getting a scalar value:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [30]: df.loc[dates[0], &#x27;A&#x27;]</span><br><span class="line">Out[30]: 0.4691122999071863</span><br></pre></td></tr></table></figure>
<p>For getting fast access to a scalar (equivalent to the prior method):</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [31]: df.at[dates[0], &#x27;A&#x27;]</span><br><span class="line">Out[31]: 0.4691122999071863</span><br></pre></td></tr></table></figure>
<h3 id="Selection-by-position"><a href="#Selection-by-position" class="headerlink" title="Selection by position"></a>Selection by position</h3><p>See more in <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-integer">Selection by Position</a>.</p>
<p>Select via the position of the passed integers:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [32]: df.iloc[3]</span><br><span class="line">Out[32]: </span><br><span class="line">A    0.721555</span><br><span class="line">B   -0.706771</span><br><span class="line">C   -1.039575</span><br><span class="line">D    0.271860</span><br><span class="line">Name: 2013-01-04 00:00:00, dtype: float64</span><br></pre></td></tr></table></figure>
<p>By integer slices, acting similar to numpy/python:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [33]: df.iloc[3:5, 0:2]</span><br><span class="line">Out[33]: </span><br><span class="line">                   A         B</span><br><span class="line">2013-01-04  0.721555 -0.706771</span><br><span class="line">2013-01-05 -0.424972  0.567020</span><br></pre></td></tr></table></figure>
<p>By lists of integer position locations, similar to the numpy/python style:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [34]: df.iloc[[1, 2, 4], [0, 2]]</span><br><span class="line">Out[34]: </span><br><span class="line">                   A         C</span><br><span class="line">2013-01-02  1.212112  0.119209</span><br><span class="line">2013-01-03 -0.861849 -0.494929</span><br><span class="line">2013-01-05 -0.424972  0.276232</span><br></pre></td></tr></table></figure>
<p>For slicing rows explicitly:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [35]: df.iloc[1:3, :]</span><br><span class="line">Out[35]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br></pre></td></tr></table></figure>
<p>For slicing columns explicitly:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [36]: df.iloc[:, 1:3]</span><br><span class="line">Out[36]: </span><br><span class="line">                   B         C</span><br><span class="line">2013-01-01 -0.282863 -1.509059</span><br><span class="line">2013-01-02 -0.173215  0.119209</span><br><span class="line">2013-01-03 -2.104569 -0.494929</span><br><span class="line">2013-01-04 -0.706771 -1.039575</span><br><span class="line">2013-01-05  0.567020  0.276232</span><br><span class="line">2013-01-06  0.113648 -1.478427</span><br></pre></td></tr></table></figure>
<p>For getting a value explicitly:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [37]: df.iloc[1, 1]</span><br><span class="line">Out[37]: -0.17321464905330858</span><br></pre></td></tr></table></figure>
<p>For getting fast access to a scalar (equivalent to the prior method):</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [38]: df.iat[1, 1]</span><br><span class="line">Out[38]: -0.17321464905330858</span><br></pre></td></tr></table></figure>
<h3 id="Boolean-indexing"><a href="#Boolean-indexing" class="headerlink" title="Boolean indexing"></a>Boolean indexing</h3><p>Using a single column’s values to select data.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [39]: df[df[&#x27;A&#x27;] &gt; 0]</span><br><span class="line">Out[39]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br></pre></td></tr></table></figure>
<p>Selecting values from a DataFrame where a boolean condition is met.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [40]: df[df &gt; 0]</span><br><span class="line">Out[40]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-01  0.469112       NaN       NaN       NaN</span><br><span class="line">2013-01-02  1.212112       NaN  0.119209       NaN</span><br><span class="line">2013-01-03       NaN       NaN       NaN  1.071804</span><br><span class="line">2013-01-04  0.721555       NaN       NaN  0.271860</span><br><span class="line">2013-01-05       NaN  0.567020  0.276232       NaN</span><br><span class="line">2013-01-06       NaN  0.113648       NaN  0.524988</span><br></pre></td></tr></table></figure>
<p>Using the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.isin.html#pandas.Series.isin"><code>isin()</code></a> method for filtering:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [41]: df2 = df.copy()</span><br><span class="line"></span><br><span class="line">In [42]: df2[&#x27;E&#x27;] = [&#x27;one&#x27;, &#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;, &#x27;four&#x27;, &#x27;three&#x27;]</span><br><span class="line"></span><br><span class="line">In [43]: df2</span><br><span class="line">Out[43]: </span><br><span class="line">                   A         B         C         D      E</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632    one</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236    one</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804    two</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860  three</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401   four</span><br><span class="line">2013-01-06 -0.673690  0.113648 -1.478427  0.524988  three</span><br><span class="line"></span><br><span class="line">In [44]: df2[df2[&#x27;E&#x27;].isin([&#x27;two&#x27;, &#x27;four&#x27;])]</span><br><span class="line">Out[44]: </span><br><span class="line">                   A         B         C         D     E</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804   two</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401  four</span><br></pre></td></tr></table></figure>
<h3 id="Setting"><a href="#Setting" class="headerlink" title="Setting"></a>Setting</h3><p>Setting a new column automatically aligns the data by the indexes.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [45]: s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range(&#x27;20130102&#x27;, periods=6))</span><br><span class="line"></span><br><span class="line">In [46]: s1</span><br><span class="line">Out[46]: </span><br><span class="line">2013-01-02    1</span><br><span class="line">2013-01-03    2</span><br><span class="line">2013-01-04    3</span><br><span class="line">2013-01-05    4</span><br><span class="line">2013-01-06    5</span><br><span class="line">2013-01-07    6</span><br><span class="line">Freq: D, dtype: int64</span><br><span class="line"></span><br><span class="line">In [47]: df[&#x27;F&#x27;] = s1</span><br></pre></td></tr></table></figure>
<p>Setting values by label:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [48]: df.at[dates[0], &#x27;A&#x27;] = 0</span><br></pre></td></tr></table></figure>
<p>Setting values by position:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [49]: df.iat[0, 1] = 0</span><br></pre></td></tr></table></figure>
<p>Setting by assigning with a NumPy array:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [50]: df.loc[:, &#x27;D&#x27;] = np.array([5] * len(df))</span><br></pre></td></tr></table></figure>
<p>The result of the prior setting operations.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [51]: df</span><br><span class="line">Out[51]: </span><br><span class="line">                   A         B         C  D    F</span><br><span class="line">2013-01-01  0.000000  0.000000 -1.509059  5  NaN</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209  5  1.0</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  5  2.0</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  5  3.0</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232  5  4.0</span><br><span class="line">2013-01-06 -0.673690  0.113648 -1.478427  5  5.0</span><br></pre></td></tr></table></figure>
<p>A <code>where</code> operation with setting.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [52]: df2 = df.copy()</span><br><span class="line"></span><br><span class="line">In [53]: df2[df2 &gt; 0] = -df2</span><br><span class="line"></span><br><span class="line">In [54]: df2</span><br><span class="line">Out[54]: </span><br><span class="line">                   A         B         C  D    F</span><br><span class="line">2013-01-01  0.000000  0.000000 -1.509059 -5  NaN</span><br><span class="line">2013-01-02 -1.212112 -0.173215 -0.119209 -5 -1.0</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929 -5 -2.0</span><br><span class="line">2013-01-04 -0.721555 -0.706771 -1.039575 -5 -3.0</span><br><span class="line">2013-01-05 -0.424972 -0.567020 -0.276232 -5 -4.0</span><br><span class="line">2013-01-06 -0.673690 -0.113648 -1.478427 -5 -5.0</span><br></pre></td></tr></table></figure>
<h2 id="Missing-data"><a href="#Missing-data" class="headerlink" title="Missing data"></a>Missing data</h2><p>pandas primarily uses the value <code>np.nan</code> to represent missing data. It is by default not included in computations. See the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data">Missing Data section</a>.</p>
<p>Reindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [55]: df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [&#x27;E&#x27;])</span><br><span class="line"></span><br><span class="line">In [56]: df1.loc[dates[0]:dates[1], &#x27;E&#x27;] = 1</span><br><span class="line"></span><br><span class="line">In [57]: df1</span><br><span class="line">Out[57]: </span><br><span class="line">                   A         B         C  D    F    E</span><br><span class="line">2013-01-01  0.000000  0.000000 -1.509059  5  NaN  1.0</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209  5  1.0  1.0</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  5  2.0  NaN</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  5  3.0  NaN</span><br></pre></td></tr></table></figure>
<p>To drop any rows that have missing data.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [58]: df1.dropna(how=&#x27;any&#x27;)</span><br><span class="line">Out[58]: </span><br><span class="line">                   A         B         C  D    F    E</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209  5  1.0  1.0</span><br></pre></td></tr></table></figure>
<p>Filling missing data.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [59]: df1.fillna(value=5)</span><br><span class="line">Out[59]: </span><br><span class="line">                   A         B         C  D    F    E</span><br><span class="line">2013-01-01  0.000000  0.000000 -1.509059  5  5.0  1.0</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209  5  1.0  1.0</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  5  2.0  5.0</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  5  3.0  5.0</span><br></pre></td></tr></table></figure>
<p>To get the boolean mask where values are <code>nan</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [60]: pd.isna(df1)</span><br><span class="line">Out[60]: </span><br><span class="line">                A      B      C      D      F      E</span><br><span class="line">2013-01-01  False  False  False  False   True  False</span><br><span class="line">2013-01-02  False  False  False  False  False  False</span><br><span class="line">2013-01-03  False  False  False  False  False   True</span><br><span class="line">2013-01-04  False  False  False  False  False   True</span><br></pre></td></tr></table></figure>
<h2 id="Operations"><a href="#Operations" class="headerlink" title="Operations"></a>Operations</h2><p>See the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#basics-binop">Basic section on Binary Ops</a>.</p>
<h3 id="Stats"><a href="#Stats" class="headerlink" title="Stats"></a>Stats</h3><p>Operations in general <em>exclude</em> missing data.</p>
<p>Performing a descriptive statistic:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [61]: df.mean()</span><br><span class="line">Out[61]: </span><br><span class="line">A   -0.004474</span><br><span class="line">B   -0.383981</span><br><span class="line">C   -0.687758</span><br><span class="line">D    5.000000</span><br><span class="line">F    3.000000</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<p>Same operation on the other axis:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [62]: df.mean(1)</span><br><span class="line">Out[62]: </span><br><span class="line">2013-01-01    0.872735</span><br><span class="line">2013-01-02    1.431621</span><br><span class="line">2013-01-03    0.707731</span><br><span class="line">2013-01-04    1.395042</span><br><span class="line">2013-01-05    1.883656</span><br><span class="line">2013-01-06    1.592306</span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure>
<p>Operating with objects that have different dimensionality and need alignment. In addition, pandas automatically broadcasts along the specified dimension.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [63]: s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)</span><br><span class="line"></span><br><span class="line">In [64]: s</span><br><span class="line">Out[64]: </span><br><span class="line">2013-01-01    NaN</span><br><span class="line">2013-01-02    NaN</span><br><span class="line">2013-01-03    1.0</span><br><span class="line">2013-01-04    3.0</span><br><span class="line">2013-01-05    5.0</span><br><span class="line">2013-01-06    NaN</span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [65]: df.sub(s, axis=&#x27;index&#x27;)</span><br><span class="line">Out[65]: </span><br><span class="line">                   A         B         C    D    F</span><br><span class="line">2013-01-01       NaN       NaN       NaN  NaN  NaN</span><br><span class="line">2013-01-02       NaN       NaN       NaN  NaN  NaN</span><br><span class="line">2013-01-03 -1.861849 -3.104569 -1.494929  4.0  1.0</span><br><span class="line">2013-01-04 -2.278445 -3.706771 -4.039575  2.0  0.0</span><br><span class="line">2013-01-05 -5.424972 -4.432980 -4.723768  0.0 -1.0</span><br><span class="line">2013-01-06       NaN       NaN       NaN  NaN  NaN</span><br></pre></td></tr></table></figure>
<h3 id="Apply"><a href="#Apply" class="headerlink" title="Apply"></a>Apply</h3><p>Applying functions to the data:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [66]: df.apply(np.cumsum)</span><br><span class="line">Out[66]: </span><br><span class="line">                   A         B         C   D     F</span><br><span class="line">2013-01-01  0.000000  0.000000 -1.509059   5   NaN</span><br><span class="line">2013-01-02  1.212112 -0.173215 -1.389850  10   1.0</span><br><span class="line">2013-01-03  0.350263 -2.277784 -1.884779  15   3.0</span><br><span class="line">2013-01-04  1.071818 -2.984555 -2.924354  20   6.0</span><br><span class="line">2013-01-05  0.646846 -2.417535 -2.648122  25  10.0</span><br><span class="line">2013-01-06 -0.026844 -2.303886 -4.126549  30  15.0</span><br><span class="line"></span><br><span class="line">In [67]: df.apply(lambda x: x.max() - x.min())</span><br><span class="line">Out[67]: </span><br><span class="line">A    2.073961</span><br><span class="line">B    2.671590</span><br><span class="line">C    1.785291</span><br><span class="line">D    0.000000</span><br><span class="line">F    4.000000</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<h3 id="Histogramming"><a href="#Histogramming" class="headerlink" title="Histogramming"></a>Histogramming</h3><p>See more at <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#basics-discretization">Histogramming and Discretization</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [68]: s = pd.Series(np.random.randint(0, 7, size=10))</span><br><span class="line"></span><br><span class="line">In [69]: s</span><br><span class="line">Out[69]: </span><br><span class="line">0    4</span><br><span class="line">1    2</span><br><span class="line">2    1</span><br><span class="line">3    2</span><br><span class="line">4    6</span><br><span class="line">5    4</span><br><span class="line">6    4</span><br><span class="line">7    6</span><br><span class="line">8    4</span><br><span class="line">9    4</span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [70]: s.value_counts()</span><br><span class="line">Out[70]: </span><br><span class="line">4    5</span><br><span class="line">6    2</span><br><span class="line">2    2</span><br><span class="line">1    1</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure>
<h3 id="String-Methods"><a href="#String-Methods" class="headerlink" title="String Methods"></a>String Methods</h3><p>Series is equipped with a set of string processing methods in the str attribute that make it easy to operate on each element of the array, as in the code snippet below. Note that pattern-matching in str generally uses <a href="https://docs.python.org/3/library/re.html">regular expressions</a> by default (and in some cases always uses them). See more at <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#text-string-methods">Vectorized String Methods</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [71]: s = pd.Series([&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;Aaba&#x27;, &#x27;Baca&#x27;, np.nan, &#x27;CABA&#x27;, &#x27;dog&#x27;, &#x27;cat&#x27;])</span><br><span class="line"></span><br><span class="line">In [72]: s.str.lower()</span><br><span class="line">Out[72]: </span><br><span class="line">0       a</span><br><span class="line">1       b</span><br><span class="line">2       c</span><br><span class="line">3    aaba</span><br><span class="line">4    baca</span><br><span class="line">5     NaN</span><br><span class="line">6    caba</span><br><span class="line">7     dog</span><br><span class="line">8     cat</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure>
<h2 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h2><h3 id="Concat"><a href="#Concat" class="headerlink" title="Concat"></a>Concat</h3><p>pandas provides various facilities for easily combining together Series and DataFrame objects with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.</p>
<p>See the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#merging">Merging section</a>.</p>
<p>Concatenating pandas objects together with <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html#pandas.concat"><code>concat()</code></a>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [73]: df = pd.DataFrame(np.random.randn(10, 4))</span><br><span class="line"></span><br><span class="line">In [74]: df</span><br><span class="line">Out[74]: </span><br><span class="line">          0         1         2         3</span><br><span class="line">0 -0.548702  1.467327 -1.015962 -0.483075</span><br><span class="line">1  1.637550 -1.217659 -0.291519 -1.745505</span><br><span class="line">2 -0.263952  0.991460 -0.919069  0.266046</span><br><span class="line">3 -0.709661  1.669052  1.037882 -1.705775</span><br><span class="line">4 -0.919854 -0.042379  1.247642 -0.009920</span><br><span class="line">5  0.290213  0.495767  0.362949  1.548106</span><br><span class="line">6 -1.131345 -0.089329  0.337863 -0.945867</span><br><span class="line">7 -0.932132  1.956030  0.017587 -0.016692</span><br><span class="line">8 -0.575247  0.254161 -1.143704  0.215897</span><br><span class="line">9  1.193555 -0.077118 -0.408530 -0.862495</span><br><span class="line"></span><br><span class="line"># break it into pieces</span><br><span class="line">In [75]: pieces = [df[:3], df[3:7], df[7:]]</span><br><span class="line"></span><br><span class="line">In [76]: pd.concat(pieces)</span><br><span class="line">Out[76]: </span><br><span class="line">          0         1         2         3</span><br><span class="line">0 -0.548702  1.467327 -1.015962 -0.483075</span><br><span class="line">1  1.637550 -1.217659 -0.291519 -1.745505</span><br><span class="line">2 -0.263952  0.991460 -0.919069  0.266046</span><br><span class="line">3 -0.709661  1.669052  1.037882 -1.705775</span><br><span class="line">4 -0.919854 -0.042379  1.247642 -0.009920</span><br><span class="line">5  0.290213  0.495767  0.362949  1.548106</span><br><span class="line">6 -1.131345 -0.089329  0.337863 -0.945867</span><br><span class="line">7 -0.932132  1.956030  0.017587 -0.016692</span><br><span class="line">8 -0.575247  0.254161 -1.143704  0.215897</span><br><span class="line">9  1.193555 -0.077118 -0.408530 -0.862495</span><br></pre></td></tr></table></figure>
<p>Note</p>
<p>Adding a column to a <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame"><code>DataFrame</code></a> is relatively fast. However, adding a row requires a copy, and may be expensive. We recommend passing a pre-built list of records to the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame"><code>DataFrame</code></a> constructor instead of building a <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame"><code>DataFrame</code></a> by iteratively appending records to it. See <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#merging-concatenation">Appending to dataframe</a> for more.</p>
<h3 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h3><p>SQL style merges. See the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#merging-join">Database style joining</a> section.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [77]: left = pd.DataFrame(&#123;&#x27;key&#x27;: [&#x27;foo&#x27;, &#x27;foo&#x27;], &#x27;lval&#x27;: [1, 2]&#125;)</span><br><span class="line"></span><br><span class="line">In [78]: right = pd.DataFrame(&#123;&#x27;key&#x27;: [&#x27;foo&#x27;, &#x27;foo&#x27;], &#x27;rval&#x27;: [4, 5]&#125;)</span><br><span class="line"></span><br><span class="line">In [79]: left</span><br><span class="line">Out[79]: </span><br><span class="line">   key  lval</span><br><span class="line">0  foo     1</span><br><span class="line">1  foo     2</span><br><span class="line"></span><br><span class="line">In [80]: right</span><br><span class="line">Out[80]: </span><br><span class="line">   key  rval</span><br><span class="line">0  foo     4</span><br><span class="line">1  foo     5</span><br><span class="line"></span><br><span class="line">In [81]: pd.merge(left, right, on=&#x27;key&#x27;)</span><br><span class="line">Out[81]: </span><br><span class="line">   key  lval  rval</span><br><span class="line">0  foo     1     4</span><br><span class="line">1  foo     1     5</span><br><span class="line">2  foo     2     4</span><br><span class="line">3  foo     2     5</span><br></pre></td></tr></table></figure>
<p>Another example that can be given is:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [82]: left = pd.DataFrame(&#123;&#x27;key&#x27;: [&#x27;foo&#x27;, &#x27;bar&#x27;], &#x27;lval&#x27;: [1, 2]&#125;)</span><br><span class="line"></span><br><span class="line">In [83]: right = pd.DataFrame(&#123;&#x27;key&#x27;: [&#x27;foo&#x27;, &#x27;bar&#x27;], &#x27;rval&#x27;: [4, 5]&#125;)</span><br><span class="line"></span><br><span class="line">In [84]: left</span><br><span class="line">Out[84]: </span><br><span class="line">   key  lval</span><br><span class="line">0  foo     1</span><br><span class="line">1  bar     2</span><br><span class="line"></span><br><span class="line">In [85]: right</span><br><span class="line">Out[85]: </span><br><span class="line">   key  rval</span><br><span class="line">0  foo     4</span><br><span class="line">1  bar     5</span><br><span class="line"></span><br><span class="line">In [86]: pd.merge(left, right, on=&#x27;key&#x27;)</span><br><span class="line">Out[86]: </span><br><span class="line">   key  lval  rval</span><br><span class="line">0  foo     1     4</span><br><span class="line">1  bar     2     5</span><br></pre></td></tr></table></figure>
<h2 id="Grouping"><a href="#Grouping" class="headerlink" title="Grouping"></a>Grouping</h2><p>By “group by” we are referring to a process involving one or more of the following steps:</p>
<blockquote>
<ul>
<li><strong>Splitting</strong> the data into groups based on some criteria</li>
<li><strong>Applying</strong> a function to each group independently</li>
<li><strong>Combining</strong> the results into a data structure</li>
</ul>
</blockquote>
<p>See the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#groupby">Grouping section</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [87]: df = pd.DataFrame(&#123;&#x27;A&#x27;: [&#x27;foo&#x27;, &#x27;bar&#x27;, &#x27;foo&#x27;, &#x27;bar&#x27;,</span><br><span class="line">   ....:                          &#x27;foo&#x27;, &#x27;bar&#x27;, &#x27;foo&#x27;, &#x27;foo&#x27;],</span><br><span class="line">   ....:                    &#x27;B&#x27;: [&#x27;one&#x27;, &#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;,</span><br><span class="line">   ....:                          &#x27;two&#x27;, &#x27;two&#x27;, &#x27;one&#x27;, &#x27;three&#x27;],</span><br><span class="line">   ....:                    &#x27;C&#x27;: np.random.randn(8),</span><br><span class="line">   ....:                    &#x27;D&#x27;: np.random.randn(8)&#125;)</span><br><span class="line">   ....: </span><br><span class="line"></span><br><span class="line">In [88]: df</span><br><span class="line">Out[88]: </span><br><span class="line">     A      B         C         D</span><br><span class="line">0  foo    one  1.346061 -1.577585</span><br><span class="line">1  bar    one  1.511763  0.396823</span><br><span class="line">2  foo    two  1.627081 -0.105381</span><br><span class="line">3  bar  three -0.990582 -0.532532</span><br><span class="line">4  foo    two -0.441652  1.453749</span><br><span class="line">5  bar    two  1.211526  1.208843</span><br><span class="line">6  foo    one  0.268520 -0.080952</span><br><span class="line">7  foo  three  0.024580 -0.264610</span><br></pre></td></tr></table></figure>
<p>Grouping and then applying the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.sum.html#pandas.core.groupby.GroupBy.sum"><code>sum()</code></a> function to the resulting groups.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [89]: df.groupby(&#x27;A&#x27;).sum()</span><br><span class="line">Out[89]: </span><br><span class="line">            C         D</span><br><span class="line">A                      </span><br><span class="line">bar  1.732707  1.073134</span><br><span class="line">foo  2.824590 -0.574779</span><br></pre></td></tr></table></figure>
<p>Grouping by multiple columns forms a hierarchical index, and again we can apply the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.sum.html#pandas.core.groupby.GroupBy.sum"><code>sum()</code></a> function.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [90]: df.groupby([&#x27;A&#x27;, &#x27;B&#x27;]).sum()</span><br><span class="line">Out[90]: </span><br><span class="line">                  C         D</span><br><span class="line">A   B                        </span><br><span class="line">bar one    1.511763  0.396823</span><br><span class="line">    three -0.990582 -0.532532</span><br><span class="line">    two    1.211526  1.208843</span><br><span class="line">foo one    1.614581 -1.658537</span><br><span class="line">    three  0.024580 -0.264610</span><br><span class="line">    two    1.185429  1.348368</span><br></pre></td></tr></table></figure>
<h2 id="Reshaping"><a href="#Reshaping" class="headerlink" title="Reshaping"></a>Reshaping</h2><p>See the sections on <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#advanced-hierarchical">Hierarchical Indexing</a> and <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#reshaping-stacking">Reshaping</a>.</p>
<h3 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [91]: tuples = list(zip(*[[&#x27;bar&#x27;, &#x27;bar&#x27;, &#x27;baz&#x27;, &#x27;baz&#x27;,</span><br><span class="line">   ....:                      &#x27;foo&#x27;, &#x27;foo&#x27;, &#x27;qux&#x27;, &#x27;qux&#x27;],</span><br><span class="line">   ....:                     [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;one&#x27;, &#x27;two&#x27;,</span><br><span class="line">   ....:                      &#x27;one&#x27;, &#x27;two&#x27;, &#x27;one&#x27;, &#x27;two&#x27;]]))</span><br><span class="line">   ....: </span><br><span class="line"></span><br><span class="line">In [92]: index = pd.MultiIndex.from_tuples(tuples, names=[&#x27;first&#x27;, &#x27;second&#x27;])</span><br><span class="line"></span><br><span class="line">In [93]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=[&#x27;A&#x27;, &#x27;B&#x27;])</span><br><span class="line"></span><br><span class="line">In [94]: df2 = df[:4]</span><br><span class="line"></span><br><span class="line">In [95]: df2</span><br><span class="line">Out[95]: </span><br><span class="line">                     A         B</span><br><span class="line">first second                    </span><br><span class="line">bar   one    -0.727965 -0.589346</span><br><span class="line">      two     0.339969 -0.693205</span><br><span class="line">baz   one    -0.339355  0.593616</span><br><span class="line">      two     0.884345  1.591431</span><br></pre></td></tr></table></figure>
<p>The <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"><code>stack()</code></a> method “compresses” a level in the DataFrame’s columns.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [96]: stacked = df2.stack()</span><br><span class="line"></span><br><span class="line">In [97]: stacked</span><br><span class="line">Out[97]: </span><br><span class="line">first  second   </span><br><span class="line">bar    one     A   -0.727965</span><br><span class="line">               B   -0.589346</span><br><span class="line">       two     A    0.339969</span><br><span class="line">               B   -0.693205</span><br><span class="line">baz    one     A   -0.339355</span><br><span class="line">               B    0.593616</span><br><span class="line">       two     A    0.884345</span><br><span class="line">               B    1.591431</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<p>With a “stacked” DataFrame or Series (having a <code>MultiIndex</code> as the <code>index</code>), the inverse operation of <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack"><code>stack()</code></a> is <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack"><code>unstack()</code></a>, which by default unstacks the <strong>last level</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [98]: stacked.unstack()</span><br><span class="line">Out[98]: </span><br><span class="line">                     A         B</span><br><span class="line">first second                    </span><br><span class="line">bar   one    -0.727965 -0.589346</span><br><span class="line">      two     0.339969 -0.693205</span><br><span class="line">baz   one    -0.339355  0.593616</span><br><span class="line">      two     0.884345  1.591431</span><br><span class="line"></span><br><span class="line">In [99]: stacked.unstack(1)</span><br><span class="line">Out[99]: </span><br><span class="line">second        one       two</span><br><span class="line">first                      </span><br><span class="line">bar   A -0.727965  0.339969</span><br><span class="line">      B -0.589346 -0.693205</span><br><span class="line">baz   A -0.339355  0.884345</span><br><span class="line">      B  0.593616  1.591431</span><br><span class="line"></span><br><span class="line">In [100]: stacked.unstack(0)</span><br><span class="line">Out[100]: </span><br><span class="line">first          bar       baz</span><br><span class="line">second                      </span><br><span class="line">one    A -0.727965 -0.339355</span><br><span class="line">       B -0.589346  0.593616</span><br><span class="line">two    A  0.339969  0.884345</span><br><span class="line">       B -0.693205  1.591431</span><br></pre></td></tr></table></figure>
<h3 id="Pivot-tables"><a href="#Pivot-tables" class="headerlink" title="Pivot tables"></a>Pivot tables</h3><p>See the section on <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#reshaping-pivot">Pivot Tables</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [101]: df = pd.DataFrame(&#123;&#x27;A&#x27;: [&#x27;one&#x27;, &#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;] * 3,</span><br><span class="line">   .....:                    &#x27;B&#x27;: [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;] * 4,</span><br><span class="line">   .....:                    &#x27;C&#x27;: [&#x27;foo&#x27;, &#x27;foo&#x27;, &#x27;foo&#x27;, &#x27;bar&#x27;, &#x27;bar&#x27;, &#x27;bar&#x27;] * 2,</span><br><span class="line">   .....:                    &#x27;D&#x27;: np.random.randn(12),</span><br><span class="line">   .....:                    &#x27;E&#x27;: np.random.randn(12)&#125;)</span><br><span class="line">   .....: </span><br><span class="line"></span><br><span class="line">In [102]: df</span><br><span class="line">Out[102]: </span><br><span class="line">        A  B    C         D         E</span><br><span class="line">0     one  A  foo -1.202872  0.047609</span><br><span class="line">1     one  B  foo -1.814470 -0.136473</span><br><span class="line">2     two  C  foo  1.018601 -0.561757</span><br><span class="line">3   three  A  bar -0.595447 -1.623033</span><br><span class="line">4     one  B  bar  1.395433  0.029399</span><br><span class="line">5     one  C  bar -0.392670 -0.542108</span><br><span class="line">6     two  A  foo  0.007207  0.282696</span><br><span class="line">7   three  B  foo  1.928123 -0.087302</span><br><span class="line">8     one  C  foo -0.055224 -1.575170</span><br><span class="line">9     one  A  bar  2.395985  1.771208</span><br><span class="line">10    two  B  bar  1.552825  0.816482</span><br><span class="line">11  three  C  bar  0.166599  1.100230</span><br></pre></td></tr></table></figure>
<p>We can produce pivot tables from this data very easily:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [103]: pd.pivot_table(df, values=&#x27;D&#x27;, index=[&#x27;A&#x27;, &#x27;B&#x27;], columns=[&#x27;C&#x27;])</span><br><span class="line">Out[103]: </span><br><span class="line">C             bar       foo</span><br><span class="line">A     B                    </span><br><span class="line">one   A  2.395985 -1.202872</span><br><span class="line">      B  1.395433 -1.814470</span><br><span class="line">      C -0.392670 -0.055224</span><br><span class="line">three A -0.595447       NaN</span><br><span class="line">      B       NaN  1.928123</span><br><span class="line">      C  0.166599       NaN</span><br><span class="line">two   A       NaN  0.007207</span><br><span class="line">      B  1.552825       NaN</span><br><span class="line">      C       NaN  1.018601</span><br></pre></td></tr></table></figure>
<h2 id="Time-series"><a href="#Time-series" class="headerlink" title="Time series"></a>Time series</h2><p>pandas has simple, powerful, and efficient functionality for performing resampling operations during frequency conversion (e.g., converting secondly data into 5-minutely data). This is extremely common in, but not limited to, financial applications. See the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries">Time Series section</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [104]: rng = pd.date_range(&#x27;1/1/2012&#x27;, periods=100, freq=&#x27;S&#x27;)</span><br><span class="line"></span><br><span class="line">In [105]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)</span><br><span class="line"></span><br><span class="line">In [106]: ts.resample(&#x27;5Min&#x27;).sum()</span><br><span class="line">Out[106]: </span><br><span class="line">2012-01-01    24182</span><br><span class="line">Freq: 5T, dtype: int64</span><br></pre></td></tr></table></figure>
<p>Time zone representation:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [107]: rng = pd.date_range(&#x27;3/6/2012 00:00&#x27;, periods=5, freq=&#x27;D&#x27;)</span><br><span class="line"></span><br><span class="line">In [108]: ts = pd.Series(np.random.randn(len(rng)), rng)</span><br><span class="line"></span><br><span class="line">In [109]: ts</span><br><span class="line">Out[109]: </span><br><span class="line">2012-03-06    1.857704</span><br><span class="line">2012-03-07   -1.193545</span><br><span class="line">2012-03-08    0.677510</span><br><span class="line">2012-03-09   -0.153931</span><br><span class="line">2012-03-10    0.520091</span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [110]: ts_utc = ts.tz_localize(&#x27;UTC&#x27;)</span><br><span class="line"></span><br><span class="line">In [111]: ts_utc</span><br><span class="line">Out[111]: </span><br><span class="line">2012-03-06 00:00:00+00:00    1.857704</span><br><span class="line">2012-03-07 00:00:00+00:00   -1.193545</span><br><span class="line">2012-03-08 00:00:00+00:00    0.677510</span><br><span class="line">2012-03-09 00:00:00+00:00   -0.153931</span><br><span class="line">2012-03-10 00:00:00+00:00    0.520091</span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure>
<p>Converting to another time zone:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [112]: ts_utc.tz_convert(&#x27;US/Eastern&#x27;)</span><br><span class="line">Out[112]: </span><br><span class="line">2012-03-05 19:00:00-05:00    1.857704</span><br><span class="line">2012-03-06 19:00:00-05:00   -1.193545</span><br><span class="line">2012-03-07 19:00:00-05:00    0.677510</span><br><span class="line">2012-03-08 19:00:00-05:00   -0.153931</span><br><span class="line">2012-03-09 19:00:00-05:00    0.520091</span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure>
<p>Converting between time span representations:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [113]: rng = pd.date_range(&#x27;1/1/2012&#x27;, periods=5, freq=&#x27;M&#x27;)</span><br><span class="line"></span><br><span class="line">In [114]: ts = pd.Series(np.random.randn(len(rng)), index=rng)</span><br><span class="line"></span><br><span class="line">In [115]: ts</span><br><span class="line">Out[115]: </span><br><span class="line">2012-01-31   -1.475051</span><br><span class="line">2012-02-29    0.722570</span><br><span class="line">2012-03-31   -0.322646</span><br><span class="line">2012-04-30   -1.601631</span><br><span class="line">2012-05-31    0.778033</span><br><span class="line">Freq: M, dtype: float64</span><br><span class="line"></span><br><span class="line">In [116]: ps = ts.to_period()</span><br><span class="line"></span><br><span class="line">In [117]: ps</span><br><span class="line">Out[117]: </span><br><span class="line">2012-01   -1.475051</span><br><span class="line">2012-02    0.722570</span><br><span class="line">2012-03   -0.322646</span><br><span class="line">2012-04   -1.601631</span><br><span class="line">2012-05    0.778033</span><br><span class="line">Freq: M, dtype: float64</span><br><span class="line"></span><br><span class="line">In [118]: ps.to_timestamp()</span><br><span class="line">Out[118]: </span><br><span class="line">2012-01-01   -1.475051</span><br><span class="line">2012-02-01    0.722570</span><br><span class="line">2012-03-01   -0.322646</span><br><span class="line">2012-04-01   -1.601631</span><br><span class="line">2012-05-01    0.778033</span><br><span class="line">Freq: MS, dtype: float64</span><br></pre></td></tr></table></figure>
<p>Converting between period and timestamp enables some convenient arithmetic functions to be used. In the following example, we convert a quarterly frequency with year ending in November to 9am of the end of the month following the quarter end:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [119]: prng = pd.period_range(&#x27;1990Q1&#x27;, &#x27;2000Q4&#x27;, freq=&#x27;Q-NOV&#x27;)</span><br><span class="line"></span><br><span class="line">In [120]: ts = pd.Series(np.random.randn(len(prng)), prng)</span><br><span class="line"></span><br><span class="line">In [121]: ts.index = (prng.asfreq(&#x27;M&#x27;, &#x27;e&#x27;) + 1).asfreq(&#x27;H&#x27;, &#x27;s&#x27;) + 9</span><br><span class="line"></span><br><span class="line">In [122]: ts.head()</span><br><span class="line">Out[122]: </span><br><span class="line">1990-03-01 09:00   -0.289342</span><br><span class="line">1990-06-01 09:00    0.233141</span><br><span class="line">1990-09-01 09:00   -0.223540</span><br><span class="line">1990-12-01 09:00    0.542054</span><br><span class="line">1991-03-01 09:00   -0.688585</span><br><span class="line">Freq: H, dtype: float64</span><br></pre></td></tr></table></figure>
<h2 id="Categoricals"><a href="#Categoricals" class="headerlink" title="Categoricals"></a>Categoricals</h2><p>pandas can include categorical data in a <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame"><code>DataFrame</code></a>. For full docs, see the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#categorical">categorical introduction</a> and the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/arrays.html#api-arrays-categorical">API documentation</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [123]: df = pd.DataFrame(&#123;&quot;id&quot;: [1, 2, 3, 4, 5, 6],</span><br><span class="line">   .....:                    &quot;raw_grade&quot;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;b&#x27;, &#x27;a&#x27;, &#x27;a&#x27;, &#x27;e&#x27;]&#125;)</span><br><span class="line">   .....: </span><br></pre></td></tr></table></figure>
<p>Convert the raw grades to a categorical data type.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [124]: df[&quot;grade&quot;] = df[&quot;raw_grade&quot;].astype(&quot;category&quot;)</span><br><span class="line"></span><br><span class="line">In [125]: df[&quot;grade&quot;]</span><br><span class="line">Out[125]: </span><br><span class="line">0    a</span><br><span class="line">1    b</span><br><span class="line">2    b</span><br><span class="line">3    a</span><br><span class="line">4    a</span><br><span class="line">5    e</span><br><span class="line">Name: grade, dtype: category</span><br><span class="line">Categories (3, object): [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;e&#x27;]</span><br></pre></td></tr></table></figure>
<p>Rename the categories to more meaningful names (assigning to <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.cat.categories.html#pandas.Series.cat.categories"><code>Series.cat.categories()</code></a> is in place!).</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [126]: df[&quot;grade&quot;].cat.categories = [&quot;very good&quot;, &quot;good&quot;, &quot;very bad&quot;]</span><br></pre></td></tr></table></figure>
<p>Reorder the categories and simultaneously add the missing categories (methods under <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.cat.html#pandas.Series.cat"><code>Series.cat()</code></a> return a new <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series"><code>Series</code></a> by default).</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [127]: df[&quot;grade&quot;] = df[&quot;grade&quot;].cat.set_categories([&quot;very bad&quot;, &quot;bad&quot;, &quot;medium&quot;,</span><br><span class="line">   .....:                                               &quot;good&quot;, &quot;very good&quot;])</span><br><span class="line">   .....: </span><br><span class="line"></span><br><span class="line">In [128]: df[&quot;grade&quot;]</span><br><span class="line">Out[128]: </span><br><span class="line">0    very good</span><br><span class="line">1         good</span><br><span class="line">2         good</span><br><span class="line">3    very good</span><br><span class="line">4    very good</span><br><span class="line">5     very bad</span><br><span class="line">Name: grade, dtype: category</span><br><span class="line">Categories (5, object): [&#x27;very bad&#x27;, &#x27;bad&#x27;, &#x27;medium&#x27;, &#x27;good&#x27;, &#x27;very good&#x27;]</span><br></pre></td></tr></table></figure>
<p>Sorting is per order in the categories, not lexical order.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [129]: df.sort_values(by=&quot;grade&quot;)</span><br><span class="line">Out[129]: </span><br><span class="line">   id raw_grade      grade</span><br><span class="line">5   6         e   very bad</span><br><span class="line">1   2         b       good</span><br><span class="line">2   3         b       good</span><br><span class="line">0   1         a  very good</span><br><span class="line">3   4         a  very good</span><br><span class="line">4   5         a  very good</span><br></pre></td></tr></table></figure>
<p>Grouping by a categorical column also shows empty categories.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [130]: df.groupby(&quot;grade&quot;).size()</span><br><span class="line">Out[130]: </span><br><span class="line">grade</span><br><span class="line">very bad     1</span><br><span class="line">bad          0</span><br><span class="line">medium       0</span><br><span class="line">good         2</span><br><span class="line">very good    3</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure>
<h2 id="Plotting"><a href="#Plotting" class="headerlink" title="Plotting"></a>Plotting</h2><p>See the <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#visualization">Plotting</a> docs.</p>
<p>We use the standard convention for referencing the matplotlib API:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [131]: import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">In [132]: plt.close(&#x27;all&#x27;)</span><br><span class="line">In [133]: ts = pd.Series(np.random.randn(1000),</span><br><span class="line">   .....:                index=pd.date_range(&#x27;1/1/2000&#x27;, periods=1000))</span><br><span class="line">   .....: </span><br><span class="line"></span><br><span class="line">In [134]: ts = ts.cumsum()</span><br><span class="line"></span><br><span class="line">In [135]: ts.plot()</span><br><span class="line">Out[135]: &lt;AxesSubplot:&gt;</span><br></pre></td></tr></table></figure>
<p><img src="https://pandas.pydata.org/pandas-docs/stable/_images/series_plot_basic.png" alt="../_images/series_plot_basic.png"></p>
<p>On a DataFrame, the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot"><code>plot()</code></a> method is a convenience to plot all of the columns with labels:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [136]: df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,</span><br><span class="line">   .....:                   columns=[&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;])</span><br><span class="line">   .....: </span><br><span class="line"></span><br><span class="line">In [137]: df = df.cumsum()</span><br><span class="line"></span><br><span class="line">In [138]: plt.figure()</span><br><span class="line">Out[138]: &lt;Figure size 640x480 with 0 Axes&gt;</span><br><span class="line"></span><br><span class="line">In [139]: df.plot()</span><br><span class="line">Out[139]: &lt;AxesSubplot:&gt;</span><br><span class="line"></span><br><span class="line">In [140]: plt.legend(loc=&#x27;best&#x27;)</span><br><span class="line">Out[140]: &lt;matplotlib.legend.Legend at 0x7fbfb29f0670&gt;</span><br></pre></td></tr></table></figure>
<p><img src="https://pandas.pydata.org/pandas-docs/stable/_images/frame_plot_basic.png" alt="../_images/frame_plot_basic.png"></p>
<h2 id="Getting-data-in-out"><a href="#Getting-data-in-out" class="headerlink" title="Getting data in/out"></a>Getting data in/out</h2><h3 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h3><p><a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-store-in-csv">Writing to a csv file.</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [141]: df.to_csv(&#x27;foo.csv&#x27;)</span><br></pre></td></tr></table></figure>
<p><a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-read-csv-table">Reading from a csv file.</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [142]: pd.read_csv(&#x27;foo.csv&#x27;)</span><br><span class="line">Out[142]: </span><br><span class="line">     Unnamed: 0          A          B          C          D</span><br><span class="line">0    2000-01-01   0.350262   0.843315   1.798556   0.782234</span><br><span class="line">1    2000-01-02  -0.586873   0.034907   1.923792  -0.562651</span><br><span class="line">2    2000-01-03  -1.245477  -0.963406   2.269575  -1.612566</span><br><span class="line">3    2000-01-04  -0.252830  -0.498066   3.176886  -1.275581</span><br><span class="line">4    2000-01-05  -1.044057   0.118042   2.768571   0.386039</span><br><span class="line">..          ...        ...        ...        ...        ...</span><br><span class="line">995  2002-09-22 -48.017654  31.474551  69.146374 -47.541670</span><br><span class="line">996  2002-09-23 -47.207912  32.627390  68.505254 -48.828331</span><br><span class="line">997  2002-09-24 -48.907133  31.990402  67.310924 -49.391051</span><br><span class="line">998  2002-09-25 -50.146062  33.716770  67.717434 -49.037577</span><br><span class="line">999  2002-09-26 -49.724318  33.479952  68.108014 -48.822030</span><br><span class="line"></span><br><span class="line">[1000 rows x 5 columns]</span><br></pre></td></tr></table></figure>
<h3 id="HDF5"><a href="#HDF5" class="headerlink" title="HDF5"></a>HDF5</h3><p>Reading and writing to <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-hdf5">HDFStores</a>.</p>
<p>Writing to a HDF5 Store.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [143]: df.to_hdf(&#x27;foo.h5&#x27;, &#x27;df&#x27;)</span><br></pre></td></tr></table></figure>
<p>Reading from a HDF5 Store.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [144]: pd.read_hdf(&#x27;foo.h5&#x27;, &#x27;df&#x27;)</span><br><span class="line">Out[144]: </span><br><span class="line">                    A          B          C          D</span><br><span class="line">2000-01-01   0.350262   0.843315   1.798556   0.782234</span><br><span class="line">2000-01-02  -0.586873   0.034907   1.923792  -0.562651</span><br><span class="line">2000-01-03  -1.245477  -0.963406   2.269575  -1.612566</span><br><span class="line">2000-01-04  -0.252830  -0.498066   3.176886  -1.275581</span><br><span class="line">2000-01-05  -1.044057   0.118042   2.768571   0.386039</span><br><span class="line">...               ...        ...        ...        ...</span><br><span class="line">2002-09-22 -48.017654  31.474551  69.146374 -47.541670</span><br><span class="line">2002-09-23 -47.207912  32.627390  68.505254 -48.828331</span><br><span class="line">2002-09-24 -48.907133  31.990402  67.310924 -49.391051</span><br><span class="line">2002-09-25 -50.146062  33.716770  67.717434 -49.037577</span><br><span class="line">2002-09-26 -49.724318  33.479952  68.108014 -48.822030</span><br><span class="line"></span><br><span class="line">[1000 rows x 4 columns]</span><br></pre></td></tr></table></figure>
<h3 id="Excel"><a href="#Excel" class="headerlink" title="Excel"></a>Excel</h3><p>Reading and writing to <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-excel">MS Excel</a>.</p>
<p>Writing to an excel file.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [145]: df.to_excel(&#x27;foo.xlsx&#x27;, sheet_name=&#x27;Sheet1&#x27;)</span><br></pre></td></tr></table></figure>
<p>Reading from an excel file.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [146]: pd.read_excel(&#x27;foo.xlsx&#x27;, &#x27;Sheet1&#x27;, index_col=None, na_values=[&#x27;NA&#x27;])</span><br><span class="line">Out[146]: </span><br><span class="line">    Unnamed: 0          A          B          C          D</span><br><span class="line">0   2000-01-01   0.350262   0.843315   1.798556   0.782234</span><br><span class="line">1   2000-01-02  -0.586873   0.034907   1.923792  -0.562651</span><br><span class="line">2   2000-01-03  -1.245477  -0.963406   2.269575  -1.612566</span><br><span class="line">3   2000-01-04  -0.252830  -0.498066   3.176886  -1.275581</span><br><span class="line">4   2000-01-05  -1.044057   0.118042   2.768571   0.386039</span><br><span class="line">..         ...        ...        ...        ...        ...</span><br><span class="line">995 2002-09-22 -48.017654  31.474551  69.146374 -47.541670</span><br><span class="line">996 2002-09-23 -47.207912  32.627390  68.505254 -48.828331</span><br><span class="line">997 2002-09-24 -48.907133  31.990402  67.310924 -49.391051</span><br><span class="line">998 2002-09-25 -50.146062  33.716770  67.717434 -49.037577</span><br><span class="line">999 2002-09-26 -49.724318  33.479952  68.108014 -48.822030</span><br><span class="line"></span><br><span class="line">[1000 rows x 5 columns]</span><br></pre></td></tr></table></figure>
<h2 id="Gotchas"><a href="#Gotchas" class="headerlink" title="Gotchas"></a>Gotchas</h2><p>If you are attempting to perform an operation you might see an exception like:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; if pd.Series([False, True, False]):</span><br><span class="line">...     print(&quot;I was true&quot;)</span><br><span class="line">Traceback</span><br><span class="line">    ...</span><br><span class="line">ValueError: The truth value of an array is ambiguous. Use a.empty, a.any() or a.all().</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>pyspark</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/pyspark/</url>
    <content><![CDATA[<p>Pyspark 入门</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="spark-context-和spark-session的关系"><a href="#spark-context-和spark-session的关系" class="headerlink" title="spark context 和spark session的关系"></a>spark context 和spark session的关系</h1><p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/pyspark/hetianqi/Documents/charging/notes_of_the_world/pyspark.assets/image-20200702140518336.png" alt="image-20200702140518336" style="zoom:50%;"></p>
<p>可以由上节图中看出，Application、SparkSession、SparkContext、RDD之间具有包含关系，并且前三者是1对1的关系。</p>
<p>SparkSession 是 Spark 2.0 版本引入的新入口，在这之前，创建一个 Application 对应的上下文是这样的(创建spark context，创建sqlcontext或者streamingContext或者别的context)：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//set up the spark configuration and create contexts</span></span><br><span class="line"><span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;SparkSessionZipsExample&quot;</span>).setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line"><span class="comment">// your handle to SparkContext to access other context like SQLContext</span></span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf).set(<span class="string">&quot;spark.some.config.option&quot;</span>, <span class="string">&quot;some-value&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> sqlContext = <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</span><br></pre></td></tr></table></figure>
<p>现在 SparkConf、SparkContext 和 SQLContext 都已经被封装在 SparkSession 当中，并且可以通过 builder 的方式创建（创建sparkSession，可直接调用sqlContext方法）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Create a SparkSession. No need to create SparkContext</span><br><span class="line">// You automatically get it as part of the SparkSession</span><br><span class="line">val warehouseLocation = &quot;file:$&#123;system:user.dir&#125;/spark-warehouse&quot;</span><br><span class="line">val spark = SparkSession</span><br><span class="line">   .builder()</span><br><span class="line">   .appName(&quot;SparkSessionZipsExample&quot;)</span><br><span class="line">   .config(&quot;spark.sql.warehouse.dir&quot;, warehouseLocation)</span><br><span class="line">   .enableHiveSupport()</span><br><span class="line">   .getOrCreate()</span><br></pre></td></tr></table></figure>
<h1 id="dataframe-dataset-rdd"><a href="#dataframe-dataset-rdd" class="headerlink" title="dataframe dataset  rdd"></a>dataframe dataset  rdd</h1><p>参考 <a href="https://www.e-learn.cn/content/qita/784122">https://www.e-learn.cn/content/qita/784122</a></p>
<p>简单来说，RDD是一种非结构化分部式数据集，每个元素都可以是不同的类型的数，通过sc.parallelize生成RDD。RDD中比较特殊的一种是key-value Pair RDD，即规定RDD的每个元素都是一个二元数组，其中第一个值是key，第二个值是value。</p>
<p>这种特性就会给Pair RDD赋予一些特殊的操作，例如<code>groupByKey()</code>可以将具有相同key进行分组，其结果仍然得到Pair RDD，然后利用<code>mapValues()</code>对相同key的value进行函数计算；<code>reduceByKey()</code>、<code>countByKey()</code>和<code>sortByKey()</code>等一系列“ByKey()”操作同理。<br>另外，两个Pair RDD具有像SQL一样的连接操作，例如两个Pair RDD进行<code>join()</code>后，具有相同key的元素的value会被放在一个元组里，key不相同的元素会被舍弃。<code>leftOuterJoin()</code>、<code>rightOuterJoin()</code>、<code>fullOuterJoin()</code>等操作同理。</p>
<p>Pair RDD已经被一定程度的格式化了，它的每个元素会具有key，但是value仍然具有很大的灵活性。DataFrame是一种完全格式化的数据集合，和数据库中的<em>表</em>的概念比较接近，它每列数据必须具有相同的数据类型。也正是由于DataFrame知道数据集合所有的类型信息，DataFrame可以进行列处理优化而获得比RDD更优的性能。<br>在内部实现上，DataFrame是由<code>Row</code>对象为元素组成的集合，每个<code>Row</code>对象存储DataFrame的一行</p>
<h2 id="RDD和dataframe使用上的的区别"><a href="#RDD和dataframe使用上的的区别" class="headerlink" title="RDD和dataframe使用上的的区别"></a>RDD和dataframe使用上的的区别</h2><ul>
<li>RDD：没有列名称，只能使用数字来索引；具有<code>map()</code>、<code>reduce()</code>等方法并可指定任意函数进行计算;</li>
<li>DataFrame：一定有列名称（即使是默认生成的），可以通过<code>.col_name</code>或者<code>[&#39;col_name&#39;]</code>来索引列；具有表的相关操作（例如<code>select()</code>、<code>filter()</code>、<code>where()</code>、<code>join</code>），但是没有<code>map()</code>、<code>reduce()</code>等方法。</li>
<li>有时候DataFrame的<em>表</em>相关操作不能处理一些问题，例如需要对一些数据利用指定的函数进行计算时，就需要将DataFrame转换为RDD。DataFrame可以直接利用<code>.rdd</code>获取对应的RDD对象，此RDD对象的每个元素使用<code>Row</code>对象来表示，每列值会成为<code>Row</code>对象的一个<code>域=&gt;值</code>映射</li>
</ul>
<h2 id="RDD转化为dataframe"><a href="#RDD转化为dataframe" class="headerlink" title="RDD转化为dataframe"></a>RDD转化为dataframe</h2><p>就像之前的例子一样，可以利用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dataframe = spark.createDataFrame(rdd, schema=None, samplingRatio=None)</span><br></pre></td></tr></table></figure>
<p>来将RDD转换为DataFrame，其中的参数设置需要注意：<br><strong>schema</strong>：DataFrame各列类型信息，在提前知道RDD所有类型信息时设定。例如</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">schema = StructType([StructField(&#x27;col1&#x27;, StringType()),          StructField(&#x27;col2&#x27;, IntegerType())])</span><br></pre></td></tr></table></figure>
<p><strong>samplingRatio</strong>：推测各列类型信息的采样比例，在未知RDD所有类型信息时，spark需要根据一定的数据量进行类型推测；默认情况下，spark会抽取前100的RDD进行推测，之后在真正将RDD转换为DataFrame时如果遇到类型信息不符会报错 <em>Some of types cannot be determined by the first 100 rows, please try again with sampling</em> 。同理采样比例较低，推测类型信息也可能错误。</p>
<h1 id="PySpark-SparkContext"><a href="#PySpark-SparkContext" class="headerlink" title="PySpark - SparkContext"></a>PySpark - SparkContext</h1><p>SparkContext是任何spark功能的入口点。当我们运行任何Spark应用程序时，会启动一个驱动程序，它具有main函数，并且此处启动了SparkContext。此类的具体定义如下：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">class pyspark.SparkContext (</span><br><span class="line">   master = <span class="literal">None</span>,</span><br><span class="line">   appName = <span class="literal">None</span>, </span><br><span class="line">   sparkHome = <span class="literal">None</span>, </span><br><span class="line">   pyFiles = <span class="literal">None</span>, </span><br><span class="line">   environment = <span class="literal">None</span>, </span><br><span class="line">   batchSize = <span class="number">0</span>, </span><br><span class="line">   serializer = PickleSerializer(), </span><br><span class="line">   conf = <span class="literal">None</span>, </span><br><span class="line">   gateway = <span class="literal">None</span>, </span><br><span class="line">   jsc = <span class="literal">None</span>, </span><br><span class="line">   profiler_cls = &lt;class <span class="symbol">&#x27;pyspark</span>.profiler.BasicProfiler&#x27;&gt;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>以下是SparkContext的参数具体含义：</p>
<ul>
<li><code>Master</code>- 它是连接到的集群的URL。</li>
<li><code>appName</code>- 您的工作名称。</li>
<li><code>sparkHome</code> - Spark安装目录。</li>
<li><code>pyFiles</code> - 要发送到集群并添加到PYTHONPATH的.zip或.py文件。</li>
<li><code>environment</code> - 工作节点环境变量。</li>
<li><code>batchSize</code> - 表示为单个Java对象的Python对象的数量。设置1以禁用批处理，设置0以根据对象大小自动选择批处理大小，或设置为-1以使用无限批处理大小。</li>
<li><code>serializer</code>- RDD序列化器。</li>
<li><code>Conf</code> - L {SparkConf}的一个对象，用于设置所有Spark属性。</li>
<li><code>gateway</code>  - 使用现有网关和JVM，否则初始化新JVM。</li>
<li><code>JSC</code> - JavaSparkContext实例。</li>
<li><code>profiler_cls</code> - 用于进行性能分析的一类自定义Profiler（默认为pyspark.profiler.BasicProfiler）。<br> 在上述参数中，主要使用master和appname。任何PySpark程序的会使用以下两行:<code>控制台启动pyspark的时候本质上也是启动了一个spark context,如果您尝试创建另一个SparkContext对象，您将收到以下错误 - “ValueError：无法一次运行多个SparkContexts”</code>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(<span class="string">&quot;local&quot;</span>, <span class="string">&quot;First App&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="读取本地文件"><a href="#读取本地文件" class="headerlink" title="读取本地文件"></a>读取本地文件</h2><ul>
<li>新建demo.py文件</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(<span class="string">&quot;local&quot;</span>, <span class="string">&quot;first app&quot;</span>) <span class="comment">#本地模式</span></span><br><span class="line">logFile = <span class="string">&quot;file:////opt/modules/hadoop-2.8.5/README.txt&quot;</span></span><br><span class="line">logData = sc.textFile(logFile).cache() <span class="comment">#对于需要重复用到的且占用内存小的RDD对象，可以通过rdd.cache()存储起来，之后再次使用的时候，直接读取内存中的RDD对象，节省时间</span></span><br><span class="line">numAs = logData.<span class="built_in">filter</span>(<span class="keyword">lambda</span> s: <span class="string">&#x27;a&#x27;</span> <span class="keyword">in</span> s).count()</span><br><span class="line">numBs = logData.<span class="built_in">filter</span>(<span class="keyword">lambda</span> s: <span class="string">&#x27;b&#x27;</span> <span class="keyword">in</span> s).count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Line with a:%i,lines with b :%i&quot;</span> % (numAs, numBs))</span><br></pre></td></tr></table></figure>
<ul>
<li>执行文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit demo.py</span><br></pre></td></tr></table></figure>
<h2 id="RDD（Resilient-Distributed-Dataset）"><a href="#RDD（Resilient-Distributed-Dataset）" class="headerlink" title="RDD（Resilient Distributed Dataset）"></a>RDD（Resilient Distributed Dataset）</h2><p>RDD是在多个节点上运行和操作以在集群上进行并行处理的元素</p>
<p>要对这些RDD进行操作，有两种方法 :</p>
<ul>
<li>Transformation：这些操作应用于RDD以创建新的RDD。Filter，groupBy和map是转换的示例。</li>
<li>Action：这些是应用于RDD的操作，它指示Spark执行计算并将结果发送回驱动程序。如count()，collect(), foreach(func)</li>
</ul>
<p>RDD定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">pyspark</span>.<span class="title">RDD</span> (<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="class">   jrdd, </span></span></span><br><span class="line"><span class="params"><span class="class">   ctx, </span></span></span><br><span class="line"><span class="params"><span class="class">   jrdd_deserializer = AutoBatchedSerializer(<span class="params">PickleSerializer(<span class="params"></span>)</span>)</span></span></span><br><span class="line"><span class="params"><span class="class"></span>)</span></span><br></pre></td></tr></table></figure>
<h1 id="RDD基础操作"><a href="#RDD基础操作" class="headerlink" title="RDD基础操作"></a>RDD基础操作</h1><h2 id="count"><a href="#count" class="headerlink" title="count()"></a>count()</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(<span class="string">&quot;local&quot;</span>, <span class="string">&quot;count app&quot;</span>)</span><br><span class="line">words = sc.parallelize(</span><br><span class="line">    [<span class="string">&quot;scala&quot;</span>,</span><br><span class="line">     <span class="string">&quot;java&quot;</span>,</span><br><span class="line">     <span class="string">&quot;hadoop&quot;</span>,</span><br><span class="line">     <span class="string">&quot;spark&quot;</span>,</span><br><span class="line">     <span class="string">&quot;akka&quot;</span>,</span><br><span class="line">     <span class="string">&quot;spark vs hadoop&quot;</span>,</span><br><span class="line">     <span class="string">&quot;pyspark&quot;</span>,</span><br><span class="line">     <span class="string">&quot;pyspark and spark&quot;</span></span><br><span class="line">     ])</span><br><span class="line">counts = words.count()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of elements in RDD -&gt; %i&quot;</span> % counts)</span><br></pre></td></tr></table></figure>
<h2 id="collect"><a href="#collect" class="headerlink" title="collect()"></a>collect()</h2><p>返回RDD中的所有元素</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">----------------------------------------collect.py - --------------------------------------</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(<span class="string">&quot;local&quot;</span>, <span class="string">&quot;collect app&quot;</span>)</span><br><span class="line">words = sc.parallelize(</span><br><span class="line">    [<span class="string">&quot;scala&quot;</span>,</span><br><span class="line">     <span class="string">&quot;java&quot;</span>,</span><br><span class="line">     <span class="string">&quot;hadoop&quot;</span>,</span><br><span class="line">     <span class="string">&quot;spark&quot;</span>,</span><br><span class="line">     <span class="string">&quot;akka&quot;</span>,</span><br><span class="line">     <span class="string">&quot;spark vs hadoop&quot;</span>,</span><br><span class="line">     <span class="string">&quot;pyspark&quot;</span>,</span><br><span class="line">     <span class="string">&quot;pyspark and spark&quot;</span></span><br><span class="line">     ])</span><br><span class="line">coll = words.collect()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Elements in RDD -&gt; %s&quot;</span> % coll)</span><br></pre></td></tr></table></figure>
<p>执行spark-submit collect.py 输出以下结果</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">Elements <span class="keyword">in</span> RDD -&gt; [<span class="symbol">&#x27;scala</span>&#x27;, <span class="symbol">&#x27;java</span>&#x27;, <span class="symbol">&#x27;hadoop</span>&#x27;, <span class="symbol">&#x27;spark</span>&#x27;, <span class="symbol">&#x27;akka</span>&#x27;, <span class="symbol">&#x27;spark</span> vs hadoop&#x27;, <span class="symbol">&#x27;pyspark</span>&#x27;, <span class="symbol">&#x27;pyspark</span> and spark&#x27;]</span><br></pre></td></tr></table></figure>
<h2 id="foreach-func"><a href="#foreach-func" class="headerlink" title="foreach(func)"></a>foreach(func)</h2><p>仅返回满足foreach内函数条件的元素。在下面的示例中，我们在foreach中调用print函数，该函数打印RDD中的所有元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># foreach.py</span></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(<span class="string">&quot;local&quot;</span>, <span class="string">&quot;ForEach app&quot;</span>)</span><br><span class="line">words = sc.parallelize (</span><br><span class="line">   [<span class="string">&quot;scala&quot;</span>, </span><br><span class="line">   <span class="string">&quot;java&quot;</span>, </span><br><span class="line">   <span class="string">&quot;hadoop&quot;</span>, </span><br><span class="line">   <span class="string">&quot;spark&quot;</span>, </span><br><span class="line">   <span class="string">&quot;akka&quot;</span>,</span><br><span class="line">   <span class="string">&quot;spark vs hadoop&quot;</span>, </span><br><span class="line">   <span class="string">&quot;pyspark&quot;</span>,</span><br><span class="line">   <span class="string">&quot;pyspark and spark&quot;</span>]</span><br><span class="line">)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span> <span class="built_in">print</span>(x)</span><br><span class="line">fore = words.foreach(f)</span><br></pre></td></tr></table></figure>
<p>执行<code>spark-submit foreach.py</code>，然后输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scala</span><br><span class="line">java</span><br><span class="line">hadoop</span><br><span class="line">spark</span><br><span class="line">akka</span><br><span class="line">spark vs hadoop</span><br><span class="line">pyspark</span><br><span class="line">pyspark and spark</span><br></pre></td></tr></table></figure>
<h2 id="filter-f"><a href="#filter-f" class="headerlink" title="filter(f)"></a>filter(f)</h2><p>返回一个包含元素的新RDD，它满足过滤器内部的功能。在下面的示例中，我们过滤掉包含’’spark’的字符串。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># filter.py</span></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(<span class="string">&quot;local&quot;</span>, <span class="string">&quot;Filter app&quot;</span>)</span><br><span class="line">words = sc.parallelize(</span><br><span class="line">    [<span class="string">&quot;scala&quot;</span>,</span><br><span class="line">     <span class="string">&quot;java&quot;</span>,</span><br><span class="line">     <span class="string">&quot;hadoop&quot;</span>,</span><br><span class="line">     <span class="string">&quot;spark&quot;</span>,</span><br><span class="line">     <span class="string">&quot;akka&quot;</span>,</span><br><span class="line">     <span class="string">&quot;spark vs hadoop&quot;</span>,</span><br><span class="line">     <span class="string">&quot;pyspark&quot;</span>,</span><br><span class="line">     <span class="string">&quot;pyspark and spark&quot;</span>]</span><br><span class="line">)</span><br><span class="line">words_filter = words.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: <span class="string">&#x27;spark&#x27;</span> <span class="keyword">in</span> x)</span><br><span class="line">filtered = words_filter.collect()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Fitered RDD -&gt; %s&quot;</span> % (filtered))</span><br></pre></td></tr></table></figure>
<p>执行<code>spark-submit filter.py</code>:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">Fitered RDD -&gt; [<span class="symbol">&#x27;spark</span>&#x27;, <span class="symbol">&#x27;spark</span> vs hadoop&#x27;, <span class="symbol">&#x27;pyspark</span>&#x27;, <span class="symbol">&#x27;pyspark</span> and spark&#x27;]</span><br></pre></td></tr></table></figure>
<h2 id="map-f-preservesPartitioning-False"><a href="#map-f-preservesPartitioning-False" class="headerlink" title="map(f, preservesPartitioning = False)"></a>map(f, preservesPartitioning = False)</h2><p>通过将该函数应用于RDD中的每个元素来返回新的RDD。在下面的示例中，我们形成一个键值对，并将每个字符串映射为值1</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># map.py</span></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(<span class="string">&quot;local&quot;</span>, <span class="string">&quot;Map app&quot;</span>)</span><br><span class="line">words = sc.parallelize(</span><br><span class="line">    [<span class="string">&quot;scala&quot;</span>,</span><br><span class="line">     <span class="string">&quot;java&quot;</span>,</span><br><span class="line">     <span class="string">&quot;hadoop&quot;</span>,</span><br><span class="line">     <span class="string">&quot;spark&quot;</span>,</span><br><span class="line">     <span class="string">&quot;akka&quot;</span>,</span><br><span class="line">     <span class="string">&quot;spark vs hadoop&quot;</span>,</span><br><span class="line">     <span class="string">&quot;pyspark&quot;</span>,</span><br><span class="line">     <span class="string">&quot;pyspark and spark&quot;</span>]</span><br><span class="line">)</span><br><span class="line">words_map = words.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>))</span><br><span class="line">mapping = words_map.collect()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Key value pair -&gt; %s&quot;</span> % (mapping))</span><br></pre></td></tr></table></figure>
<p>执行spark-submit map.py</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">Key <span class="keyword">value</span> pair -&gt; [(<span class="string">&#x27;scala&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;java&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;hadoop&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;spark&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;akka&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;spark vs hadoop&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;pyspark&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;pyspark and spark&#x27;</span>, <span class="number">1</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="reduce-f"><a href="#reduce-f" class="headerlink" title="reduce(f)"></a>reduce(f)</h2><p>执行指定的可交换和关联二元操作后，将返回RDD中的元素。在下面的示例中，我们从运算符导入add包并将其应用于’num’以执行简单的加法运算。说白了和Python的reduce一样：假如有一组整数[x1,x2,x3]，利用reduce执行加法操作add，对第一个元素执行add后，结果为sum=x1,然后再将sum和x2执行add，sum=x1+x2，最后再将x2和sum执行add，此时sum=x1+x2+x3。</p>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"># reduce.py</span><br><span class="line">from pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">from <span class="keyword">operator</span> import add</span><br><span class="line">sc <span class="title">=</span> <span class="type">SparkContext</span>(<span class="string">&quot;local&quot;</span>, <span class="string">&quot;Reduce app&quot;</span>)</span><br><span class="line">nums <span class="operator">=</span> sc.parallelize([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">adding <span class="operator">=</span> nums.reduce(add)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Adding all the elements -&gt; %i&quot;</span> <span class="operator">%</span> (adding))</span><br></pre></td></tr></table></figure>
<p>执行<code>spark-submit reduce.py</code>:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">Adding all the elements -&gt; <span class="number">15</span></span><br></pre></td></tr></table></figure>
<h2 id="join-other-numPartitions-None"><a href="#join-other-numPartitions-None" class="headerlink" title="join(other, numPartitions = None)"></a>join(other, numPartitions = None)</h2><p>它返回RDD，其中包含一对带有匹配键的元素以及该特定键的所有值。</p>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line">from pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc <span class="operator">=</span> <span class="type">SparkContext</span>(<span class="string">&quot;local&quot;</span>, <span class="string">&quot;Join app&quot;</span>)</span><br><span class="line">x <span class="operator">=</span> sc.parallelize([(<span class="string">&quot;spark&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;hadoop&quot;</span>, <span class="number">4</span>)])</span><br><span class="line">y <span class="operator">=</span> sc.parallelize([(<span class="string">&quot;spark&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;hadoop&quot;</span>, <span class="number">5</span>)])</span><br><span class="line">joined <span class="operator">=</span> x.join(y)</span><br><span class="line"><span class="keyword">final</span> <span class="operator">=</span> joined.collect()</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;Join RDD -&gt; %s&quot;</span> <span class="operator">%</span> (<span class="keyword">final</span>))</span><br></pre></td></tr></table></figure>
<p>执行<code>spark-submit join.py</code>:</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">Join RDD -&gt; [</span><br><span class="line">   (<span class="symbol">&#x27;spark</span>&#x27;, (<span class="number">1</span>, <span class="number">2</span>)),  </span><br><span class="line">   (<span class="symbol">&#x27;hadoop</span>&#x27;, (<span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h1 id="RDD转成pandas-dataframe"><a href="#RDD转成pandas-dataframe" class="headerlink" title="RDD转成pandas.dataframe"></a>RDD转成pandas.dataframe</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> HiveContext,SparkSession</span><br><span class="line">sc = SparkContext(<span class="string">&quot;local&quot;</span>, <span class="string">&quot;Map app&quot;</span>)</span><br><span class="line">hiveContext = HiveContext(sc)</span><br><span class="line">sql=<span class="string">&quot;select pin,cpp_base_sex from dmr_c.dmrc_model_t03_market_bt_profile_s_d where dt&gt;&#x27;2020-01-01&#x27; limit 100&quot;</span></span><br><span class="line">read_df=hiveContext.sql(sql) <span class="comment"># spark的dataframe</span></span><br><span class="line">df = read_df.toPandas() <span class="comment">#pandas的dataframe</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="内存不足"><a href="#内存不足" class="headerlink" title="内存不足"></a>内存不足</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 方式一：</span></span><br><span class="line">spark.conf.<span class="built_in">set</span>(<span class="string">&quot;spark.sql.execution.arrow.enabled&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式二：设置多个conf</span></span><br><span class="line"><span class="keyword">from</span> pyspark.conf <span class="keyword">import</span> SparkConf</span><br><span class="line">sparkConf = SparkConf()</span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&#x27;spark.driver.maxResultSize&#x27;</span>, <span class="string">&#x27;3G&#x27;</span>)</span><br><span class="line">sc = SparkSession.builder.config(conf=sparkConf).enableHiveSupport().getOrCreate()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="运行太慢"><a href="#运行太慢" class="headerlink" title="运行太慢"></a>运行太慢</h3>]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>pyplot</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/pyplot/</url>
    <content><![CDATA[<p>5 minute to pyplot</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="中文显示"><a href="#中文显示" class="headerlink" title="中文显示"></a>中文显示</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import matplotlib</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">loss1=[1,2,3]</span><br><span class="line">loss2=[1,2,1]</span><br><span class="line">loss3=[2,3,1]</span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[&#x27;font.family&#x27;]=&#x27;STSong&#x27;#显示中文 修改了全局变量</span><br><span class="line">matplotlib.rcParams[&#x27;font.size&#x27;]=10</span><br><span class="line">plt.title(&#x27;主成分分析&#x27;)</span><br><span class="line">plt.xlabel(&#x27;主成分数量&#x27;)</span><br><span class="line">plt.ylabel(&#x27;loss&#x27;)</span><br><span class="line">plt.plot(loss1,label=&#x27;loss1&#x27;)</span><br><span class="line">plt.plot(loss2,label=&#x27;loss2&#x27;)</span><br><span class="line">plt.plot(loss3,label=&#x27;loss3&#x27;)</span><br><span class="line">plt.legend()#图例</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>效果图<br></p>
<h1 id="多个子图"><a href="#多个子图" class="headerlink" title="多个子图"></a>多个子图</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import matplotlib</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">loss1=[1,2,3]</span><br><span class="line">loss2=[1,2,1]</span><br><span class="line">loss3=[2,3,1]</span><br><span class="line"></span><br><span class="line">plt.subplot(2,1,1) #两行一列图中的第一幅图</span><br><span class="line">plt.plot(loss1)</span><br><span class="line">plt.plot(loss2)</span><br><span class="line">plt.xlabel(&#x27;epoch&#x27;)</span><br><span class="line">plt.ylabel(&#x27;loss&#x27;)</span><br><span class="line">plt.legend(labels=[&#x27;train_loss&#x27;, &#x27;test_loss&#x27;])</span><br><span class="line"></span><br><span class="line">plt.subplot(2,1,2) #两行一列图中的第一幅图</span><br><span class="line">plt.plot(loss2)</span><br><span class="line">plt.plot(loss3)</span><br><span class="line">plt.xlabel(&#x27;epoch&#x27;)</span><br><span class="line">plt.ylabel(&#x27;auc&#x27;)</span><br><span class="line">plt.legend(labels=[&#x27;train_auc&#x27;, &#x27;test_auc&#x27;])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>效果图</p>

<h1 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h1><h2 id="2D三点图"><a href="#2D三点图" class="headerlink" title="2D三点图"></a>2D三点图</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import matplotlib</span><br><span class="line">import numpy as np</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">x=np.random.rand(2,20)</span><br><span class="line">label=np.random.randint(2, size=20)</span><br><span class="line"></span><br><span class="line">plt.scatter(x[0,:],x[1,:],c=label)#同一个label的点是同一个颜色</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>效果图</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/pyplot/1563430474219.png" alt="1563430474219"></p>
<h2 id="3d-三点图"><a href="#3d-三点图" class="headerlink" title="3d 三点图"></a>3d 三点图</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax.scatter(X_new[:,<span class="number">0</span>].reshape(-<span class="number">1</span>),X_new[:,<span class="number">1</span>].reshape(-<span class="number">1</span>), X_new[:,<span class="number">2</span>].reshape(-<span class="number">1</span>))</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X Label&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Y Label&#x27;</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;Z Label&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>效果：</p>

<h1 id="实时画图"><a href="#实时画图" class="headerlink" title="实时画图"></a>实时画图</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.axis([<span class="number">0</span>,<span class="number">50</span>,<span class="number">60</span>,<span class="number">80</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">    z = <span class="number">68</span> + <span class="number">4</span> * np.random.randn(<span class="number">50</span>)</span><br><span class="line">    zm = np.cumsum(z) / <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(z)+<span class="number">1</span>)</span><br><span class="line">    plt.plot(zm)    </span><br><span class="line"></span><br><span class="line">n = np.arange(<span class="number">1</span>,<span class="number">51</span>)</span><br><span class="line">su = <span class="number">68</span> + <span class="number">4</span> / np.sqrt(n)</span><br><span class="line">sl = <span class="number">68</span> - <span class="number">4</span> / np.sqrt(n)</span><br><span class="line"></span><br><span class="line">plt.plot(n,su,n,sl) </span><br><span class="line">plt.show()<span class="comment">#阻塞函数</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>python</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/python/</url>
    <content><![CDATA[<p>python常用操作</p>
<span id="more"></span>
<h1 id="python中的魔数方法"><a href="#python中的魔数方法" class="headerlink" title="python中的魔数方法"></a>python中的魔数方法</h1><p>pydthon中双下划线开头的方法称为魔数方法，常见的有</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Demo</span>()</span></span><br><span class="line"><span class="class">	<span class="title">def</span> <span class="title">__init__</span>():</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>():</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__new__</span>():</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="快速安装python依赖包"><a href="#快速安装python依赖包" class="headerlink" title="快速安装python依赖包"></a>快速安装python依赖包</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># requirements.txt</span><br><span class="line">certifi==2020.4.5.1</span><br><span class="line">chardet==3.0.4</span><br><span class="line">idna==2.9</span><br><span class="line">lxml==4.5.1</span><br><span class="line">requests==2.23.0</span><br><span class="line">urllib3==1.25.9</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="importlib-动态导入包"><a href="#importlib-动态导入包" class="headerlink" title="importlib 动态导入包"></a>importlib 动态导入包</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入指定类或方法</span></span><br><span class="line"><span class="keyword">from</span> model_fn <span class="keyword">import</span> dmtTrainer</span><br><span class="line">module = importlib.import_module(FLAGS.model_fn)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dmtTrainer = module.dmtTrainer</span><br></pre></td></tr></table></figure>
<h1 id="argparse"><a href="#argparse" class="headerlink" title="argparse"></a>argparse</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1引入模块</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2建立解析对象</span></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3增加属性：给xx实例增加一个aa属性 # xx.add_argument(&quot;aa&quot;)</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;role&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&quot;Role of this trainer in &#123;&#x27;local&#x27;, &quot;</span></span><br><span class="line">                             <span class="string">&quot;&#x27;leader&#x27;, &#x27;follower&#x27;&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4属性给与args实例： 把parser中设置的所有&quot;add_argument&quot;给返回到args子类实例当中， 那么parser中增加的属性内容都会在args实例中，使用即可。</span></span><br><span class="line">args = parser.parse_args()</span><br><span class="line">parser.parse_args()</span><br></pre></td></tr></table></figure>
<p>运行时使用</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python main.py --role=&#x27;leader&#x27;</span><br></pre></td></tr></table></figure>
<h1 id="命名规则"><a href="#命名规则" class="headerlink" title="命名规则"></a>命名规则</h1><p>类： 大驼峰<br>方法：小驼峰<br>变量：小写字母+下划线<br>常量：大写字母+下划线</p>
<h1 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h1><blockquote>
<p>内部函数调用外部变量的行为叫做闭包</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func1</span>(<span class="params">name</span>):</span> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">func2</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(name)</span><br><span class="line">   <span class="keyword">return</span> func2()</span><br></pre></td></tr></table></figure>
<h1 id="dict排序"><a href="#dict排序" class="headerlink" title="dict排序"></a>dict排序</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">d = &#123;<span class="string">&#x27;d1&#x27;</span>:<span class="number">2</span>, <span class="string">&#x27;d2&#x27;</span>:<span class="number">4</span>, <span class="string">&#x27;d4&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;d3&#x27;</span>:<span class="number">3</span>,&#125;</span><br><span class="line">res = <span class="built_in">sorted</span>(d.items(),key=<span class="keyword">lambda</span> d:d[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<h1 id="python的u-r-b分别什么意思"><a href="#python的u-r-b分别什么意思" class="headerlink" title="python的u,r,b分别什么意思"></a>python的u,r,b分别什么意思</h1><p> u: 表示unicode字符串，默认模式，里边的特殊字符会被识别。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print(u&#x27;hi\thi\thi&#x27;)</span><br></pre></td></tr></table></figure>
<p>执行之后：<br><strong>hi hi hi</strong></p>
<p> b: 表示二进制字符串，括号内的内容原样输出。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print(b&#x27;hi\thi\thi&#x27;)</span><br></pre></td></tr></table></figure>
<p>执行之后：<br><strong>b’hi\thi\thi’</strong></p>
<p> r：不转义字符串，要输出的内容原样输出。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print(r&#x27;hi\thi\thi&#x27;)</span><br></pre></td></tr></table></figure>
<p>执行之后：<br><strong>hi\thi\thi</strong></p>
<h1 id="dic快速保存和读取"><a href="#dic快速保存和读取" class="headerlink" title="dic快速保存和读取"></a>dic快速保存和读取</h1><blockquote>
<pre><code>   #保存
   dict_name = &#123;1:&#123;1:2,3:4&#125;,2:&#123;3:4,4:5&#125;&#125;
   f = open(&#39;temp.txt&#39;,&#39;w&#39;)
   f.write(str(dict_name))
   f.close()

   #读取
   f = open(&#39;temp.txt&#39;,&#39;r&#39;)
   a = f.read()
   dict_name = eval(a)
</code></pre></blockquote>
<h1 id="如果不存在则创建文件"><a href="#如果不存在则创建文件" class="headerlink" title="如果不存在则创建文件"></a>如果不存在则创建文件</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filename):</span><br><span class="line">    os.system(<span class="string">r&quot;touch &#123;&#125;&quot;</span>.<span class="built_in">format</span>(path))<span class="comment">#调用系统命令行来创建文件</span></span><br></pre></td></tr></table></figure>
<h1 id="获取当前路径"><a href="#获取当前路径" class="headerlink" title="获取当前路径"></a>获取当前路径</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sys.path.append(os.getcwd()) #添加当前文件夹路径</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="built_in">print</span> (sys.argv[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(os.getcwd())</span><br></pre></td></tr></table></figure>
<h1 id="utf-8编码"><a href="#utf-8编码" class="headerlink" title="utf-8编码"></a>utf-8编码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> sys.getdefaultencoding() != <span class="string">&#x27;utf-8&#x27;</span>:</span><br><span class="line">    reload(sys)</span><br><span class="line">    sys.setdefaultencoding(<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="文件读取"><a href="#文件读取" class="headerlink" title="文件读取"></a>文件读取</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pandas.read_table(filename,sep=<span class="string">&#x27;\t&#x27;</span>) <span class="comment">#dataframe</span></span><br><span class="line">data.to_csv(filename,sep=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line"></span><br><span class="line">data=np.loadtxt(filename,delimiter=<span class="string">&#x27;\t&#x27;</span>) <span class="comment">#narray</span></span><br><span class="line">np.save(filename,narray)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&#x27;r&#x27;</span>.encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f: <span class="comment">#list</span></span><br><span class="line">	lines=f.readlines()</span><br></pre></td></tr></table></figure>
<h1 id="产生随机矩阵"><a href="#产生随机矩阵" class="headerlink" title="产生随机矩阵"></a>产生随机矩阵</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df=pd.DataFrame(np.random.randn(<span class="number">4</span>,<span class="number">4</span>),columns=[<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;C&#x27;</span>,<span class="string">&#x27;D&#x27;</span>])</span><br></pre></td></tr></table></figure>
<h1 id="提取年月日"><a href="#提取年月日" class="headerlink" title="提取年月日"></a>提取年月日</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=[<span class="string">&#x27;2019-01-01 12:00:00&#x27;</span>,<span class="string">&#x27;2019-02-01 12:00:00&#x27;</span>]</span><br><span class="line">a.apply(<span class="keyword">lambda</span> x:x[<span class="number">0</span>,<span class="number">7</span>])</span><br></pre></td></tr></table></figure>
<h1 id="百分位数"><a href="#百分位数" class="headerlink" title="百分位数"></a>百分位数</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#dataframe</span></span><br><span class="line">feat_res[<span class="string">&#x27;f_p75&#x27;</span>] = X[X[feat] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>][feat].quantile(<span class="number">0.75</span>)</span><br></pre></td></tr></table></figure>
<h1 id="计时"><a href="#计时" class="headerlink" title="计时"></a>计时</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">time_start=time.time()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line">time_end=time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;totally cost &#123;:.3f&#125; s&#x27;</span>.<span class="built_in">format</span>(time_end-time_start))</span><br></pre></td></tr></table></figure>
<h1 id="python调用shell"><a href="#python调用shell" class="headerlink" title="python调用shell"></a>python调用shell</h1><blockquote>
<p>os.system(command) </p>
</blockquote>
<p>  此函数会启动子进程，在子进程中执行command，并返回command命令执行完毕后的退出状态，如果command有执行内容，会在标准输出显示。这实际上是使用C标准库函数system()实现的。</p>
<p>​    缺点：这个函数在执行command命令时需要重新打开一个终端，并且无法保存command命令的执行结果。</p>
<blockquote>
<p>os.popen(command,mode)</p>
</blockquote>
<p>打开一个与command进程之间的管道。这个函数的返回值是一个文件对象，可以读或者写(由mode决定，mode默认是’r’)。如果mode为’r’，可以使用此函数的返回值调用read()来获取command命令的执行结果。</p>
<p>os.system(cmd)或os.popen(cmd)，前者返回值是脚本的退出状态码，后者的返回值是脚本执行过程中的输出内容。实际使用时视需求情况而选择。</p>
<h1 id="XGB-相关"><a href="#XGB-相关" class="headerlink" title="XGB 相关"></a>XGB 相关</h1><h2 id="xgboost-sklearn-XGBClassifier"><a href="#xgboost-sklearn-XGBClassifier" class="headerlink" title="xgboost.sklearn.XGBClassifier"></a>xgboost.sklearn.XGBClassifier</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost.sklearn <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">watchlist = [(x_train, y_train), (x_test, y_test)]  <span class="comment"># [(test[res_train],y_test)]</span></span><br><span class="line">model = XGBClassifier(**params)</span><br><span class="line">model.fit(x_train, y_train, eval_set=watchlist)  </span><br><span class="line">    </span><br><span class="line"><span class="comment"># feature importance</span></span><br><span class="line">importance = model.get_booster().get_fscore()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line"> y_test_pro = model.predict_proba(x_test)[:,<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 模型保存</span></span><br><span class="line"><span class="comment">#法一</span></span><br><span class="line">model.get_booster().dump_model(<span class="string">&#x27;xgb.dump&#x27;</span>) <span class="comment">#该方法储存的是raw text文件，不能用于load_model，用于直观解释模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#法二</span></span><br><span class="line">model.save_model(<span class="string">&#x27;xgb.dump&#x27;</span>) <span class="comment">#该同法一</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#法三 推荐方法</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">pickle.dump(model, <span class="built_in">open</span>(<span class="string">&quot;pima.pickle.dat&quot;</span>, <span class="string">&quot;wb&quot;</span>)) <span class="comment">#该方法储存的是二进制文件，可以load_model</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#load model</span></span><br><span class="line"><span class="comment">#法一</span></span><br><span class="line">clf = XGBClassifier()</span><br><span class="line">booster = Booster()</span><br><span class="line">booster.load_model(<span class="string">&#x27;./model.xgb&#x27;</span>)</span><br><span class="line">clf._Booster = booster</span><br><span class="line"></span><br><span class="line"><span class="comment">#法二</span></span><br><span class="line">clf.predict(...)</span><br><span class="line">loaded_model = pickle.load(<span class="built_in">open</span>(<span class="string">&quot;pima.pickle.dat&quot;</span>, <span class="string">&quot;rb&quot;</span>))</span><br></pre></td></tr></table></figure>
<h2 id="哈哈"><a href="#哈哈" class="headerlink" title="哈哈"></a>哈哈</h2><h1 id="dataframe-转为-DMATRIX"><a href="#dataframe-转为-DMATRIX" class="headerlink" title="dataframe 转为 DMATRIX"></a>dataframe 转为 DMATRIX</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dtrain = xgb.DMatrix(df_train[col_feat], label=df_train[&#x27;y&#x27;])</span><br></pre></td></tr></table></figure>
<h1 id="获取叶子节点"><a href="#获取叶子节点" class="headerlink" title="获取叶子节点"></a>获取叶子节点</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loaded_model = pickle.load(<span class="built_in">open</span>(f_xgb_model+<span class="string">&#x27;.pickle&#x27;</span>, <span class="string">&quot;rb&quot;</span>))</span><br><span class="line">dtrain = xgb.DMatrix(df_train[col_feat], label=df_train[<span class="string">&#x27;y&#x27;</span>])</span><br><span class="line">y=loaded_model.get_booster().predict(dtrain,pred_leaf=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h1 id="装饰器-decorator"><a href="#装饰器-decorator" class="headerlink" title="装饰器(decorator)"></a>装饰器(decorator)</h1><p><a href="https://www.cnblogs.com/wolf-yasen/p/11240500.html">https://www.cnblogs.com/wolf-yasen/p/11240500.html</a></p>
<blockquote>
<p>本质上，decorator就是一个返回函数的高阶函数</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@a</span></span><br><span class="line"><span class="meta">@b</span></span><br><span class="line"><span class="meta">@c</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>():</span></span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"><span class="comment">#相当于执行了  f = a(b(c(f)))</span></span><br><span class="line"><span class="comment">#调用f的时候，实际上调用的是a(b(c(f)))</span></span><br></pre></td></tr></table></figure>
<p>装饰器（decorator）可以给函数动态加上功能</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">func</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>():</span></span><br><span class="line">        start = time.clock()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;this is a order test, if you need not it, delete it&quot;</span>) <span class="comment"># 用于测试执行顺序,可以跟着走一遍</span></span><br><span class="line">        end = time.clock()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;start:&quot;</span>, start, <span class="string">&quot; end:&quot;</span>, end)</span><br><span class="line">        <span class="keyword">return</span> func <span class="comment"># 这种获得返回值的方法可能在多层修饰器的时候有矛盾,我先用!!!标记, 等理顺后再回来修改,如果我发布之后这里依然存在...说明我忘记了...</span></span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@test</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;this is a test&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;this is a return value&quot;</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">#相当于执行了 foo = log(foo)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(foo())</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="comment"># this is a test wrapper, if you need not it, delete it</span></span><br><span class="line"><span class="comment"># this is a test</span></span><br><span class="line"><span class="comment"># start: 4.44444839506524e-07  end: 1.8222238419767486e-05</span></span><br><span class="line"><span class="comment"># this is a return value</span></span><br></pre></td></tr></table></figure>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/python/hetianqi/Documents/charging/notes_of_the_world/python.assets/image-20200409175624696.png" alt="image-20200409175624696"></p>
<h2 id="property修饰器"><a href="#property修饰器" class="headerlink" title="@property修饰器"></a>@property修饰器</h2><p>把一个getter方法变成属性，只需要加上<code>@property</code>就可以了，此时，<code>@property</code>本身又创建了另一个装饰器<code>@score.setter</code>，负责把一个setter方法变成属性赋值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Screen</span>(<span class="params"><span class="built_in">object</span></span>):</span>  </span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">width</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.W</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @width.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">width</span>(<span class="params">self, value</span>):</span></span><br><span class="line">        self.W = value </span><br><span class="line">  <span class="comment"># 测试:</span></span><br><span class="line">s = Screen()</span><br><span class="line">s.width=<span class="number">10</span> </span><br><span class="line">s.width</span><br></pre></td></tr></table></figure>
<p>代码也可改为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Screen</span>(<span class="params"><span class="built_in">object</span></span>):</span>  </span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">width</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self._width</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @width.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">width</span>(<span class="params">self, value</span>):</span></span><br><span class="line">        self._width = value </span><br><span class="line">  <span class="comment"># 测试:</span></span><br><span class="line">s = Screen()</span><br><span class="line">s.width=<span class="number">10</span> </span><br><span class="line">s.width</span><br></pre></td></tr></table></figure>
<h1 id="python变量中的下划线"><a href="#python变量中的下划线" class="headerlink" title="python变量中的下划线"></a>python变量中的下划线</h1><ul>
<li>xx: 公有变量</li>
<li>_x: 单前置下划线,私有化属性或方法，from somemodule import *禁止导入,类对象和子类可以访问</li>
<li>__xx：双前置下划线,避免与子类中的属性命名冲突，无法在外部直接访问(名字重整所以访问不到)</li>
<li><strong>xx</strong>:双前后下划线,用户名字空间的魔法对象或属性。例如:<strong>init</strong> , __ 不要自己发明这样的名字</li>
<li>xx_:单后置下划线,用于避免与Python关键词的冲突</li>
</ul>
<h1 id="生成器（generator）"><a href="#生成器（generator）" class="headerlink" title="生成器（generator）"></a>生成器（generator）</h1><p>如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。</p>
<blockquote>
<p>实例：生成斐波那契数列</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;# 一般写法</span><br><span class="line">&gt;def fib1(max):</span><br><span class="line">	n, a, b = 0,0,1</span><br><span class="line">	while n&lt;max:</span><br><span class="line">			print(b)</span><br><span class="line">	    a,b = b,a+b</span><br><span class="line">	    n+=1</span><br><span class="line">	return &#x27;done&#x27;</span><br><span class="line">&gt;# 调用</span><br><span class="line">&gt;fib1(6)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;<span class="comment"># 生成器写法</span></span><br><span class="line">&gt;<span class="function"><span class="keyword">def</span> <span class="title">fib2</span>(<span class="params"><span class="built_in">max</span></span>):</span></span><br><span class="line">   n, a, b = <span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span></span><br><span class="line">   <span class="keyword">while</span> n&lt;<span class="built_in">max</span>:</span><br><span class="line">       <span class="keyword">yield</span> b</span><br><span class="line">       a,b = b,a+b</span><br><span class="line">       n+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;done&#x27;</span></span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line">&gt;<span class="keyword">for</span> i <span class="keyword">in</span> fib2(<span class="number">6</span>):</span><br><span class="line">     <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>
</blockquote>
<h1 id="迭代器（iterable）"><a href="#迭代器（iterable）" class="headerlink" title="迭代器（iterable）"></a>迭代器（iterable）</h1><p>我们已经知道，可以直接作用于<code>for</code>循环的数据类型有以下几种：</p>
<p>一类是集合数据类型，如<code>list</code>、<code>tuple</code>、<code>dict</code>、<code>set</code>、<code>str</code>等；</p>
<p>一类是<code>generator</code>，包括生成器和带<code>yield</code>的generator function。</p>
<p>这些可以直接作用于<code>for</code>循环的对象统称为可迭代对象：<code>Iterable</code>。</p>
<p>可以使用<code>isinstance()</code>判断一个对象是否是<code>Iterable</code>对象</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from collections.abc import Iterable</span><br><span class="line">&gt;&gt;&gt; isinstance([], Iterable)</span><br><span class="line">True</span><br></pre></td></tr></table></figure>
<p>可以被<code>next()</code>函数调用并不断返回下一个值的对象称为迭代器：<code>Iterator</code>。可以使用<code>isinstance()</code>判断一个对象是否是<code>Iterator</code>对象：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from collections.abc import Iterator</span><br><span class="line">&gt;&gt;&gt; isinstance((x for x in range(10)), Iterator)</span><br><span class="line">True</span><br></pre></td></tr></table></figure>
<p>生成器都是<code>Iterator</code>对象，但<code>list</code>、<code>dict</code>、<code>str</code>虽然是<code>Iterable</code>，却不是<code>Iterator</code>。</p>
<p>把<code>list</code>、<code>dict</code>、<code>str</code>等<code>Iterable</code>变成<code>Iterator</code>可以使用<code>iter()</code>函数：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">isinstance(iter([]), Iterator)</span><br><span class="line">True</span><br></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>凡是可作用于<code>for</code>循环的对象都是<code>Iterable</code>类型；</p>
<p>凡是可作用于<code>next()</code>函数的对象都是<code>Iterator</code>类型，它们表示一个惰性计算的序列；</p>
<p>集合数据类型如<code>list</code>、<code>dict</code>、<code>str</code>等是<code>Iterable</code>但不是<code>Iterator</code>，不过可以通过<code>iter()</code>函数获得一个<code>Iterator</code>对象。</p>
<p>Python的<code>for</code>循环本质上就是通过不断调用<code>next()</code>函数实现的，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for x in [1, 2, 3, 4, 5]:</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure>
<p>实际上完全等价于：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 首先获得Iterator对象:</span><br><span class="line">it = iter([1, 2, 3, 4, 5])</span><br><span class="line"># 循环:</span><br><span class="line">while True:</span><br><span class="line">    try:</span><br><span class="line">        # 获得下一个值:</span><br><span class="line">        x = next(it)</span><br><span class="line">    except StopIteration:</span><br><span class="line">        # 遇到StopIteration就退出循环</span><br><span class="line">        break</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>python面向对象编程</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<p>python 面向对象</p>
<span id="more"></span>
<p>[TOC]</p>
<p>类(Class):** 用来描述具有相同的属性和方法的对象的集合。它定义了该集合中每个对象所共有的属性和方法。对象是类的实例。</p>
<h1 id="类的封装"><a href="#类的封装" class="headerlink" title="类的封装"></a>类的封装</h1><h2 id="装饰器（Decorators）"><a href="#装饰器（Decorators）" class="headerlink" title="装饰器（Decorators）"></a>装饰器（Decorators）</h2><p>python中一切皆对象，函数也可以当做对象</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hi</span>(<span class="params">name</span>):</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;hi ,&quot;</span>,name)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 我们甚至可以将一个函数赋值给一个变量，比如</span></span><br><span class="line">greet = hi</span><br><span class="line"><span class="comment"># 我们这里没有在使用小括号，因为我们并不是在调用hi函数</span></span><br><span class="line"><span class="comment"># 而是在将它放在greet变量里头。我们尝试运行下这个</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>函数中可以定义函数，即函数可以嵌套</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greet</span>(<span class="params">name</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sayhi</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;hi, &quot;</span>,name)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sayhello</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;hello, &quot;</span>,name)</span><br><span class="line">  sayhi()</span><br><span class="line">  sayhello()</span><br><span class="line">greet(<span class="string">&#x27;tiana&#x27;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>函数可以返回函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greet</span>(<span class="params">name</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sayhi</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;hi, &quot;</span>,name)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sayhello</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;hello, &quot;</span>,name)</span><br><span class="line">  <span class="keyword">return</span> sayhi,sayhello</span><br><span class="line">  sayhello()</span><br><span class="line">a,b = greet(<span class="string">&#x27;tiana&#x27;</span>)</span><br><span class="line">a()</span><br><span class="line">b()</span><br></pre></td></tr></table></figure>
<ul>
<li>函数作为参数传到另一个函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hi</span>(<span class="params">name</span>):</span></span><br><span class="line">  <span class="keyword">return</span> <span class="string">&quot;hi,&quot;</span> + name</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dosthwithfunc</span>(<span class="params">func</span>):</span></span><br><span class="line">  <span class="built_in">print</span>(func(<span class="string">&#x27;tina&#x27;</span>))</span><br><span class="line">  </span><br><span class="line">dosthwithfunc(hi)</span><br></pre></td></tr></table></figure>
<ul>
<li>自定义第一个装饰器</li>
</ul>
<blockquote>
<p><strong>注意：**</strong>@wraps**接受一个函数来进行装饰，并加入了复制函数名称、注释文档、参数列表等等的功能。这可以让我们在装饰器里面访问在装饰之前的函数的属性。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义装饰函数。装饰函数是一个以函数为参数，返回函数的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">a_new_decorator</span>(<span class="params">func</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span>(<span class="params">name</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;do sth before func&quot;</span>)</span><br><span class="line">    func(name)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;do sth after func&quot;</span>)</span><br><span class="line">  <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">a_new_decorator2</span>(<span class="params">a_func</span>):</span></span><br><span class="line"><span class="meta">    @wraps(<span class="params">a_func</span>) </span><span class="comment">#加了这个装饰器可以使得这个定义的装饰函数返回的函数的名字是a_func而不是warpTheFunction</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapTheFunction</span>():</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;I am doing some boring work before executing a_func()&quot;</span>)</span><br><span class="line">        a_func()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;I am doing some boring work after executing a_func()&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> wrapTheFunction</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hi</span>(<span class="params">name</span>):</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;hi, &quot;</span>+name)</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 第一种装饰法</span></span><br><span class="line"><span class="meta">@a_new_decorator  </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hi2</span>(<span class="params">name</span>):</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;hi, &quot;</span>+name)</span><br><span class="line">hi2(<span class="string">&quot;Tiana&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种装饰法</span></span><br><span class="line">new_hi = a_new_decorator(hi)</span><br><span class="line">new_hi(<span class="string">&quot;Tiana&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#do sth before func</span></span><br><span class="line"><span class="comment">#hi, Tiana</span></span><br><span class="line"><span class="comment">#do sth after func</span></span><br></pre></td></tr></table></figure>
<ul>
<li>在函数中创建装饰器</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logit</span>(<span class="params">logfile=<span class="string">&#x27;out.log&#x27;</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">logging_decorator</span>(<span class="params">func</span>):</span></span><br><span class="line"><span class="meta">        @wraps(<span class="params">func</span>)</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">wrapped_function</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line">            log_string = func.__name__ + <span class="string">&quot; was called&quot;</span></span><br><span class="line">            <span class="built_in">print</span>(log_string)</span><br><span class="line">            <span class="comment"># 打开logfile，并写入内容</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(logfile, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> opened_file:</span><br><span class="line">                <span class="comment"># 现在将日志打到指定的logfile</span></span><br><span class="line">                opened_file.write(log_string + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span> func(*args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> wrapped_function</span><br><span class="line">    <span class="keyword">return</span> logging_decorator</span><br><span class="line"> </span><br><span class="line"><span class="meta">@logit()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myfunc1</span>():</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"> </span><br><span class="line">myfunc1()</span><br><span class="line"><span class="comment"># Output: myfunc1 was called</span></span><br><span class="line"><span class="comment"># 现在一个叫做 out.log 的文件出现了，里面的内容就是上面的字符串</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">@logit(<span class="params">logfile=<span class="string">&#x27;func2.log&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myfunc2</span>():</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"> </span><br><span class="line">myfunc2()</span><br><span class="line"><span class="comment"># Output: myfunc2 was called</span></span><br><span class="line"><span class="comment"># 现在一个叫做 func2.log 的文件出现了，里面的内容就是上面的字符串</span></span><br></pre></td></tr></table></figure>
<h3 id="抽象方法"><a href="#抽象方法" class="headerlink" title="抽象方法"></a>抽象方法</h3><h2 id="call"><a href="#call" class="headerlink" title="__call__"></a>__call__</h2><h1 id="自定义类的引用"><a href="#自定义类的引用" class="headerlink" title="自定义类的引用"></a>自定义类的引用</h1><p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B/python面向对象编程.assets/image-20200710093905513.png" alt="image-20200710093905513"></p>
<ul>
<li><strong>init</strong>.py 可以是空文件，指明models是一个package，models下面的子文件或文件夹可通过 import bao’ming</li>
</ul>
<h1 id="面向对象技术简介"><a href="#面向对象技术简介" class="headerlink" title="面向对象技术简介"></a>面向对象技术简介</h1><ul>
<li><strong>类(Class):</strong> 用来描述具有相同的属性和方法的对象的集合。它定义了该集合中每个对象所共有的属性和方法。对象是类的实例。</li>
<li><strong>类变量：</strong>类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。</li>
<li><strong>数据成员：</strong>类变量或者实例变量, 用于处理类及其实例对象的相关的数据。</li>
<li><strong>方法重写：</strong>如果从父类继承的方法不能满足子类的需求，可以对其进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。</li>
<li><strong>局部变量：</strong>定义在方法中的变量，只作用于当前实例的类。</li>
<li><strong>实例变量：</strong>在类的声明中，属性是用变量来表示的。这种变量就称为实例变量，是在类声明的内部但是在类的其他成员方法之外声明的。</li>
<li><strong>继承：</strong>即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟”是一个（is-a）”关系（例图，Dog是一个Animal）。</li>
<li><strong>实例化：</strong>创建一个类的实例，类的具体对象。</li>
<li><strong>方法：</strong>类中定义的函数。</li>
<li><strong>对象：</strong>通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。</li>
</ul>
<hr>
<h1 id="创建类"><a href="#创建类" class="headerlink" title="创建类"></a>创建类</h1><p>使用 class 语句来创建一个新类，class 之后为类的名称并以冒号结尾:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class ClassName:</span><br><span class="line">   &#x27;类的帮助信息&#x27;   #类文档字符串</span><br><span class="line">   class_suite  #类体</span><br></pre></td></tr></table></figure>
<p>类的帮助信息可以通过ClassName.<strong>doc</strong>查看。</p>
<p>class_suite 由类成员，方法，数据属性组成。</p>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>以下是一个简单的 Python 类的例子:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span>:</span></span><br><span class="line">   <span class="string">&#x27;所有员工的基类&#x27;</span></span><br><span class="line">   empCount = <span class="number">0</span></span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, salary</span>):</span></span><br><span class="line">      self.name = name</span><br><span class="line">      self.salary = salary</span><br><span class="line">      Employee.empCount += <span class="number">1</span></span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayCount</span>(<span class="params">self</span>):</span></span><br><span class="line">     <span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayEmployee</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;Name : &quot;</span>, self.name,  <span class="string">&quot;, Salary: &quot;</span>, self.salary</span><br></pre></td></tr></table></figure>
<ul>
<li>empCount 变量是一个类变量，它的值将在这个类的所有实例之间共享。你可以在内部类或外部类使用 Employee.empCount 访问。</li>
<li>第一种方法<strong>init</strong>()方法是一种特殊的方法，被称为类的构造函数或初始化方法，当创建了这个类的实例时就会调用该方法</li>
<li>self 代表类的实例，self 在定义类的方法时是必须有的，虽然在调用时不必传入相应的参数。</li>
</ul>
<h3 id="self代表类的实例，而非类"><a href="#self代表类的实例，而非类" class="headerlink" title="self代表类的实例，而非类"></a>self代表类的实例，而非类</h3><p>类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的<strong>第一个参数名称</strong>, 按照惯例它的名称是 self。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">prt</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(self)</span><br><span class="line">        <span class="built_in">print</span>(self.__class__)</span><br><span class="line"> </span><br><span class="line">t = Test()</span><br><span class="line">t.prt()</span><br></pre></td></tr></table></figure>
<p>以上实例执行结果为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;__main__.Test instance at <span class="number">0x10d066878</span>&gt;</span><br><span class="line">__main__.Test</span><br></pre></td></tr></table></figure>
<p>从执行结果可以很明显的看出，self 代表的是类的实例，代表当前对象的地址，而 <strong>self.<strong>class</strong></strong> 则指向类。</p>
<p>self 不是 python 关键字，我们把他换成 runoob 也是可以正常执行的:</p>
<hr>
<h1 id="创建实例对象"><a href="#创建实例对象" class="headerlink" title="创建实例对象"></a>创建实例对象</h1><p>实例化类其他编程语言中一般用关键字 new，但是在 Python 中并没有这个关键字，类的实例化类似函数调用方式。</p>
<p>以下使用类的名称 Employee 来实例化，并通过 <strong>init</strong> 方法接收参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;创建 Employee 类的第一个对象&quot;</span></span><br><span class="line">emp1 = Employee(<span class="string">&quot;Zara&quot;</span>, <span class="number">2000</span>)</span><br><span class="line"><span class="string">&quot;创建 Employee 类的第二个对象&quot;</span></span><br><span class="line">emp2 = Employee(<span class="string">&quot;Manni&quot;</span>, <span class="number">5000</span>)</span><br></pre></td></tr></table></figure>
<h1 id="访问属性"><a href="#访问属性" class="headerlink" title="访问属性"></a>访问属性</h1><p>您可以使用点号 <strong>.</strong> 来访问对象的属性。使用如下类的名称访问类变量:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">emp1.displayEmployee()</span><br><span class="line">emp2.displayEmployee()</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount</span><br></pre></td></tr></table></figure>
<h2 id="实例属性-amp-类属性"><a href="#实例属性-amp-类属性" class="headerlink" title="实例属性 &amp; 类属性"></a>实例属性 &amp; 类属性</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">		country=<span class="string">&#x27;CHINA&#x27;</span> <span class="comment">#类变量，作用域是类</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name</span>):</span></span><br><span class="line">        self.name = name <span class="comment">#实例属性，在创建类时指定，作用域是实例</span></span><br><span class="line"></span><br><span class="line">s = Student(<span class="string">&#x27;Bob&#x27;</span>) <span class="comment">#创建实例s的实例属性name</span></span><br><span class="line">s.score = <span class="number">90</span></span><br></pre></td></tr></table></figure>
<h3 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span>:</span></span><br><span class="line">   <span class="string">&#x27;所有员工的基类&#x27;</span></span><br><span class="line">   empCount = <span class="number">0</span></span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, salary</span>):</span></span><br><span class="line">      self.name = name</span><br><span class="line">      self.salary = salary</span><br><span class="line">      Employee.empCount += <span class="number">1</span></span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayCount</span>(<span class="params">self</span>):</span></span><br><span class="line">     <span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayEmployee</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;Name : &quot;</span>, self.name,  <span class="string">&quot;, Salary: &quot;</span>, self.salary</span><br><span class="line"> </span><br><span class="line"><span class="string">&quot;创建 Employee 类的第一个对象&quot;</span></span><br><span class="line">emp1 = Employee(<span class="string">&quot;Zara&quot;</span>, <span class="number">2000</span>)</span><br><span class="line"><span class="string">&quot;创建 Employee 类的第二个对象&quot;</span></span><br><span class="line">emp2 = Employee(<span class="string">&quot;Manni&quot;</span>, <span class="number">5000</span>)</span><br><span class="line">emp1.displayEmployee()</span><br><span class="line">emp2.displayEmployee()</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount</span><br></pre></td></tr></table></figure>
<p>执行以上代码输出结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Name :  Zara ,Salary:  <span class="number">2000</span></span><br><span class="line">Name :  Manni ,Salary:  <span class="number">5000</span></span><br><span class="line">Total Employee <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>你可以添加，删除，修改类的属性，如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">emp1.age = <span class="number">7</span>  <span class="comment"># 添加一个 &#x27;age&#x27; 属性</span></span><br><span class="line">emp1.age = <span class="number">8</span>  <span class="comment"># 修改 &#x27;age&#x27; 属性</span></span><br><span class="line"><span class="keyword">del</span> emp1.age  <span class="comment"># 删除 &#x27;age&#x27; 属性</span></span><br></pre></td></tr></table></figure>
<p>你也可以使用以下函数的方式来访问属性：</p>
<ul>
<li>getattr(obj, name[, default]) : 访问对象的属性。</li>
<li>hasattr(obj,name) : 检查是否存在一个属性。</li>
<li>setattr(obj,name,value) : 设置一个属性。如果属性不存在，会创建一个新属性。</li>
<li>delattr(obj, name) : 删除属性。</li>
</ul>
<p>hasattr(emp1, ‘age’)    # 如果存在 ‘age’ 属性返回 True。 getattr(emp1, ‘age’)    # 返回 ‘age’ 属性的值 setattr(emp1, ‘age’, 8) # 添加属性 ‘age’ 值为 8 delattr(emp1, ‘age’)    # 删除属性 ‘age’</p>
<hr>
<h3 id="Python内置类属性实例"><a href="#Python内置类属性实例" class="headerlink" title="Python内置类属性实例"></a><strong>Python内置类属性实例</strong></h3><ul>
<li><strong>dict</strong> : 类的属性（包含一个字典，由类的数据属性组成）</li>
<li><strong>doc</strong> :类的文档字符串</li>
<li><strong>name</strong>: 类名</li>
<li><strong>module</strong>: 类定义所在的模块（类的全名是’<strong>main</strong>.className’，如果类位于一个导入模块mymod中，那么className.<strong>module</strong> 等于 mymod）</li>
<li><strong>bases</strong> : 类的所有父类构成元素（包含了一个由所有父类组成的元组）</li>
</ul>
<p>Python内置类属性调用实例如下：</p>
<blockquote>
<p>双下划线开始的方法叫做<strong>魔法方法</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Employee</span>:</span></span><br><span class="line">   <span class="string">&#x27;所有员工的基类&#x27;</span></span><br><span class="line">   empCount = <span class="number">0</span></span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, salary</span>):</span></span><br><span class="line">      self.name = name</span><br><span class="line">      self.salary = salary</span><br><span class="line">      Employee.empCount += <span class="number">1</span></span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayCount</span>(<span class="params">self</span>):</span></span><br><span class="line">     <span class="built_in">print</span> <span class="string">&quot;Total Employee %d&quot;</span> % Employee.empCount</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">displayEmployee</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;Name : &quot;</span>, self.name,  <span class="string">&quot;, Salary: &quot;</span>, self.salary</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Employee.__doc__:&quot;</span>, Employee.__doc__</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Employee.__name__:&quot;</span>, Employee.__name__</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Employee.__module__:&quot;</span>, Employee.__module__</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Employee.__bases__:&quot;</span>, Employee.__bases__</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Employee.__dict__:&quot;</span>, Employee.__dict__</span><br></pre></td></tr></table></figure>
<p>执行以上代码输出结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Employee.__doc__: 所有员工的基类</span><br><span class="line">Employee.__name__: Employee</span><br><span class="line">Employee.__module__: __main__</span><br><span class="line">Employee.__bases__: ()</span><br><span class="line">Employee.__dict__: &#123;<span class="string">&#x27;__module__&#x27;</span>: <span class="string">&#x27;__main__&#x27;</span>, <span class="string">&#x27;displayCount&#x27;</span>: &lt;function displayCount at <span class="number">0x10a939c80</span>&gt;, <span class="string">&#x27;empCount&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;displayEmployee&#x27;</span>: &lt;function displayEmployee at <span class="number">0x10a93caa0</span>&gt;, <span class="string">&#x27;__doc__&#x27;</span>: <span class="string">&#x27;\xe6\x89\x80\xe6\x9c\x89\xe5\x91\x98\xe5\xb7\xa5\xe7\x9a\x84\xe5\x9f\xba\xe7\xb1\xbb&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>: &lt;function __init__ at <span class="number">0x10a939578</span>&gt;&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="python对象销毁-垃圾回收"><a href="#python对象销毁-垃圾回收" class="headerlink" title="python对象销毁(垃圾回收)"></a>python对象销毁(垃圾回收)</h1><p>Python 使用了引用计数这一简单技术来跟踪和回收垃圾。</p>
<p>在 Python 内部记录着所有使用中的对象各有多少引用。</p>
<p>一个内部跟踪变量，称为一个引用计数器。</p>
<p>当对象被创建时， 就创建了一个引用计数， 当这个对象不再需要时， 也就是说， 这个对象的引用计数变为0 时， 它被垃圾回收。但是回收不是”立即”的， 由解释器在适当的时机，将垃圾对象占用的内存空间回收。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="number">40</span>      <span class="comment"># 创建对象  &lt;40&gt;</span></span><br><span class="line">b = a       <span class="comment"># 增加引用， &lt;40&gt; 的计数</span></span><br><span class="line">c = [b]     <span class="comment"># 增加引用.  &lt;40&gt; 的计数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> a       <span class="comment"># 减少引用 &lt;40&gt; 的计数</span></span><br><span class="line">b = <span class="number">100</span>     <span class="comment"># 减少引用 &lt;40&gt; 的计数</span></span><br><span class="line">c[<span class="number">0</span>] = -<span class="number">1</span>   <span class="comment"># 减少引用 &lt;40&gt; 的计数</span></span><br></pre></td></tr></table></figure>
<p>垃圾回收机制不仅针对引用计数为0的对象，同样也可以处理循环引用的情况。循环引用指的是，两个对象相互引用，但是没有其他变量引用他们。这种情况下，仅使用引用计数是不够的。Python 的垃圾收集器实际上是一个引用计数器和一个循环垃圾收集器。作为引用计数的补充， 垃圾收集器也会留心被分配的总量很大（及未通过引用计数销毁的那些）的对象。 在这种情况下， 解释器会暂停下来， 试图清理所有未引用的循环。</p>
<h3 id="实例-2"><a href="#实例-2" class="headerlink" title="实例"></a>实例</h3><p>析构函数 <strong>del</strong> ，<strong>del</strong>在对象销毁的时候被调用，当对象不再被使用时，<strong>del</strong>方法运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!/usr/<span class="built_in">bin</span>/python</span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Point</span>:</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"> self, x=<span class="number">0</span>, y=<span class="number">0</span></span>):</span></span><br><span class="line">      self.x = x</span><br><span class="line">      self.y = y</span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__del__</span>(<span class="params">self</span>):</span></span><br><span class="line">      class_name = self.__class__.__name__</span><br><span class="line">      <span class="built_in">print</span> class_name, <span class="string">&quot;销毁&quot;</span></span><br><span class="line"> </span><br><span class="line">pt1 = Point()</span><br><span class="line">pt2 = pt1</span><br><span class="line">pt3 = pt1</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">id</span>(pt1), <span class="built_in">id</span>(pt2), <span class="built_in">id</span>(pt3) <span class="comment"># 打印对象的id</span></span><br><span class="line"><span class="keyword">del</span> pt1</span><br><span class="line"><span class="keyword">del</span> pt2</span><br><span class="line"><span class="keyword">del</span> pt3</span><br></pre></td></tr></table></figure>
<p>以上实例运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">3083401324 3083401324 3083401324</span><br><span class="line">Point 销毁</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong>通常你需要在单独的文件中定义一个类，</p>
<h1 id="类的继承"><a href="#类的继承" class="headerlink" title="类的继承"></a>类的继承</h1><p>面向对象的编程带来的主要好处之一是代码的重用，实现这种重用的方法之一是通过继承机制。</p>
<p>通过继承创建的新类称为<strong>子类</strong>或<strong>派生类</strong>，被继承的类称为<strong>基类</strong>、<strong>父类</strong>或<strong>超类</strong>。</p>
<p><strong>继承语法</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class 派生类名(基类名)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>在python中继承中的一些特点：</p>
<ul>
<li><p>1、如果在子类中需要父类的构造方法就需要显示的调用父类的构造方法，或者不重写父类的构造方法。详细说明可查看：<a href="https://www.runoob.com/w3cnote/python-extends-init.html">python 子类继承父类构造函数说明</a>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Father</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,name</span>):</span></span><br><span class="line">    self.name = name</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getName</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;name:&quot;</span>,self.name)</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Son</span>(<span class="params">Father</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,name</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(Son,self).__init__(name)</span><br><span class="line">    <span class="comment"># or</span></span><br><span class="line">    <span class="comment"># Father.__init__(name)</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>2、在调用基类的方法时，需要加上基类的类名前缀，且需要带上 self 参数变量。区别在于类中调用普通函数时并不需要带上 self 参数</p>
</li>
<li><p>3、Python 总是首先查找对应类型的方法，如果它不能在派生类中找到对应的方法，它才开始到基类中逐个查找。（先在本类中查找调用的方法，找不到才去基类中找）。</p>
</li>
</ul>
<p>如果在继承元组中列了一个以上的类，那么它就被称作”多重继承” 。</p>
<p><strong>语法：</strong></p>
<p>派生类的声明，与他们的父类类似，继承的基类列表跟在类名之后，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class SubClassName (ParentClass1[, ParentClass2, ...]):</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<h3 id="实例-3"><a href="#实例-3" class="headerlink" title="实例"></a>实例</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parent</span>:</span>        <span class="comment"># 定义父类</span></span><br><span class="line">   parentAttr = <span class="number">100</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;调用父类构造函数&quot;</span></span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">parentMethod</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&#x27;调用父类方法&#x27;</span></span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">setAttr</span>(<span class="params">self, attr</span>):</span></span><br><span class="line">      Parent.parentAttr = attr</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">getAttr</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;父类属性 :&quot;</span>, Parent.parentAttr</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child</span>(<span class="params">Parent</span>):</span> <span class="comment"># 定义子类</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&quot;调用子类构造方法&quot;</span></span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">childMethod</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&#x27;调用子类方法&#x27;</span></span><br><span class="line"> </span><br><span class="line">c = Child()          <span class="comment"># 实例化子类</span></span><br><span class="line">c.childMethod()      <span class="comment"># 调用子类的方法</span></span><br><span class="line">c.parentMethod()     <span class="comment"># 调用父类方法</span></span><br><span class="line">c.setAttr(<span class="number">200</span>)       <span class="comment"># 再次调用父类的方法 - 设置属性值</span></span><br><span class="line">c.getAttr()          <span class="comment"># 再次调用父类的方法 - 获取属性值</span></span><br></pre></td></tr></table></figure>
<p>以上代码执行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">调用子类构造方法</span><br><span class="line">调用子类方法</span><br><span class="line">调用父类方法</span><br><span class="line">父类属性 : 200</span><br></pre></td></tr></table></figure>
<p>你可以继承多个类</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class A:        # 定义类 A</span><br><span class="line">.....</span><br><span class="line"></span><br><span class="line">class B:         # 定义类 B</span><br><span class="line">.....</span><br><span class="line"></span><br><span class="line">class C(A, B):   # 继承类 A 和 B</span><br><span class="line">.....</span><br></pre></td></tr></table></figure>
<p>你可以使用issubclass()或者isinstance()方法来检测。</p>
<ul>
<li>issubclass() - 布尔函数判断一个类是另一个类的子类或者子孙类，语法：issubclass(sub,sup)</li>
<li>isinstance(obj, Class) 布尔函数如果obj是Class类的实例对象或者是一个Class子类的实例对象则返回true。</li>
</ul>
<hr>
<h1 id="方法重写"><a href="#方法重写" class="headerlink" title="方法重写"></a>方法重写</h1><p>如果你的父类方法的功能不能满足你的需求，你可以在子类重写你父类的方法：</p>
<p>实例：</p>
<h3 id="实例-4"><a href="#实例-4" class="headerlink" title="实例"></a>实例</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parent</span>:</span>        <span class="comment"># 定义父类</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">myMethod</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&#x27;调用父类方法&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child</span>(<span class="params">Parent</span>):</span> <span class="comment"># 定义子类</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">myMethod</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="built_in">print</span> <span class="string">&#x27;调用子类方法&#x27;</span></span><br><span class="line"> </span><br><span class="line">c = Child()          <span class="comment"># 子类实例</span></span><br><span class="line">c.myMethod()         <span class="comment"># 子类调用重写方法</span></span><br></pre></td></tr></table></figure>
<p>执行以上代码输出结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">调用子类方法</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="基础重载方法"><a href="#基础重载方法" class="headerlink" title="基础重载方法"></a>基础重载方法</h2><p>下表列出了一些通用的功能，你可以在自己的类重写：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">序号</th>
<th style="text-align:left">方法, 描述 &amp; 简单的调用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left"><strong><strong>init</strong> ( self [,args…] )</strong> 构造函数 简单的调用方法: <em>obj = className(args)</em></td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left"><strong><strong>del</strong>( self )</strong> 析构方法, 删除一个对象 简单的调用方法 : <em>del obj</em></td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:left"><strong><strong>repr</strong>( self )</strong> 转化为供解释器读取的形式 简单的调用方法 : <em>repr(obj)</em></td>
</tr>
<tr>
<td style="text-align:left">4</td>
<td style="text-align:left"><strong><strong>str</strong>( self )</strong> 用于将值转化为适于人阅读的形式 简单的调用方法 : <em>str(obj)</em></td>
</tr>
<tr>
<td style="text-align:left">5</td>
<td style="text-align:left"><strong><strong>cmp</strong> ( self, x )</strong> 对象比较 简单的调用方法 : <em>cmp(obj, x)</em></td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="运算符重载"><a href="#运算符重载" class="headerlink" title="运算符重载"></a>运算符重载</h3><p>Python同样支持运算符重载，实例如下：</p>
<h3 id="实例-5"><a href="#实例-5" class="headerlink" title="实例"></a>实例</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Vector</span>:</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, a, b</span>):</span></span><br><span class="line">      self.a = a</span><br><span class="line">      self.b = b</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="keyword">return</span> <span class="string">&#x27;Vector (%d, %d)&#x27;</span> % (self.a, self.b)</span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__add__</span>(<span class="params">self,other</span>):</span></span><br><span class="line">      <span class="keyword">return</span> Vector(self.a + other.a, self.b + other.b)</span><br><span class="line"> </span><br><span class="line">v1 = Vector(<span class="number">2</span>,<span class="number">10</span>)</span><br><span class="line">v2 = Vector(<span class="number">5</span>,-<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span> v1 + v2</span><br></pre></td></tr></table></figure>
<p>以上代码执行结果如下所示:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Vector(7,8)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="类属性与方法"><a href="#类属性与方法" class="headerlink" title="类属性与方法"></a>类属性与方法</h2><h3 id="类的私有属性"><a href="#类的私有属性" class="headerlink" title="类的私有属性"></a>类的私有属性</h3><p><strong>__private_attrs</strong>：两个下划线开头，声明该属性为私有，不能在类的外部被使用或直接访问。在类内部的方法中使用时 <strong>self.__private_attrs</strong>。</p>
<h3 id="类的方法"><a href="#类的方法" class="headerlink" title="类的方法"></a>类的方法</h3><p>在类的内部，使用 <strong>def</strong> 关键字可以为类定义一个方法，与一般函数定义不同，类方法必须包含参数 self,且为第一个参数</p>
<h3 id="类的私有方法"><a href="#类的私有方法" class="headerlink" title="类的私有方法"></a>类的私有方法</h3><p><strong>__private_method</strong>：两个下划线开头，声明该方法为私有方法，不能在类的外部调用。在类的内部调用 <strong>self.__private_methods</strong></p>
<h3 id="实例-6"><a href="#实例-6" class="headerlink" title="实例"></a>实例</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JustCounter</span>:</span></span><br><span class="line">    __secretCount = <span class="number">0</span>  <span class="comment"># 私有变量</span></span><br><span class="line">    publicCount = <span class="number">0</span>    <span class="comment"># 公开变量</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">count</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.__secretCount += <span class="number">1</span></span><br><span class="line">        self.publicCount += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span> self.__secretCount</span><br><span class="line"> </span><br><span class="line">counter = JustCounter()</span><br><span class="line">counter.count()</span><br><span class="line">counter.count()</span><br><span class="line"><span class="built_in">print</span> counter.publicCount</span><br><span class="line"><span class="built_in">print</span> counter.__secretCount  <span class="comment"># 报错，实例不能访问私有变量</span></span><br></pre></td></tr></table></figure>
<p>Python 通过改变名称来包含类名:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">2</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;test.py&quot;, line 17, in &lt;module&gt;</span><br><span class="line">    print counter.__secretCount  # 报错，实例不能访问私有变量</span><br><span class="line">AttributeError: JustCounter instance has no attribute &#x27;__secretCount&#x27;</span><br></pre></td></tr></table></figure>
<p>Python不允许实例化的类访问私有数据，但你可以使用 <strong>object._className__attrName</strong>（ <strong>对象名._类名__私有属性名</strong> ）访问属性，参考以下实例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/usr/bin/python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"></span><br><span class="line">class Runoob:</span><br><span class="line">    __site = &quot;www.runoob.com&quot;</span><br><span class="line"></span><br><span class="line">runoob = Runoob()</span><br><span class="line">print runoob._Runoob__site</span><br></pre></td></tr></table></figure>
<p>执行以上代码，执行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">www.runoob.com</span><br></pre></td></tr></table></figure>
<h3 id="单下划线、双下划线、头尾双下划线说明："><a href="#单下划线、双下划线、头尾双下划线说明：" class="headerlink" title="单下划线、双下划线、头尾双下划线说明："></a>单下划线、双下划线、头尾双下划线说明：</h3><ul>
<li><strong><strong>foo</strong></strong>: 定义的是特殊方法，一般是系统定义名字 ，类似 <strong><strong>init</strong>()</strong> 之类的。</li>
<li><strong>_foo</strong>: 以单下划线开头的表示的是 protected 类型的变量，即保护类型只能允许其本身与子类进行访问，不能用于 <strong>from module import *</strong></li>
<li><strong>__foo</strong>: 双下划线的表示的是私有类型(private)的变量, 只能是允许这个类本身进行访问了。</li>
</ul>
<h1 id="创建对象"><a href="#创建对象" class="headerlink" title="创建对象"></a>创建对象</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SuperParams</span>:</span></span><br><span class="line">    batch_num=<span class="number">50</span></span><br><span class="line">    <span class="built_in">iter</span>=<span class="number">100</span></span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> SuperParams</span><br><span class="line">batch_num=SuperParams.batch_num</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Args</span>(<span class="params">SuperParams</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,is_training=<span class="literal">True</span></span>):</span></span><br><span class="line">        self.dnn_depth=<span class="number">3</span></span><br><span class="line"><span class="comment"># 调用</span></span><br><span class="line"><span class="built_in">print</span>(Args().dnn_depth)</span><br><span class="line"><span class="built_in">print</span>(Args().batch_num)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>__init__ 函数中的变量是</p>
<h1 id="对象调用"><a href="#对象调用" class="headerlink" title="对象调用"></a>对象调用</h1>]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>scala</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/scala/</url>
    <content><![CDATA[<p>5 minutes to scala</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="变量声明"><a href="#变量声明" class="headerlink" title="变量声明"></a>变量声明</h1><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> a=<span class="symbol">&#x27;hell</span>o&#x27; <span class="comment">//不能通过a=&#x27;hello2&#x27;赋值</span></span><br><span class="line"><span class="keyword">var</span> a=<span class="symbol">&#x27;hell</span>o&#x27; <span class="comment">//可以通过a=&#x27;hello2&#x27;赋值</span></span><br></pre></td></tr></table></figure>
<h1 id="基础数据类型"><a href="#基础数据类型" class="headerlink" title="基础数据类型"></a>基础数据类型</h1><h2 id="unit，int，string"><a href="#unit，int，string" class="headerlink" title="unit，int，string"></a>unit，int，string</h2><p>unit: 不返回任何有实际意义的结果</p>
<h2 id="array"><a href="#array" class="headerlink" title="array"></a>array</h2><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//申明</span></span><br><span class="line"><span class="keyword">var</span> z = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">String</span>](<span class="number">3</span>) <span class="comment">//长度为3</span></span><br><span class="line"><span class="keyword">val</span> age=<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> name=<span class="type">Array</span>(&#x27;a&#x27;,&#x27;b&#x27;)</span><br><span class="line">name zip age <span class="comment">//res0: Array[(Char, Int)] = Array((a,1), (b,2))</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="tuple"><a href="#tuple" class="headerlink" title="tuple"></a>tuple</h2><h2 id="list"><a href="#list" class="headerlink" title="list"></a>list</h2><h2 id="map"><a href="#map" class="headerlink" title="map"></a>map</h2><h1 id="定义函数"><a href="#定义函数" class="headerlink" title="定义函数"></a>定义函数</h1><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max</span></span>(x:int,y:int):int=&#123;</span><br><span class="line">    <span class="keyword">if</span> (x&gt;y) x <span class="keyword">else</span> y</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max</span></span>(x:int,y:int)=<span class="keyword">if</span> (x&gt;y) x <span class="keyword">else</span> y </span><br></pre></td></tr></table></figure>
<h1 id="for"><a href="#for" class="headerlink" title="for"></a>for</h1><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> args=</span><br></pre></td></tr></table></figure>
<h1 id="if"><a href="#if" class="headerlink" title="if"></a>if</h1>]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>shell</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/shell/</url>
    <content><![CDATA[<p>常用shell命令</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="etc-profile、-etc-bashrc、-bash-profile、-bashrc"><a href="#etc-profile、-etc-bashrc、-bash-profile、-bashrc" class="headerlink" title="/etc/profile、/etc/bashrc、~/.bash_profile、~/.bashrc"></a>/etc/profile、/etc/bashrc、~/.bash_profile、~/.bashrc</h1><h2 id="etc-profile"><a href="#etc-profile" class="headerlink" title="/etc/profile"></a>/etc/profile</h2><p>此文件为系统的每个用户设置环境信息，当用户第一次登录时，该文件被执行。并从 /etc/profile.d 目录的配置文件中收集 shell 的设置。如果你有对 /etc/profile 有修改的话必须得 source 一下你的修改才会生效，此修改对每个用户都生效。</p>
<h2 id="etc-bashrc（ubuntu为-etc-bash-bashrc）"><a href="#etc-bashrc（ubuntu为-etc-bash-bashrc）" class="headerlink" title="/etc/bashrc（ubuntu为 /etc/bash.bashrc）"></a>/etc/bashrc（ubuntu为 /etc/bash.bashrc）</h2><p>为每一个运行 bash shell 的用户执行此文件。当 bash shell 被打开时，该文件被读取。如果你想对所有的使用 bash 的用户修改某个配置并在以后打开的 bash 都生效的话可以修改这个文件，修改这个文件不用重启，重新打开一个 bash 即可生效。<br>Ubuntu没有此文件，与之对应的是/ect/bash.bashrc。</p>
<h2 id="bash-profile（ubuntu为-profile）"><a href="#bash-profile（ubuntu为-profile）" class="headerlink" title="~/.bash_profile（ubuntu为 ~/.profile）"></a>~/.bash_profile（ubuntu为 ~/.profile）</h2><p>每个用户都可使用该文件输入专用于自己使用的 shell 信息，当用户登录时，该文件仅仅执行一次！默认情况下,它设置一些环境变量，执行用户的~/ .bashrc 文件。 此文件类似于 /etc/profile，也是需要需要 source 才会生效，/etc/profile 对所有用户生效，~/.bash_profile 只对当前用户生效。~/.profile(由Bourne Shell和Korn Shell使用)和.login(由C Shell使用)两个文件是.bash_profile的同义词，目的是为了兼容其它Shell。</p>
<h1 id="Linux的Shell种类"><a href="#Linux的Shell种类" class="headerlink" title="Linux的Shell种类"></a>Linux的Shell种类</h1><p>常见的有：</p>
<ul>
<li><p>Bourne Shell（/usr/bin/sh或/bin/sh）、<br>Bourne Again Shell（/bin/bash）、<br>C Shell（/usr/bin/csh）、<br>K Shell（/usr/bin/ksh）、<br>Shell for Root（/sbin/sh）等等。</p>
</li>
<li><p>不同的Shell语言的语法有所不同，所以不能交换使用。每种Shell都有其特色之处，基本上，掌握其中任何一种 就足够了。在本文中，我们关注的重点是Bash，也就是Bourne Again Shell，由于易用和免费，Bash在日常工作中被广泛使用；同时，Bash也是大多数Linux系统默认的Shell。</p>
</li>
<li>在一般情况下，人们并不区分 Bourne Shell和Bourne Again Shell，所以，在下面的文字中，我们可以看到#!/bin/sh，它同样也可以改为#!/bin/bash。(定义使用哪种sh解释器来解释脚本)</li>
</ul>
<h1 id="如果不存在则创建文件夹"><a href="#如果不存在则创建文件夹" class="headerlink" title="如果不存在则创建文件夹"></a>如果不存在则创建文件夹</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">if [ ! -d &quot;$build_dir&quot; ]; then</span><br><span class="line">        mkdir $build_dir</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<h1 id="df"><a href="#df" class="headerlink" title="df"></a>df</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">df -hl 查看磁盘剩余空间</span><br><span class="line">df -h 查看每个根路径的分区大小</span><br></pre></td></tr></table></figure>
<h1 id="alias-外部传参"><a href="#alias-外部传参" class="headerlink" title="alias 外部传参"></a>alias 外部传参</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">alias</span> <span class="built_in">cd</span>=<span class="string">&#x27;func() &#123; cd $1; ls;&#125;; func&#x27;</span> <span class="comment">#定义一个函数func（）&#123;......&#125;；func; &#123;&#125;中间是要alias的执行的命令，多个命令用；隔开，最后；结尾</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/notebook/download</span><br><span class="line"><span class="built_in">alias</span> dl=<span class="string">&#x27;func() &#123; cp $1 /notebook/download/; &#125;; func&#x27;</span></span><br><span class="line"><span class="built_in">alias</span> push=<span class="string">&#x27;func() &#123; cd /notebook/download/; git add . ; git commit -m &quot;update&quot;; git push origin master; &#125;; func&#x27;</span></span><br></pre></td></tr></table></figure>
<h1 id="du"><a href="#du" class="headerlink" title="du"></a>du</h1><h2 id="查看磁盘大小"><a href="#查看磁盘大小" class="headerlink" title="查看磁盘大小"></a>查看磁盘大小</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> du -s * | sort -nr  #查看大小并按大小排序</span><br><span class="line">du -h ftp #查看指定文件夹下所有文件大小（包括子文件夹）</span><br><span class="line">du -sh [目录名] 返回该目录的大小</span><br><span class="line">du -sm [文件夹] 返回该文件夹总M数</span><br></pre></td></tr></table></figure>
<p>-</p>
<h1 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">grep &#x27;hi&#x27; test.txt #显示包含hi的行</span><br></pre></td></tr></table></figure>
<h1 id="find"><a href="#find" class="headerlink" title="find"></a>find</h1><h2 id="遍历符合条件的文件"><a href="#遍历符合条件的文件" class="headerlink" title="遍历符合条件的文件"></a>遍历符合条件的文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for f in `find . -name &quot;正则匹配&quot; ` #.是路径   双引号和飘号要注意</span><br><span class="line">do</span><br><span class="line">	echo $f</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<h2 id="对于多个文件执行操作"><a href="#对于多个文件执行操作" class="headerlink" title="对于多个文件执行操作"></a>对于多个文件执行操作</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -name &quot;*.sh&quot; | xargs wc -l</span><br></pre></td></tr></table></figure>
<h2 id="删除符合条件的多个文件"><a href="#删除符合条件的多个文件" class="headerlink" title="删除符合条件的多个文件"></a>删除符合条件的多个文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . -type f -name &quot;$&#123;file_name&#125;_*&quot; | xargs rm -f</span><br></pre></td></tr></table></figure>
<h2 id="统计python文件总行数"><a href="#统计python文件总行数" class="headerlink" title="统计python文件总行数"></a>统计python文件总行数</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -name &quot;*.py&quot; | xargs wc -l &gt;&gt; temp.txt</span><br></pre></td></tr></table></figure>
<h1 id="shellcheck检查sh文件"><a href="#shellcheck检查sh文件" class="headerlink" title="shellcheck检查sh文件"></a>shellcheck检查sh文件</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -name &quot;*.sh&quot; | xargs shellcheck &gt;&gt; temp2.txt</span><br><span class="line">grep &#x27;In ./&#x27;</span><br></pre></td></tr></table></figure>
<h1 id="获取当前路径"><a href="#获取当前路径" class="headerlink" title="获取当前路径"></a>获取当前路径</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CUR_DIR=$(<span class="built_in">cd</span> $(dirname <span class="variable">$0</span>); <span class="built_in">pwd</span>) <span class="comment">#但是用source调用脚本时$0的值为&quot;-bash&quot;，词命令无法获取地址</span></span><br><span class="line">CUR_DIR=<span class="string">&quot;<span class="subst">$( cd <span class="string">&quot;<span class="subst">$( dirname <span class="string">&quot;<span class="variable">$&#123;BASH_SOURCE[0]&#125;</span>&quot;</span> )</span>&quot;</span> &amp;&amp; pwd )</span>&quot;</span></span><br></pre></td></tr></table></figure>
<h1 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h1><h2 id="获取hive表最新分区"><a href="#获取hive表最新分区" class="headerlink" title="获取hive表最新分区"></a>获取hive表最新分区</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">newest_dt=$(hive -e <span class="string">&quot;show partitions cf_model.htq_hztz_xdtz_brs_s;&quot;</span>|tail -1)</span><br><span class="line">newest_dt=<span class="variable">$&#123;newest_dt:3&#125;</span></span><br></pre></td></tr></table></figure>
<h1 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h1><h2 id="插入行"><a href="#插入行" class="headerlink" title="插入行"></a>插入行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -i &#x27;1i\要添加的内容&#x27;  yourfile</span><br></pre></td></tr></table></figure>
<h2 id="删除指定行"><a href="#删除指定行" class="headerlink" title="删除指定行"></a>删除指定行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -i ‘1d’ filename</span><br></pre></td></tr></table></figure>
<h2 id="替换指定字符"><a href="#替换指定字符" class="headerlink" title="替换指定字符"></a>替换指定字符</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -i &#x27;s/foo/bar/g&#x27; myfile #-i会修改代码</span><br></pre></td></tr></table></figure>
<h2 id="查看指定行"><a href="#查看指定行" class="headerlink" title="查看指定行"></a>查看指定行</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -n &#x27;5,10p&#x27; filename 这样你就可以只查看文件的第5行到第10行。</span><br></pre></td></tr></table></figure>
<h1 id="split"><a href="#split" class="headerlink" title="split"></a>split</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">split -l 2000 urls.txt -d -a 2 url_</span><br><span class="line">解释一下：</span><br><span class="line">-l：按行分割，上面表示将urls.txt文件按2000行一个文件分割为多个文件</span><br><span class="line">-d：添加数字后缀，比如上图中的00，01，02</span><br><span class="line">-a 2：表示用两位数据来顺序命名</span><br><span class="line">url_：看上图就应该明白了，用来定义分割后的文件名前面的部分。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="conda管理环境"><a href="#conda管理环境" class="headerlink" title="conda管理环境"></a>conda管理环境</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda info -envs #列出所有环境</span><br><span class="line">source activate 环境名</span><br><span class="line">source deactivate #回到默认环境</span><br></pre></td></tr></table></figure>
<p><a href="https://blog.csdn.net/cxk207017/article/details/89598139">https://blog.csdn.net/cxk207017/article/details/89598139</a></p>
<p>conda测试指南<br>在开始这个conda测试之前，你应该已经下载并安装好了Anaconda或者Miniconda<br>注意：在安装之后，你应该关闭并重新打开windows命令行。</p>
<p>一、Conda测试过程：<br>使用conda。首先我们将要确认你已经安装好了conda<br>配置环境。下一步我们将通过创建几个环境来展示conda的环境管理功能。使你更加轻松的了解关于环境的一切。我们将学习如何确认你在哪个环境中，以及如何做复制一个环境作为备份。<br>测试python。然后我们将检查哪一个版本的python可以被安装，以及安装另一个版本的python，还有在两个版本的python之间的切换。<br>检查包。我们将1)罗列出安装在我们电脑上的包，2)浏览可用的包，3)使用conda install命令来来安装以及移除一些包。对于一些不能使用conda安装的包，我们将4)在Anaconda.org网站上搜索。对于那些在其它位置的包，我们将5)使用pip命令来实现安装。我们还会安装一个可以免费试用30天的商业包IOPro<br>移除包、环境以及conda.我们将以学习删除你的包、环境以及conda来结束这次测试。<br>二、完整过程<br>提示：在任何时候你可以通过在命令后边跟上—help来获得该命令的完整文档。例如，你可以通过如下的命令来学习conda的update命令。</p>
<p>conda update —help<br>\1. 管理conda：<br>Conda既是一个包管理器又是一个环境管理器。你肯定知道包管理器，它可以帮你发现和查看包。但是如果当我们想要安装一个包，但是这个包只支持跟我们目前使用的python不同的版本时。你只需要几行命令，就可以搭建起一个可以运行另外python版本的环境。，这就是conda环境管理器的强大功能。<br>提示：无论你使用Linux、OS X或者Windows命令行工具，在你的命令行终端conda指令都是一样的，除非有特别说明。</p>
<p>检查conda已经被安装。<br>为了确保你已经在正确的位置安装好了conda，让我们来检查你是否已经成功安装好了Anaconda。在你的命令行终端窗口，输入如下代码：</p>
<p>conda —version<br>Conda会返回你安装Anaconda软件的版本。<br>提示：如果你看到了错误信息，检查你是否在安装过程中选择了仅为当前用户按安装，并且是否以同样的账户来操作。确保用同样的账户登录安装了之后重新打开命令行终端窗口。</p>
<p>升级当前版本的conda<br>接下来，让我们通过使用如下update命令来升级conda：</p>
<p>conda update conda<br>conda将会比较新旧版本并且告诉你哪一个版本的conda可以被安装。它也会通知你伴随这次升级其它包同时升级的情况。<br>如果新版本的conda可用，它会提示你输入y进行升级.</p>
<p>proceed ([y]/n)? y<br>conda更新到最新版后，我们将进入下一个主题。</p>
<h2 id="管理环境"><a href="#管理环境" class="headerlink" title="管理环境"></a>管理环境</h2><p>现在我们通过创建一些环境来展示conda的环境操作，然后移动它们。</p>
<h3 id="创建并激活一个环境"><a href="#创建并激活一个环境" class="headerlink" title="创建并激活一个环境"></a>创建并激活一个环境</h3><p>使用conda create命令，后边跟上你希望用来称呼它的任何名字：</p>
<blockquote>
<p>conda create —n py3 python=3</p>
<p>这条命令将会给biopython包创建一个新的环境，位置在/envs/snowflakes<br>小技巧：很多跟在—后边常用的命令选项，可以被略写为一个短线加命令首字母。所以—name选项和-n的作用是一样的。通过conda -h或conda –-help来看大量的缩写。</p>
</blockquote>
<h3 id="激活这个新环境"><a href="#激活这个新环境" class="headerlink" title="激活这个新环境"></a>激活这个新环境</h3><p>Linux，OS X: source activate snowflakes<br>Windows：activate snowflake`<br>小技巧：新的开发环境会被默认安装在你conda目录下的envs文件目录下。你可以指定一个其他的路径；去通过conda create -h了解更多信息吧。<br>小技巧：如果我们没有指定安装python的版本，donda会安装我们最初安装conda时所装的那个版本的python。</p>
<p>创建第二个环境<br>这次让我们来创建并命名一个新环境，然后安装另一个版本的python以及两个包 Astroid 和 Babel。</p>
<p>conda create -n bunnies python=3 Astroid Babel<br>这将创建第二个基于python3 ，包含Astroid 和 Babel 包，称为bunnies的新环境，在/envs/bunnies文件夹里。<br>小技巧：在此同时安装你想在这个环境中运行的包，<br>小提示：在你创建环境的同时安装好所有你想要的包，在后来依次安装可能会导致依赖性问题（貌似是，不太懂这个术语怎么翻）。<br>小技巧：你可以在conda create命令后边附加跟多的条件，键入conda create –h 查看更多细节。</p>
<p>列出所有的环境<br>现在让我们来检查一下截至目前你所安装的环境，使用conda environment info 命令来查看它:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda info --envs</span><br></pre></td></tr></table></figure>
<p>你将会看到如下的环境列表：</p>
<p>conda environments:</p>
<p> snowflakes          * /home/username/miniconda/envs/snowflakes</p>
<p> bunnies               /home/username/miniconda/envs/bunnies</p>
<p> root                  /home/username/miniconda<br>确认当前环境<br>你现在处于哪个环境中呢？snowflakes还是bunnies？想要确定它，输入下面的代码：</p>
<p>conda info -envis<br>conda将会显示所有环境的列表，当前环境会显示在一个括号内。</p>
<p>(snowflakes)<br>注意：conda有时也会在目前活动的环境前边加上*号。</p>
<p>切换到另一个环境(activate/deactivate)<br>为了切换到另一个环境，键入下列命令以及所需环境的名字。</p>
<p>Linux，OS X: source activate snowflakes<br>Windows：activate snowflakes<br>如果要从你当前工作环境的路径切换到系统根目录时，键入：</p>
<p>Linux，OS X: source deactivate<br>Windows: deactivate<br>当该环境不再活动时，将不再被提前显示。</p>
<p>复制一个环境<br>通过克隆来复制一个环境。这儿将通过克隆snowfllakes来创建一个称为flowers的副本。</p>
<p>conda create -n flowers —clone snowflakes<br>通过conda info –-envs来检查环境<br>你现在应该可以看到一个环境列表：flowers, bunnies, and snowflakes.</p>
<p>删除一个环境<br>如果你不想要这个名为flowers的环境，就按照如下方法移除该环境：</p>
<p>conda remove -n flowers —all<br>为了确定这个名为flowers的环境已经被移除，输入以下命令：</p>
<p>conda info -e<br>flowers 已经不再在你的环境列表里了，所以我们知道它被删除了。</p>
<p>学习更多关于环境的知识<br>如果你想学习更多关于conda的命令，就在该命令后边跟上 -h</p>
<p>conda remove -h<br>\3. 管理Python<br>conda对Python的管理跟其他包的管理类似，所以可以很轻松地管理和升级多个安装。</p>
<p>检查python版本<br>首先让我们检查那个版本的python可以被安装：</p>
<p>conda search —full —name python<br>你可以使用conda search python来看到所有名字中含有“python”的包或者加上—full —name命令选项来列出完全与“python”匹配的包。</p>
<p>安装一个不同版本的python<br>现在我们假设你需要python3来编译程序，但是你不想覆盖掉你的python2.7来升级，你可以创建并激活一个名为snakes的环境，并通过下面的命令来安装最新版本的python3：</p>
<p>conda create -n snakes python=３<br>·Linux，OS X：source activate snakes<br>·Windows： activate snakes<br>小提示：给环境取一个很形象的名字，例如“Python3”是很明智的，但是并不有趣。</p>
<p>确定环境添加成功<br>为了确保snakes环境已经被安装了，键入如下命令：</p>
<p>conda info -e<br>conda会显示环境列表，当前活动的环境会被括号括起来（snakes）</p>
<p>检查新的环境中的python版本<br>确保snakes环境中运行的是python3：</p>
<p>python —version<br>使用不同版本的python<br>为了使用不同版本的python，你可以切换环境，通过简单的激活它就可以，让我们看看如何返回默认2.7</p>
<p>·Linux，OS X: source activate snowflakes<br>·Windows：activate snowflakes<br>检查python版本：<br>确保snowflakes环境中仍然在运行你安装conda时安装的那个版本的python。</p>
<p>python —version<br>注销该环境<br>当你完成了在snowflakes环境中的工作室，注销掉该环境并转换你的路径到先前的状态：</p>
<p>·Linux，OS X：source deactivate<br>·Windows：deactivate<br>\4. 管理包<br>现在让我们来演示包。我们已经安装了一些包（Astroid，Babel和一些特定版本的python），当我们创建一个新环境时。我们检查我们已经安装了那些包，检查哪些是可用的，寻找特定的包并安装它。接下来我们在Anconda.org仓库中查找并安装一些指定的包，用conda来完成更多pip可以实现的安装，并安装一个商业包。</p>
<p>查看该环境中包和其版本的列表：<br>使用这条命令来查看哪个版本的python或其他程序安装在了该环境中，或者确保某些包已经被安装了或被删除了。在你的终端窗口中输入：</p>
<blockquote>
<p>conda list<br>使用conda命令查看可用包的列表<br>一个可用conda安装的包的列表，按照Python版本分类，可以从这个地址获得：<br><a href="http://docs.continuum.io/anaconda/pkg-docs.html">http://docs.continuum.io/anaconda/pkg-docs.html</a></p>
</blockquote>
<p>查找一个包<br>首先让我们来检查我们需要的这个包是否可以通过conda来安装：</p>
<p>conda search beautifulsoup4<br>它展示了这个包，所以我们知道它是可用的。</p>
<p>安装一个新包<br>我们将在当前环境中安装这个Beautiful Soup包，使用conda命令如下；<br>conda install —name bunnies beautifulsoup4<br>提示：你必须告诉conda你要安装环境的名字（-n bunies）否则它将会被安装到当前环境中。<br>现在激活bunnies环境，并且用conda list来显示哪些程序被安装了。</p>
<p>·Linux，OS X：source activate bunnies<br>·Windows：activate bunnies<br>所有的平台：<br>conda list<br>从Anaconda.org安装一个包<br>如果一个包不能使用conda安装，我们接下来将在Anaconda.org网站查找。Anaconda.org向公开和私有包仓库提供包管理服务。Anaconda.org是一个连续分析产品。<br>提示：你在Anaconda.org下载东西的时候不强制要求注册。<br>为了从Anaconda.org下载到当前的环境中，我们需要通过指定Anaconda.org为一个特定通道，通过输入这个包的完整路径来实现。<br>在浏览器中，去 <a href="http://anaconda.org">http://anaconda.org</a> 网站。我们查找一个叫“bottleneck”的包，所以在左上角的叫“Search Anaconda Cloud”搜索框中输入“bottleneck”并点击search按钮。<br>Anaconda.org上会有超过一打的bottleneck包的版本可用，但是我们想要那个被下载最频繁的版本。所以你可以通过下载量来排序，通过点击Download栏。<br>点击包的名字来选择最常被下载的包。它会链接到Anaconda.org详情页显示下载的具体命令：</p>
<p>conda install —channel https：//conda .anaconda.ort/pandas bottleneck<br>检查被下载的包<br>conda list<br>通过pip命令来安装包<br>对于那些无法通过conda安装或者从Anaconda.org获得的包，我们通常可以用pip（“pip install packages”的简称）来安装包。<br>提示： pip只是一个包管理器，所以它不能为你管理环境。pip甚至不能升级python，因为它不像conda一样把python当做包来处理。但是它可以安装一些conda安装不了的包，和vice versa（此处不会翻译）。pip和conda都集成在Anaconda或miniconda里边。</p>
<p>我们激活我们想放置程序的环境，然后通过pip安装一个叫“See”的程序。</p>
<p>·Linux，OS X： source activate bunnies<br>·Windows：activate bunnies<br>所有平台：<br>pip install see<br>检查pip安装<br>检查See是否被安装：</p>
<p>conda list<br>安装商业包<br>安装商业包与你安装其他的包的过程异常。举个例子，让我们安装并删除一个更新的商业包的免费试用 IOPro，可以加速你的python处理速度：</p>
<p>conda install iopro<br>提示：除了学术使用，该版本在30天后试用期满</p>
<p>你现在可以安装以及检查你想用conda安装的任何包，无论使用conda命令、从Anaconda.org下载或者使用pip安装，无论开源软件还是商业包。</p>
<p>\5. 移除包、环境、或者conda<br>如果你愿意的话。让我们通过移除一个或多个试验包、环境以及conda来结束这次测试指导。</p>
<p>移除包<br>假设你决定不再使用商业包IOPro。你可以在bunnies环境中移除它。</p>
<p>conda remove -n bunnies iopro<br>确认包已经被移除<br>使用conda list命令来确认IOPro已经被移除了</p>
<p>conda list<br>移除环境<br>我们不再需要snakes环境了，所以输入以下命令：<br>conda remove -n snakes —all</p>
<p>确认环境被移除<br>为了确认snakes环境已经被移除了，输入以下命令：</p>
<p> conda info —envis<br>snakes不再显示在环境列表里了，所以我们知道它已经被删除了</p>
<p>删除conda<br>Linux，OS X：<br>移除Anaconda 或 Miniconda 安装文件夹<br>rm -rf ~/miniconda OR  rm -rf ~/anaconda<br>Windows：<br>去控制面板，点击“添加或删除程序”，选择“Python2.7（Anaconda）”或“Python2.7（Miniconda）”并点击删除程序。</p>
<h3 id="5K服务器环境安装实例"><a href="#5K服务器环境安装实例" class="headerlink" title="5K服务器环境安装实例"></a>5K服务器环境安装实例</h3><blockquote>
<p>conda create -n py3 python=3.6   #创建叫做py3的环境，python版本是3.6</p>
<p>conda info -e #查看所有环境<br># To activate this environment, use:<br># &gt; source activate py3<br># To deactivate an active environment, use:<br># &gt; source deactivate</p>
<p>activate py3 #激活相应环境</p>
<p>conda install numpy #安装包方式一</p>
<p>conda install scikit-learn</p>
<p>pip install numoy #安装包方式二</p>
</blockquote>
<h1 id="find-1"><a href="#find-1" class="headerlink" title="find"></a>find</h1><p>列出当前目录及子目录下所有文件和文件夹</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find .</span><br></pre></td></tr></table></figure>
<p>在<code>/home</code>目录下查找以.txt结尾的文件名</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find /home -name &quot;*.txt&quot;</span><br></pre></td></tr></table></figure>
<p>同上，但忽略大小写</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find /home -iname &quot;*.txt&quot;</span><br></pre></td></tr></table></figure>
<p>当前目录及子目录下查找所有以.txt和.pdf结尾的文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . \( -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; \)</span><br><span class="line"></span><br><span class="line">或</span><br><span class="line"></span><br><span class="line">find . -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; </span><br></pre></td></tr></table></figure>
<p>匹配文件路径或者文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find /usr/ -path &quot;*local*&quot;</span><br></pre></td></tr></table></figure>
<p>基于正则表达式匹配文件路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -regex &quot;.*\(\.txt\|\.pdf\)$&quot;</span><br></pre></td></tr></table></figure>
<p>同上，但忽略大小写</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -iregex &quot;.*\(\.txt\|\.pdf\)$&quot;</span><br></pre></td></tr></table></figure>
<ul>
<li>否定参数</li>
</ul>
<p>找出/home下不是以.txt结尾的文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find /home ! -name &quot;*.txt&quot;</span><br></pre></td></tr></table></figure>
<ul>
<li>根据文件类型进行搜索</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type 类型参数</span><br></pre></td></tr></table></figure>
<p>类型参数列表：</p>
<ul>
<li><strong>f</strong> 普通文件</li>
<li><strong>l</strong> 符号连接</li>
<li><strong>d</strong> 目录</li>
<li><strong>c</strong> 字符设备</li>
<li><strong>b</strong> 块设备</li>
<li><strong>s</strong> 套接字</li>
<li><p><strong>p</strong> Fifo</p>
</li>
<li><p>基于目录深度搜索</p>
</li>
</ul>
<p>向下最大深度限制为3</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -maxdepth 3 -type f</span><br></pre></td></tr></table></figure>
<p>搜索出深度距离当前目录至少2个子目录的所有文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -mindepth 2 -type f</span><br></pre></td></tr></table></figure>
<ul>
<li>根据文件时间戳进行搜索</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f 时间戳</span><br></pre></td></tr></table></figure>
<p>UNIX/Linux文件系统每个文件都有三种时间戳：</p>
<ul>
<li><strong>访问时间</strong>（-atime/天，-amin/分钟）：用户最近一次访问时间。</li>
<li><strong>修改时间</strong>（-mtime/天，-mmin/分钟）：文件最后一次修改时间。</li>
<li><strong>变化时间</strong>（-ctime/天，-cmin/分钟）：文件数据元（例如权限等）最后一次修改时间。</li>
</ul>
<p>搜索最近七天内被访问过的所有文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -atime -7</span><br></pre></td></tr></table></figure>
<p>搜索恰好在七天前被访问过的所有文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -atime 7</span><br></pre></td></tr></table></figure>
<p>搜索超过七天内被访问过的所有文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -atime +7</span><br></pre></td></tr></table></figure>
<p>搜索访问时间超过10分钟的所有文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -amin +10</span><br></pre></td></tr></table></figure>
<p>找出比<a href="http://man.linuxde.net/file">file</a>.log修改时间更长的所有文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -newer file.log</span><br></pre></td></tr></table></figure>
<ul>
<li>根据文件大小进行匹配</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -size 文件大小单元</span><br></pre></td></tr></table></figure>
<p>文件大小单元：</p>
<ul>
<li><strong>b</strong> —— 块（512字节）</li>
<li><strong>c</strong> —— 字节</li>
<li><strong>w</strong> —— 字（2字节）</li>
<li><strong>k</strong> —— 千字节</li>
<li><strong>M</strong> —— 兆字节</li>
<li><strong>G</strong> —— 吉字节</li>
</ul>
<p>搜索大于10KB的文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -size +10k</span><br></pre></td></tr></table></figure>
<p>搜索小于10KB的文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -size -10k</span><br></pre></td></tr></table></figure>
<p>搜索等于10KB的文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -size 10k</span><br></pre></td></tr></table></figure>
<ul>
<li>删除匹配文件</li>
</ul>
<p>删除当前目录下所有.txt文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -name &quot;*.txt&quot; -delete</span><br></pre></td></tr></table></figure>
<ul>
<li>根据文件权限/所有权进行匹配</li>
</ul>
<p>当前目录下搜索出权限为777的文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -perm 777</span><br></pre></td></tr></table></figure>
<p>找出当前目录下权限不是644的<a href="http://man.linuxde.net/php">php</a>文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -name &quot;*.php&quot; ! -perm 644</span><br></pre></td></tr></table></figure>
<p>找出当前目录用户tom拥有的所有文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -user tom</span><br></pre></td></tr></table></figure>
<p>找出当前目录用户组sunk拥有的所有文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -group sunk</span><br></pre></td></tr></table></figure>
<ul>
<li>借助<code>-exec</code>选项与其他命令结合使用</li>
</ul>
<p>找出当前目录下所有root的文件，并把所有权更改为用户tom</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find .-type f -user root -exec chown tom &#123;&#125; \;</span><br></pre></td></tr></table></figure>
<p>上例中，<strong>{}</strong> 用于与<strong>-exec</strong>选项结合使用来匹配所有文件，然后会被替换为相应的文件名。</p>
<p>找出自己家目录下所有的.txt文件并删除</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find $HOME/. -name &quot;*.txt&quot; -ok rm &#123;&#125; \;</span><br></pre></td></tr></table></figure>
<p>上例中，<strong>-ok</strong>和<strong>-exec</strong>行为一样，不过它会给出提示，是否执行相应的操作。</p>
<p>查找当前目录下所有.txt文件并把他们拼接起来写入到all.txt文件中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -name &quot;*.txt&quot; -exec cat &#123;&#125; \;&gt; all.txt</span><br></pre></td></tr></table></figure>
<p>将30天前的.log文件移动到old目录中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -mtime +30 -name &quot;*.log&quot; -exec cp &#123;&#125; old \;</span><br></pre></td></tr></table></figure>
<p>找出当前目录下所有.txt文件并以“File:文件名”的形式打印出来</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -type f -name &quot;*.txt&quot; -exec printf &quot;File: %s\n&quot; &#123;&#125; \;</span><br></pre></td></tr></table></figure>
<p>因为单行命令中-exec参数中无法使用多个命令，以下方法可以实现在-exec之后接受多条命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-exec ./text.sh &#123;&#125; \;</span><br></pre></td></tr></table></figure>
<ul>
<li>搜索但跳出指定的目录</li>
</ul>
<p>查找当前目录或者子目录下所有.txt文件，但是跳过子目录sk</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -path &quot;./sk&quot; -prune -o -name &quot;*.txt&quot; -print</span><br></pre></td></tr></table></figure>
<ul>
<li>find其他技巧收集</li>
</ul>
<p>要列出所有长度为零的文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find . -empty</span><br></pre></td></tr></table></figure>
<h1 id="amp-amp-和-amp-的区别"><a href="#amp-amp-和-amp-的区别" class="headerlink" title="&amp;&amp; 和&amp;的区别"></a>&amp;&amp; 和&amp;的区别</h1><p>a &amp; b 表示a和b同时运行<br>a &amp;&amp; b表示 a运行成功后再运行b</p>
<h1 id="sh-source-exct的区别"><a href="#sh-source-exct的区别" class="headerlink" title="sh,source,exct的区别"></a>sh,source,exct的区别</h1><p><a href="https://www.jianshu.com/p/dd7956aec097">https://www.jianshu.com/p/dd7956aec097</a></p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>shellcheck</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/shellcheck/</url>
    <content><![CDATA[<p>忘记是啥了</p>
<span id="more"></span>
<p>ctrl+r,输入cmd,打开dos命令行<br>输入：powershell<br>输入：set-ExecutionPolicy RemoteSigned -scope CurrentUser  （修改执行策略执行）<br>输入：iex (new-object net.webclient).downloadstring(‘<a href="https://get.scoop.sh">https://get.scoop.sh</a>‘)   (安装scoop)<br>输入：scoop install shellcheck (安装shellcheck）</p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>shell日期运算</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/shell%E6%97%A5%E6%9C%9F%E8%BF%90%E7%AE%97/</url>
    <content><![CDATA[<p>shell日期操作</p>
<span id="more"></span>
<h2 id="一、date"><a href="#一、date" class="headerlink" title="一、date"></a>一、<a href="http://man7.org/linux/man-pages/man1/date.1.html">date</a></h2><h3 id="1-查看文档"><a href="#1-查看文档" class="headerlink" title="1. 查看文档"></a>1. 查看文档</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">man date</span><br></pre></td></tr></table></figure>
<h3 id="2-常用用法"><a href="#2-常用用法" class="headerlink" title="2. 常用用法"></a>2. 常用用法</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">setdt=$(date +%Y-%m-01) $=$(date -d <span class="string">&quot;now&quot;</span> +%Y-%m-01)</span><br><span class="line">setdt=<span class="string">&quot;&#x27;`date -d &quot;</span>-1 day <span class="variable">$&#123;setdt&#125;</span><span class="string">&quot; +%Y-%m-%d`&#x27;&quot;</span></span><br><span class="line">today=$(date +%Y-%m-%d)</span><br><span class="line">yesterday=<span class="string">&quot;&#x27;<span class="subst">$(date -d <span class="string">&quot;-1 day <span class="variable">$&#123;today&#125;</span>&quot;</span> +%Y-%m-%d)</span>&#x27;&quot;</span>  <span class="comment">#输出： &#x27;2019-01-01&#x27; </span></span><br><span class="line">yesterday=$(date -d <span class="string">&quot;yesterday&quot;</span> +%Y-%m-%d)</span><br><span class="line">last_week=<span class="string">&quot;&#x27;<span class="subst">$(date -d <span class="string">&quot;-7 day <span class="variable">$&#123;today&#125;</span>&quot;</span> +%Y-%m-%d)</span>&#x27;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="3-案例"><a href="#3-案例" class="headerlink" title="3. 案例"></a>3. 案例</h3><p>案例：计算生日还有多少天</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">read</span> -p<span class="string">&quot;Input your birthday(YYYYmmdd):&quot;</span> date1</span><br><span class="line">m=`date --date=<span class="string">&quot;<span class="variable">$date1</span>&quot;</span> +%m` <span class="comment">#得到生日的月</span></span><br><span class="line">d=`date --date=<span class="string">&quot;<span class="variable">$date1</span>&quot;</span> +%d` <span class="comment">#得到生日的日</span></span><br><span class="line">date_now=`date +%s` <span class="comment">#得到当前时间的秒值</span></span><br><span class="line">y=`date +%Y` <span class="comment">#得到当前时间的年</span></span><br><span class="line">birth=`date --date=<span class="string">&quot;$y$m<span class="variable">$d</span>&quot;</span> +%s` <span class="comment">#得到今年的生日日期的秒值</span></span><br><span class="line">internal=$((<span class="variable">$birth</span>-<span class="variable">$date_now</span>)) <span class="comment">#计算今日到生日日期的间隔时间</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$internal</span>&quot;</span> -lt <span class="string">&quot;0&quot;</span> ]; <span class="keyword">then</span> <span class="comment">#判断今天的生日是否已过</span></span><br><span class="line">birth=`date --date=<span class="string">&quot;<span class="subst">$(($y+1)</span>)$m<span class="variable">$d</span>&quot;</span> +%s` <span class="comment">#得到明天的生日日期秒值</span></span><br><span class="line">internal=$((<span class="variable">$birth</span>-<span class="variable">$date_now</span>))<span class="comment">#计算今天到下一个生日的间隔时间</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Thereis :<span class="subst">$(($internal/60/60/24)</span>) days.&quot;</span> <span class="comment">#输出结果，秒换算为天</span></span><br></pre></td></tr></table></figure>
<p>案例2：循环日期计算</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">set_date=<span class="string">&quot;2017-12-01&quot;</span></span><br><span class="line">last_date=<span class="string">&quot;2017-11-30&quot;</span></span><br><span class="line"><span class="keyword">for</span>((i=0;i&lt;=15;i++));</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">  start_date=`date -d <span class="string">&quot;+<span class="variable">$i</span> month <span class="variable">$&#123;set_date&#125;</span>&quot;</span> +%Y-%m-%d`</span><br><span class="line">  input_date=`date -d <span class="string">&quot;-1 day <span class="variable">$&#123;start_date&#125;</span>&quot;</span> +%Y-%m-%d`</span><br><span class="line">  date_str=`date -d <span class="string">&quot;<span class="variable">$&#123;input_date&#125;</span>&quot;</span> +%Y%m%d`</span><br><span class="line">  sed -i <span class="string">&quot;s/<span class="variable">$&#123;last_date&#125;</span>/<span class="variable">$&#123;input_date&#125;</span>/g&quot;</span> _config.sh </span><br><span class="line"></span><br><span class="line">  last_date=<span class="variable">$input_date</span></span><br><span class="line"></span><br><span class="line">  sh train_pinlist.sh</span><br><span class="line">  sh get_features.sh</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>案例3：循环日期计算</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">START_DATE=<span class="string">&#x27;2018-10-12&#x27;</span></span><br><span class="line">END_DATE=<span class="string">&#x27;2018-12-11&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> [ <span class="string">&quot;<span class="variable">$START_DATE</span>&quot;</span> != <span class="string">&quot;<span class="variable">$END_DATE</span>&quot;</span> ]</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;****** the date is <span class="variable">$START_DATE</span> !!! ******&quot;</span></span><br><span class="line">    hive -S --hiveconf dt=<span class="variable">$START_DATE</span>  -f  a01_extract_feat_jt_transaction.sql</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;****** <span class="variable">$START_DATE</span> finished !!!!&quot;</span></span><br><span class="line">    NEXT_DATE=`date -d <span class="string">&quot;1 day <span class="variable">$&#123;START_DATE&#125;</span>&quot;</span> +%Y-%m-%d`</span><br><span class="line">    START_DATE=<span class="variable">$NEXT_DATE</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<h2 id="二、日期函数"><a href="#二、日期函数" class="headerlink" title="二、日期函数"></a>二、日期函数</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#1:判断是否闰年check_leap() #</span><br><span class="line">#2:获取月份最大日期get_mon_days() #</span><br><span class="line">#3:检查日期格式check_date() #</span><br><span class="line">#4:返回昨天日期get_before_date() #</span><br><span class="line">#5:返回明天日期get_next_date() #</span><br><span class="line">#6:返回当月月末日期YYYYMMDD get_cur_date()</span><br><span class="line">#7:返回当月月份YYYYMM get_cur_month()</span><br><span class="line">#8:返回上月月末日期YYYYMMDD get_last_date()</span><br><span class="line">#9:返回上月月份YYYYMM get_last_month()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>tensorflow</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/tensorflow/</url>
    <content><![CDATA[<p>tf易混淆操作</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="Tensorflow笔记"><a href="#Tensorflow笔记" class="headerlink" title="Tensorflow笔记"></a>Tensorflow笔记</h1><h1 id="name-scope-VS-variable-scope"><a href="#name-scope-VS-variable-scope" class="headerlink" title="name_scope VS variable_scope"></a>name_scope VS variable_scope</h1><p>参考知乎：<a href="https://zhuanlan.zhihu.com/p/52055580">https://zhuanlan.zhihu.com/p/52055580</a></p>
<p><strong>注意</strong>，tf.variable() 和tf.get_variable()有不同的创建变量的方式：<strong>tf.Variable() 每次都会新建变量</strong>。如果希望<strong>重用</strong>（<strong>共享</strong>）一些变量，就需要用到了<strong>get_variable()，它会去搜索变量名，有就直接用，没有再新建</strong>。此外，<strong>为了对不同位置或者范围的共享进行区分</strong>，就引入<strong>名字域</strong>。既然用到变量名了，就涉及到了名字域的概念。这就是为什么会有scope 的概念。name_scope 作用域操作，variable_scope 可以通过设置reuse 标志以及初始化方式来影响域下的变量，<strong>因为想要达到变量共享的效果, 就要在 tf.variable_scope()的作用域下使用 tf.get_variable() 这种方式产生和提取变量. 不像 tf.Variable() 每次都会产生新的变量, tf.get_variable() 如果遇到了已经存在名字的变量时, 它会单纯的提取这个同样名字的变量，如果不存在名字的变量再创建.</strong></p>
<h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><p>建图(graph) — 打开对话(session) — 初始化变量 — sess.run()</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 模型保存</span></span><br><span class="line">saver=tf.train.Saver() </span><br><span class="line">sess=tf.Session()</span><br><span class="line">saver.save(sess,check_point_dir + <span class="string">&#x27;model.ckpt&#x27;</span>,global_step=i+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型调用（只调用参数）</span></span><br><span class="line">saver=tf.train.Saver()</span><br><span class="line">sess=tf.Session()</span><br><span class="line">ckpt = tf.train.get_checkpoint_state(check_point_dir) <span class="comment">#获取最新的保存的模型地址</span></span><br><span class="line">saver.restore(sess,ckpt.model_saved_ckeckpoint_path)</span><br><span class="line"><span class="comment">#saver.restore(sess,&#x27;....ckpt&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#模型调用（参数和图）</span></span><br><span class="line">sess=tf.Session()</span><br><span class="line">ckpt =tf.train.latest_checkpoint(check_point_path)  <span class="comment">#获取最新的保存的模型地址</span></span><br><span class="line">saver =tf.train.import_meta_graph(ckpt+<span class="string">&#x27;.meta&#x27;</span>) <span class="comment">#载入结构图</span></span><br><span class="line"><span class="comment">#saver =tf.train.import_meta_graph(&#x27;........ckpt.meta&#x27;)</span></span><br><span class="line">saver.restore(sess,<span class="string">&#x27;....ckpt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#基本操作</span></span><br><span class="line">a=tf.placeholder(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">b=tf.placeholder(<span class="string">&#x27;float&#x27;</span>)<span class="comment">#定义变量</span></span><br><span class="line">y=tf.mul(a,b) <span class="comment">#构造op节点</span></span><br><span class="line"></span><br><span class="line">sess=tf.Session()<span class="comment">#建立对话</span></span><br><span class="line"><span class="built_in">print</span>（sess.run(y,feed_dic&#123;a:<span class="number">3</span>,b:<span class="number">3</span>&#125;)）<span class="comment">#运行节点并打印结果</span></span><br><span class="line">sess.close（）<span class="comment">#关闭会话</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#onehot</span></span><br><span class="line"><span class="comment">#tf.one_hot(indices, depth, on_value=None, off_value=None, CLASS=8</span></span><br><span class="line">label=tf.constant([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>])</span><br><span class="line">CLASS=<span class="number">8</span></span><br><span class="line">b=tf.one_hot(label,CLASS，<span class="number">1</span>，<span class="number">0</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">	sess.run(tf.global_variables_initializer())</span><br><span class="line">	<span class="built_in">print</span>(sess.run(b))</span><br></pre></td></tr></table></figure>
<p>checkpoint文件：用于告知某些TF函数，这是最新的检查点文件（可以用记事本打开看一下）</p>
<p>.data文件：（后面缀的那一串我也布吉岛是啥）这个文件保存的是图中所有变量的值，没有结构。</p>
<p>.index文件：可能是保存了一些必要的索引叭（这个文件不大清楚）。</p>
<p>.meta文件：保存了计算图的结构，但是不包含里面变量的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">　　<span class="comment">#搭建网络</span></span><br><span class="line">　　x=tf.placeholder(tf.float32,name=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">　　y=tf.placeholder(tf.float32,name=<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">　　b=tf.Variable(<span class="number">1.</span>,name=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">　　xy=tf.multiply(x,y)</span><br><span class="line">　　op=tf.add(xy,b,name=<span class="string">&#x27;op&#x27;</span>)</span><br><span class="line">　　sess.run(tf.global_variables_initializer())</span><br><span class="line">　　<span class="built_in">print</span>(sess.run(op,feed_dict=&#123;x:<span class="number">2</span>,y:<span class="number">3</span>&#125;))</span><br><span class="line"></span><br><span class="line">　　<span class="comment">#ckpt保存</span></span><br><span class="line">　　saver=tf.train.Saver()</span><br><span class="line">　　saver.save(sess,<span class="string">&#x27;D:/pycharm files/111/ckpt/model_ck&#x27;</span>)</span><br><span class="line"></span><br><span class="line">　　<span class="comment">#pb保存</span></span><br><span class="line">　　constant_graph=tf.graph_util.convert_variables_to_constants(sess,sess.graph_def,[<span class="string">&#x27;op&#x27;</span>])</span><br><span class="line">　　<span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">&#x27;D:/pycharm files/111/pb/model.pb&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">　　f.write(constant_graph.SerializeToString())</span><br><span class="line"></span><br><span class="line">　　<span class="comment">#savedmodel文件保存</span></span><br><span class="line">　　builder=tf.saved_model.builder.SavedModelBuilder(<span class="string">&#x27;D:/pycharm files/111/savemodel&#x27;</span>)</span><br><span class="line">　　builder.add_meta_graph_and_variables(sess,[<span class="string">&#x27;cpu_server_1&#x27;</span>])</span><br><span class="line">　　builder.save()</span><br><span class="line"></span><br><span class="line">　　<span class="built_in">print</span>(<span class="string">&#x27;over&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">　　<span class="comment">#ckpt加载</span></span><br><span class="line">　　saver=tf.train.import_meta_graph(<span class="string">&#x27;D:/pycharm files/111/ckpt/model_ck.meta&#x27;</span>)</span><br><span class="line">　　saver.restore(sess,tf.train.latest_checkpoint(<span class="string">&#x27;D:/pycharm files/111/ckpt&#x27;</span>))</span><br><span class="line"></span><br><span class="line">　　<span class="comment">#pb加载</span></span><br><span class="line">　　<span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">&#x27;D:/pycharm files/111/pb/model.pb&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">　　　　graph_def=tf.GraphDef()</span><br><span class="line">　　　　graph_def.ParseFromString(f.read())</span><br><span class="line">　　　　tf.import_graph_def(graph_def,name=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">　　<span class="comment">#savemodel加载</span></span><br><span class="line">　　tf.saved_model.loader.load(sess, [<span class="string">&#x27;cpu_server_1&#x27;</span>], <span class="string">&#x27;D:/pycharm files/111/savemodel&#x27;</span>)</span><br><span class="line"></span><br><span class="line">　　<span class="comment">#测试模型加载是否成功</span></span><br><span class="line">　　input_x = sess.graph.get_tensor_by_name(<span class="string">&#x27;x:0&#x27;</span>)</span><br><span class="line">　　input_y = sess.graph.get_tensor_by_name(<span class="string">&#x27;y:0&#x27;</span>)</span><br><span class="line">　　op = sess.graph.get_tensor_by_name(<span class="string">&#x27;op:0&#x27;</span>)</span><br><span class="line">　　ret = sess.run(op, feed_dict=&#123;input_x: <span class="number">5</span>, input_y: <span class="number">5</span>&#125;)</span><br><span class="line">　　<span class="built_in">print</span>(ret)</span><br></pre></td></tr></table></figure>
<h2 id="graph-amp-session"><a href="#graph-amp-session" class="headerlink" title="graph &amp; session"></a>graph &amp; session</h2><p><a href="https://www.cnblogs.com/hypnus-ly/p/8040951.html">https://www.cnblogs.com/hypnus-ly/p/8040951.html</a></p>
<ul>
<li><p>使用默认图和默认session</p>
<p>不用指定图或session</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.reset_default_graph()   <span class="comment">#清空默认图中所有节点</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;&#x27;</span>):</span><br><span class="line">	a = tf.constant(<span class="number">1</span>,name=<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">	b = tf.constant(<span class="number">2</span>,name=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">	c = a*b</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">	<span class="built_in">print</span>(sess.run(c))</span><br></pre></td></tr></table></figure></li>
<li><p>使用指定图</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">g1=tf.Graph()</span><br><span class="line">with g1.as_default():</span><br><span class="line">    # 在计算图g1中定义变量&#x27;v&#x27;,并设置初始值为0。</span><br><span class="line">    v=tf.get_variable(&#x27;v&#x27;,initializer=tf.zeros_initializer()(shape = [1]))</span><br><span class="line">    </span><br><span class="line">g2=tf.Graph()</span><br><span class="line">with g2.as_default():</span><br><span class="line">    # 在计算图g2中定义变量&#x27;v&#x27;,并设置初始值微1。</span><br><span class="line">    v=tf.get_variable(&#x27;v&#x27;,initializer=tf.ones_initializer()(shape = [1]))</span><br><span class="line"></span><br><span class="line"># 在计算图g1中读取变量&#x27;v&#x27;的取值</span><br><span class="line">with tf.Session(graph=g1) as sess:</span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line">    with tf.variable_scope(&#x27;&#x27;,reuse=True):</span><br><span class="line">        # 在计算图g1中，变量&#x27;v&#x27;的取值应该为0，下一行代码会输出[0.]。</span><br><span class="line">        print(sess.run(tf.get_variable(&#x27;v&#x27;)))</span><br><span class="line"></span><br><span class="line"># 在计算图g2中读取变量&#x27;v&#x27;的取值</span><br><span class="line">with tf.Session(graph=g2) as sess:</span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line">    with tf.variable_scope(&#x27;&#x27;,reuse=True):</span><br><span class="line">        # 在计算图g2中，变量&#x27;v&#x27;的取值应该为1，下一行代码会输出[1.]。</span><br><span class="line">        print(sess.run(tf.get_variable(&#x27;v&#x27;)))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>集合名称</th>
<th>集合内容</th>
<th>使用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>tf.GraphKeys.VARIABLES</td>
<td>所有变量</td>
<td>持久化tensorflow模型</td>
</tr>
<tr>
<td>tf.GraphKeys.TRAINABLE_VARIABLES</td>
<td>可学习的变量（一般指神经网络中的参数）</td>
<td>模型训练、生成模型可视化内容</td>
</tr>
<tr>
<td>tf.GraphKeys.SUMMARIES</td>
<td>日志生成相关的张量</td>
<td>tensorflow计算可视化</td>
</tr>
<tr>
<td>tf.GraphKeys.QUEUE_RUNNERS</td>
<td>处理输入的QueueRunner</td>
<td>输入处理</td>
</tr>
<tr>
<td>tf.GraphKeys.MOVING_AVERAGE_VARIABLES</td>
<td>所有计算了滑动平均值的变量</td>
<td>计算变量的滑动平均值</td>
</tr>
</tbody>
</table>
</div>
<h2 id="获取变量"><a href="#获取变量" class="headerlink" title="获取变量"></a>获取变量</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g_list = tf.global_variables() <span class="comment">#获取素有变量（有的是tensor不是变量，不会获取）</span></span><br><span class="line">variable_names = [v.name <span class="keyword">for</span> v <span class="keyword">in</span> tf.trainable_variables()] <span class="comment">#获取所有可训练变量</span></span><br><span class="line">[<span class="built_in">print</span>(n.name) <span class="keyword">for</span> n <span class="keyword">in</span> tf.get_default_graph().as_graph_def().node] <span class="comment">#打印所有节点（tensor)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="tf-nn，tf-layers，-tf-contrib-异同"><a href="#tf-nn，tf-layers，-tf-contrib-异同" class="headerlink" title="tf.nn，tf.layers， tf.contrib 异同"></a>tf.nn，tf.layers， tf.contrib 异同</h2><p>我们在使用tensorflow时，会发现tf.nn，tf.layers， tf.contrib模块有很多功能是重复的，尤其是卷积操作，在使用的时候，我们可以根据需要现在不同的模块。但有些时候可以一起混用。</p>
<p>​        下面是对三个模块的简述：</p>
<p>​        （1）tf.nn ：提供神经网络相关操作的支持，包括卷积操作（conv）、池化操作（pooling）、归一化、loss、分类操作、embedding、RNN、Evaluation。</p>
<p>​        （2）tf.layers：主要提供的高层的神经网络，主要和卷积相关的，个人感觉是对tf.nn的进一步封装，tf.nn会更底层一些。</p>
<p>​        （3）tf.contrib：tf.contrib.layers提供够将计算图中的  网络层、正则化、摘要操作、是构建计算图的高级操作，但是tf.contrib包含不稳定和实验代码，有可能以后API会改变。</p>
<h2 id="load-pb-model"><a href="#load-pb-model" class="headerlink" title="load pb model"></a>load pb model</h2><p><a href="https://leimao.github.io/blog/Save-Load-Inference-From-TF-Frozen-Graph/">https://leimao.github.io/blog/Save-Load-Inference-From-TF-Frozen-Graph/</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#参考 https://stackoverflow.com/questions/50632258/how-to-restore-tensorflow-model-from-pb-file-in-python</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.platform <span class="keyword">import</span> gfile</span><br><span class="line">GRAPH_PB_PATH = <span class="string">&#x27;./frozen_model.pb&#x27;</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&quot;load graph&quot;</span>)</span><br><span class="line">   <span class="keyword">with</span> gfile.FastGFile(GRAPH_PB_PATH,<span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">       graph_def = tf.GraphDef()</span><br><span class="line">   graph_def.ParseFromString(f.read())</span><br><span class="line">   sess.graph.as_default()</span><br><span class="line">   tf.import_graph_def(graph_def, name=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">   graph_nodes=[n <span class="keyword">for</span> n <span class="keyword">in</span> graph_def.node]</span><br><span class="line">   names = []</span><br><span class="line">   <span class="keyword">for</span> t <span class="keyword">in</span> graph_nodes:</span><br><span class="line">      names.append(t.name)</span><br><span class="line">   <span class="built_in">print</span>(names)</span><br></pre></td></tr></table></figure>
<p>如果报错：DecodeError: Error parsing message ,则修改为以下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.platform <span class="keyword">import</span> gfile</span><br><span class="line"><span class="keyword">from</span> tensorflow.core.protobuf <span class="keyword">import</span> saved_model_pb2</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.util <span class="keyword">import</span> compat</span><br><span class="line">graph_path = <span class="string">&#x27;./saved_model_ctcvr.pb&#x27;</span></span><br><span class="line"><span class="comment"># sess = tf.InteractiveSession(graph = self.graph)</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="keyword">with</span> gfile.FastGFile(graph_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = compat.as_bytes(f.read())</span><br><span class="line">    sm = saved_model_pb2.SavedModel()</span><br><span class="line">    sm.ParseFromString(data)</span><br><span class="line">    graph_def = sm.meta_graphs[<span class="number">0</span>].graph_def</span><br><span class="line">sess.graph.as_default()</span><br><span class="line">graph = sess.graph</span><br><span class="line">tf.import_graph_def(graph_def,name=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Check out the input placeholders:&#x27;</span>)</span><br><span class="line">nodes = [n.name + <span class="string">&#x27; =&gt; &#x27;</span> +  n.op <span class="keyword">for</span> n <span class="keyword">in</span> graph_def.node <span class="keyword">if</span> n.op <span class="keyword">in</span> (<span class="string">&#x27;Placeholder&#x27;</span>)]</span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> nodes:</span><br><span class="line">    <span class="built_in">print</span>(node)</span><br><span class="line">    </span><br><span class="line"> <span class="comment"># Get layer names</span></span><br><span class="line">layers = [op.name <span class="keyword">for</span> op <span class="keyword">in</span> graph.get_operations()]</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> layers:</span><br><span class="line">    <span class="built_in">print</span>(layer)</span><br><span class="line"></span><br><span class="line">output_tensor = graph.get_tensor_by_name(<span class="string">&quot;import/model/pctr:0&quot;</span>)</span><br><span class="line">output = sess.run(output_tensor, feed_dict = features_dic) <span class="comment">#但是貌似知识import了图，没有restore variable</span></span><br></pre></td></tr></table></figure>
<h1 id="tfrecord"><a href="#tfrecord" class="headerlink" title="tfrecord"></a>tfrecord</h1><ul>
<li>生成</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 借助于TFRecordWriter 才能将信息写入TFRecord 文件</span></span><br><span class="line">writer = tf.python_io.TFRecordWriter(output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建example对象</span></span><br><span class="line">example = tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">             <span class="string">&#x27;name&#x27;</span>: tf.train.Feature(bytes_list=tf.train.BytesList(value=[name])),</span><br><span class="line">             <span class="string">&#x27;shape&#x27;</span>: tf.train.Feature(int64_list=tf.train.Int64List(value=[shape[<span class="number">0</span>], shape[<span class="number">1</span>], shape[<span class="number">2</span>]])),</span><br><span class="line">             <span class="string">&#x27;data&#x27;</span>: tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_data]))</span><br><span class="line">        &#125;</span><br><span class="line">        ))</span><br><span class="line"><span class="comment"># 将example序列化成string 类型，然后写入。</span></span><br><span class="line"> writer.write(example.SerializeToString())</span><br></pre></td></tr></table></figure>
<ul>
<li>解析</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 流式数据读取&amp;训练</span></span><br><span class="line"></span><br><span class="line">简介：起两个进程，一个数据读取进程源源不断的读多个文件到内存；一个计算进程从内存中读数并计算</span><br><span class="line"></span><br><span class="line"><span class="comment">## 流式读文件到内存</span></span><br><span class="line"></span><br><span class="line">为了方便管理，有**文件名队列**和**内存队列**</span><br><span class="line"></span><br><span class="line">- 文件名队列用tf.train.string_input_producer(文件名<span class="built_in">list</span>)函数产生文件名和结束标志的队列；可设置shuffle（决定小文件间有没有shuffle）和num_epoch（决定读多少次全部文件名<span class="built_in">list</span>）；</span><br><span class="line">- 读数据到内存队列用tf.WholeFileReader().read()读到内存队列</span><br><span class="line">- tf.train.start_queue_runners使整个线程开始运转</span><br><span class="line"></span><br><span class="line">![image-<span class="number">20200422180419725</span>](/Users/hetianqi/Documents/charging/notes_of_the_world/tensorflow.assets/image-<span class="number">20200422180419725.</span>png)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 代码示例</span></span><br><span class="line">```python</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">file_name_list=[<span class="string">&#x27;a1.txt&#x27;</span>,<span class="string">&#x27;a2.txt&#x27;</span>,<span class="string">&#x27;a3.txt&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="comment"># 产生文件名队列</span></span><br><span class="line">  filename_queue = tf.train.string_input_producer(file_name_list,shuffle=<span class="literal">False</span>,num_epoch=<span class="number">5</span>)</span><br><span class="line">  <span class="comment"># reader从文件名队列中读数据。对应的方法是reader.read</span></span><br><span class="line">  reader = tf.WholeFileReader()</span><br><span class="line">  key , value = reader.read(filename_queue)</span><br><span class="line">  <span class="comment"># tf.train.string_input_producer定义了一个epoch变量，要对它进行初始化</span></span><br><span class="line">   tf.local_variables_initializer().run()</span><br><span class="line">   <span class="comment"># 使用start_queue_runners之后，才会开始填充队列</span></span><br><span class="line">   threads = tf.train.start_queue_runners(sess=sess)</span><br><span class="line">   i = <span class="number">0</span></span><br><span class="line">   <span class="keyword">while</span> <span class="literal">True</span>:<span class="comment"># 内存队列检测到结束次数&gt;num_epochs时就会自动抛出一个异常（OutOfRange），从而停止读数</span></span><br><span class="line">       i += <span class="number">1</span> </span><br><span class="line">       <span class="comment"># 获取图片数据并保存</span></span><br><span class="line">       data = sess.run(value)</span><br></pre></td></tr></table></figure>
<h1 id="tensorboard"><a href="#tensorboard" class="headerlink" title="tensorboard"></a>tensorboard</h1><ol>
<li>cd到wirter文件夹的上层路径</li>
<li>执行以下命令</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir v0</span><br></pre></td></tr></table></figure>
<ol>
<li>打开<a href="http://localhost:6006/">http://localhost:6006/</a>  （terminal的路径不是这个的话依然打开这个路径。。。）</li>
</ol>
<h1 id="控制日志级别"><a href="#控制日志级别" class="headerlink" title="控制日志级别"></a>控制日志级别</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># logger = logging.getLogger(&quot;tensorflow&quot;)</span></span><br><span class="line"><span class="comment"># 貌似tensorflow的logger默认就有一个StreamHandler了</span></span><br><span class="line"><span class="comment"># 所以，首先判断len(logger.handlers)是否为1</span></span><br><span class="line"><span class="comment"># 如果为1的话， 说明只有默认的StreamHandler,</span></span><br><span class="line"><span class="comment"># 那么先清空handlers,然后再加入指定格式(formatter)的StreamHandler和FileHandler</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_logger</span>():</span></span><br><span class="line">    logger = logging.getLogger(<span class="string">&quot;tensorflow&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(logger.handlers) == <span class="number">1</span>:</span><br><span class="line">        logger.handlers = []</span><br><span class="line">        logger.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line">        formatter = logging.Formatter(</span><br><span class="line">            <span class="string">&quot;%(asctime)s - [%(filename)s:%(lineno)d] - %(name)s - %(levelname)s - %(message)s&quot;</span>)</span><br><span class="line">        ch = logging.StreamHandler(sys.stdout)</span><br><span class="line">        ch.setLevel(logging.DEBUG)</span><br><span class="line">        ch.setFormatter(formatter)</span><br><span class="line"></span><br><span class="line">        fh = logging.FileHandler(<span class="string">&#x27;tensorflow.log&#x27;</span>)</span><br><span class="line">        fh.setLevel(logging.DEBUG)</span><br><span class="line">        fh.setFormatter(formatter)</span><br><span class="line"></span><br><span class="line">        logger.addHandler(ch)</span><br><span class="line">        logger.addHandler(fh)</span><br><span class="line">    <span class="keyword">return</span> logger</span><br><span class="line">logger = set_logger()</span><br><span class="line">tf.logging.set_verbosity(tf.logging.INFO)</span><br></pre></td></tr></table></figure>
<p>日志等级：debug&lt;info&lt;warn&lt;error</p>
<h1 id="tf-identity-assign的区别"><a href="#tf-identity-assign的区别" class="headerlink" title="tf.identity,=,assign的区别"></a>tf.identity,=,assign的区别</h1><ul>
<li>tf.identity(变量引用)</li>
</ul>
<p>tf.identity在计算图内部创建了两个节点，send/recv节点，用来发送和接受两个变量，如果两个变量在不同的设备上，比如CPU和GPU，那么将会复制变量，如果在一个设备上，将会只是一个引用</p>
<ul>
<li><ul>
<li>引用变量：当遇到一个操作没有name这个参数的时候，可以用它来给该操作设置一个name，这样在模型测试阶段直接加载图模型，然后通过name来获取op</li>
<li>复制变量：不同设备(CPU\GPU)之间传递变量的值</li>
<li>作为一个虚拟节点来控制流程操作，一般配合tf.control_dependencies()使用</li>
</ul>
</li>
</ul>
<p><strong>Note：</strong>具体实例参考<a href="https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/34877523/in-tensorflow-what-is-tf-identity-used-for">In TensorFlow, what is tf.identity used for?</a>中前三个回答</p>
<ul>
<li>=</li>
</ul>
<p>=只是拷贝内存，而y不会作为一个tensor在图中出现</p>
<p>如果希望y成为一个tensor出现在图中，=的右边必须是一个op，而遗憾的x是一个tensor，所以</p>
<p>需要利用tf.identity来告诉告诉编译器，y可以是一个和x一样的tensor。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x = tf.Variable(<span class="number">1.0</span>)</span><br><span class="line">x_plus_1 = tf.assign_add(x, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies([x_plus_1]):</span><br><span class="line">    y = x</span><br><span class="line">    <span class="comment">#y = tf.identity(x)</span></span><br><span class="line"></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;y=&#x27;</span>,y.<span class="built_in">eval</span>())</span><br><span class="line">        </span><br><span class="line"><span class="comment">#y= 1.0</span></span><br><span class="line"><span class="comment">#y= 1.0</span></span><br><span class="line"><span class="comment">#y= 1.0</span></span><br><span class="line"><span class="comment">#y= 1.0</span></span><br><span class="line"><span class="comment">#y= 1.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x = tf.Variable(<span class="number">1.0</span>)</span><br><span class="line">x_plus_1 = tf.assign_add(x, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies([x_plus_1]):</span><br><span class="line">    y = tf.identity(x)</span><br><span class="line"></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">    init.run()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;y=&#x27;</span>,y.<span class="built_in">eval</span>())</span><br><span class="line"></span><br><span class="line"><span class="comment">#y= 2.0</span></span><br><span class="line"><span class="comment">#y= 3.0</span></span><br><span class="line"><span class="comment">#y= 4.0</span></span><br><span class="line"><span class="comment">#y= 5.0</span></span><br><span class="line"><span class="comment">#y= 6.0        </span></span><br></pre></td></tr></table></figure>
<h1 id="TensorFlow入门12-—-Checkpoints，保存和恢复Estimator创建的模型"><a href="#TensorFlow入门12-—-Checkpoints，保存和恢复Estimator创建的模型" class="headerlink" title="TensorFlow入门12 — Checkpoints，保存和恢复Estimator创建的模型"></a>TensorFlow入门12 — Checkpoints，保存和恢复Estimator创建的模型</h1><p>参考 <a href="https://www.jianshu.com/p/60c3b084fe44">https://www.jianshu.com/p/60c3b084fe44</a></p>
<p>模型训练好了后，下一步就是保存（Save）和恢复（restore）模型，TensorFlow提供两种模型格式（Model Format）</p>
<p>1，Checkpoints, 该格式依赖于创建模型的代码.</p>
<p>2，SavedModel, 该格式不依赖于创建模型的代码.</p>
<p>本文主要讨论检查点(Checkpoint).</p>
<p>如《<a href="https://www.jianshu.com/p/4e1d4bfd056d">从数据的角度理解TensorFlow鸢尾花分类程序6</a>》一文所述，在创建tf.estimator.DNNClassifier对象时，其构造函数<strong>init</strong>有一个参数：</p>
<p><strong>model_dir：</strong>保存模型参数的路径。（Directory to save model parameters, graph and etc. This can also be used to load checkpoints from the directory into a estimator to continue training a previously saved model.）</p>
<p>a.当没有指定的时候，Estimator 会将检查点文件写入由 Python 的 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdocs.python.org%2F3%2Flibrary%2Ftempfile.html%23tempfile.mkdtemp">tempfile.mkdtemp</a>函数选择的临时目录中。用语句 print(tempfile.gettempdir())可以查出本机的临时目录</p>
<p><img src="https:////upload-images.jianshu.io/upload_images/10758717-617d15c988fca257.png?imageMogr2/auto-orient/strip|imageView2/2/w/704/format/webp" alt="img"></p>
<p>tempfile.gettempdir</p>
<p>b.当指定了目录的时候，例如：<em>model_dir = ‘models/iris’</em>，Estimator 会将检查点文件写入~/models/iris</p>
<p><img src="https:////upload-images.jianshu.io/upload_images/10758717-ede38dbd30efd3c9.png?imageMogr2/auto-orient/strip|imageView2/2/w/1074/format/webp" alt="img"></p>
<p>有了保存检查点文件路径后，tf.estimator.DNNClassifier对象会在<strong>运行train方法的时候，写入检查点文件，</strong>如下图所示：</p>
<p><img src="https:////upload-images.jianshu.io/upload_images/10758717-82fde1420900d6b5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>train方法负责写入检查点文件</p>
<p><strong>那train方法以什么频率写入检查点文件呢？</strong></p>
<p>默认情况下，Estimator 按照以下时间安排将<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdevelopers.google.com%2Fmachine-learning%2Fglossary%2F%23checkpoint">检查点</a>保存到 model_dir 中：</p>
<p>a.每 10 分钟（600 秒）写入一个检查点。</p>
<p>b.在 train 方法开始（第一次迭代）和完成（最后一次迭代）时写入一个检查点。</p>
<p>c.只在目录中保留 5 个最近写入的检查点。</p>
<p><strong>保存好检查点文件后，如何恢复模型呢？</strong></p>
<p>Estimator 将一个检查点保存到 model_dir 中后，每次调用 Estimator 的 train、eval 或 predict 方法时，都会发生下列情况：</p>
<p>a) Estimator 通过运行 model_fn() 构建模型<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdevelopers.google.com%2Fmachine-learning%2Fglossary%2F%23graph">图</a>。（要详细了解 model_fn()，请参阅<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.tensorflow.org%2Fget_started%2Fcustom_estimators">创建自定义 Estimator</a>。）</p>
<p>b) Estimator 根据最近写入的检查点中存储的数据来初始化新模型的权重。</p>
<p>换言之，如下图所示，一旦存在检查点，TensorFlow 就会在您每次调用 train()、evaluate() 或 predict() 时重建模型。</p>
<p><img src="https:////upload-images.jianshu.io/upload_images/10758717-d5376e32b383d1de.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong>不当恢复</strong></p>
<p>通过检查点恢复模型的状态这一操作<strong>仅在模型和检查点兼容时可行</strong>。例如，假设训练了一个 tf.estimator.DNNClassifier，它包含 2 个隐藏层且每层都有 10 个节点；在训练之后（TensorFlow已在 models/iris 中创建检查点），将每个隐藏层中的神经元数量从 10 更改为 3，然后重新训练模型，由于检查点中的状态与 修改后tf.estimator.DNNClassifier 中描述的模型不兼容，因此重新训练失败并出现以下错误，如下图所示：</p>
<p><img src="https:////upload-images.jianshu.io/upload_images/10758717-66ba8e48437be765.PNG?imageMogr2/auto-orient/strip|imageView2/2/w/976/format/webp" alt="img"></p>
<p>不当恢复</p>
<p><strong>解决不当恢复</strong></p>
<p>1，当模型参数一直在变化的时候，最简单的方式是，不要指定<em>model_dir，</em>这样TensorFlow不会启动Checkpoint模型恢复，方便你随时修改模型。</p>
<p>2，启动Checkpoint的情况下，用Git为每个 model-dir 所需的代码保存一个副本，即为每个模型版本创建一个单独的 git 分支。这种区分将有助于保证检查点的可恢复性。</p>
<p><strong>总结</strong>：检查点提供了一种简单的自动机制来保存和恢复由 Estimator 创建的模型。</p>
<h1 id="分布式训练"><a href="#分布式训练" class="headerlink" title="分布式训练"></a>分布式训练</h1><ul>
<li>ps: Parameter Sever, 参数服务器</li>
<li>chief: ps-worker架构中的主节点</li>
<li>worker: 正常训练节点</li>
<li>evaluator: 评估节点，不参与训练，只用来进行训练数据评估</li>
</ul>
<h1 id="记录timeline-tf-train-ProfilerHook"><a href="#记录timeline-tf-train-ProfilerHook" class="headerlink" title="记录timeline-tf.train.ProfilerHook"></a>记录timeline-tf.train.ProfilerHook</h1><p>通过ProfilerHook对tensor代码中的各个节点耗时情况进行分析</p>
<p><a href="https://zhuanlan.zhihu.com/p/147319531">https://zhuanlan.zhihu.com/p/147319531</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_and_eval</span>(<span class="params">model</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param model: 声明的estimator实例</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    :usage: 进行模型训练，并在指定步长的时候进行结果评估</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    timeline_hook = tf.train.ProfilerHook(save_steps=<span class="number">100</span>, output_dir=os.path.join(</span><br><span class="line">            os.getcwd(), <span class="string">&#x27;./timeline_track&#x27;</span></span><br><span class="line">        ))</span><br><span class="line"></span><br><span class="line">    hook = tf.contrib.estimator.stop_if_no_increase_hook(</span><br><span class="line">        model,</span><br><span class="line">        metric_name=<span class="string">&#x27;ctcvr_cvr_auc_esmm&#x27;</span>,</span><br><span class="line">        max_steps_without_increase=configuration_params[<span class="string">&#x27;max_steps_without_increase&#x27;</span>],</span><br><span class="line">        <span class="comment"># maximum number of training steps with no decrease in the given metric.</span></span><br><span class="line">        min_steps=configuration_params[<span class="string">&#x27;min_steps&#x27;</span>],  <span class="comment"># stop is never requested if global step is less than this value</span></span><br><span class="line">        run_every_steps=configuration_params[<span class="string">&#x27;run_every_steps&#x27;</span>],</span><br><span class="line">        run_every_secs=<span class="literal">None</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    train_spec = tf.estimator.TrainSpec(</span><br><span class="line">        input_fn=<span class="keyword">lambda</span>: input_fn(os.path.join(os.getcwd(),</span><br><span class="line">                                               CONFIG_TRAIN[<span class="string">&#x27;train_data&#x27;</span>]),</span><br><span class="line">                                  <span class="string">&#x27;train&#x27;</span>, CONFIG_TRAIN[<span class="string">&#x27;batch_size&#x27;</span>]),</span><br><span class="line">        hooks=[hook, timeline_hook]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    eval_spec = tf.estimator.EvalSpec(</span><br><span class="line">        input_fn=<span class="keyword">lambda</span>: input_fn(os.path.join(os.getcwd(),</span><br><span class="line">                                               CONFIG_TRAIN[<span class="string">&#x27;test_data&#x27;</span>]),</span><br><span class="line">                                  <span class="string">&#x27;eval&#x27;</span>, <span class="number">128</span>),</span><br><span class="line">        steps=CONFIG.evalconfig[<span class="string">&#x27;steps&#x27;</span>],</span><br><span class="line">        throttle_secs=<span class="number">30</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    tf.estimator.train_and_evaluate(model, train_spec, eval_spec)</span><br></pre></td></tr></table></figure>
<p>timeline.json：每个保存步长输出的监控文件</p>
<ul>
<li><p>web展示</p>
<ol>
<li><p>在chrome中打开“chome://tracing”页面</p>
<p><img src="https://pic4.zhimg.com/80/v2-cfed5df9f0c6ae2d180e7b8c65ed233b_720w.jpg" alt="img"></p>
</li>
</ol>
</li>
</ul>
<ul>
<li><ul>
<li>点击“load”，将上一步中生成time-line.json文件导入，导入任意一个即可</li>
<li>输出结果如下：</li>
</ul>
</li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-5dd2ee82f762b8fa9ef2a64e631f9cf1_720w.jpg" alt="img"></p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>tensorflow常用函数</title>
    <url>/2022/03/24/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/tensorflow%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p>tensorflow常用的一些函数</p>
<span id="more"></span>
<h2 id="mask和padding"><a href="#mask和padding" class="headerlink" title="mask和padding"></a>mask和padding</h2><h2 id="矩阵分割与合并"><a href="#矩阵分割与合并" class="headerlink" title="矩阵分割与合并"></a>矩阵分割与合并</h2><h3 id="tf-split"><a href="#tf-split" class="headerlink" title="tf.split()"></a>tf.split()</h3><h3 id="tf-stack"><a href="#tf-stack" class="headerlink" title="tf.stack()"></a>tf.stack()</h3><h3 id="tf-reshape"><a href="#tf-reshape" class="headerlink" title="tf.reshape()"></a>tf.reshape()</h3><h3 id="tf-contrib-lookup-index-table-from-file"><a href="#tf-contrib-lookup-index-table-from-file" class="headerlink" title="tf.contrib.lookup.index_table_from_file()"></a>tf.contrib.lookup.index_table_from_file()</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//vocab.tags.txt</span><br><span class="line">poi</span><br><span class="line">query</span><br><span class="line">spu</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">features = tf.constant([<span class="string">&#x27;poi&#x27;</span>, <span class="string">&#x27;query&#x27;</span>, <span class="string">&#x27;spu&#x27;</span>,<span class="string">&#x27;haha&#x27;</span>])</span><br><span class="line">reverse_vocab_tags = tf.contrib.lookup.index_table_from_file(</span><br><span class="line">  <span class="string">&#x27;vocab.tags.txt&#x27;</span>, key_dtype=tf.string</span><br><span class="line">  , num_oov_buckets=<span class="number">100</span>,)</span><br><span class="line"></span><br><span class="line">values = reverse_vocab_tags.lookup(features)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  tf.tables_initializer().run()</span><br><span class="line">  <span class="built_in">print</span>(values.<span class="built_in">eval</span>())</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>iterm奇淫技巧</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/iterm%E5%A5%87%E6%B7%AB%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<p>item 配置</p>
<span id="more"></span>
<h1 id="1-修改tag名称"><a href="#1-修改tag名称" class="headerlink" title="1.修改tag名称"></a>1.修改tag名称</h1><p>快捷键 ： command+i  ，修改session name。</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/iterm%E5%A5%87%E6%B7%AB%E6%8A%80%E5%B7%A7/iterm奇淫技巧/image-20210901114300463.png" alt="image-20210901114300463" style="zoom:25%;"></p>
<p>右键-new tag 现在的tag就能显示自定义名称</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/iterm%E5%A5%87%E6%B7%AB%E6%8A%80%E5%B7%A7/iterm奇淫技巧/image-20210901114353748.png" alt="image-20210901114353748" style="zoom:25%;"></p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>typora主题</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/typora%E4%B8%BB%E9%A2%98/</url>
    <content><![CDATA[<p>typora主题自动编号配置</p>
<span id="more"></span>
<p>[TOC]</p>
<p><a href="https://pastebin.com/NYugSbXk">https://pastebin.com/NYugSbXk</a></p>
<h1 id="typora主题"><a href="#typora主题" class="headerlink" title="typora主题"></a>typora主题</h1><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-pseudo">:root</span> &#123;</span><br><span class="line">    --side-bar-bg-<span class="attribute">color</span>: <span class="number">#fff</span>;</span><br><span class="line">    --control-text-<span class="attribute">color</span>: <span class="number">#777</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* cyrillic-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Roboto Mono&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Roboto Mono&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;RobotoMono-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/L0x5DF4xlVMF-BfR8bXMIjhGq3-cXbKDO1w.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0460</span>-<span class="number">052</span>F, U+<span class="number">1</span>C80-<span class="number">1</span>C88, U+<span class="number">20</span>B4, U+<span class="number">2</span>DE0-<span class="number">2</span>DFF, U+A640-A69F, U+FE2E-FE2F;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* cyrillic */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Roboto Mono&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Roboto Mono&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;RobotoMono-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/L0x5DF4xlVMF-BfR8bXMIjhPq3-cXbKDO1w.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0400</span>-<span class="number">045</span>F, U+<span class="number">0490</span>-<span class="number">0491</span>, U+<span class="number">04</span>B0-<span class="number">04</span>B1, U+<span class="number">2116</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* greek-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Roboto Mono&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Roboto Mono&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;RobotoMono-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/L0x5DF4xlVMF-BfR8bXMIjhHq3-cXbKDO1w.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">1</span>F00-<span class="number">1</span>FFF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* greek */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Roboto Mono&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Roboto Mono&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;RobotoMono-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/L0x5DF4xlVMF-BfR8bXMIjhIq3-cXbKDO1w.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0370</span>-<span class="number">03</span>FF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* vietnamese */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Roboto Mono&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Roboto Mono&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;RobotoMono-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/L0x5DF4xlVMF-BfR8bXMIjhEq3-cXbKDO1w.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0102</span>-<span class="number">0103</span>, U+<span class="number">0110</span>-<span class="number">0111</span>, U+<span class="number">1</span>EA0-<span class="number">1</span>EF9, U+<span class="number">20</span>AB;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* latin-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Roboto Mono&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Roboto Mono&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;RobotoMono-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/L0x5DF4xlVMF-BfR8bXMIjhFq3-cXbKDO1w.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0100</span>-<span class="number">024</span>F, U+<span class="number">0259</span>, U+<span class="number">1</span>E00-<span class="number">1</span>EFF, U+<span class="number">2020</span>, U+<span class="number">20</span>A0-<span class="number">20</span>AB, U+<span class="number">20</span>AD-<span class="number">20</span>CF, U+<span class="number">2113</span>, U+<span class="number">2</span>C60-<span class="number">2</span>C7F, U+A720-A7FF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* latin */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Roboto Mono&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Roboto Mono&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;RobotoMono-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/L0x5DF4xlVMF-BfR8bXMIjhLq3-cXbKD.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0000</span>-<span class="number">00</span>FF, U+<span class="number">0131</span>, U+<span class="number">0152</span>-<span class="number">0153</span>, U+<span class="number">02</span>BB-<span class="number">02</span>BC, U+<span class="number">02</span>C6, U+<span class="number">02</span>DA, U+<span class="number">02</span>DC, U+<span class="number">2000</span>-<span class="number">206</span>F, U+<span class="number">2074</span>, U+<span class="number">20</span>AC, U+<span class="number">2122</span>, U+<span class="number">2191</span>, U+<span class="number">2193</span>, U+<span class="number">2212</span>, U+<span class="number">2215</span>, U+FEFF, U+FFFD;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* cyrillic-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Light&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Light&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmhduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0460</span>-<span class="number">052</span>F, U+<span class="number">1</span>C80-<span class="number">1</span>C88, U+<span class="number">20</span>B4, U+<span class="number">2</span>DE0-<span class="number">2</span>DFF, U+A640-A69F, U+FE2E-FE2F;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* cyrillic */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Light&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Light&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwkxduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0400</span>-<span class="number">045</span>F, U+<span class="number">0490</span>-<span class="number">0491</span>, U+<span class="number">04</span>B0-<span class="number">04</span>B1, U+<span class="number">2116</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* greek-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Light&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Light&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmxduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">1</span>F00-<span class="number">1</span>FFF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* greek */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Light&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Light&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwlBduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0370</span>-<span class="number">03</span>FF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* vietnamese */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Light&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Light&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmBduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0102</span>-<span class="number">0103</span>, U+<span class="number">0110</span>-<span class="number">0111</span>, U+<span class="number">1</span>EA0-<span class="number">1</span>EF9, U+<span class="number">20</span>AB;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* latin-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Light&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Light&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwmRduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0100</span>-<span class="number">024</span>F, U+<span class="number">0259</span>, U+<span class="number">1</span>E00-<span class="number">1</span>EFF, U+<span class="number">2020</span>, U+<span class="number">20</span>A0-<span class="number">20</span>AB, U+<span class="number">20</span>AD-<span class="number">20</span>CF, U+<span class="number">2113</span>, U+<span class="number">2</span>C60-<span class="number">2</span>C7F, U+A720-A7FF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* latin */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">300</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Light&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Light&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwlxdu.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0000</span>-<span class="number">00</span>FF, U+<span class="number">0131</span>, U+<span class="number">0152</span>-<span class="number">0153</span>, U+<span class="number">02</span>BB-<span class="number">02</span>BC, U+<span class="number">02</span>C6, U+<span class="number">02</span>DA, U+<span class="number">02</span>DC, U+<span class="number">2000</span>-<span class="number">206</span>F, U+<span class="number">2074</span>, U+<span class="number">20</span>AC, U+<span class="number">2122</span>, U+<span class="number">2191</span>, U+<span class="number">2193</span>, U+<span class="number">2212</span>, U+<span class="number">2215</span>, U+FEFF, U+FFFD;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* cyrillic-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Regular&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNa7lqDY.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0460</span>-<span class="number">052</span>F, U+<span class="number">1</span>C80-<span class="number">1</span>C88, U+<span class="number">20</span>B4, U+<span class="number">2</span>DE0-<span class="number">2</span>DFF, U+A640-A69F, U+FE2E-FE2F;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* cyrillic */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Regular&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qPK7lqDY.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0400</span>-<span class="number">045</span>F, U+<span class="number">0490</span>-<span class="number">0491</span>, U+<span class="number">04</span>B0-<span class="number">04</span>B1, U+<span class="number">2116</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* greek-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Regular&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNK7lqDY.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">1</span>F00-<span class="number">1</span>FFF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* greek */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Regular&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qO67lqDY.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0370</span>-<span class="number">03</span>FF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* vietnamese */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Regular&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qN67lqDY.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0102</span>-<span class="number">0103</span>, U+<span class="number">0110</span>-<span class="number">0111</span>, U+<span class="number">1</span>EA0-<span class="number">1</span>EF9, U+<span class="number">20</span>AB;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* latin-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Regular&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qNq7lqDY.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0100</span>-<span class="number">024</span>F, U+<span class="number">0259</span>, U+<span class="number">1</span>E00-<span class="number">1</span>EFF, U+<span class="number">2020</span>, U+<span class="number">20</span>A0-<span class="number">20</span>AB, U+<span class="number">20</span>AD-<span class="number">20</span>CF, U+<span class="number">2113</span>, U+<span class="number">2</span>C60-<span class="number">2</span>C7F, U+A720-A7FF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* latin */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">400</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro Regular&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-Regular&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7l.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0000</span>-<span class="number">00</span>FF, U+<span class="number">0131</span>, U+<span class="number">0152</span>-<span class="number">0153</span>, U+<span class="number">02</span>BB-<span class="number">02</span>BC, U+<span class="number">02</span>C6, U+<span class="number">02</span>DA, U+<span class="number">02</span>DC, U+<span class="number">2000</span>-<span class="number">206</span>F, U+<span class="number">2074</span>, U+<span class="number">20</span>AC, U+<span class="number">2122</span>, U+<span class="number">2191</span>, U+<span class="number">2193</span>, U+<span class="number">2212</span>, U+<span class="number">2215</span>, U+FEFF, U+FFFD;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* cyrillic-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">600</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro SemiBold&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-SemiBold&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmhduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0460</span>-<span class="number">052</span>F, U+<span class="number">1</span>C80-<span class="number">1</span>C88, U+<span class="number">20</span>B4, U+<span class="number">2</span>DE0-<span class="number">2</span>DFF, U+A640-A69F, U+FE2E-FE2F;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* cyrillic */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">600</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro SemiBold&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-SemiBold&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwkxduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0400</span>-<span class="number">045</span>F, U+<span class="number">0490</span>-<span class="number">0491</span>, U+<span class="number">04</span>B0-<span class="number">04</span>B1, U+<span class="number">2116</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* greek-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">600</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro SemiBold&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-SemiBold&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmxduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">1</span>F00-<span class="number">1</span>FFF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* greek */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">600</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro SemiBold&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-SemiBold&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlBduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0370</span>-<span class="number">03</span>FF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* vietnamese */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">600</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro SemiBold&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-SemiBold&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmBduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0102</span>-<span class="number">0103</span>, U+<span class="number">0110</span>-<span class="number">0111</span>, U+<span class="number">1</span>EA0-<span class="number">1</span>EF9, U+<span class="number">20</span>AB;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* latin-ext */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">600</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro SemiBold&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-SemiBold&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwmRduz8A.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0100</span>-<span class="number">024</span>F, U+<span class="number">0259</span>, U+<span class="number">1</span>E00-<span class="number">1</span>EFF, U+<span class="number">2020</span>, U+<span class="number">20</span>A0-<span class="number">20</span>AB, U+<span class="number">20</span>AD-<span class="number">20</span>CF, U+<span class="number">2113</span>, U+<span class="number">2</span>C60-<span class="number">2</span>C7F, U+A720-A7FF;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* latin */</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&#x27;Source Sans Pro&#x27;</span>;</span><br><span class="line">    <span class="attribute">font-style</span>: normal;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">600</span>;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">local</span>(<span class="string">&#x27;Source Sans Pro SemiBold&#x27;</span>), <span class="built_in">local</span>(<span class="string">&#x27;SourceSansPro-SemiBold&#x27;</span>), <span class="built_in">url</span>(<span class="string">&#x27;vue/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlxdu.woff2&#x27;</span>) <span class="built_in">format</span>(<span class="string">&#x27;woff2&#x27;</span>);</span><br><span class="line">    unicode-range: U+<span class="number">0000</span>-<span class="number">00</span>FF, U+<span class="number">0131</span>, U+<span class="number">0152</span>-<span class="number">0153</span>, U+<span class="number">02</span>BB-<span class="number">02</span>BC, U+<span class="number">02</span>C6, U+<span class="number">02</span>DA, U+<span class="number">02</span>DC, U+<span class="number">2000</span>-<span class="number">206</span>F, U+<span class="number">2074</span>, U+<span class="number">20</span>AC, U+<span class="number">2122</span>, U+<span class="number">2191</span>, U+<span class="number">2193</span>, U+<span class="number">2212</span>, U+<span class="number">2215</span>, U+FEFF, U+FFFD;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">html</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">16px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">body</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: Source Sans Pro, Helvetica Neue, Arial, sans-serif <span class="meta">!important</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#34495e</span>;</span><br><span class="line">    -webkit-<span class="attribute">font-smoothing</span>: antialiased;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">1.6rem</span>;</span><br><span class="line">    <span class="attribute">letter-spacing</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">overflow-x</span>: hidden;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> &#123;</span><br><span class="line">    <span class="attribute">max-width</span>: <span class="number">860px</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span> auto;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">20px</span> <span class="number">30px</span> <span class="number">100px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">p</span> &#123;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">1.6rem</span>;</span><br><span class="line">    <span class="attribute">word-spacing</span>: .<span class="number">05rem</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">ol</span> <span class="selector-tag">li</span> &#123;</span><br><span class="line">    <span class="attribute">text-indent</span>: <span class="number">0.5rem</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> &gt; <span class="selector-tag">ul</span><span class="selector-pseudo">:first</span>-child,</span><br><span class="line"><span class="selector-id">#write</span> &gt; <span class="selector-tag">ol</span><span class="selector-pseudo">:first</span>-child &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">30px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">body</span> &gt; *<span class="selector-pseudo">:first</span>-child &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">0</span> <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">body</span> &gt; *<span class="selector-pseudo">:last-child</span> &#123;</span><br><span class="line">    <span class="attribute">margin-bottom</span>: <span class="number">0</span> <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">a</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#42b983</span>;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">600</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span> <span class="number">2px</span>;</span><br><span class="line">    <span class="attribute">text-decoration</span>: none;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h1</span>,</span><br><span class="line"><span class="selector-tag">h2</span>,</span><br><span class="line"><span class="selector-tag">h3</span>,</span><br><span class="line"><span class="selector-tag">h4</span>,</span><br><span class="line"><span class="selector-tag">h5</span>,</span><br><span class="line"><span class="selector-tag">h6</span> &#123;</span><br><span class="line">    <span class="attribute">position</span>: relative;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">1rem</span>;</span><br><span class="line">    <span class="attribute">margin-bottom</span>: <span class="number">1rem</span>;</span><br><span class="line">    <span class="attribute">font-weight</span>: bold;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">1.4</span>;</span><br><span class="line">    <span class="attribute">cursor</span>: text;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h1</span><span class="selector-pseudo">:hover</span> <span class="selector-tag">a</span><span class="selector-class">.anchor</span>,</span><br><span class="line"><span class="selector-tag">h2</span><span class="selector-pseudo">:hover</span> <span class="selector-tag">a</span><span class="selector-class">.anchor</span>,</span><br><span class="line"><span class="selector-tag">h3</span><span class="selector-pseudo">:hover</span> <span class="selector-tag">a</span><span class="selector-class">.anchor</span>,</span><br><span class="line"><span class="selector-tag">h4</span><span class="selector-pseudo">:hover</span> <span class="selector-tag">a</span><span class="selector-class">.anchor</span>,</span><br><span class="line"><span class="selector-tag">h5</span><span class="selector-pseudo">:hover</span> <span class="selector-tag">a</span><span class="selector-class">.anchor</span>,</span><br><span class="line"><span class="selector-tag">h6</span><span class="selector-pseudo">:hover</span> <span class="selector-tag">a</span><span class="selector-class">.anchor</span> &#123;</span><br><span class="line">    <span class="attribute">text-decoration</span>: none;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h1</span> tt,</span><br><span class="line"><span class="selector-tag">h1</span> <span class="selector-tag">code</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: inherit <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h2</span> tt,</span><br><span class="line"><span class="selector-tag">h2</span> <span class="selector-tag">code</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: inherit <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h3</span> tt,</span><br><span class="line"><span class="selector-tag">h3</span> <span class="selector-tag">code</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: inherit <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h4</span> tt,</span><br><span class="line"><span class="selector-tag">h4</span> <span class="selector-tag">code</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: inherit <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h5</span> tt,</span><br><span class="line"><span class="selector-tag">h5</span> <span class="selector-tag">code</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: inherit <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h6</span> tt,</span><br><span class="line"><span class="selector-tag">h6</span> <span class="selector-tag">code</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: inherit <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h2</span> <span class="selector-tag">a</span>,</span><br><span class="line"><span class="selector-tag">h3</span> <span class="selector-tag">a</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#34495e</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h1</span> &#123;</span><br><span class="line">   <span class="comment">/*padding-bottom:0rem;</span></span><br><span class="line"><span class="comment">   color:#165f60;*/</span></span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">1.5rem</span>;</span><br><span class="line">    <span class="attribute">line-height</span>:<span class="number">1.5rem</span>;</span><br><span class="line">    <span class="attribute">border-bottom</span>: <span class="number">1px</span> solid <span class="number">#ddd</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h2</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">1.4rem</span>;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">1.4rem</span>;</span><br><span class="line">    <span class="comment">/*margin: 35px 0 15px;</span></span><br><span class="line"><span class="comment">    padding-bottom: 0.5em;</span></span><br><span class="line"><span class="comment">    border-bottom: 1px solid #ddd;*/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h3</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">1.2rem</span>;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">1.2rem</span>;</span><br><span class="line">    <span class="comment">/*margin: 20px 0 7px;*/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h4</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">1rem</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h5</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">1rem</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h6</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">1rem</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#777</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">p</span>,</span><br><span class="line"><span class="selector-tag">blockquote</span>,</span><br><span class="line"><span class="selector-tag">ul</span>,</span><br><span class="line"><span class="selector-tag">ol</span>,</span><br><span class="line"><span class="selector-tag">dl</span>,</span><br><span class="line"><span class="selector-tag">table</span> &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0.8em</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">li</span> &gt; <span class="selector-tag">ol</span>,</span><br><span class="line"><span class="selector-tag">li</span> &gt; <span class="selector-tag">ul</span> &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">hr &#123;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">2px</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">16px</span> <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#e7e7e7</span>;</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">0</span> none;</span><br><span class="line">    <span class="attribute">overflow</span>: hidden;</span><br><span class="line">    <span class="attribute">box-sizing</span>: content-box;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">body</span> &gt; <span class="selector-tag">h2</span><span class="selector-pseudo">:first</span>-child &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding-top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">body</span> &gt; <span class="selector-tag">h1</span><span class="selector-pseudo">:first</span>-child &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding-top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">body</span> &gt; <span class="selector-tag">h1</span><span class="selector-pseudo">:first</span>-child + <span class="selector-tag">h2</span> &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding-top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">body</span> &gt; <span class="selector-tag">h3</span><span class="selector-pseudo">:first</span>-child,</span><br><span class="line"><span class="selector-tag">body</span> &gt; <span class="selector-tag">h4</span><span class="selector-pseudo">:first</span>-child,</span><br><span class="line"><span class="selector-tag">body</span> &gt; <span class="selector-tag">h5</span><span class="selector-pseudo">:first</span>-child,</span><br><span class="line"><span class="selector-tag">body</span> &gt; <span class="selector-tag">h6</span><span class="selector-pseudo">:first</span>-child &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding-top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">a</span><span class="selector-pseudo">:first</span>-child <span class="selector-tag">h1</span>,</span><br><span class="line"><span class="selector-tag">a</span><span class="selector-pseudo">:first</span>-child <span class="selector-tag">h2</span>,</span><br><span class="line"><span class="selector-tag">a</span><span class="selector-pseudo">:first</span>-child <span class="selector-tag">h3</span>,</span><br><span class="line"><span class="selector-tag">a</span><span class="selector-pseudo">:first</span>-child <span class="selector-tag">h4</span>,</span><br><span class="line"><span class="selector-tag">a</span><span class="selector-pseudo">:first</span>-child <span class="selector-tag">h5</span>,</span><br><span class="line"><span class="selector-tag">a</span><span class="selector-pseudo">:first</span>-child <span class="selector-tag">h6</span> &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding-top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h1</span> <span class="selector-tag">p</span>,</span><br><span class="line"><span class="selector-tag">h2</span> <span class="selector-tag">p</span>,</span><br><span class="line"><span class="selector-tag">h3</span> <span class="selector-tag">p</span>,</span><br><span class="line"><span class="selector-tag">h4</span> <span class="selector-tag">p</span>,</span><br><span class="line"><span class="selector-tag">h5</span> <span class="selector-tag">p</span>,</span><br><span class="line"><span class="selector-tag">h6</span> <span class="selector-tag">p</span> &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">li</span> <span class="selector-tag">p</span><span class="selector-class">.first</span> &#123;</span><br><span class="line">    <span class="attribute">display</span>: inline-block;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">ul</span>,</span><br><span class="line"><span class="selector-tag">ol</span> &#123;</span><br><span class="line">    <span class="attribute">padding-left</span>: <span class="number">30px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">ul</span><span class="selector-pseudo">:first</span>-child,</span><br><span class="line"><span class="selector-tag">ol</span><span class="selector-pseudo">:first</span>-child &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">ul</span><span class="selector-pseudo">:last-child</span>,</span><br><span class="line"><span class="selector-tag">ol</span><span class="selector-pseudo">:last-child</span> &#123;</span><br><span class="line">    <span class="attribute">margin-bottom</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">blockquote</span> &#123;</span><br><span class="line">    <span class="attribute">border-left</span>: <span class="number">4px</span> solid <span class="number">#42b983</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">10px</span> <span class="number">15px</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#777</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="built_in">rgba</span>(<span class="number">66</span>, <span class="number">185</span>, <span class="number">131</span>, .<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">table</span> &#123;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">word-break</span>: initial;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">table</span> <span class="selector-tag">tr</span> &#123;</span><br><span class="line">    <span class="attribute">border-top</span>: <span class="number">1px</span> solid <span class="number">#dfe2e5</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">table</span> <span class="selector-tag">tr</span><span class="selector-pseudo">:nth-child</span>(<span class="number">2</span>n),</span><br><span class="line"><span class="selector-tag">thead</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#fafafa</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">table</span> <span class="selector-tag">tr</span> <span class="selector-tag">th</span> &#123;</span><br><span class="line">    <span class="attribute">font-weight</span>: bold;</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">1px</span> solid <span class="number">#dfe2e5</span>;</span><br><span class="line">    <span class="attribute">border-bottom</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">text-align</span>: left;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">6px</span> <span class="number">13px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">table</span> <span class="selector-tag">tr</span> <span class="selector-tag">td</span> &#123;</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">1px</span> solid <span class="number">#dfe2e5</span>;</span><br><span class="line">    <span class="attribute">text-align</span>: left;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">6px</span> <span class="number">13px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">table</span> <span class="selector-tag">tr</span> <span class="selector-tag">th</span><span class="selector-pseudo">:first</span>-child,</span><br><span class="line"><span class="selector-tag">table</span> <span class="selector-tag">tr</span> <span class="selector-tag">td</span><span class="selector-pseudo">:first</span>-child &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">table</span> <span class="selector-tag">tr</span> <span class="selector-tag">th</span><span class="selector-pseudo">:last-child</span>,</span><br><span class="line"><span class="selector-tag">table</span> <span class="selector-tag">tr</span> <span class="selector-tag">td</span><span class="selector-pseudo">:last-child</span> &#123;</span><br><span class="line">    <span class="attribute">margin-bottom</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">strong</span> &#123;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span> <span class="number">1px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">em</span> &#123;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span> <span class="number">5px</span> <span class="number">0</span> <span class="number">2px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">table</span> <span class="selector-tag">thead</span> <span class="selector-tag">th</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#f2f2f2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-class">.CodeMirror-gutters</span> &#123;</span><br><span class="line">    <span class="attribute">border-right</span>: none;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-class">.md-fences</span> &#123;</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">1px</span> solid <span class="number">#F4F4F4</span>;</span><br><span class="line">    -webkit-<span class="attribute">font-smoothing</span>: initial;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0.8rem</span> <span class="number">0</span> <span class="meta">!important</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0.3rem</span> <span class="number">0</span> <span class="meta">!important</span>;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">1.43rem</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#F8F8F8</span> <span class="meta">!important</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">2px</span>;</span><br><span class="line">    <span class="attribute">font-family</span>: Roboto Mono, Source Sans Pro, Monaco, courier, monospace <span class="meta">!important</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">0.85rem</span>;</span><br><span class="line">    <span class="attribute">word-wrap</span>: normal;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-class">.CodeMirror-wrap</span> <span class="selector-class">.CodeMirror-code</span> pre &#123;</span><br><span class="line">    <span class="attribute">padding-left</span>: <span class="number">12px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">code</span>, tt &#123;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span> <span class="number">2px</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">2px</span> <span class="number">4px</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">2px</span>;</span><br><span class="line">    <span class="attribute">font-family</span>: Roboto Mono, Source Sans Pro, Monaco, courier, monospace <span class="meta">!important</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">0.92rem</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#e96900</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#f8f8f8</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-class">.md-footnote</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#f8f8f8</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#e96900</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* heighlight. */</span></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">mark</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#EBFFEB</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">2px</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">2px</span> <span class="number">4px</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">0</span> <span class="number">2px</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#222</span>;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">500</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">del</span> &#123;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">1px</span> <span class="number">2px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-inner</span> <span class="selector-class">.cm-link</span>,</span><br><span class="line"><span class="selector-class">.cm-s-inner</span><span class="selector-class">.cm-link</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#22a2c9</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.cm-s-inner</span> <span class="selector-class">.cm-string</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#22a2c9</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-task-list-item</span> &gt; <span class="selector-tag">input</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: -<span class="number">1.3em</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">@media</span> print &#123;</span><br><span class="line">    <span class="selector-tag">html</span> &#123;</span><br><span class="line">        <span class="attribute">font-size</span>: <span class="number">13px</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="selector-tag">table</span>,</span><br><span class="line">    pre &#123;</span><br><span class="line">        <span class="attribute">page-break-inside</span>: avoid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    pre &#123;</span><br><span class="line">        <span class="attribute">word-wrap</span>: break-word;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-fences</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#f8f8f8</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> pre<span class="selector-class">.md-meta-block</span> &#123;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">1rem</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">85%</span>;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">1.45</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#f7f7f7</span>;</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">3px</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#777777</span>;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">0</span> <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.mathjax-block</span> &gt; <span class="selector-class">.code-tooltip</span> &#123;</span><br><span class="line">    <span class="attribute">bottom</span>: .<span class="number">375rem</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> &gt; <span class="selector-tag">h3</span><span class="selector-class">.md-focus</span>:before &#123;</span><br><span class="line">    left: -<span class="number">1.5625rem</span>;</span><br><span class="line">    <span class="attribute">top</span>: .<span class="number">375rem</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> &gt; <span class="selector-tag">h4</span><span class="selector-class">.md-focus</span>:before &#123;</span><br><span class="line">    left: -<span class="number">1.5625rem</span>;</span><br><span class="line">    <span class="attribute">top</span>: .<span class="number">285714286rem</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> &gt; <span class="selector-tag">h5</span><span class="selector-class">.md-focus</span>:before &#123;</span><br><span class="line">    left: -<span class="number">1.5625rem</span>;</span><br><span class="line">    <span class="attribute">top</span>: .<span class="number">285714286rem</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> &gt; <span class="selector-tag">h6</span><span class="selector-class">.md-focus</span>:before &#123;</span><br><span class="line">    left: -<span class="number">1.5625rem</span>;</span><br><span class="line">    <span class="attribute">top</span>: .<span class="number">285714286rem</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-image</span> &gt; <span class="selector-class">.md-meta</span> &#123;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">3px</span>;</span><br><span class="line">    <span class="attribute">font-family</span>: Consolas, <span class="string">&quot;Liberation Mono&quot;</span>, Courier, monospace;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">2px</span> <span class="number">0</span> <span class="number">0</span> <span class="number">4px</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">0.9em</span>;</span><br><span class="line">    <span class="attribute">color</span>: inherit;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-tag</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: inherit;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc</span> &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">20px</span>;</span><br><span class="line">    <span class="attribute">padding-bottom</span>: <span class="number">20px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.sidebar-tabs</span> &#123;</span><br><span class="line">    <span class="attribute">border-bottom</span>: none;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#typora-quick-open</span> &#123;</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">1px</span> solid <span class="number">#ddd</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#f8f8f8</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#typora-quick-open-item</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#FAFAFA</span>;</span><br><span class="line">    <span class="attribute">border-color</span>: <span class="number">#FEFEFE</span> <span class="number">#e5e5e5</span> <span class="number">#e5e5e5</span> <span class="number">#eee</span>;</span><br><span class="line">    <span class="attribute">border-style</span>: solid;</span><br><span class="line">    <span class="attribute">border-width</span>: <span class="number">1px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#md-notification</span>:before &#123;</span><br><span class="line">    top: <span class="number">10px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**************************************</span></span><br><span class="line"><span class="comment"> * Header Counters in TOC</span></span><br><span class="line"><span class="comment"> **************************************/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* No link underlines in TOC */</span></span><br><span class="line"><span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">text-decoration</span>: none;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-content</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h1toc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h1</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">counter-reset</span>: h2toc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h2</span> &#123;</span><br><span class="line"><span class="attribute">margin-left</span>: <span class="number">2rem</span>;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h3toc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h3</span> &#123;</span><br><span class="line"><span class="attribute">margin-left</span>: <span class="number">3rem</span>;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h4toc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h4</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">4rem</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">counter-reset</span>: h5toc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h5</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">5rem</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">counter-reset</span>: h6toc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h6</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">6rem</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h1</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h1toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;.&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h1</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h2</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h2toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2toc) <span class="string">&quot;.&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h2</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h3</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h3toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3toc) <span class="string">&quot;.&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h3</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h4</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h4toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4toc) <span class="string">&quot;.&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h4</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h5</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h5toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h5toc) <span class="string">&quot;.&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h5</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h6</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h6toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h5toc) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h6toc) <span class="string">&quot;.&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-toc-h6</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/** focus mode */</span></span><br><span class="line"></span><br><span class="line"><span class="selector-class">.on-focus-mode</span> <span class="selector-tag">blockquote</span> &#123;</span><br><span class="line">    <span class="attribute">border-left-color</span>: <span class="built_in">rgba</span>(<span class="number">85</span>, <span class="number">85</span>, <span class="number">85</span>, <span class="number">0.12</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">header</span>,</span><br><span class="line"><span class="selector-class">.context-menu</span>,</span><br><span class="line"><span class="selector-class">.megamenu-content</span>,</span><br><span class="line"><span class="selector-tag">footer</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&quot;Segoe UI&quot;</span>, <span class="string">&quot;Arial&quot;</span>, sans-serif;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.file-node-content</span><span class="selector-pseudo">:hover</span> <span class="selector-class">.file-node-icon</span>,</span><br><span class="line"><span class="selector-class">.file-node-content</span><span class="selector-pseudo">:hover</span> <span class="selector-class">.file-node-open-state</span> &#123;</span><br><span class="line">    <span class="attribute">visibility</span>: visible;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.mac-seamless-mode</span> <span class="selector-id">#typora-sidebar</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="built_in">var</span>(--side-bar-bg-color);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.md-lang</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#b4654d</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.html-for-mac</span> <span class="selector-class">.context-menu</span> &#123;</span><br><span class="line">    --item-hover-bg-<span class="attribute">color</span>: <span class="number">#E6F0FE</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** initialize css counter */</span></span><br><span class="line"><span class="selector-id">#write</span> &#123;</span><br><span class="line"><span class="attribute">counter-reset</span>: h1</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">h1</span> &#123;</span><br><span class="line"><span class="attribute">counter-reset</span>: h2</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">h2</span> &#123;</span><br><span class="line"><span class="attribute">counter-reset</span>: h3</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">h3</span> &#123;</span><br><span class="line"><span class="attribute">counter-reset</span>: h4</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">h4</span> &#123;</span><br><span class="line"><span class="attribute">counter-reset</span>: h5</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">h5</span> &#123;</span><br><span class="line"><span class="attribute">counter-reset</span>: h6</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/** put counter result into headings */</span></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h1</span>:before &#123;</span><br><span class="line">counter-increment: h1;</span><br><span class="line"><span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h2</span>:before &#123;</span><br><span class="line">counter-increment: h2;</span><br><span class="line"><span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h3</span>:before,</span><br><span class="line">h3.md-focus.md-heading:before /** override the default style for focused headings */ &#123;</span><br><span class="line">counter-increment: h3;</span><br><span class="line"><span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h4</span>:before,</span><br><span class="line">h4.md-focus.md-heading:before &#123;</span><br><span class="line">counter-increment: h4;</span><br><span class="line"><span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h5</span>:before,</span><br><span class="line">h5.md-focus.md-heading:before &#123;</span><br><span class="line">counter-increment: h5;</span><br><span class="line"><span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h5) <span class="string">&quot;. &quot;</span>&#125;</span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h6</span>:before,</span><br><span class="line">h6.md-focus.md-heading:before &#123;</span><br><span class="line">counter-increment: h6;</span><br><span class="line"><span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h5) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h6) <span class="string">&quot;.</span></span><br><span class="line"><span class="string">&quot;</span>&#125;</span><br><span class="line"><span class="comment">/** override the default style for focused headings */</span></span><br><span class="line"><span class="selector-id">#write</span>&gt;<span class="selector-tag">h3</span><span class="selector-class">.md-focus</span>:before,</span><br><span class="line">#write&gt;h4.md-focus:before,</span><br><span class="line">#write&gt;h5.md-focus:before,</span><br><span class="line">#write&gt;h6.md-focus:before,</span><br><span class="line">h3.md-focus:before,</span><br><span class="line">h4.md-focus:before,</span><br><span class="line">h5.md-focus:before,</span><br><span class="line">h6.md-focus:before &#123;</span><br><span class="line">color: inherit;</span><br><span class="line"><span class="attribute">border</span>: inherit;</span><br><span class="line"><span class="attribute">border-radius</span>: inherit;</span><br><span class="line"><span class="attribute">position</span>: inherit;</span><br><span class="line"><span class="attribute">left</span>:initial;</span><br><span class="line"><span class="attribute">float</span>: none;</span><br><span class="line"><span class="attribute">top</span>:initial;</span><br><span class="line"><span class="attribute">font-size</span>: inherit;</span><br><span class="line"><span class="attribute">padding-left</span>: inherit;</span><br><span class="line"><span class="attribute">padding-right</span>: inherit;</span><br><span class="line"><span class="attribute">vertical-align</span>: inherit;</span><br><span class="line"><span class="attribute">font-weight</span>: inherit;</span><br><span class="line"><span class="attribute">line-height</span>: inherit;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/***                           TOC                       */</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="内容自动编号"><a href="#内容自动编号" class="headerlink" title="内容自动编号"></a>内容自动编号</h1><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** initialize css counter */</span></span><br><span class="line"><span class="selector-id">#write</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h1</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h2</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h3</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h3</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h4</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h4</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h5</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">h5</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h6</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** put counter result into headings */</span></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h1</span>:before &#123;</span><br><span class="line">    counter-increment: h1;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h2</span>:before &#123;</span><br><span class="line">    counter-increment: h2;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h3</span>:before,</span><br><span class="line">h3.md-focus.md-heading:before /** override the default style for focused headings */ &#123;</span><br><span class="line">    counter-increment: h3;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h4</span>:before,</span><br><span class="line">h4.md-focus.md-heading:before &#123;</span><br><span class="line">    counter-increment: h4;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h5</span>:before,</span><br><span class="line">h5.md-focus.md-heading:before &#123;</span><br><span class="line">    counter-increment: h5;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h5) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h6</span>:before,</span><br><span class="line">h6.md-focus.md-heading:before &#123;</span><br><span class="line">    counter-increment: h6;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h5) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h6) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** override the default style for focused headings */</span></span><br><span class="line"><span class="selector-id">#write</span>&gt;<span class="selector-tag">h3</span><span class="selector-class">.md-focus</span>:before,</span><br><span class="line">#write&gt;h4.md-focus:before,</span><br><span class="line">#write&gt;h5.md-focus:before,</span><br><span class="line">#write&gt;h6.md-focus:before,</span><br><span class="line">h3.md-focus:before,</span><br><span class="line">h4.md-focus:before,</span><br><span class="line">h5.md-focus:before,</span><br><span class="line">h6.md-focus:before &#123;</span><br><span class="line">    color: inherit;</span><br><span class="line">    <span class="attribute">border</span>: inherit;</span><br><span class="line">    <span class="attribute">border-radius</span>: inherit;</span><br><span class="line">    <span class="attribute">position</span>: inherit;</span><br><span class="line">    <span class="attribute">left</span>:initial;</span><br><span class="line">    <span class="attribute">float</span>: none;</span><br><span class="line">    <span class="attribute">top</span>:initial;</span><br><span class="line">    <span class="attribute">font-size</span>: inherit;</span><br><span class="line">    <span class="attribute">padding-left</span>: inherit;</span><br><span class="line">    <span class="attribute">padding-right</span>: inherit;</span><br><span class="line">    <span class="attribute">vertical-align</span>: inherit;</span><br><span class="line">    <span class="attribute">font-weight</span>: inherit;</span><br><span class="line">    <span class="attribute">line-height</span>: inherit;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="目录自动编号"><a href="#目录自动编号" class="headerlink" title="目录自动编号"></a>目录自动编号</h1><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**************************************</span></span><br><span class="line"><span class="comment"> * Header Counters in TOC</span></span><br><span class="line"><span class="comment"> **************************************/</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/* No link underlines in TOC */</span></span><br><span class="line"><span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">text-decoration</span>: none;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-content</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h1toc</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h1</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">1.5rem</span>;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h2toc</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h2</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">1.1rem</span>;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">2rem</span>;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h3toc</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h3</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">3rem</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: .<span class="number">9rem</span>;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h4toc</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h4</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">4rem</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: .<span class="number">85rem</span>;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h5toc</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h5</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">5rem</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: .<span class="number">8rem</span>;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h6toc</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h6</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">6rem</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: .<span class="number">75rem</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h1</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h1toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h1</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h2</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h2toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h2toc) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h2</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h3</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h3toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h2toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h3toc) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h3</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h4</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h4toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h2toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h3toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h4toc) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h4</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h5</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h5toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h2toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h3toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h4toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h5toc) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h5</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h6</span>:before &#123;</span><br><span class="line">    color: black;</span><br><span class="line">    <span class="attribute">counter-increment</span>: h6toc;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h2toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h3toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h4toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h5toc) <span class="string">&quot;. &quot;</span> <span class="built_in">counter</span>(h6toc) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-class">.md-toc-h6</span> <span class="selector-class">.md-toc-inner</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**************************************</span></span><br><span class="line"><span class="comment"> * Header Counters in Content</span></span><br><span class="line"><span class="comment"> **************************************/</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">/** initialize css counter */</span></span><br><span class="line"><span class="selector-id">#write</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h1</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-tag">h1</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h2</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-tag">h2</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h3</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-tag">h3</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h4</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-tag">h4</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h5</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-tag">h5</span> &#123;</span><br><span class="line">    <span class="attribute">counter-reset</span>: h6</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/** put counter result into headings */</span></span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h1</span>:before &#123;</span><br><span class="line">    counter-increment: h1;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h2</span>:before &#123;</span><br><span class="line">    counter-increment: h2;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h3</span>:before, h3.md-focus.md-heading:before &#123; /*override the default style for focused headings */</span><br><span class="line">    counter-increment: h3;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h4</span>:before, h4.md-focus.md-heading:before &#123;</span><br><span class="line">    counter-increment: h4;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h5</span>:before, h5.md-focus.md-heading:before &#123;</span><br><span class="line">    counter-increment: h5;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h5) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="selector-id">#write</span> <span class="selector-tag">h6</span>:before, h6.md-focus.md-heading:before &#123;</span><br><span class="line">    counter-increment: h6;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">counter</span>(h1) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h2) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h3) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h4) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h5) <span class="string">&quot;.&quot;</span> <span class="built_in">counter</span>(h6) <span class="string">&quot;. &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/** override the default style for focused headings */</span></span><br><span class="line"><span class="selector-id">#write</span>&gt;<span class="selector-tag">h3</span><span class="selector-class">.md-focus</span>:before, #write&gt;h4.md-focus:before, #write&gt;h5.md-focus:before, #write&gt;h6.md-focus:before, h3.md-focus:before, h4.md-focus:before, h5.md-focus:before, h6.md-focus:before &#123;</span><br><span class="line">    color: inherit;</span><br><span class="line">    <span class="attribute">border</span>: inherit;</span><br><span class="line">    <span class="attribute">border-radius</span>: inherit;</span><br><span class="line">    <span class="attribute">position</span>: inherit;</span><br><span class="line">    <span class="attribute">left</span>: initial;</span><br><span class="line">    <span class="attribute">float</span>: none;</span><br><span class="line">    <span class="attribute">top</span>: initial;</span><br><span class="line">    <span class="attribute">font-size</span>: inherit;</span><br><span class="line">    <span class="attribute">padding-left</span>: inherit;</span><br><span class="line">    <span class="attribute">padding-right</span>: inherit;</span><br><span class="line">    <span class="attribute">vertical-align</span>: inherit;</span><br><span class="line">    <span class="attribute">font-weight</span>: inherit;</span><br><span class="line">    <span class="attribute">line-height</span>: inherit;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ter-increment: h4;<br>    content: counter(h1) “.” counter(h2) “.” counter(h3) “.” counter(h4) “. “<br>}</p>
<h1 id="write-h5-before-h5-md-focus-md-heading-before"><a href="#write-h5-before-h5-md-focus-md-heading-before" class="headerlink" title="write h5:before, h5.md-focus.md-heading:before {"></a>write h5:before, h5.md-focus.md-heading:before {</h1><pre><code>counter-increment: h5;
content: counter(h1) &quot;.&quot; counter(h2) &quot;.&quot; counter(h3) &quot;.&quot; counter(h4) &quot;.&quot; counter(h5) &quot;. &quot;
</code></pre><p>}</p>
<h1 id="write-h6-before-h6-md-focus-md-heading-before"><a href="#write-h6-before-h6-md-focus-md-heading-before" class="headerlink" title="write h6:before, h6.md-focus.md-heading:before {"></a>write h6:before, h6.md-focus.md-heading:before {</h1><pre><code>counter-increment: h6;
content: counter(h1) &quot;.&quot; counter(h2) &quot;.&quot; counter(h3) &quot;.&quot; counter(h4) &quot;.&quot; counter(h5) &quot;.&quot; counter(h6) &quot;. &quot;
</code></pre><p>}</p>
<p>/<em>* override the default style for focused headings </em>/</p>
<h1 id="write-gt-h3-md-focus-before-write-gt-h4-md-focus-before-write-gt-h5-md-focus-before-write-gt-h6-md-focus-before-h3-md-focus-before-h4-md-focus-before-h5-md-focus-before-h6-md-focus-before"><a href="#write-gt-h3-md-focus-before-write-gt-h4-md-focus-before-write-gt-h5-md-focus-before-write-gt-h6-md-focus-before-h3-md-focus-before-h4-md-focus-before-h5-md-focus-before-h6-md-focus-before" class="headerlink" title="write&gt;h3.md-focus:before, #write&gt;h4.md-focus:before, #write&gt;h5.md-focus:before, #write&gt;h6.md-focus:before, h3.md-focus:before, h4.md-focus:before, h5.md-focus:before, h6.md-focus:before {"></a>write&gt;h3.md-focus:before, #write&gt;h4.md-focus:before, #write&gt;h5.md-focus:before, #write&gt;h6.md-focus:before, h3.md-focus:before, h4.md-focus:before, h5.md-focus:before, h6.md-focus:before {</h1><pre><code>color: inherit;
border: inherit;
border-radius: inherit;
position: inherit;
left: initial;
float: none;
top: initial;
font-size: inherit;
padding-left: inherit;
padding-right: inherit;
vertical-align: inherit;
font-weight: inherit;
line-height: inherit;
</code></pre><p>}<br>```</p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>xgboost包</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/xgboost%E5%8C%85/</url>
    <content><![CDATA[<p>xgb模型的保存与调用</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="模型的保存与restore"><a href="#模型的保存与restore" class="headerlink" title="模型的保存与restore"></a>模型的保存与restore</h1><p>常用的模型文件有dump, pickle,model三种格式，其中dump文件是可读文件，pickle和model文件是二进制文件。model文件是xgb官方支持的文件，适合所有版本，pickle文件使用第三方pickle包进行序列化。</p>
<p>xgb接口有xgboost.Booster()和xgboost.sklearn.XGBClassifier两个接口，xgboost.Booster()只能使用DMatrix形式数据进行训练，dmatrix数据可通过csv,txt,libsvm,dataframe得到，见<a href="https://xgboost.readthedocs.io/en/latest/python/python_intro.html">https://xgboost.readthedocs.io/en/latest/python/python_intro.html</a></p>
<p>XGBClassifier可使用Grid Search 和并行处理</p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/xgboost%E5%8C%85/xgboost包.assets/image-20201026101441254.png" alt="image-20201026101441254"></p>
<p>xgboost.sklearn.XGBClassifier可直接读dataframe数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># xgboost.Booster()版本模型restore和预测</span></span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">dtrain = xgb.DMatrix(x,label=df[<span class="string">&#x27;y_flag&#x27;</span>],feature_names=df.columns[<span class="number">2</span>:]) <span class="comment">#x: dataframe;feature_names可指定特征名，取决于训练时是否有特征名</span></span><br><span class="line">m1 = xgb.Booster(model_file=<span class="string">&#x27;test.model&#x27;</span>) </span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">m1 = xgb.Booster()</span><br><span class="line">m1.load_model(f_model)</span><br><span class="line">score = m1.predict(dtrain)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># xgboost.sklearn.XGBClassifier版本restore和预测</span></span><br><span class="line">m2 = XGBClassifier()</span><br><span class="line">m2.load_model(f_model)  </span><br><span class="line">a = m2.predict_proba(x)[:,<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h1 id="模型的训练与保存"><a href="#模型的训练与保存" class="headerlink" title="模型的训练与保存"></a>模型的训练与保存</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># XGBClassifier 版本</span></span><br><span class="line"><span class="keyword">from</span> xgboost.sklearn <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">model=XGBClassifier(params) <span class="comment">#params：dict,模型参数</span></span><br><span class="line">watchlist=[(x_train, y_train), (x_test, y_test)]</span><br><span class="line">model.fit(x,y, eval_set=watchlist)</span><br><span class="line"><span class="comment">#模型保存</span></span><br><span class="line">model.get_booster().dump_model(f_model + <span class="string">&#x27;.dump&#x27;</span>) <span class="comment">#可读文件</span></span><br><span class="line">model.get_booster().save_model(f_model + <span class="string">&#x27;.model&#x27;</span>) <span class="comment">#model二进制文件</span></span><br><span class="line">pickle.dump(model, <span class="built_in">open</span>(f_model + <span class="string">&#x27;.pickle.dat&#x27;</span>, <span class="string">&quot;wb&quot;</span>)) <span class="comment">#pickl二进制文件</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># xgboost.Booster 版本</span></span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">model = xgb.train(param, dtrain, num_round)  <span class="comment"># dtrain是训练数据集</span></span><br><span class="line">scores = bst.predict(dtrain)    </span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>作业，进程，线程管道梳理</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BD%9C%E4%B8%9A%EF%BC%8C%E8%BF%9B%E7%A8%8B%EF%BC%8C%E7%BA%BF%E7%A8%8B%E7%AE%A1%E9%81%93%E6%A2%B3%E7%90%86/</url>
    <content><![CDATA[<p>进程-线程科普</p>
<span id="more"></span>
<p>作业，进程，线程，管程，管道梳理</p>
<p>[TOC]</p>
<h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><p>进程（process）：程序在一个数据集上的一次运行过程。是操作系统资源分配的基本单位。</p>
<p> 线程（thread）：是进程中的一个实体，是被操作系统独立调度和执行的基本单位。一个进程包含一个或多个线程。</p>
<blockquote>
<p>多线程间是共用内存空间的，但有的内存只能同时被一个线程访问，有的内存只能同时被有限个线程访问。所以每个内存会有一个锁，当超额的线程访问此内存时就需要排队。当一个线程长时间占用内存时就会导致“锁死”</p>
</blockquote>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E4%BD%9C%E4%B8%9A%EF%BC%8C%E8%BF%9B%E7%A8%8B%EF%BC%8C%E7%BA%BF%E7%A8%8B%E7%AE%A1%E9%81%93%E6%A2%B3%E7%90%86/pics\作业，进程，线程管道梳理.assets\image-20200331114405031.png" alt="image-20200331114405031"></p>
<h1 id="shell中多进程管理"><a href="#shell中多进程管理" class="headerlink" title="shell中多进程管理"></a>shell中多进程管理</h1><h1 id="python中多进程管理"><a href="#python中多进程管理" class="headerlink" title="python中多进程管理"></a>python中多进程管理</h1><ul>
<li>单进程：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">long_time_task</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;当前进程: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(os.getpid()))</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;结果: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="number">8</span> ** <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;当前母进程: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(os.getpid()))</span><br><span class="line">    start = time.time()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        long_time_task()</span><br><span class="line"></span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;用时&#123;&#125;秒&quot;</span>.<span class="built_in">format</span>((end-start)))</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">当前母进程: 14236</span><br><span class="line">当前进程: 14236</span><br><span class="line">结果: 1152921504606846976</span><br><span class="line">当前进程: 14236</span><br><span class="line">结果: 1152921504606846976</span><br><span class="line">用时4.01080060005188秒</span><br></pre></td></tr></table></figure>
<ul>
<li>多进程后：</li>
</ul>
<p>Process方法接收两个参数, 第一个是target，一般指向函数名，第二个时args，需要向函数传递的参数。对于创建的新进程，调用start()方法即可让其开始。我们可以使用os.getpid()打印出当前进程的名字。之所以我们使用join()方法就是为了让母进程阻塞，等待子进程都完成后才打印出总共耗时，否则输出时间只是母进程执行的时间。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">long_time_task</span>(<span class="params">i</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;子进程: &#123;&#125; - 任务&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(os.getpid(), i))</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;结果: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="number">8</span> ** <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;当前母进程: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(os.getpid()))</span><br><span class="line">    start = time.time()</span><br><span class="line">    p1 = Process(target=long_time_task, args=(<span class="number">1</span>,))</span><br><span class="line">    p2 = Process(target=long_time_task, args=(<span class="number">2</span>,))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;等待所有子进程完成。&#x27;</span>)</span><br><span class="line">    p1.start()</span><br><span class="line">    p2.start()</span><br><span class="line">    p1.join()</span><br><span class="line">    p2.join()</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;总共用时&#123;&#125;秒&quot;</span>.<span class="built_in">format</span>((end - start)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">当前母进程: 6920</span><br><span class="line">等待所有子进程完成。</span><br><span class="line">子进程: 17020 - 任务1</span><br><span class="line">子进程: 5904 - 任务2</span><br><span class="line">结果: 1152921504606846976</span><br><span class="line">结果: 1152921504606846976</span><br><span class="line">总共用时2.131091356277466秒</span><br></pre></td></tr></table></figure>
<h1 id="python调用shell的方法"><a href="#python调用shell的方法" class="headerlink" title="python调用shell的方法"></a>python调用shell的方法</h1><h2 id="os-system（cmd）"><a href="#os-system（cmd）" class="headerlink" title="os.system（cmd）"></a>os.system（cmd）</h2><p>返回值：shell运行指令后的状态码，int，0表示运行成功，256表示未找到。<strong>适用于shell不需要输出内容的场景</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">val = os.system(<span class="string">&#x27;ls -al&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;val&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="os-popen"><a href="#os-popen" class="headerlink" title="os.popen()"></a>os.popen()</h2><p>返回值：文件的形式返回shell指令运行后的结果，需要获取内容时可使用read()或readlines（）方法</p>
<h2 id="commands"><a href="#commands" class="headerlink" title="commands"></a>commands</h2><h2 id="subprocess"><a href="#subprocess" class="headerlink" title="subprocess"></a>subprocess</h2>]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>单机模型的Spark分布式预测</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%9E%8B%E7%9A%84Spark%E5%88%86%E5%B8%83%E5%BC%8F%E9%A2%84%E6%B5%8B/</url>
    <content><![CDATA[<p>单机模型spark分布式预测</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="单机模型的Spark分布式预测"><a href="#单机模型的Spark分布式预测" class="headerlink" title="单机模型的Spark分布式预测"></a>单机模型的Spark分布式预测</h1><h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h2><p>目前京东体系内的月活跃用户是3亿左右，在推荐、广告、营销等场景下，需要每天对这些活跃用户做不同的业务预测。单机训练的Python模型在对3亿用户预测时，需要自己写代码对数据进行拆分并用并行程序来处理，即便如此，复杂模型也往往需要几个小时甚至十几个小时的时间才能预测完。这个时长可能是用户不能忍受的。</p>
<p>此外，代码改写和调试过程也比较繁琐和费时。</p>
<p>基于此，我们需要有一个能把单机训练的Python模型转换成分布式预测的高效方案。</p>
<h2 id="2-方案"><a href="#2-方案" class="headerlink" title="2. 方案"></a>2. 方案</h2><p>经过调研及测试，我们找到一个利用PySpark<code>GROUPED_MAP</code>类型的<code>pandas_udf</code>来对单机训练的Python模型做分布式预测的方案。</p>
<p><code>GROUPED_MAP</code>类型的<code>pandas_udf</code>会从<code>Grouped DataFrame</code>中取到一个group的所有数据并加载如内存中转化为<code>pandas.DataFrame</code>。所以我们在调用udf之前需要对数据进行显式分组，每个分组的所有数据应该能加载进Executor上Task的内存中。</p>
<p>此外，借助Apache Arrow，Spark和Python之间的数据交换效率会更高。</p>
<h3 id="step-1：定义pandas-udf用于预测"><a href="#step-1：定义pandas-udf用于预测" class="headerlink" title="step 1：定义pandas_udf用于预测"></a>step 1：定义pandas_udf用于预测</h3><p>定义一个<code>GROUPED_MAP</code>类型的<code>pandas_udf</code>。<br><code>pandas_udf</code>的输入参数是<code>pandas.DataFrame</code>，要求的返回也是<code>pandas.DataFrame</code>。所以写udf的过程跟写单机预测程序相同。</p>
<ul>
<li><p><code>pandas_udf</code>从main里获得model对象，适用于model是可以pickle的python对象</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> pandas_udf, PandasUDFType</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;model_file_path&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    model = joblib.load(f)</span><br><span class="line"></span><br><span class="line">predictors = [<span class="string">&#x27;feature1&#x27;</span>, <span class="string">&#x27;feature2&#x27;</span>]</span><br><span class="line"><span class="meta">@pandas_udf(<span class="params"><span class="string">&quot;pin string, class int&quot;</span>, PandasUDFType.GROUPED_MAP</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_udf</span>(<span class="params">pdf</span>):</span></span><br><span class="line">    pred = model.predict(pdf[predictors])</span><br><span class="line">    rdf = pd.DataFrame(&#123;<span class="string">&#x27;pin&#x27;</span>: pdf[<span class="string">&#x27;pin&#x27;</span>], <span class="string">&#x27;class&#x27;</span>: pred&#125;, columns=[<span class="string">&#x27;pin&#x27;</span>, <span class="string">&#x27;class&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> rdf</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用sc.addFile()分发模型文件，<code>pandas_udf</code>每次从文件加载模型，适用于不能被pickle的模型对象</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> pandas_udf, PandasUDFType</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkFiles</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">sc.addFile(<span class="string">&#x27;model_file_path/model.pkl&#x27;</span>)</span><br><span class="line"></span><br><span class="line">predictors = [<span class="string">&#x27;feature1&#x27;</span>, <span class="string">&#x27;feature2&#x27;</span>]</span><br><span class="line"><span class="meta">@pandas_udf(<span class="params"><span class="string">&quot;pin string, class int&quot;</span>, PandasUDFType.GROUPED_MAP</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_udf</span>(<span class="params">pdf</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(SparkFiles.get(<span class="string">&#x27;model.pkl&#x27;</span>), <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        model = joblib.load(f)</span><br><span class="line">    pred = model.predict(pdf[predictors])</span><br><span class="line">    rdf = pd.DataFrame(&#123;<span class="string">&#x27;pin&#x27;</span>: pdf[<span class="string">&#x27;pin&#x27;</span>], <span class="string">&#x27;class&#x27;</span>: pred&#125;, columns=[<span class="string">&#x27;pin&#x27;</span>, <span class="string">&#x27;class&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> rdf</span><br></pre></td></tr></table></figure>
<ul>
<li>使用sc.addPyFile()分发模型文件到executor的工作目录，<code>pandas_udf</code>每次从文件加载模型，适用于不能被pickle的模型对象</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> pandas_udf, PandasUDFType</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkFiles</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">sc.addPyFile(<span class="string">&#x27;model_file_path/model.pkl&#x27;</span>)</span><br><span class="line"></span><br><span class="line">predictors = [<span class="string">&#x27;feature1&#x27;</span>, <span class="string">&#x27;feature2&#x27;</span>]</span><br><span class="line"><span class="meta">@pandas_udf(<span class="params"><span class="string">&quot;pin string, class int&quot;</span>, PandasUDFType.GROUPED_MAP</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_udf</span>(<span class="params">pdf</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;model.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        model = joblib.load(f)</span><br><span class="line">    pred = model.predict(pdf[predictors])</span><br><span class="line">    rdf = pd.DataFrame(&#123;<span class="string">&#x27;pin&#x27;</span>: pdf[<span class="string">&#x27;pin&#x27;</span>], <span class="string">&#x27;class&#x27;</span>: pred&#125;, columns=[<span class="string">&#x27;pin&#x27;</span>, <span class="string">&#x27;class&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> rdf</span><br></pre></td></tr></table></figure>
<h3 id="step-2-分组执行udf函数"><a href="#step-2-分组执行udf函数" class="headerlink" title="step 2: 分组执行udf函数"></a>step 2: 分组执行udf函数</h3><p>这里给出了一个做分组的方法，具体的分组大小需要根据自己的数据（特征数量及类型）和配置的Executor内存大小来确定。可以在单机上加载不同数据量进内存，看下大小，再给预测时的中间变量预留些空间，可以大致估计出来Executor上的数据量，根据这个数据量以及全部数据量计算出分组个数。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nparts = <span class="number">1000</span></span><br><span class="line">output = data_df.select(<span class="string">&quot;pin&quot;</span>, *predictors, (f.ceil(f.rand()*nparts)).alias(<span class="string">&#x27;grouper&#x27;</span>))\</span><br><span class="line">    .groupby(<span class="string">&quot;grouper&quot;</span>)\</span><br><span class="line">    .apply(predict_udf)</span><br></pre></td></tr></table></figure></p>
<h2 id="3-基本原理"><a href="#3-基本原理" class="headerlink" title="3. 基本原理"></a>3. 基本原理</h2><p>利用PySpark的<code>pandas_udf</code>函数的功能，将待预测的数据从分布式文件系统读取出来并划分成很多小数据集，分发给不同的节点去预测，预测之后再把结果以分布式文件的方式保存到集群上。其中<code>pandas_udf</code>函数负责<code>Spark DataFrame</code>和<code>pandas DataFrame</code>之间的转换。<code>pandas_udf</code>的执行可以分成三个阶段：</p>
<ul>
<li>第一个阶段：在预测之前，pandas_udf接收到Spark DataFrame，然后把它转换成pandas的DataFrame；</li>
<li>第二个阶段：在python进程中执行udf的逻辑，并以pandas DataFrame的类型返回预测结果；</li>
<li>第三个阶段：pandas_udf把返回的pandas DataFrame转换成Spark DataFrame</li>
</ul>
<p>其他环节跟普通的Spark程序的执行逻辑一样。</p>
<p>（+架构图）</p>
<p>单机并行程序的时间消耗主要在数据IO上，单机预测需要先把数据从Hive中读取出来保存到磁盘文件中，然后python再把文件载入内存做预测，预测结果写到磁盘文件中，最后把结果文件导入到Hive中。整个过程有大量的磁盘IO消耗。而改为PySpark的<code>pandas_udf</code>函数之后，省掉了从Hive到磁盘、从磁盘到python内存和最后的从磁盘到Hive的过程，剩余的IO由Spark控制和优化，从而在效率上会有很大提升。</p>
<h2 id="4-实践"><a href="#4-实践" class="headerlink" title="4. 实践"></a>4. 实践</h2><p>在KuAI上使用5K集群Spark环境实现上述方案时需要额外配置一下Python环境。此处以Notebook里运行为例，Spark-submit的方式使用可以参考KuAI帮助文档的5K-Spark使用部分。</p>
<h3 id="Step-1：安装python包"><a href="#Step-1：安装python包" class="headerlink" title="Step 1：安装python包"></a>Step 1：安装python包</h3><p>在py35环境下安装所需要的python包<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda deactivate</span><br><span class="line">codna activate py35</span><br><span class="line">pip install pkg_name</span><br></pre></td></tr></table></figure></p>
<h3 id="Step-2：压缩py35安装文件夹"><a href="#Step-2：压缩py35安装文件夹" class="headerlink" title="Step 2：压缩py35安装文件夹"></a>Step 2：压缩py35安装文件夹</h3><p>切换到/opt/conda/envs文件夹下，压缩py35文件夹</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/conda/envs/py35</span><br><span class="line">zip -r py35.zip *</span><br></pre></td></tr></table></figure>
<h3 id="Step-3：上传到hdfs上"><a href="#Step-3：上传到hdfs上" class="headerlink" title="Step 3：上传到hdfs上"></a>Step 3：上传到hdfs上</h3><p>在hdfs上以你的域名（邮箱前缀）建个文件夹，把py35.zip上传至该文件夹下：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop fs -mkdir /tmp/user_name</span><br><span class="line">hadoop fs -put py35.zip /tmp/user_name/</span><br></pre></td></tr></table></figure></p>
<h3 id="Step-4：重启pyspark-kernel"><a href="#Step-4：重启pyspark-kernel" class="headerlink" title="Step 4：重启pyspark kernel"></a>Step 4：重启pyspark kernel</h3><h3 id="Step-5：案例"><a href="#Step-5：案例" class="headerlink" title="Step 5：案例"></a>Step 5：案例</h3><p>以用户的一个真实模型为例，代码如下，可以作为参考。</p>
<p>该案例中使用的模型和数据均由量化中台部的算法工程师庞伟栋提供，在此表示感谢！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pyspark.conf <span class="keyword">import</span> SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.context <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession </span><br><span class="line"></span><br><span class="line">sparkConf = SparkConf()</span><br><span class="line"><span class="comment"># 设置driver及executor上的python环境</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = <span class="string">&quot;py35/bin/python&quot;</span></span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.pyspark.python&quot;</span>, <span class="string">&quot;py35/bin/python&quot;</span>)</span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.yarn.dist.archives&quot;</span>, <span class="string">&quot;hdfs://ns1/tmp/user_name/py35.zip#py35&quot;</span>)  <span class="comment"># user_name替换成您自己的域名</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置Driver进程的内存</span></span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&#x27;spark.driver.memory&#x27;</span>, <span class="string">&#x27;8G&#x27;</span>)</span><br><span class="line"><span class="comment"># 设置Driver的CPU core数量</span></span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&#x27;spark.driver.cores&#x27;</span>, <span class="string">&#x27;4&#x27;</span>)</span><br><span class="line"><span class="comment"># 设置Spark作业总共要用多少个Executor进程来执行</span></span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.executor.instances&quot;</span>, <span class="string">&quot;10&quot;</span>)</span><br><span class="line"><span class="comment"># 设置每个Executor进程的CPU core数量</span></span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.executor.cores&quot;</span>, <span class="string">&quot;2&quot;</span>)</span><br><span class="line"><span class="comment"># 设置每个Executor进程的内存</span></span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.executor.memory&quot;</span>, <span class="string">&quot;9124m&quot;</span>)</span><br><span class="line"><span class="comment"># 设置Spark应用的名称</span></span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.app.name&quot;</span>, <span class="string">&quot;app-name&quot;</span>)</span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.shuffle.service.enabled&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.dynamicAllocation.enabled&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.dynamicAllocation.executorIdleTimeout&quot;</span>, <span class="string">&quot;600s&quot;</span>)</span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.driver.maxResultSize&quot;</span>, <span class="string">&quot;10g&quot;</span>)</span><br><span class="line"><span class="comment"># 打开pyarrow</span></span><br><span class="line">sparkConf.<span class="built_in">set</span>(<span class="string">&quot;spark.sql.execution.arrow.enabled&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.config(conf=sparkConf).enableHiveSupport().getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">tx_date=<span class="string">&#x27;2019-12-01&#x27;</span></span><br><span class="line">data_df = spark.sql(<span class="string">&quot;select * from dmc_qm.dmcqm_lhmx_jr_app_biz2_prefer_before_download_s_d where dt=&#x27;&#123;tx_date&#125;&#x27;&quot;</span>.<span class="built_in">format</span>(tx_date=tx_date))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;model_100feats.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    bestModel=joblib.load(f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型解析函数并注册</span></span><br><span class="line">xgbfeatureCols = bestModel.feature_names</span><br><span class="line"><span class="comment"># 定义打分结果表的列</span></span><br><span class="line">result_key_col=[<span class="string">&#x27;pin&#x27;</span>] <span class="comment"># 关键字列</span></span><br><span class="line">result_prob_col=<span class="string">&#x27;score&#x27;</span> <span class="comment"># 输出的打分名称</span></span><br><span class="line"><span class="comment"># biz_nm</span></span><br><span class="line">biz_nm=&#123;<span class="string">&#x27;0.0&#x27;</span>:<span class="string">&#x27;运营型产品&#x27;</span>,<span class="string">&#x27;1.0&#x27;</span>:<span class="string">&#x27;小金库&#x27;</span>,<span class="string">&#x27;2.0&#x27;</span>:<span class="string">&#x27;金条&#x27;</span>,<span class="string">&#x27;3.0&#x27;</span>:<span class="string">&#x27;基金理财&#x27;</span>,<span class="string">&#x27;4.0&#x27;</span>:<span class="string">&#x27;小白&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;5.0&#x27;</span>:<span class="string">&#x27;借钱业务&#x27;</span>,<span class="string">&#x27;6.0&#x27;</span>:<span class="string">&#x27;产品众筹&#x27;</span>,<span class="string">&#x27;7.0&#x27;</span>:<span class="string">&#x27;金融机构服务（零售）&#x27;</span>,<span class="string">&#x27;8.0&#x27;</span>:<span class="string">&#x27;产险&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;9.0&#x27;</span>:<span class="string">&#x27;黄金理财&#x27;</span>,<span class="string">&#x27;10.0&#x27;</span>:<span class="string">&#x27;小金卡&#x27;</span>,<span class="string">&#x27;11.0&#x27;</span>:<span class="string">&#x27;固收理财&#x27;</span>,<span class="string">&#x27;12.0&#x27;</span>:<span class="string">&#x27;寿险&#x27;</span>,<span class="string">&#x27;13.0&#x27;</span>:<span class="string">&#x27;小白卡&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;14.0&#x27;</span>:<span class="string">&#x27;出众&#x27;</span>,<span class="string">&#x27;15.0&#x27;</span>:<span class="string">&#x27;车险&#x27;</span>,<span class="string">&#x27;16.0&#x27;</span>:<span class="string">&#x27;汽车金融&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> fn</span><br><span class="line"><span class="comment"># 转换类型</span></span><br><span class="line">expr=[fn.col(c) <span class="keyword">for</span> c <span class="keyword">in</span> result_key_col]+[fn.col(c).cast(<span class="string">&quot;float&quot;</span>) <span class="keyword">for</span> c <span class="keyword">in</span> xgbfeatureCols]</span><br><span class="line">data_df = data_df.select(*expr)</span><br><span class="line">data_df=data_df.na.fill(<span class="number">999999</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> pandas_udf, PandasUDFType</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 定义返回的结果结构，传入的df会带着grouper字段</span></span><br><span class="line">type_all = <span class="string">&quot;&quot;&quot;pin string, class int&quot;&quot;&quot;</span></span><br><span class="line"><span class="meta">@pandas_udf(<span class="params">type_all, PandasUDFType.GROUPED_MAP</span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_udf</span>(<span class="params">pdf</span>):</span></span><br><span class="line">    <span class="comment"># pdf is a pandas.DataFrame</span></span><br><span class="line">    xgb_dmatrix = xgb.DMatrix(pdf[xgbfeatureCols], feature_names=xgbfeatureCols)</span><br><span class="line">    probs = bestModel.predict(xgb_dmatrix)</span><br><span class="line">    re = np.argmax(probs, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># pdf = pdf.assign(probs=probs)</span></span><br><span class="line">    <span class="comment"># rdf = pd.DataFrame(&#123;&#x27;pin&#x27;:pdf[&#x27;pin&#x27;], &#x27;class&#x27;: re&#125;)</span></span><br><span class="line">    <span class="comment"># rdf = rdf.ix[:, [&#x27;pin&#x27;, &#x27;class&#x27;]]</span></span><br><span class="line">    rdf = pd.DataFrame(&#123;<span class="string">&#x27;pin&#x27;</span>:pdf[<span class="string">&#x27;pin&#x27;</span>], <span class="string">&#x27;class&#x27;</span>: re&#125;, columns=[<span class="string">&#x27;pin&#x27;</span>, <span class="string">&#x27;class&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rdf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> f</span><br><span class="line">nparts = <span class="number">7670</span></span><br><span class="line"><span class="comment"># 划分成nparts个group，每个task在处理一个group时，把对应的dataframe完全加载如内存中</span></span><br><span class="line">output = data_df.select(<span class="string">&quot;pin&quot;</span>, *xgbfeatureCols, (f.ceil(f.rand()*nparts)).alias(<span class="string">&#x27;grouper&#x27;</span>))\</span><br><span class="line">    .groupby(<span class="string">&quot;grouper&quot;</span>)\</span><br><span class="line">    .apply(predict_udf)</span><br><span class="line"></span><br><span class="line">spark.sql(<span class="string">&#x27;use dmr_dev&#x27;</span>)</span><br><span class="line">spark.sql(<span class="string">&#x27;drop table if exists dmr_dev.dmcqm_lhmx_jr_app_biz2_prefer_before_download_s_d_result&#x27;</span>)</span><br><span class="line">spark.sql(<span class="string">&quot;&quot;&quot;create table if not exists dmr_dev.dmcqm_lhmx_jr_app_biz2_prefer_before_download_s_d_result(</span></span><br><span class="line"><span class="string">pin string comment &#x27;&#x27;,</span></span><br><span class="line"><span class="string">class string comment &#x27;&#x27;</span></span><br><span class="line"><span class="string">)&quot;&quot;&quot;</span>)</span><br><span class="line">output.registerTempTable(<span class="string">&#x27;result_table&#x27;</span>)</span><br><span class="line">spark.sql(<span class="string">&#x27;use dmr_dev&#x27;</span>)</span><br><span class="line">spark.sql(<span class="string">&#x27;insert overwrite table dmr_dev.dmcqm_lhmx_jr_app_biz2_prefer_before_download_s_d_result select * from result_table&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="5-当变量个数超过255"><a href="#5-当变量个数超过255" class="headerlink" title="5.当变量个数超过255"></a>5.当变量个数超过255</h2><p>当模型的变量个数超过255时，<code>GROUPED_MAP</code>类型的<code>pandas_udf</code>会报错:<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">org.apache.spark.api.python.PythonException: Traceback (most recent call last):</span><br><span class="line">File &quot;path/to/lib/spark2/python/lib/pyspark.zip/pyspark/worker.py&quot;, line 219, in main</span><br><span class="line">func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)</span><br><span class="line">File &quot;path/to/lib/spark2/python/lib/pyspark.zip/pyspark/worker.py&quot;, line 148, in read_udfs</span><br><span class="line">mapper = eval(mapper_str, udfs)</span><br><span class="line">File &quot;&lt;string&gt;&quot;, line 1</span><br><span class="line">SyntaxError: more than 255 arguments</span><br></pre></td></tr></table></figure></p>
<p>可以由两种方法来解决：</p>
<ul>
<li>升级Spark到2.4以上，但在yarn环境下，几乎不可能随时升级</li>
<li>升级Python到3.7以上</li>
</ul>
<p>很显然，我们应该使用Python 3.7来解决这个问题。如何在5K Spark上使用Python 3.7？请移步<a href="http://git.jd.com/gongjuntai/sparkbasket/blob/master/5KSparkNotes-UsePython37.md">《5K Spark Notes — Use Python 3.7》</a>。</p>
<hr>
<p>参考：<a href="https://issues.apache.org/jira/browse/SPARK-25801">https://issues.apache.org/jira/browse/SPARK-25801</a></p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>初识Thrift</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E5%88%9D%E8%AF%86Thrift/</url>
    <content><![CDATA[<p>thrift入门</p>
<span id="more"></span>
<p>[TOC]</p>
<p>RPC（远程服务调用）</p>
<ul>
<li>thrift框架是什么，Thrift是一套包含序列化功能和支持服务通信的RPC（远程服务调用）框架，也是一种微服务框架。其主要特点是可以跨语言使用，这也是这个框架最吸引人的地方。</li>
<li><p>IDL(Interface Definition Language)即接口定义语言，是CORBA规范的一部分，是跨平台开发的基础。IDL提供一套通用的数据类型，并以这些数据类型来定义更为复杂的数 据类型</p>
</li>
<li><p>pipline （以java为例）</p>
</li>
</ul>
<ol>
<li><p>help.thrift—-文件定义抽象service</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">namespace java tutorial</span><br><span class="line">namespace py tutorial</span><br><span class="line"></span><br><span class="line">typedef i32 int // We can use typedef to get pretty names for the types we are using</span><br><span class="line">service MultiplicationService</span><br><span class="line">&#123;</span><br><span class="line">        int multiply(1:int n1, 2:int n2),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>编译thrift文件得到service抽象类，类中定义了接口方法 public interface Iface</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">thrift --gen java help.thrift  #生成MultiplicationService类，有虚方法 Iface</span><br></pre></td></tr></table></figure>
</li>
<li><p>自定义handler，实现（implements）service的interface（接口）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.thrift.TException;</span><br><span class="line"><span class="keyword">import</span> tutorial.MultiplicationService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiplicationHandler</span> <span class="keyword">implements</span> <span class="title">MultiplicationService</span>.<span class="title">Iface</span> </span>&#123; <span class="comment">//实现方法</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">multiply</span><span class="params">(<span class="keyword">int</span> n1, <span class="keyword">int</span> n2)</span> <span class="keyword">throws</span> TException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Multiply(&quot;</span> + n1 + <span class="string">&quot;,&quot;</span> + n2 + <span class="string">&quot;)&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> n1 * n2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>定义server</p>
</li>
</ol>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>注释和代码规范</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E6%B3%A8%E9%87%8A%E5%92%8C%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>各种代码的注释规范</p>
<span id="more"></span>
<p>[TOC]</p>
<h2 id="scala规范"><a href="#scala规范" class="headerlink" title="scala规范"></a>scala规范</h2><p>注释使用和 Java 完全一样</p>
<p>（ 1）单行注释： // </p>
<p>（ 2）多行注释： /<em> </em>/ </p>
<p>（ 3）文档注释： /<em>* </em> */  文档注释要在一个方法或类前边进行注释 </p>
<p><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/%E6%B3%A8%E9%87%8A%E5%92%8C%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/image-20220318143823448.png" alt="image-20220318143823448" style="zoom:50%;"></p>
<h2 id="python注释规范"><a href="#python注释规范" class="headerlink" title="python注释规范"></a>python注释规范</h2><h2 id="java注释规范"><a href="#java注释规范" class="headerlink" title="java注释规范"></a>java注释规范</h2>]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2022/07/24/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/pytorch%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<p>[TOC]</p>
<h1 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h1><p>torch.utils.data.Dataset： 存储sample数据集</p>
<p>torch.utils.data.DataLoader ： 包装数据可迭代对象</p>
<h2 id="数据集下载"><a href="#数据集下载" class="headerlink" title="数据集下载"></a>数据集下载</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> ToTensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download training data from open datasets.</span></span><br><span class="line">training_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor(),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download test data from open datasets.</span></span><br><span class="line">test_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor(),</span><br><span class="line">)</span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data loaders.</span></span><br><span class="line">train_dataloader = DataLoader(training_data, batch_size=batch_size)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> test_dataloader:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Shape of X [N, C, H, W]: <span class="subst">&#123;X.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Shape of y: <span class="subst">&#123;y.shape&#125;</span> <span class="subst">&#123;y.dtype&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h2 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line">labels_map = &#123;</span><br><span class="line">    <span class="number">0</span>: <span class="string">&quot;T-Shirt&quot;</span>,</span><br><span class="line">    <span class="number">1</span>: <span class="string">&quot;Trouser&quot;</span>,</span><br><span class="line">    <span class="number">2</span>: <span class="string">&quot;Pullover&quot;</span>,</span><br><span class="line">    <span class="number">3</span>: <span class="string">&quot;Dress&quot;</span>,</span><br><span class="line">    <span class="number">4</span>: <span class="string">&quot;Coat&quot;</span>,</span><br><span class="line">    <span class="number">5</span>: <span class="string">&quot;Sandal&quot;</span>,</span><br><span class="line">    <span class="number">6</span>: <span class="string">&quot;Shirt&quot;</span>,</span><br><span class="line">    <span class="number">7</span>: <span class="string">&quot;Sneaker&quot;</span>,</span><br><span class="line">    <span class="number">8</span>: <span class="string">&quot;Bag&quot;</span>,</span><br><span class="line">    <span class="number">9</span>: <span class="string">&quot;Ankle Boot&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line">figure = plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">cols, rows = <span class="number">3</span>, <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, cols * rows + <span class="number">1</span>):</span><br><span class="line">    sample_idx = torch.randint(<span class="built_in">len</span>(training_data), size=(<span class="number">1</span>,)).item()</span><br><span class="line">    img, label = training_data[sample_idx]</span><br><span class="line">    figure.add_subplot(rows, cols, i)</span><br><span class="line">    plt.title(labels_map[label])</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.imshow(img.squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="自定义数据集"><a href="#自定义数据集" class="headerlink" title="自定义数据集"></a>自定义数据集</h2><p>继承  类，实现<strong>init</strong>, <strong>len</strong>, and <strong>getitem</strong>方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> torchvision.io <span class="keyword">import</span> read_image</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomImageDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, annotations_file, img_dir, transform=<span class="literal">None</span>, target_transform=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.img_labels = pd.read_csv(annotations_file)</span><br><span class="line">        self.img_dir = img_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.target_transform = target_transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span> <span class="comment">#返回sample数</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_labels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, <span class="number">0</span>])</span><br><span class="line">        image = read_image(img_path)</span><br><span class="line">        label = self.img_labels.iloc[idx, <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">        <span class="keyword">if</span> self.target_transform:</span><br><span class="line">            label = self.target_transform(label)</span><br><span class="line">        <span class="keyword">return</span> image, label</span><br></pre></td></tr></table></figure>
<h1 id="Creating-Models"><a href="#Creating-Models" class="headerlink" title="Creating Models"></a>Creating Models</h1><h2 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h2><p>继承nn.Model并实现__init__和forward函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Get cpu or gpu device for training.</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Using <span class="subst">&#123;device&#125;</span> device&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define model</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNetwork</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NeuralNetwork, self).__init__()</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.linear_relu_stack = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span> <span class="comment">#实现前向传导</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        logits = self.linear_relu_stack(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line">model = NeuralNetwork().to(device)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure>
<h2 id="优化模型"><a href="#优化模型" class="headerlink" title="优化模型"></a>优化模型</h2><p>定义loss和optimizer</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">dataloader, model, loss_fn, optimizer</span>):</span></span><br><span class="line">    size = <span class="built_in">len</span>(dataloader.dataset)</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        X, y = X.to(device), y.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute prediction error</span></span><br><span class="line">        pred = model(X) <span class="comment">#自动执行forward</span></span><br><span class="line">        loss = loss_fn(pred, y)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backpropagation</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment">#梯度清零（某些优化方法可用梯度累加等）</span></span><br><span class="line">        loss.backward() <span class="comment">#计算梯度</span></span><br><span class="line">        optimizer.step() <span class="comment">#更新变量</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            loss, current = loss.item(), batch * <span class="built_in">len</span>(X)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;loss: <span class="subst">&#123;loss:&gt;7f&#125;</span>  [<span class="subst">&#123;current:&gt;5d&#125;</span>/<span class="subst">&#123;size:&gt;5d&#125;</span>]&quot;</span>)</span><br><span class="line">            </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">dataloader, model, loss_fn</span>):</span></span><br><span class="line">    size = <span class="built_in">len</span>(dataloader.dataset)</span><br><span class="line">    num_batches = <span class="built_in">len</span>(dataloader)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): <span class="comment">#整个网络都停止自动求导，可以大大加快速度，也可以使用大的batch_size来测试</span></span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> dataloader:</span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            pred = model(X)</span><br><span class="line">            test_loss += loss_fn(pred, y).item()</span><br><span class="line">            correct += (pred.argmax(<span class="number">1</span>) == y).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">    test_loss /= num_batches</span><br><span class="line">    correct /= size</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Test Error: \n Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.1</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;test_loss:&gt;8f&#125;</span> \n&quot;</span>)  </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">epochs = <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;t+<span class="number">1</span>&#125;</span>\n-------------------------------&quot;</span>)</span><br><span class="line">    train(train_dataloader, model, loss_fn, optimizer)</span><br><span class="line">    test(test_dataloader, model, loss_fn)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Done!&quot;</span>)</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>2020[DFN](IJCAI)(Tencent)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BDFN%5D(IJCAI)(Tencent)/</url>
    <content><![CDATA[<p>(1) Xie R, Ling C, Wang Y, Wang R, Xia F, Lin L. Deep Feedback Network for Recommendation. In: <em>Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence</em>. International Joint Conferences on Artificial Intelligence Organization; 2020:2519-2525. doi:<a href="https://doi.org/10.24963/ijcai.2020/349">10.24963/ijcai.2020/349</a></p>
<p><strong>代码链接</strong>：<a href="https://github.com/qqxiaochongqq/DFN">https://github.com/qqxiaochongqq/DFN</a></p>
<p><strong>简介</strong></p>
<p>本文是微信团队在头条新闻场景的精排模型。用户的显式、隐式反馈都反映了其兴趣偏好了，但是目前大多数推荐模型都只利用了用户的隐式正反馈（点击）。本文综合利用用户的[显式，隐式]×[正反馈，负反馈]联合建模用户的<strong>无偏兴趣</strong>（unbiased preference）</p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p><strong>动机</strong></p>
<p>用户的显式、隐式反馈都反映了其兴趣偏好。但是目前大多数推荐模型都只利用了用户的隐式正反馈（点击），这会导致以下几个问题：</p>
<ol>
<li>仅关注到用户喜欢什么而忽略了用户不喜欢什么，另一方面导致模型短视且倾向于提供同质的结果，最终影响用户体验。</li>
<li>除了被动接收模型选择的信息外，用户还需要有效且高效的反馈机制来主动与推荐系统交互。负反馈的缺失会损害这种反馈机制。</li>
<li>隐反馈存在噪声</li>
</ol>
<p>[显式，隐式]×[正反馈，负反馈]能够相互补充，从而建模用户的<strong>无偏兴趣</strong>（unbiased preference）</p>
<p><strong>解法</strong></p>
<p>本文场景是微信的头条新闻推荐场景。反馈包括隐式正反馈（点击），隐式负反馈（曝光未点击），显式负反馈（不喜欢）。本文通过transformer分别对三个序列进行编码，再通过external feedback interac- tion component用点击和不喜欢信息对曝光未点击信息进行去噪。本文相关研究领域包括推荐系统、隐反馈建模、负反馈建模。</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[DFN](IJCAI)(Tencent)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BDFN%5D(IJCAI)(Tencent)/image-20220613165420841-5110465.png" class title="image-20220613165420841">
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[DFN](IJCAI)(Tencent)/image-20220613172517134.png" alt="image-20220613172517134" style="zoom:100%;"></p>
<ul>
<li><p>Internal Feedback Interaction Component</p>
<p>行为内部使用transformer+avg_pooling进行编码，最后生成点击行为向量、曝光未点击向量、不喜欢向量。具体来说，以点击序列为例，将target加入序列中，然后进行正常的transformer编码。</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[DFN](IJCAI)(Tencent)/image-20220613173119757.png" alt="image-20220613173119757" style="zoom:100%;"></p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[DFN](IJCAI)(Tencent)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BDFN%5D(IJCAI)(Tencent)/image-20220613173148124.png" class title="image-20220613173148124">
</li>
<li><p>External Feedback Interaction Component</p>
<p>基本思路是通过点击和不喜欢信息甄别曝光未点击序列中哪些是真正不喜欢的。即用点击和不喜欢的行为向量分别作为query对曝光未点击系列进行attention聚合。</p>
</li>
</ul>
<p>最后用户行为序列包含5个部分，分别是：点击向量，不喜欢向量，曝光未点击向量，曝光未点击中偏向于喜欢的向量，曝光未点击中偏向于不喜欢的向量。</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[DFN](IJCAI)(Tencent)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BDFN%5D(IJCAI)(Tencent)/image-20220613173553259.png" class title="image-20220613173553259">
<ul>
<li><p>优化目标</p>
<p>优化目标包含点击、不喜欢、曝光未点击3部分</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[DFN](IJCAI)(Tencent)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BDFN%5D(IJCAI)(Tencent)/image-20220613174416596.png" class title="image-20220613174416596">
</li>
<li><p>后续规划</p>
</li>
</ul>
<ol>
<li>使用更复杂的模型进行特征交互</li>
<li>增加更多显示反馈</li>
</ol>
<p><strong>评论</strong></p>
<p>微信头条（WeChat Top Stories ）的精排模型。用点击、曝光未点击、不喜欢三个序列，序列内部用transformer编码，<strong>序列间用点击和不喜欢两个序列对曝光未点击序列进行增强和过滤</strong>，优化目标中预估点击、曝光未点击、不喜欢三种行为。</p>
<p>session内隐式负反馈的编码可借鉴此方法</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>负反馈建模</tag>
      </tags>
  </entry>
  <entry>
    <title>tensroflow各种模型保存和加载</title>
    <url>/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/tensroflow%E5%90%84%E7%A7%8D%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/</url>
    <content><![CDATA[<p>tf模型保存和加载</p>
<span id="more"></span>
<p><a href="https://zhuanlan.zhihu.com/p/128546377">https://zhuanlan.zhihu.com/p/128546377</a></p>
<p>[TOC]</p>
<h1 id="Tensorflow笔记：模型保存、加载和Fine-tune"><a href="#Tensorflow笔记：模型保存、加载和Fine-tune" class="headerlink" title="Tensorflow笔记：模型保存、加载和Fine-tune"></a>Tensorflow笔记：模型保存、加载和Fine-tune</h1><p><a href="https://www.zhihu.com/people/chong-yu-4-73"><img src="/2022/03/01/0_%E4%BB%A3%E7%A0%81%E7%9B%B8%E5%85%B3/tensroflow%E5%90%84%E7%A7%8D%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/tensroflow各种模型保存和加载/v2-da8a1fcd82fbe5f7206ac58cee088681_xs.jpg" alt="锟斤拷"></a></p>
<p><a href="https://www.zhihu.com/people/chong-yu-4-73">锟斤拷</a></p>
<p>50 人赞同了该文章</p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>尝试过迁移学习的同学们都知道，Tensorflow的模型保存加载有不同格式，使用方法也不一样，新手会觉得乱七八糟，所以本文做一个梳理。从模型的保存到加载，再到使用，力求理清这个流程。</p>
<h2 id="1-保存"><a href="#1-保存" class="headerlink" title="1. 保存"></a>1. 保存</h2><p>Tensorflow的保存分为三种：1. checkpoint模式；2. pb模式；3. saved_model模式。</p>
<h3 id="1-1-先假设有这么个模型"><a href="#1-1-先假设有这么个模型" class="headerlink" title="1.1 先假设有这么个模型"></a>1.1 先假设有这么个模型</h3><p>首先假定我们已经有了这样一个简单的线性回归网络结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">size = 10</span><br><span class="line"># 构建input</span><br><span class="line">X = tf.placeholder(name=&quot;input&quot;, shape=[None, size], dtype=tf.float32)</span><br><span class="line">y = tf.placeholder(name=&quot;label&quot;, shape=[None, 1], dtype=tf.float32)</span><br><span class="line"># 网络结构</span><br><span class="line">beta = tf.get_variable(name=&quot;beta&quot;, shape=[size, 1], initializer=tf.glorot_normal_initializer())</span><br><span class="line">bias = tf.get_variable(name=&quot;bias&quot;, shape=[1], initializer=tf.glorot_normal_initializer())</span><br><span class="line">pred = tf.add(tf.matmul(X, beta), bias, name=&quot;output&quot;)</span><br><span class="line"># 构建损失</span><br><span class="line">loss = tf.losses.mean_squared_error(y, pred)</span><br><span class="line"># 构建train_op</span><br><span class="line">train_op = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8).minimize(loss)</span><br></pre></td></tr></table></figure>
<p>我们来简单初始化，然后跑一下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 假设这是一个batch_size=8的batch</span><br><span class="line">feed_X = np.ones((8,size)).astype(np.float32)</span><br><span class="line">feed_y = np.ones((8,1)).astype(np.float32)</span><br><span class="line"># 先看一下pred，在训练一个step，在看一下pred是否有变化</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(pred, feed_dict=&#123;X:feed_X&#125;))</span><br><span class="line">    sess.run(train_op, feed_dict=&#123;X:feed_X, y:feed_y&#125;)</span><br><span class="line">    print(sess.run(pred, feed_dict=&#123;X:feed_X&#125;))</span><br></pre></td></tr></table></figure>
<p>可以看到初始化的输出y值，以及训练1个step之后的模型输出发生了变化。</p>
<h3 id="1-2-checkpoint模式"><a href="#1-2-checkpoint模式" class="headerlink" title="1.2 checkpoint模式"></a>1.2 checkpoint模式</h3><p>checkpoint模式将网络和变量数据分开保存，保存好的模型长这个样子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|--checkpoint_dir</span><br><span class="line">|    |--checkpoint</span><br><span class="line">|    |--test-model-550.meta</span><br><span class="line">|    |--test-model-550.data-00000-of-00001</span><br><span class="line">|    |--test-model-550.index</span><br></pre></td></tr></table></figure>
<p>checkpoint_dir就是保存时候指定的路径，路径下会生成4个文件。其中.meta文件（其实就是pb格式文件）用来保存模型结构，.data和.index文件用来保存模型中的各种变量，而checkpoint文件里面记录了最新的checkpoint文件以及其它checkpoint文件列表，在inference时可以通过修改这个文件，指定使用哪个model。那么要如何保存呢？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 只有sess中有变量的值，所以保存模型的操作只能在sess内</span><br><span class="line">checkpoint_dir = &quot;./model_ckpt/&quot;</span><br><span class="line">saver = tf.train.Saver(max_to_keep=1)    # saver 不需要在sess内</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    saver.save(sess, checkpoint_dir + &quot;test-model&quot;,global_step=i, write_meta_graph=True)</span><br></pre></td></tr></table></figure>
<p>实际就两步。执行之后就可以在checkpoint_dir下面看到前面提到的4个文件了。（这里的max_to_keep是指本次训练在checkpoint_dir这个路径下最多保存多少个模型文件，新模型会覆盖旧模型以节省空间）。</p>
<h3 id="1-3-pb模式"><a href="#1-3-pb模式" class="headerlink" title="1.3 pb模式"></a>1.3 pb模式</h3><p>pb模式保存的模型，只有在目标路径pb_dir = “./model_pb/“下孤孤单单的一个文件”test-model.pb”，这也是它相比于其他几种方式的优势，简单明了。假设还是前面的网络结构，如果想保存成pb模式该怎么做呢？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 只有sess中有变量的值，所以保存模型的操作只能在sess内</span><br><span class="line">pb_dir = &quot;./model_pb/&quot;</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    graph_def = tf.get_default_graph().as_graph_def()</span><br><span class="line">    # 这里是指定要冻结并保存到pb模型中的变量</span><br><span class="line">    var_list = [&quot;input&quot;, &quot;label&quot;, &quot;beta&quot;, &quot;bias&quot;, &quot;output&quot;]   # 如果有name_scope，要写全名，如:&quot;name_scope/beta&quot; </span><br><span class="line">    constant_graph = tf.graph_util.convert_variables_to_constants(sess, graph_def, var_list)</span><br><span class="line">    with tf.gfile.FastGFile(pb_dir + &quot;test-model.pb&quot;, mode=&#x27;wb&#x27;) as f:</span><br><span class="line">        f.write(constant_graph.SerializeToString())</span><br></pre></td></tr></table></figure>
<p>其实pb模式本质上就是把变量先冻结成常数，然后保存到图结构中。这样就可以直接加载图结构和“参数”了。</p>
<h3 id="1-4-saved-model模式"><a href="#1-4-saved-model模式" class="headerlink" title="1.4 saved_model模式"></a>1.4 saved_model模式</h3><p>虽然saved_model也支持模型加载，并进行迁移学习。可是不得不说<strong>saved_model几乎就是为了部署而生的</strong>，因为依靠tf.Serving部署模型时要求模型格式必须是saved_model格式。除此以外saved_model还有另外一个优点就是可以跨语言读取，所以本文也介绍一下这种模式的保存于加载。<strong>本文样例的保存在参数设置上会考虑到方便部署</strong>。保存好的saved_model结构长这个样子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|--saved_model_dir</span><br><span class="line">|    |--1</span><br><span class="line">|        |--saved_model.pb</span><br><span class="line">|        |--variables</span><br><span class="line">|            |--variables.data-00000-of-00001</span><br><span class="line">|            |--variables.index</span><br></pre></td></tr></table></figure>
<p>保存时需要将保存路径精确到”saved_model_dir/1/ “，会在下面生成一个pb文件，以及一个variables文件夹。其中“1”文件夹是表示版本的文件夹，应该是一个整数。人为设定这个“版本文件夹”的原因是，在模型部署的时候需要将模型位置精确到saved_model_dir，tf.Serving会在saved_model_dir下搜索版本号最大的路径下的模型进行服务。模型保存的方法是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 只有sess中有变量的值，所以保存模型的操作只能在sess内</span><br><span class="line">version = &quot;1/&quot;</span><br><span class="line">saved_model_dir = &quot;./saved_model/test-model-dir/&quot;</span><br><span class="line">builder = tf.saved_model.builder.SavedModelBuilder(saved_model_dir + version)</span><br><span class="line"></span><br><span class="line"># 构建 signature</span><br><span class="line">signature = tf.saved_model.signature_def_utils.build_signature_def(</span><br><span class="line">        # 获取输入输出的信息（shape,dtype等），在部署服务后请求带来的数据会喂到inputs中，服务吐的结果会以outputs的形式返回</span><br><span class="line">        inputs=&#123;&quot;input&quot;: tf.saved_model.utils.build_tensor_info(X)&#125;,          # 获取输入tensor的信息，这个字典可以有多个key-value对</span><br><span class="line">        outputs=&#123;&quot;output&quot;: tf.saved_model.utils.build_tensor_info(pred)&#125;,     # 获取输出tensor的信息，这个字典可以有多个key-value对</span><br><span class="line">        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME    # 就是&#x27;tensorflow/serving/predict&#x27;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 保存到 saved_model</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    builder.add_meta_graph_and_variables(sess, </span><br><span class="line">        tags=[tf.saved_model.tag_constants.SERVING],         # 如果用来部署，就这样写。否则可以写其他，如[&quot;test-model&quot;]</span><br><span class="line">        signature_def_map=&#123;&quot;serving_default&quot;: signature&#125;,    # 如果用来部署，字典的key必须是&quot;serving_default&quot;。否则可以写其他</span><br><span class="line">    )</span><br><span class="line">    builder.save()</span><br></pre></td></tr></table></figure>
<p>因为涉及到部署，比较复杂，这里不得不说明一下。</p>
<p>在保存之前需要构建一个signature，用来构造signature的build_signature_def函数有三个参数：inputs、outputs、method_name。其中inputs和outputs分别用来获取输入输出向量的信息，在部署服务后来的数据会喂到inputs中，服务吐的结果会以outputs的形式返回；而method_name如果用来部署模型的话需要设置为”tensorflow/serving/predict”, “tensorflow/serving/classify”, “tensorflow/serving/regress” 中的一个。如果不是用来服务，就可以写一个其他的。</p>
<p>在保存的时候，除了刚刚构建的signature，还需要提供一个tags 参数，如果用来部署的话需要填[tf.saved_model.tag_constants.SERVING]，否则可以填其他。另外如果用来部署模型的话，signature_def_map的key必须是”serving_default”。</p>
<h2 id="2-加载"><a href="#2-加载" class="headerlink" title="2. 加载"></a>2. 加载</h2><p>下面说如何加载，checkpoint和pb两种模式的加载方法也不一样。下面分别说</p>
<h3 id="2-1-checkpoint加载（略烦）"><a href="#2-1-checkpoint加载（略烦）" class="headerlink" title="2.1 checkpoint加载（略烦）"></a>2.1 checkpoint加载（略烦）</h3><p>checkpoint模式的网络结构和变量是分来保存的，加载的时候也需要分别加载。而网络结构部分你有两种选择：1. 加载.meta文件中的结构， 2. 手动重新写一遍原样结构。</p>
<p>我们先说后一个，如果你不光有模型文件，还有源码，可以把源码构建模型那部分复制过来，然后只加载变量就好，这是手动重新搭建网络结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">size = 10</span><br><span class="line"># 构建input</span><br><span class="line">X = tf.placeholder(name=&quot;input&quot;, shape=[None, size], dtype=tf.float32)</span><br><span class="line">y = tf.placeholder(name=&quot;label&quot;, shape=[None, 1], dtype=tf.float32)</span><br><span class="line"># 网络结构</span><br><span class="line">beta = tf.get_variable(name=&quot;beta&quot;, shape=[size, 1], initializer=tf.glorot_normal_initializer())</span><br><span class="line">bias = tf.get_variable(name=&quot;bias&quot;, shape=[1], initializer=tf.glorot_normal_initializer())</span><br><span class="line">pred = tf.sigmoid(tf.matmul(X, beta) + bias, name=&quot;output&quot;)</span><br></pre></td></tr></table></figure>
<p>然后加载变量：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 假设这是一个batch_size=8的batch</span><br><span class="line">feed_X = np.ones((8,size)).astype(np.float32)</span><br><span class="line">feed_y = np.ones((8,1)).astype(np.float32)</span><br><span class="line"># 用加载出来的参数，跑一下pred</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    saver.restore(sess, tf.train.latest_checkpoint(&#x27;./model_ckpt/&#x27;))    # 加载模型中的变量</span><br><span class="line">    # sess.run(tf.global_variables_initializer())    # 重新初始化一下参数</span><br><span class="line">    print(sess.run(pred, feed_dict=&#123;X:feed_X&#125;))</span><br></pre></td></tr></table></figure>
<p>所以手动构建网络结构后，只需要saver.restore一下，就可以加载模型中的参数。</p>
<p>另外，如果将上面的sess.run(tf.global_variables_initializer())注释掉，那每次运行的结果都一样，可见此时模型中的变量确实是加载进来的变量。如果取消注释这一句，每次跑出来的结果都不同，因为加载进来的变量又被初始化函数覆盖了，所以每次都不一样。这也说明了：<strong>通过checkpoint这种模式加载进来的变量，依然是变量，而且是trainable=True的</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print(tf.trainable_variables())</span><br></pre></td></tr></table></figure>
<p>结果为：[<tf.Variable 'beta:0' shape="(10," 1) dtype="float32_ref">, <tf.Variable 'bias:0' shape="(1,)" dtype="float32_ref">]</tf.Variable></tf.Variable></p>
<p>那如果我懒，活着没有源码，无法手动构建网络呢？就需要从.meta文件里导入网络结构了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 不手动构建，从文件中加载网络结构</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">size = 10</span><br><span class="line"># 加载网络</span><br><span class="line">saver=tf.train.import_meta_graph(&#x27;./model_ckpt/test-model-0.meta&#x27;)</span><br></pre></td></tr></table></figure>
<p>什么？这就完了？网络结构在哪呢？先别急，这种方法就是这样，网络结构已经加载进来了，那怎么用呢？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 假设这是一个batch</span><br><span class="line">feed_X = np.ones((8,size)).astype(np.float32)</span><br><span class="line">feed_y = np.ones((8,1)).astype(np.float32)</span><br><span class="line"># 下面我们来跑一下 pred</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    saver.restore(sess, tf.train.latest_checkpoint(&#x27;./model_ckpt/&#x27;))  # 加载模型变量</span><br><span class="line">    graph = tf.get_default_graph()</span><br><span class="line">    X = graph.get_tensor_by_name(&quot;input:0&quot;)        # 根据tensor名字获取tensor变量</span><br><span class="line">    pred = graph.get_tensor_by_name(&quot;output:0&quot;)    # 根据tensor名字获取tensor变量</span><br><span class="line">    # sess.run(tf.global_variables_initializer())  # 是否重新初始化变量</span><br><span class="line">    print(sess.run(pred, feed_dict=&#123;X:feed_X&#125;))</span><br></pre></td></tr></table></figure>
<p>其实前面把网络结构加载进来之后，如果需要对某tensor进行操作的话（run、feed、concat等等）需要通过tensor的name获取成变量。同样通过sess.run(tf.global_variables_initializer())可以看出，加载进来的变量，还是变量。</p>
<p>总结一下：手动构建网络结构的话，缺点是麻烦！优点是你想用什么变量直接用就行；而通过.meta文件来加载网络结构，优点是省事，缺点是如果想用某个变量，必须通过name获取变量。</p>
<h3 id="2-2-pb模式加载"><a href="#2-2-pb模式加载" class="headerlink" title="2.2 pb模式加载"></a>2.2 pb模式加载</h3><p>相比之下，pb模式的加载旧没那么复杂，因为他的网络结构和数据是存在一起的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># 直接从pb获取tensor</span><br><span class="line">pb_dir = &quot;./model_pb/&quot;</span><br><span class="line">with tf.gfile.FastGFile(pb_dir + &quot;test-model.pb&quot;, &quot;rb&quot;) as f:</span><br><span class="line">    graph_def = tf.GraphDef()</span><br><span class="line">    graph_def.ParseFromString(f.read())    # 从pb文件中导入信息</span><br><span class="line">    # 从网络中通过tensor的name获取为变量</span><br><span class="line">    X, pred = tf.import_graph_def(graph_def, return_elements=[&quot;input:0&quot;, &quot;output:0&quot;])</span><br></pre></td></tr></table></figure>
<p>现在我们就已经有了X和pred，下面来跑一个pred吧</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 假设这是一个batch</span><br><span class="line">feed_X = np.ones((8,size)).astype(np.float32)</span><br><span class="line">feed_y = np.ones((8,1)).astype(np.float32)</span><br><span class="line"># 跑一下 pred</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    # sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(pred, feed_dict=&#123;X:feed_X&#125;))</span><br></pre></td></tr></table></figure>
<p>就这么简单！从pb中获取进来的“变量”就可以直接用。为什么我要给变量两个字打上引号呢？因为在pb模型里保存的其实是常量了，取消注释sess.run(tf.global_variables_initializer())后，多次运行的结果还是一样的。此时的“beta:0”和”bias:0”已经不再是variable，而是constant。<strong>这带来一个好处：读取模型中的tensor可以在Session外进行。相比之下checkpoint只能在Session内读取模型，对Fine-tune来说就比较麻烦。</strong></p>
<h3 id="2-3-saved-model模式加载"><a href="#2-3-saved-model模式加载" class="headerlink" title="2.3 saved_model模式加载"></a>2.3 saved_model模式加载</h3><p>前两种加载方法想要获取tensor，要么需要手动搭建网络，要么需要知道tensor的name，如果用模型和训模型的不是同一个人，那在没有源码的情况下，就不方便获取每个tensor的name。好在saved_model可以通过前面提到的signature_def_map的方法获取tensor。先看一下直接通过tensor的name获取变量的加载方式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 假设这是一个batch</span><br><span class="line">size = 10</span><br><span class="line">feed_X = np.ones((8,size)).astype(np.float32)</span><br><span class="line">feed_y = np.ones((8,1)).astype(np.float32)</span><br><span class="line"></span><br><span class="line">saved_model_dir = &quot;./saved_model/1/&quot;</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    # tf.saved_model.tag_constants.SERVING == &quot;serve&quot;，这里load时的tags需要和保存时的tags一致</span><br><span class="line">    meta_graph_def = tf.saved_model.loader.load(sess, tags=[&quot;serve&quot;], export_dir=saved_model_dir)</span><br><span class="line">    graph = tf.get_default_graph()</span><br><span class="line">    X = graph.get_tensor_by_name(&quot;input:0&quot;)</span><br><span class="line">    pred = graph.get_tensor_by_name(&quot;output:0&quot;)</span><br><span class="line">    # sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(pred, feed_dict=&#123;X:feed_X&#125;))</span><br></pre></td></tr></table></figure>
<p>这里和checkpoint的加载过程很相似，先一个load过程，然后get_tensor_by_name。这需要我们事先知道tensor的name。如果有了signature的信息就不一样了：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 假设这是一个batch</span><br><span class="line">size = 10</span><br><span class="line">feed_X = np.ones((8,size)).astype(np.float32)</span><br><span class="line">feed_y = np.ones((8,1)).astype(np.float32)</span><br><span class="line"></span><br><span class="line">saved_model_dir = &quot;./saved_model/1/&quot;</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    # tf.saved_model.tag_constants.SERVING == &quot;serve&quot;，这里load时的tags需要和保存时的tags一致</span><br><span class="line">    meta_graph_def = tf.saved_model.loader.load(sess, tags=[&quot;serve&quot;], export_dir=saved_model_dir)</span><br><span class="line">    signature = meta_graph_def.signature_def</span><br><span class="line">    # print(signature)    # signature 内包含了保存模型时，signature_def_map 的信息</span><br><span class="line">    X = signature[&quot;serving_default&quot;].inputs[&quot;input&quot;].name</span><br><span class="line">    pred = signature[&quot;serving_default&quot;].outputs[&quot;output&quot;].name</span><br><span class="line">    print(sess.run(pred, feed_dict=&#123;X:feed_X&#125;))</span><br></pre></td></tr></table></figure>
<p>这时即使我们没有源码，也可以通过print(signature)获知关于tensor的信息，如上就展示了没有源码时，通过signature获取tensor的name，并获取tensor的过程。这里输出的signature长这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># signature长什么样</span><br><span class="line">print(signature)</span><br><span class="line"></span><br><span class="line"># 输出</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">INFO:tensorflow:Restoring parameters from ./saved_model/1/variables/variables</span><br><span class="line">&#123;&#x27;serving_default&#x27;: inputs &#123;</span><br><span class="line">  key: &quot;input&quot;</span><br><span class="line">  value &#123;</span><br><span class="line">    name: &quot;input:0&quot;</span><br><span class="line">    dtype: DT_FLOAT</span><br><span class="line">    tensor_shape &#123;</span><br><span class="line">      dim &#123;</span><br><span class="line">        size: -1</span><br><span class="line">      &#125;</span><br><span class="line">      dim &#123;</span><br><span class="line">        size: 10</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">outputs &#123;</span><br><span class="line">  key: &quot;output&quot;</span><br><span class="line">  value &#123;</span><br><span class="line">    name: &quot;output:0&quot;</span><br><span class="line">    dtype: DT_FLOAT</span><br><span class="line">    tensor_shape &#123;</span><br><span class="line">      dim &#123;</span><br><span class="line">        size: -1</span><br><span class="line">      &#125;</span><br><span class="line">      dim &#123;</span><br><span class="line">        size: 1</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">method_name: &quot;tensorflow/serving/predict&quot;</span><br><span class="line">&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<h2 id="3-Fine-tune"><a href="#3-Fine-tune" class="headerlink" title="3. Fine-tune"></a>3. Fine-tune</h2><p>最后不管保存还是加载模型，多数情况都是为了能够进行迁移学习。其实大部分无非就是将模型加载进来之后，使用某一个节点的值，作为我们后续模型的输入呗。比如我要用前面的模型结果作为特征通过一元罗辑回归去预测z，这样新的网络结构就是这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># 加载模型部分，直接从pb获取X和pred</span><br><span class="line">pb_dir = &quot;./model_pb/&quot;</span><br><span class="line">with tf.gfile.FastGFile(pb_dir + &quot;test-model.pb&quot;, &quot;rb&quot;) as f:</span><br><span class="line">    graph_def = tf.GraphDef()</span><br><span class="line">    graph_def.ParseFromString(f.read())</span><br><span class="line">    X, pred = tf.import_graph_def(graph_def, return_elements=[&quot;input:0&quot;, &quot;output:0&quot;])</span><br><span class="line"></span><br><span class="line"># 下面是 Fine-tune 部分</span><br><span class="line"># 新的 label</span><br><span class="line">z = tf.placeholder(name=&quot;new_label&quot;, shape=[None, 1], dtype=tf.float32)</span><br><span class="line"># 新的参数</span><br><span class="line">new_beta = tf.get_variable(name=&quot;new_beta&quot;, shape=[1], initializer=tf.glorot_normal_initializer())</span><br><span class="line">new_bias = tf.get_variable(name=&quot;new_bias&quot;, shape=[1], initializer=tf.glorot_normal_initializer())</span><br><span class="line"># 一元罗辑回归，通过pred去预测z</span><br><span class="line">new_pred = tf.sigmoid(new_beta * pred + new_beta)    # 这种变量不写name的习惯是不好的哦</span><br><span class="line"></span><br><span class="line"># 下面是构建模型的损失函数以及train_op</span><br><span class="line"># log_loss</span><br><span class="line">new_loss = tf.reduce_mean(tf.losses.log_loss(predictions=new_pred, labels=z))</span><br><span class="line"># train_op</span><br><span class="line">train_op = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8).minimize(new_loss)</span><br></pre></td></tr></table></figure>
<p>就是这样，把保存好的模型看作一个黑盒，喂进去X吐出来pred，然后我们直接用pred就好了。</p>
<p>但是这里存在一个问题，就是只能通过name获取节点。比如这里的new_pred就没有name，那我想要基于这个新模型再次进行Fine-tune的时候，就不能获取这个new_pred，就无法进行Fine-tune。所以大家还是要养成一个好习惯，多给变量起名字，尤其是placeholder！要是连placeholder都没名字，别人就没法用你的模型啦。如果保存的是saved_model，建议一定要设置signature。</p>
<p>下面来实验一下这个Fine-tune的模型吧：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 假设这是一个batch</span><br><span class="line">feed_X = np.ones((8,size)).astype(np.float32)</span><br><span class="line">feed_z = np.array([[1],[1],[0],[0],[1],[1],[0],[0]]).astype(np.float32)</span><br><span class="line"># 跑一下 new_pred 之后train一个step，在看看 new_pred 有没有改变</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    print(sess.run(new_pred, feed_dict=&#123;X:feed_X&#125;))</span><br><span class="line">    sess.run(train_op,  feed_dict=&#123;X:feed_X, z:feed_z&#125;)</span><br><span class="line">    print(sess.run(new_pred, feed_dict=&#123;X:feed_X&#125;))</span><br></pre></td></tr></table></figure>
<p>这里补充一下：<strong>通过pb模式导入进来的参数其实是constants，所以在Fine-tune的时候不会变化，而通过checkpoint模式导入进来的参数是variables，在后续Fine-tune的时候是会发生变化的</strong>。具体让不让他trainable就看你的实际需要了。</p>
<h2 id="4-其他补充"><a href="#4-其他补充" class="headerlink" title="4. 其他补充"></a>4. 其他补充</h2><p>在2.2中，加载pb模型的时候，并不需要把所有的tensor都获取到，只要“一头一尾”即可。因为头（”input:0”）是需要进行feed操作的，而尾（”output:0”）是需要输出，或者在迁移学习中要进行其他操作。至于中间哪些其他不需要进行操作的tensor，可以不获取。</p>
<p>因为只有pb模式在加载的时候，可以在Session外进行加载，方便Fine-tune。所以个人建议，如果要进行迁移学习，先将模型转化为pb模式。</p>
<p>其他的想起来在写</p>
]]></content>
      <categories>
        <category>代码相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>代码相关</tag>
      </tags>
  </entry>
  <entry>
    <title>2020[S3-Rec](ICKM)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BS3-Rec%5D(ICKM)/</url>
    <content><![CDATA[<p>Zhou K, Wang H, Zhao W X, et al. S3-rec: Self-supervised learning for sequential recommendation with mutual information maximization[C]//Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management. 2020: 1893-1902 </p>
<p><strong>简介</strong>：本文来自美团和人大，采用预训练+微调的方式训练序列推荐模型。序列预测任务中通常用预测任务相关的loss进行优化，这会导致模型过分强调最终性能，没有很好的捕捉上下文和序列之间的关联。S3-Rec基于互信息最大化（mutual information maximization ,MIM）的思想，通过在预训练中引入4个互信息相关的任务来自监督挖掘数据内在关联，优化最终的表征。</p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p><strong>动机</strong></p>
<p>以预测任务loss为优化目标的序列推荐存在两个问题：</p>
<ol>
<li>模型的优化仅依赖最终预测结果和标签，会带来数据稀疏的问题</li>
<li>模型过分强调最终性能，难以学习更抽象的数据模式，忽略了数据内在关系</li>
</ol>
<p>序列推荐场景下上下文特征有不同的存在形式和特性，设计一种统一的方式来捕捉各种特征间的关系是很难的，本文介于MIM的思想统一的建模不同上线文特征间的关系。</p>
<p><strong>解法</strong></p>
<p><strong>评论</strong></p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><ul>
<li><p>Since it overemphasizes the final performance, the association or fusion between context data and sequence data has not been well captured and utilized for sequential recommendation</p>
<p>使用ctr loss使得模型过分强调最终的性能，上下文和序列之间的关联并没有被很好的捕捉</p>
</li>
<li><p>The main idea of our approach is to utilize the intrinsic data correlation to derive self-supervision signals and enhance the data representations via pre-training methods for improving sequential recommendation.</p>
<p>通过预训练，利用数据间的内在相关性来自监督的学习数据表征</p>
</li>
<li><p>This method splits the input data into multiple (possibly overlapping) views and maximizes the mutual informa- tion between representations of these views.</p>
<p>MIM方法把数据拆成多个视图并最大化这些视图中的互信息。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>表示学习</tag>
        <tag>预训练</tag>
        <tag>自监督学习</tag>
        <tag>互信息最大化</tag>
      </tags>
  </entry>
  <entry>
    <title>2021[EdgeRec](Alibaba)(CIKM)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BEdgeRec%5D/</url>
    <content><![CDATA[<p>(1) Gong Y, Jiang Z, Feng Y, et al. EdgeRec: recommender system on edge in Mobile Taobao[C]//Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management. 2020: 2477-2484.</p>
<p><strong>简介</strong></p>
<p>首次尝试设计和实现新颖的端上推荐系统（EdgeRec），它实现了实时用户感知和实时系统反馈。此外，我们提出了<strong>异构行为建模（Heterogeneous User Behavior Sequence Modeling）</strong>对曝光页和商品详情页用户行为进行编码，<strong>上下文感知重排（ Context-aware Reranking with Behavior Attention Network）</strong>对历史兴趣向量进行聚合，以捕捉用户的不同兴趣并相应地调整推荐结果。应用在淘宝首页feed流场景重排阶段。</p>
<p>文章内容比较充实，在架构设计、特征系统设计、负反馈利用方面都值得参考。</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[EdgeRec]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BEdgeRec%5D/image-20220526183035304.png" class title="image-20220526183035304">
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p>第一部分介绍了整个推荐系统框架，包括客户端（CN），模型服务（MS），推荐系统(RS)，离线训练（OT）。</p>
<ul>
<li>MS是端上的重排模块，也是系统的核心，接收CN的触发请求（三种触发请求）并进行实时重排。</li>
<li>CN负责前端展现和信息手机</li>
<li>RS是云上的推荐系统，包括召回和排序，返回客户端一个分页内的初始排序</li>
<li>OT：端上的模型训练。embedding存储在云上，其他模型结构存储在端上（3M左右大小）</li>
</ul>
<p>计算效率优化：用户行为建模和基于上下文的重排模型是异步进行的，用户行为建模因为是GRU，通过流式计算复杂度为O(1)</p>
<p>存储优化：embedding矩阵存储在云端，以特征形式下发到客户端</p>
<p>整个推荐流程为：</p>
<ol>
<li><p>请求服务器—服务器召回和排序模型得到一个page内的初始item排序（50个item）</p>
</li>
<li><p>客户端接收触发器信号对页面内item进行重排</p>
</li>
<li>触发重排的行为包括：1）点击item; 2）删除item ; 3）k次曝光未点击</li>
</ol>
<p>第二部分介绍了重排模型。</p>
<h4 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h4><p>信息流广告推荐在能效方面存在3个痛点：</p>
<ol>
<li>用户实时感知/决策弱：分页请求导致页内无法实时调整；数据延迟导致实时性较弱</li>
<li>云端存储和计算瓶颈</li>
<li>千人一模的局限性：对长尾数据拟合较弱</li>
</ol>
<p>根本原因是<strong>用户意图的变化</strong>与<strong>推荐系统的请求时机</strong>和<strong>商品展现时机</strong>不匹配。因此，我们希望将<strong>请求决策</strong>和<strong>展现决策</strong>这两项最接近用户的任务放到端上，利用端智能的能力，进行进一步的优化</p>
<h4 id="解法"><a href="#解法" class="headerlink" title="解法"></a>解法</h4><p><strong>问题定义</strong>：已知初始排序$S_r$,预估每个item在当前上下文下的评分$\phi(x_i,s,c)$，其中$x_i$是item特征，s是原始上下文特征（local ranking context）,c是用户实时行为特征（real-time user behavior context），主要工作是对c的编码</p>
<p><strong>特征体系</strong>：特征包括曝光页面action、商详页页面action、item特征</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[EdgeRec]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BEdgeRec%5D/image-20220614145858688.png" class title="image-20220614145858688">
<p><strong>异构行为建模 (Heterogeneous User Behavior SequenceModeling, HUBSM）</strong>:即模型图中左右两个框内结构。</p>
<p>用户行为包含两种异构性（heterogeneity）。第一种是瀑布流页面行为和商品详情页行为。由于商品详情页行为更密集，所以两种行为分开建模。第二种异构性是用户的行为和商品属性。用户行为动作特征揭示了用户对物品的行为分布，而物品特征表示相应物品特征的分布。对二者分别编码（本文采用GRU）再进行融合（本文采用concat）。</p>
<ul>
<li>曝光页行为编码</li>
</ul>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[EdgeRec]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BEdgeRec%5D/image-20220527094756107.png" class title="image-20220527094756107">
<ul>
<li><p>详情页行为编码</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[EdgeRec]/image-20220527095112504.png" alt="image-20220527095112504" style="zoom:100%;"></p>
</li>
</ul>
<p><strong>上下文感知的行为编码Context-aware Reranking with Behavior Attention Networks</strong></p>
<ul>
<li><p>candidate编码（初始序列）</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[EdgeRec]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BEdgeRec%5D/image-20220527095218176.png" class title="image-20220527095218176">
</li>
<li><p>behavior attention：candidate为Q，历史item为K，历史item和action的融合embedding为value进行attention</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020[EdgeRec]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2020%5BEdgeRec%5D/image-20220527100225837.png" class title="image-20220527100225837">
</li>
</ul>
<p><strong>在线实验</strong>：实验表明曝光页更多捕捉用户不感兴趣的程度，详情页更多捕捉用户感兴趣的程度</p>
<h4 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h4><p>本文算法部分包括两个创新点，一个是异构用户行为建模—即对action和item分别编码再进行融合。另一个是上下文感知的行为建模—-即以item相关信息为Q，K，以融合item和action的向量作为V对用户历史行为进行attention聚合。action和item分别建模除了因为action和item不在一个向量空间，也因为淘宝场景下action种类众多，包含更多信息，需要进行独立编码。</p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><ul>
<li><p>Our work, to our best knowledge, is the first attempt to design and implement the novel Recommender System on Edge (EdgeRec), which achieves Real-time User Perception and Real-time System Feedback</p>
<p>我们的工作首次尝试设计和实现端上推荐系统，实现实时的用户感知和系统反馈。</p>
</li>
<li><p>Moreover, we propose Heterogeneous User Behavior Sequence Modeling and Context-aware Reranking with Behavior Attention Networks to cap- ture user’s diverse interests and adjust recommendation results accordingly.</p>
<p>我们提出异构的用户行为序列建模和上下文感知的attention进行重排序，来捕捉用户丰富的行为并对推荐结果进行重排序</p>
</li>
<li><p>To summarize, feature system in our work is novel and pro- moted (1) from “relying on only positive feedback interactions” to “simultaneously paying attention to positive and negative feedback interactions”, (2) from “concerning on only interacted items” to “considering both interacted items and their corresponding actions”, and (3) from “in quasi real-time way” to “in ultra real-time way”.</p>
<p>特征系统的新颖性体现在：1)正反馈-&gt;同时关注正负反馈； 2)仅关注交互的item-&gt;关注item及其动作（收藏，加购等 3）；从准实时-&gt;超实时</p>
</li>
</ul>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://mp.weixin.qq.com/s/LgF3FkLCid4tv_zKjU1C3g">双11专栏 | EdgeRec：电商信息流的端上推荐系统</a></p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>异构用户行为建模</tag>
        <tag>attention</tag>
      </tags>
  </entry>
  <entry>
    <title>2021[NOVA](AAAI)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021%5BNOVA%5D/</url>
    <content><![CDATA[<p>(1) Liu, C.; Li, X.; Cai, G.; Dong, Z.; Zhu, H.; Shang, L. Non-Invasive Self-Attention for Side Information Fusion in Sequential Recommendation. <em>arXiv:2103.03578 [cs]</em> <strong>2021</strong>.</p>
<p><strong>简介</strong></p>
<p>NOVA是华为诺亚方舟实验室2021年提出的一篇论文，用于优化序列推荐中side info的融合问题。相较于传统的推荐算法，基于深度学习的算法在推荐场景取得了显著进步（如CNN，RNN）。最近，BERT 框架也作为一种很有前途的方法出现，这得益于其在处理序列数据中的自注意力机制。 然而，原始 BERT 框架的一个限制是它只考虑自然语言标记的一个输入源。 在 BERT 框架下利用各种类型的信息仍然是一个悬而未决的问题。我们实验中发现简单的直接融合不同种类的side info效果甚微，甚至是负向的，所以<strong>我们提出NOVA(non-invasive self-attention mechanism 非侵入式的自监督)在BERT框架下更有效的利用辅助信息</strong>（side info）。NOVA用辅助信息改变注意力分布，而不是直接改变embedding，后者会导致信息过多。</p>
<p>后续研究方向：1.更强的融合函数 2.相较于layer by layer的融合更有效的融合方式</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021[NOVA]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021%5BNOVA%5D/image-20220523140959081.png" class title="image-20220523140959081">
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><h4 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h4><p>参考bert模型在NLP上的出色表现，bert模型也用于做序列推荐。但序列推荐相较于NLP有更多的side info。NLP任务中位置特征可以看做一种side info，通过跟token enbedding相加的形式进行融合，但是推荐场景下side info种类更多，重要性差异化更明显。目前少有对side info融合方式的研究，通常是暴力的concat或者相加，或者采用门结构进行融合。理论上越多的side info的引入能提升模型效果，但实际上如果融合方式不合理，信息的引入甚至会降低模型效果。</p>
<p>作者认为暴力的信息融合方法，虽然可以把item和各种side用一个向量表示（或者说在同一个向量空间中表示），但也会导致side信息不可逆的入侵（invasion）item的信息空间，导致在模型的深层越来越难以利用到原始的item信息，从而导致Bert无法学习到最佳的Attention分布和深层Embedding表示。</p>
<h4 id="解法"><a href="#解法" class="headerlink" title="解法"></a>解法</h4><p>side info可以分为item相关的（如品牌）和行为相关的（如时段、行为类型），</p>
<ul>
<li><p>embedding</p>
<p>产生两个emebdding序列，分别是融合的embedding（F是融合函数，E是embedding layer）和item的embedding</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021[NOVA]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021%5BNOVA%5D/image-20220614163145889.png" class title="image-20220614163145889">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021[NOVA]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021%5BNOVA%5D/image-20220614163244302.png" class title="image-20220614163244302">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021[NOVA]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021%5BNOVA%5D/image-20220614163421196.png" class title="image-20220614163421196">
</li>
<li><p>nova attention</p>
</li>
</ul>
<p>用item embedding作为Q，融合embedding作为K，V。由于item信息每层都在变，而side信息是不变的，因此在每一层都会将item信息和side信息用fusing function进行融合，生成只在本层使用的Integrated Embedding。</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021[NOVA]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021%5BNOVA%5D/image-20220614163459628.png" class title="image-20220614163459628">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021[NOVA]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021%5BNOVA%5D/image-20220614163512579.png" class title="image-20220614163512579">
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文的增益点在于bert框架下nova attention可保证每一层的每个元素还是item的表征。在非bert框架下，如din等结构中attention仅仅是单层结构，增益可能不及预期。且nova attention会导致side info学习不够充分。</p>
<h3 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h3><ol>
<li>Theoretically, side information should be beneficial by providing more data. Nonetheless, it is challenging to design models that can efficiently make use of the extra information.</li>
</ol>
<p>理论上来说提供更多的辅助信息是有效的，但如何有效的利用辅助信息是很有挑战性的</p>
<ol>
<li>As shown in Figure 1, with NOVA, the side information acts as an auxiliary for the self-attention module to learn better attention distribu- tion, instead of being fused into item representations， which might cause side effects such as information overwhelm- ing</li>
</ol>
<p>NOVA中辅助信息用来学习attention分布，而不是直接融合到embedding中（如concat,pooling），后者会导致信息冗余</p>
<ol>
<li><p>业界对sideinfo的常用处理方法<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021[NOVA]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021%5BNOVA%5D/image-20220521170335625.png" class title="image-20220521170335625"></p>
</li>
<li><p>Side information可以分为item相关的和行为相关的。</p>
</li>
<li><p>From this perspective, the original BERT also take positional information as the only side information, using addition as the fusion function F.</p>
<p>BERT可以看做只有位置这种辅助信息，通过相加的方式融合到item embedding中</p>
</li>
<li><p>侵入式的融合方法会使得embedding是一种复合嵌入空间，会给解码带来不必要的麻烦</p>
</li>
<li><p>Accordingly, we proposed a novel method called non- invasive self-attention (NOVA), to maintain the consistency of embedding space, while exploiting side information to model the sequences more efficiently.</p>
<p>NOVA能保持嵌入空间一致性的同时有效利用辅助信息。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>辅助信息融合</tag>
        <tag>行为序列建模</tag>
      </tags>
  </entry>
  <entry>
    <title>2021[CL4SRec](SIGIR)(Alibaba)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021%5BCL4SRec%5D(SIGIR)(Alibaba)/</url>
    <content><![CDATA[<p>(1) Xie, X.; Sun, F.; Liu, Z.; Wu, S.; Gao, J.; Ding, B.; Cui, B. Contrastive Learning for Sequential Recommendation. <em>arXiv preprint arXiv:2010.14395</em> <strong>2020</strong></p>
<p>本文来自阿里团队。序列推荐是RS中重要部分，尽管近年来取得了很大成功，但仍然因为数据稀疏难以通过优化大量的参数来学习高质量的用户表征。为了解决这个问题，受CV领域CL的启发，我们提出基于CL的多任务模型CL4SRec,一方面能通过CL的框架从用户自身行为中获取自监督信号，从而更高效的编码用户行为模式。另一方面通过3中数据增强方式构建自监督信号。</p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a><strong>简介</strong></h4><p>本文来自阿里团队。序列推荐是RS中重要部分，尽管近年来取得了很大成功，但仍然因为数据稀疏难以通过优化大量的参数来学习高质量的用户表征。为了解决这个问题，受CV领域CL的启发，我们提出基于CL的多任务模型CL4SRec,一方面能通过CL的框架从用户自身行为中获取自监督信号，从而更高效的编码用户行为模式。另一方面通过3中数据增强方式构建自监督信号。</p>
<h5 id="贡献："><a href="#贡献：" class="headerlink" title="贡献："></a>贡献：</h5><ol>
<li>第一次把CL引入sequence recommendation</li>
<li>通过3种方式构建自监督信号</li>
</ol>
<h5 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h5><ol>
<li><p>Sequence Recommendation</p>
<p>RNN,LSTM,GRU,Caser,Transformer,GNN</p>
</li>
<li><p>Self-supervised Learning</p>
<p>CV/NLP</p>
</li>
</ol>
<p><strong>解法</strong></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2021[CL4SRec](SIGIR)(Alibaba)/image-20220727144809769.png" alt="image-20220727144809769" style="zoom:50%;"></p>
<ul>
<li><p>问题定义</p>
</li>
<li><p>CL4SRec框架</p>
<ul>
<li><p>数据增强</p>
<p>Crop: 是用户行为的一个局部表示，在没有全面信息的情况下学习用户的广义表示；无关的局部可以看做是next item预测的变种</p>
<p>mask：防止编码器的过拟合</p>
<p>reorder：推荐场景下用户行为顺序概念较弱，减轻编码器对顺序的依赖</p>
</li>
</ul>
</li>
</ul>
<p><strong>评论</strong></p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><ul>
<li><p>dif- ferent from dot product, distances typically satisfy triangle inequal- ity1, which transits additional collaborative closeness and benefits a lot in item cold start issue.</p>
<p>用距离代替点击能缓解协同传递性问题，因为距离满足三角不等式。这在冷启动场景有为有用</p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>对比学习</tag>
        <tag>序列推荐</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[CIM](WWW)(JD)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BCIM%5D/</url>
    <content><![CDATA[<p>Zheng K, Wang L, Li Y, et al. Implicit User Awareness Modeling via Candidate Items for CTR Prediction in Search Ads[C]//Proceedings of the ACM Web Conference 2022. 2022: 246-255.</p>
<p>本文来自京东搜索广告团队。用户的点击行为通常存在对展示的物品的强烈对比模式，而候选item可以作为展示item的替代项，受此启发本文提出基于CIM（candidate item model）来模拟用户对候选集的感知。CIM通过引入额外的模块把候选集编码到上下文向量中，可广泛的扩展到各种CTR模型。隐式的建模用户的<strong>比较行为模式</strong>在其他问题上也有巨大潜力。</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[CIM]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BCIM%5D/image-20220530165235408.png" class title="image-20220530165235408">
<span id="more"></span>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>用户行为存在广泛的对比模式，但这种模式只会发生在用户有感知的item中。如何收集用户感知的item呢？可以收集曝光日志，但这种做会遇到冷启动、噪声（曝光了但其实用户并未注意）、收集信息渠道不完整等问题。所以本文用召回的候选集作为曝光信息的替代项，通过对召回的候选集预估曝光概率来预估用户是否对此有感知，并在此基础上进行”对比行为”建模。为了建模曝光概率，模型中加入曝光损失进行监督学习。</p>
<p>文章的动机不太有说服力，曝光概率替代曝光信息能减少特征加工和存储的开销，但对于冷启动、曝光噪音问题的解决似乎没有太大作用。当曝光渠道很多，曝光日志难以采集时可以考虑。即以计算换推理阶段的特征处理。</p>
<h3 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h3><ul>
<li><p>The idea of implicitly modeling comparison patterns within awareness has great potential to extend to other learning problems.</p>
<p>隐式的建模用户的”比较行为”在其他问题上也有很大潜力</p>
</li>
<li><p>It could be naturally used to capture comparison pat- terns between positive and negative instances during training, by establishing auxiliary pairwise loss between the positive instance and a negative instance</p>
</li>
<li><p>In this paper, we propose to implicitly model user awareness from the candidate item set by predicting their impression probabilities</p>
<p>通过预估候选集的曝光概率来隐式建模用户对候选集的感知</p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>行为序列建模</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[CML](WSDM)(Baidu)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BCML%5D(WSDM)/</url>
    <content><![CDATA[<p>link：<a href="https://arxiv.org/pdf/2202.08523.pdf">https://arxiv.org/pdf/2202.08523.pdf</a></p>
<p>code：<a href="https://github.com/weiwei1206/CML.git">https://github.com/weiwei1206/CML.git</a></p>
<p>Wei, Wei, et al. “Contrastive meta learning with behavior multiplicity for recommendation.” <em>Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</em>. 2022</p>
<p><strong>简介</strong>：本文来自百度搜索团队.通过对比元学习为不同用户维护专用的跨类型行为依赖模型，从而建模个性化的用户-商品间的多重关系。借助对比学习的思想，通过将辅助行为信息作为监督信号引入，能建模不同行为间的依赖性。</p>
<p>后续研究方向有1. 用CML框架预训练建模用户画像，服务于线上模型; 2.CML解耦用户兴趣向量</p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p><strong>动机</strong></p>
<p>传统的推荐系统通常假设用户和item之间只有一种交互关系，无法从多种类型的用户行为中建模多重用户-商品的关系。近期有一些工作研究各种行为之间的依赖性，但是存在两个挑战：</p>
<ol>
<li>行为稀疏。要预测的行为相对于其他行为是稀疏的</li>
<li>通过模型来捕捉用户的行为模式。不同用户的行为模式是不同的。当要同时建模多种行为模式时，这个差异性会更大。</li>
</ol>
<p>本文通过对比元学习不同用户维护专用的跨类型行为依赖模型，从而建模个性化的用户-商品间的多重关系。</p>
<p><strong>解法</strong></p>
<ol>
<li>构建异构行为图</li>
</ol>
<p>节点是user和item，边包含不同的行为。</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[CML](WSDM)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BCML%5D(WSDM)/image-20220627191534632.png" class title="image-20220627191534632">
<p>每个节点的embedding由周围L度邻居节点不同行为聚合得到。</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[CML](WSDM)/image-20220627191652389.png" alt="image-20220627191652389" style="zoom:50%;"></p>
<p>最后将不同行为聚合成一个embedding</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[CML](WSDM)/image-20220627191834147.png" alt="image-20220627191834147" style="zoom:50%;"></p>
<p><strong>评论</strong></p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><ul>
<li><p>dif- ferent from dot product, distances typically satisfy triangle inequal- ity1, which transits additional collaborative closeness and benefits a lot in item cold start issue.</p>
<p>用距离代替点击能缓解协同传递性问题，因为距离满足三角不等式。这在冷启动场景有为有用</p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>表示学习</tag>
        <tag>不确定性建模</tag>
        <tag>度量学习</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[ContraRec](TOIS)(Tsinghua)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BContraRec%5D(TOIS)(Tsinghua)/</url>
    <content><![CDATA[<p>(1)Wang, C.; Ma, W.; Chen, C. Sequential Recommendation with Multiple Contrast Signals. <em>ACM Trans. Inf. Syst.</em> <strong>2022</strong>, 3522673. <a href="https://doi.org/10.1145/3522673">https://doi.org/10.1145/3522673</a>.</p>
<p><strong>简介</strong>：</p>
<p>代码：<a href="https://github.com/THUwangcy/ReChorus/tree/TOIS22">https://github.com/THUwangcy/ReChorus/tree/TOIS22</a></p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p><strong>动机</strong></p>
<p><strong>解法</strong></p>
<p><strong>实验</strong></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[ContraRec](TOIS)(Tsinghua)/image-20220718211321196.png" alt="image-20220718211321196" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[ContraRec](TOIS)(Tsinghua)/image-20220718211436859.png" alt="image-20220718211436859" style="zoom:50%;"></p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><ul>
<li>ContraRec和CL4SRec相比，有几个不同点：<ol>
<li>正样本的构造处理增强的序列，还有同target的序列</li>
<li>主loss由softmax cross entropy改为InfoNce</li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>对比学习</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[DIF-SR](SIGIR)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/</url>
    <content><![CDATA[<p>(1)Xie Y, Zhou P, Kim S. Decoupled Side Information Fusion for Sequential Recommendation[J]. arXiv preprint arXiv:2204.11046, 2022.</p>
<p><strong>简介</strong>：本文来自香港大学。将各种辅助信息融合和item信息融合，并通过attention进行序列编码是一种通用的兴趣提取结构。但是这会存在两个问题：</p>
<ol>
<li>异构信息的混合相关性给注意力机制带来了额外的干扰</li>
<li>embedding的早期融合限制了注意力机制的表达能力</li>
</ol>
<p>DIF-SR解耦了item embeding和辅助信息的attention机制，并加入预测side info的辅助任务进一步激活辅助信息的交互。理论和实验都表明DIF能学习到更高秩（RANK）的attention矩阵和更灵活的梯度（attnention中side info和item的梯度分离）。</p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><h4 id="动机"><a href="#动机" class="headerlink" title="动机"></a><strong>动机</strong></h4><p>基于辅助信息和item信息融合后复合嵌入进行的embedding会限制attention结构的表征能力，因为复合嵌入空间不可避免的会引入不相关信息，从而造成随机干扰，最终限制attention矩阵的学习。这点可以从attention矩阵的秩定量分析得到。</p>
<p>attention矩阵的秩通常很小，这回导致低秩瓶颈问题（rank bottleneck），一是因为attention矩阵是key和query的相似度得到的，所以受key和query的向量维度d决定。二是由于上文所说的复合嵌入导致的随机干扰。三是通过简单的融合策略（如add），所有side info共享所有梯度，这导致模型难以学到side info间的相对重要性。</p>
<p>受BERT中解耦位置信息的成功启发，本文探讨结构辅助信息对模型的影响。</p>
<h4 id="解法"><a href="#解法" class="headerlink" title="解法"></a><strong>解法</strong></h4><p>基本思路是将item和所有side info分别独立的计算attention，然后再融合（而不是先融合再计算attention）。该方法通过减少不必要的随机扰动和各side info有独立的梯度使得attention 矩阵秩增加。</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616170910543.png" class title="image-20220616170910543">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616175741125-5373463.png" class title="image-20220616175741125">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616175939060-5373581.png" class title="image-20220616175939060">
<p>模型包括三个模块：Embedding Module, Decoupled Side Infor- mation Fusion Module , Prediction Module with AAP。整个模型结构跟SASRec一样，只是把多头自注意力模块变成解耦的辅助信息多头自注意力模块。DIF模块输入包含item和side info两部分，为了防止side info的过拟合，side info在每一层都是一样的。</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616180913128.png" class title="image-20220616180913128">
<p>其中R表示每个block的item表征；f1-fp表示p种side info的表征。DIF计算如下（以一个head为例：各自分别计算attention score，得到p个n<em>n的attention矩阵，n是序列长度； 再通过融合函数F把p个矩阵融合融合成一个n </em> n的矩阵，融合的当时有加，元素相乘，gate。最后n*n矩阵作为权重对IDembedding进行加权）：</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616181250747-5374372.png" class title="image-20220616181250747">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616181309115-5374390.png" class title="image-20220616181309115">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616181420328.png" class title="image-20220616181420328">
<h4 id="辅助任务"><a href="#辅助任务" class="headerlink" title="辅助任务"></a><strong>辅助任务</strong></h4><p>通过加入预测辅助信息的辅助任务来增强side info的学习，值得一提的是辅助任务是通过影响attention矩阵最终影响item表征的，如之前的先融合再attention的机制无法实现此目的。</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616182845186.png" class title="image-20220616182845186">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616183230015.png" class title="image-20220616183230015">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616183248598.png" class title="image-20220616183248598">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616183217773.png" class title="image-20220616183217773">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIF](SIGIR)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIF%5D(SIGIR)/image-20220616183303260.png" class title="image-20220616183303260">
<h4 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h4><p>本文创新点有两个，一是辅助信息解耦的attention机制，二是训练过程加入side info的预测任务。通过分析attention矩阵秩的方法来定量分析attention机制的表达能力也比较新颖。本文是基于transformer结构的生成模型，也可借鉴到CTR模型中。NOVA其实已经实现的item和辅助信息的解耦，DIF在此基础上对各个域的side info进行解耦。</p>
<p>消融实验中表明如果不采用解耦的attention，辅助任务的加入并不一定能提高模型效果，这个也跟我们实验一致。</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>表示学习</tag>
        <tag>辅助信息建模</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[DIHN](WWW)(Alibaba)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIHN%5D(WWW)(Alibaba)/</url>
    <content><![CDATA[<p>(1) Shen, Q.; Wen, H.; Tao, W.; Zhang, J.; Lv, F.; Chen, Z.; Li, Z. Deep Interest Highlight Network for Click-Through Rate Prediction in Trigger-Induced Recommendation. In <em>Proceedings of the ACM Web Conference 2022</em>; 2022; pp 422–430.</p>
<p>本文来自阿里飞猪团队，首次提出<strong>触发推荐问题</strong>（Trigger- Induced Recommendation ，TIR)。TIR场景触发item显示的表征了用户的即时兴趣，传统的兴趣建模（DIN等）target attention的方式忽略了触发item的信息，导致对即时兴趣学习不准确。本文通过Deep Interest Highlight Network (DIHN)建模用户即时兴趣</p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p><strong>动机</strong></p>
<p>TRI场景如下图</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIHN](WWW)(Alibaba)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BDIHN%5D(WWW)(Alibaba)/image-20220718154001194.png" class title="image-20220718154001194">
<p>TIR场景触发item显示的表征了用户的即时兴趣，传统的兴趣建模（DIN等）target attention的方式忽略了触发item的信息，导致对即时兴趣学习不准确。本文通过Deep Interest Highlight Network (DIHN)建模用户即时兴趣。</p>
<p>即时兴趣建模存在两个难点：</p>
<ol>
<li>即时兴趣噪音。用户可能意外点击触发item，需要辨别用户的真实即时兴趣</li>
<li>用户的历史行为包含多种兴趣，需要提取即时兴趣相关部分</li>
</ol>
<p><strong>解法</strong></p>
<p>DIHN包含3个模块。</p>
<p>UIN: 预估用户对触发item的点击率，以解决第一个难点</p>
<p>FEM：融合target item和triger item的embedding（后续作为用户行为兴趣提取的query）。weight由UIN的中间层得到</p>
<p>HIEM: 用FEM的结果作为query，对历史行为进行聚合。Hard模式下会先过滤行为</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIHN](WWW)(Alibaba)/image-20220718154330203.png" alt="image-20220718154330203" style="zoom:50%;"></p>
<p><strong>实验</strong></p>
<p>公开数据集使用alimama数据集，自己构造triger item。base line模型考虑传统序列模型</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIHN](WWW)(Alibaba)/image-20220718154840729.png" alt="image-20220718154840729" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[DIHN](WWW)(Alibaba)/image-20220718154917028.png" alt="image-20220718154917028" style="zoom:50%;"></p>
<p><strong>评论</strong></p>
<p>UIN模块比较新颖，实时信息的处理可参考</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>诱发推荐</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[FMLP-Rec](WWW)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BFMLP-Rec%5D/</url>
    <content><![CDATA[<p>(1) Zhou, K.; Yu, H.; Zhao, W. X.; Wen, J.-R. Filter-Enhanced MLP Is All You Need for Sequential Recommendation. <em>Proceedings of the ACM Web Conference 2022</em> <strong>2022</strong>, 2388–2399. <a href="https://doi.org/10.1145/3485447.3512111">https://doi.org/10.1145/3485447.3512111</a>.</p>
<p>最近深度学习通过用户的历史行为建模用户的兴趣，从而进行更准确的推荐。但用户的行为是有<strong>噪音</strong>的，深度模型很容易过拟合用户行为。为了解决这个问题，本文借鉴信号处理中的滤波算法的思想（filtering algorithm）在频域中衰减噪声。实验发现过滤算法可以显著改进代表性序列推荐模型的效果，且简单的简单的过滤算法（例如，带阻滤波器）与全 MLP 架构相结合甚至可以胜过基于 Transformer 的竞争模型。受此启发我们提出FMLP-Rec模型，仅采用MLP结构叠加滤波算法。</p>
<span id="more"></span>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>作者人为用户行为序列中有很多噪音，而深度模型很容易对噪音过拟合。为了去噪，借鉴信号处理中的滤波算法思想，通过快速傅里叶变换（FFT）将行为序列从时域转为频域信号，并在频域信号进行过滤，实验的过滤方法有高通滤波（HPF），低通滤波（LPF），带阻滤波器（BSF）。过滤后的信号通过逆傅里叶变化转化为时域信号。理论上可以证明频域上的滤波器相当于时域上的循环卷积，可以更好的捕捉用户的周期性行为。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220531164129575.png" alt="image-20220531164129575"><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[FMLP-Rec]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BFMLP-Rec%5D/image-20220531165101362.png" class title="image-20220531165101362"></p>
<h3 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h3><ul>
<li><p>Considering the above issues, we aim to simplify the Transformer- based sequential recommender as well as increase its robustness to resist the noise in logged data</p>
<p>本文目标是简化transformer模型，同时增强对行为序列噪音的鲁棒性</p>
</li>
<li><p>Theoretically speaking, according to convolution theorem [45], it can be proved that learnable filters are equivalent to the circular convolution in the time domain, which has a larger receptive field on the whole sequence, and can better capture periodic characteris- tics of user behaviors.</p>
<p>从理论上讲，根据卷积定理[45]，可以证明可学习滤波器相当于时域的循环卷积，它在整个序列上具有更大的感受野，可以更好地捕捉用户的周期性特征 行为。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>用户行为去噪</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[FeedRec](WWW)(Microsoft)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BFeedRec%5D(WWW)(Microsoft)/</url>
    <content><![CDATA[<p>(1)</p>
<p>Wu, C.; Wu, F.; Qi, T.; Huang, Y. FeedRec: News Feed Recommendation with Various User Feedbacks. arXiv February 4, 2022.</p>
<p><strong>简介</strong>：.</p>
<p>&lt;!- more —&gt;</p>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p><strong>动机</strong></p>
<p><strong>解法</strong></p>
<p>提出多反馈建模的统一框架，用强反馈对弱反馈进行提纯。</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[FeedRec](WWW)(Microsoft)/image-20220719123653782.png" alt="image-20220719123653782" style="zoom:50%;"></p>
<p><strong>实验</strong></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[FeedRec](WWW)(Microsoft)/image-20220719123906323.png" alt="image-20220719123906323" style="zoom:50%;"></p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3>]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>负反馈建模</tag>
        <tag>多行为建模</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[STOSA](WWW)(spotity)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BICL%5D(WWW)/</url>
    <content><![CDATA[<p>(1)</p>
<p>Chen, Y.; Liu, Z.; Li, J.; McAuley, J.; Xiong, C. Intent Contrastive Learning for Sequential Recommendation. In <em>Proceedings of the ACM Web Conference 2022</em>; 2022; pp 2172–2182. <a href="https://doi.org/10.1145/3485447.3512090">https://doi.org/10.1145/3485447.3512090</a>.</p>
<p><strong>简介</strong>：传统的RS都是通过用户历史交互item来表征用户偏好，但是不同的行为序列可能包含相同的潜在意图，最终导致一样的下一次行为。本文提出Intent Contrastive Learning (ICL)，通过聚类和对比学习方法从用户行为中学习不同用户共享的潜在意图，并融合到推荐模型中。</p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p><strong>动机</strong></p>
<p>传统的RS都是通过用户历史交互item来表征用户偏好，但是不同的行为序列可能包含相同的潜在意图，最终导致一样的下一次行为。本文提出Intent Contrastive Learning (ICL)，通过聚类和对比学习方法从用户行为中学习不同用户共享的潜在意图，并融合到推荐模型中。</p>
<p><strong>精确的学习用户意图</strong>是比较困难的，历史工作中</p>
<p>潜在意图的学习存在3个难点：</p>
<ol>
<li>潜在意图没有标签</li>
<li>不同的行为可能包含一样的意图</li>
<li>有效的把意图融合到推荐系统中并不容易</li>
</ol>
<p><strong>解法</strong></p>
<ol>
<li>初始化兴趣空间c</li>
<li>编码用户行为j，并基于Loss优化RS、P(c|h)。其中CL包含sequence CL和<strong>intent CL</strong></li>
<li>基于用户行为向量h进行聚类，优化c</li>
</ol>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[ICL](WWW)/image-20220718164630267.png" alt="image-20220718164630267" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[ICL](WWW)/image-20220718164653425.png" alt="image-20220718164653425" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[ICL](WWW)/image-20220718164720518.png" alt="image-20220718164720518" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[ICL](WWW)/image-20220718164611924.png" alt="image-20220718164611924" style="zoom:50%;"></p>
<p>训练复杂度是传统序列推荐的3倍，推理复杂度不变</p>
<p><strong>实验</strong></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[ICL](WWW)/image-20220718163401661.png" alt="image-20220718163401661" style="zoom:50%;"></p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[ICL](WWW)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BICL%5D(WWW)/image-20220718163452712-8133297.png" class title="image-20220718163452712">
<p><strong>评论</strong></p>
<ul>
<li>聚类和RS交替训练比较新颖</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>表示学习</tag>
        <tag>不确定性建模</tag>
        <tag>度量学习</tag>
      </tags>
  </entry>
  <entry>
    <title>2021[Learning List-wise Representation in Reinforcement Learning for Ads Allocation with Multiple Auxiliary Tasks](MEITUAN)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BLearning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20%5D/</url>
    <content><![CDATA[<p>(1) Wang, Z.; Liao, G.; Shi, X.; Wu, X.; Zhang, C.; Wang, Y.; Wang, X.; Wang, D. Learning List-Wise Representation in Reinforcement Learning for Ads Allocation with Multiple Auxiliary Tasks. <em>arXiv:2204.00888 [cs]</em> <strong>2022</strong>.</p>
<p>本文是美团团队的混排模型。随着强化学习的发展，推荐场景的也对其产生了很大兴趣，主要用强化学习优化混排过程。为了实现最优分配，从point-wise的分配方式过渡为list-wise的方式。但这会导致状态-行为空间维度过高，从而模型泛化性降低，导致RL中agent的探索和采样效率低下。</p>
<p>为了优化以上问题，根据专家经验，本文在基于RL的重分配模型中加入三个辅助任务（reconstruction, prediction,  contrastive learning）来更学习list-wise更有效、泛化性更高的表示，从而提高RL模型的效果。</p>
<p>后续研究方向：1.自适应的平衡各个子任务 2.优化离线强化学习相较于在线强化学习存在的问题，如distribution shift problem</p>
<span id="more"></span>
<p>[TOC]</p>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p>加入辅助任务是优化list-wise的RL重分配模型状态-行为空间过高问题的一种通用方式，但现有工作中辅助任务的选取缺少对业务场景先验知识的运用。本文结合美团外卖场景选择了3个辅助任务。</p>
<p>reconstruction：学习表征</p>
<p>prediction：学习reward</p>
<p>contrastive-learning: 对状态-行为空间进行聚合和区分</p>
<p>本文相关的研究工作包括广告分配和表示学习两个方向</p>
<h4 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h4><p>基于RL的list-wise混排模型面临由于状态-决策空间过大而引起的模型泛化性能低、采样效率低、探索效率低的问题。业界处理此问题的通用做法是引入辅助任务帮助学习状态-决策的表征（representation），从而优化RL模型。现有工作中辅助任务的选取缺少场景相关的专家经验，而专家经验对于表征学习是很重要的。所以本文根据外卖场景下的专家经验选择3个辅助任务对RL模型进行优化。</p>
<h4 id="解法"><a href="#解法" class="headerlink" title="解法"></a>解法</h4><h5 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h5><p>每个页面有K个槽位（slot），有一个自然队列和广告队列，将两个队列进行合并，合并过程中不改变各自的顺序。</p>
<h5 id="BASE-AGENT"><a href="#BASE-AGENT" class="headerlink" title="BASE AGENT"></a>BASE AGENT</h5><p>本文的RL采用的是Q learning的方式，即优化目标为找到使得一个episode reward最大的策略$\pi$.</p>
<p>在数学上，广告分配问题被表述为一个 MDP，可以用一个元组 (S, A, 𝑟, 𝑃, 𝛾) 表示。</p>
<p>S：状态空间，包括召回的两个item队列，用户特征，用户历史行为序列，上下文特征</p>
<p>A: 行为空间，即K个槽位每个位置是广告还是自然结果</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609194048401.png" alt="image-20220609194048401" style="zoom:50%;"></p>
<p>r:奖励，包括广告费、平台服务费、用户体验</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609194203459.png" alt="image-20220609194203459" style="zoom:50%;"></p>
<p>P: 状态转移概率。用户的一次翻页是一次状态转移，当用户不再往下滑则是状态的终止。</p>
<p>$\gamma$:折扣系数，平衡短期奖励和长期奖励</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609174811991.png" alt="image-20220609174811991" style="zoom:50%;"></p>
<p><strong>用户行为编码阶段</strong>即用队列中的item分别作为Q与用户历史行为通过attention机制对历史行为进行聚合。最终得到队列长度个向量e.</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609195350578.png" alt="image-20220609195350578" style="zoom:50%;"></p>
<p><strong>序列融合阶段</strong>用action对e序列进行融合。</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609195628089.png" alt="image-20220609195628089" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609195710776.png" alt="image-20220609195710776" style="zoom:50%;"></p>
<p><strong>Q value预测阶段</strong>通过MLP预测Q</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609212721453.png" alt="image-20220609212721453" style="zoom:50%;"></p>
<h5 id="辅助任务"><a href="#辅助任务" class="headerlink" title="辅助任务"></a>辅助任务</h5><p>本文选取的3个辅助任务分别是重构任务（reconstruction）、预测任务（prediction）、对比学习任务（contrastive-learning）。三个任务选择动机及学习目标如下：</p>
<p><strong>重构任务</strong>：外卖场景下有一些对用户决策影响很大的信息，如配送费、品牌等。重构任务的加入就是为了防止学到的embedding丢失这些信息。根据专家经验选了M个最终要的因子作为重构目标。即对每个槽位的item都预测其M个核心指标。每个指标都是二分类任务。</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609213020298.png" alt="image-20220609213020298" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609174638195.png" alt="image-20220609174638195" style="zoom:50%;"></p>
<p><strong>预测任务</strong>：预测任务对每个槽位的item有点击和下拉两个标签。点击标签的加入有助于学习reward。下拉标签有助于学习转移概率。</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609213406900.png" alt="image-20220609213406900" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609213419829.png" alt="image-20220609213419829" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609213432409.png" alt="image-20220609213432409" style="zoom:50%;"></p>
<p><strong>对比学习任务</strong>：对比学习使得锚点接近正样本，远离负样本。本文通过引入对比学习使得状态-行为空间对存在这种相对关系，锚点就是一个sample的状态-行为对，正样本是在sample的基础上加随机扰动（把当前page中未曝光的item改成随机的），负样本是从其他请求中随机采样。</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609214434265.png" alt="image-20220609214434265" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609214720687.png" alt="image-20220609214720687" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609214810476.png" alt="image-20220609214810476" style="zoom:50%;"></p>
<h5 id="离线训练"><a href="#离线训练" class="headerlink" title="离线训练"></a>离线训练</h5><p>L_dqn是为了训练模型能够准确的预测一个episode的reward。Q(s,a)由公式5得到。max Q(s’,a’) = Q(s’,a’)(j基于的假设是Q learning下的决策都是最大化Q的决策)</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609214848521.png" alt="image-20220609214848521" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Learning%20List-wise%20Representation%20in%20Reinforcement%20Learning%20for%20Ads%20Allocation%20with%20Multiple%20Auxiliary%20Tasks%20]/image-20220609215127472.png" alt="image-20220609215127472" style="zoom:50%;"></p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><ul>
<li><p>dif- ferent from dot product, distances typically satisfy triangle inequal- ity1, which transits additional collaborative closeness and benefits a lot in item cold start issue.</p>
<p>用距离代替点击能缓解协同传递性问题，因为距离满足三角不等式。这在冷启动场景有为有用</p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>表示学习</tag>
        <tag>强化学习</tag>
        <tag>组合预估</tag>
        <tag>推荐算法</tag>
        <tag>多任务学习</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[MISS](ICDE)(HUAWEI)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BMISS%5D(ICDE)(HUAWEI)/</url>
    <content><![CDATA[<p>(1)</p>
<p>Guo, W.; Zhang, C.; He, Z.; Qin, J.; Guo, H.; Chen, B.; Tang, R.; He, X.; Zhang, R. MISS: Multi-Interest Self-Supervised Learning Framework for Click-Through Rate Prediction. arXiv January 28, 2022.</p>
<p><strong>简介</strong>：….</p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p><strong>动机</strong></p>
<p><strong>解法</strong></p>
<p><strong>评论</strong></p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><p>- </p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>对比学习</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[Re4](WWW)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BRe4%5D(WWW)/</url>
    <content><![CDATA[<p>(1)</p>
<p>Zhang, S.; Yang, L.; Yao, D.; Lu, Y.; Feng, F.; Zhao, Z.; Chua, T.; Wu, F. Re4: Learning to Re-Contrast, Re-Attend, Re-Construct for Multi-Interest Recommendation. In <em>Proceedings of the ACM Web Conference 2022</em>; 2022; pp 2216–2226.</p>
<p><strong>简介</strong>：现有的多兴趣建模尽管很有效，但是仅使用编码器利用前向流（forward-flow）表征用户多兴趣。由于没有加入显示的约束，此方式无法保证兴趣向量的正交，也无法保证兴趣向量和历史item在语义空间的关系。本文提出Re4的框架，通过加入3个反向流（backward-flow）任务使得兴趣向量更有区分性，更有效。</p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p><strong>解法</strong></p>
<p>现有的多兴趣建模尽管很有效，但是仅使用编码器利用前向流（forward-flow）表征用户多兴趣。由于没有加入显示的约束，此方式无法保证兴趣向量的正交，也无法保证兴趣向量和历史item在语义空间的关系。本文提出Re4的框架，通过加入3个反向流（backward-flow）任务，重新检验兴趣向量和item的关系，使得兴趣向量更有区分性，更有效。</p>
<p>本文通过3个反向的辅助任务对用户多兴趣表征进行约束，使兴趣向量能1）捕捉不同方面的兴趣  2）反应相关的item 3）行为编码（forward flow）中的attention和最终推荐任务的相关性指标一致。</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Re4](WWW)/image-20220719110738434.png" alt="image-20220719110738434" style="zoom:50%;"></p>
<ul>
<li>Re-contrast：通过兴趣向量的对比保证兴趣向量的区分性</li>
</ul>
<p>正样本对：兴趣向量；兴趣向量相关item</p>
<p>负样本：兴趣向量：其他兴趣向量；随机sample item</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Re4](WWW)/image-20220718192342966.png" alt="image-20220718192342966" style="zoom:50%;"></p>
<ul>
<li>Re-attend: 使得编码中的相关性度量和最后RS的相关性度量（如Match阶段）匹配</li>
</ul>
<p>item i 和兴趣的权重 和 RS计算相似度的方式计算的权重</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Re4](WWW)/image-20220718192005631.png" alt="image-20220718192005631" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Re4](WWW)/image-20220718192125534.png" alt="image-20220718192125534" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Re4](WWW)/image-20220718192320834.png" alt="image-20220718192320834" style="zoom:50%;"></p>
<ul>
<li>Re-construct: 通过兴趣向量反向预估item embedding，保证兴趣向量能还原相关item</li>
</ul>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Re4](WWW)/image-20220718192544491.png" alt="image-20220718192544491" style="zoom:50%;"></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Re4](WWW)/image-20220718192602342.png" alt="image-20220718192602342" style="zoom:50%;"></p>
<p><strong>实验</strong></p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[Re4](WWW)/image-20220718193024716.png" alt="image-20220718193024716" style="zoom:50%;"></p>
<p><strong>评论</strong></p>
<p>通过Re-contrast增加不同兴趣的区分性。有点兴趣解耦的意思</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>对比学习</tag>
        <tag>多兴趣建模</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[RACP](WSDM)(Alibaba)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BRACP%5D(WSDM)/</url>
    <content><![CDATA[<p>(1) Fan, Z. Modeling Users’ Contextualized Page-Wise Feedback for Click-Through Rate Prediction in E-Commerce Search. 9.</p>
<p>本文是来自于淘宝搜索团队的CTR预估模型。建模用户的历史行为对个性化搜索和推荐都很重要，现有方法主要是对用户历史正反馈的建模（点击序列），忽略了产生反馈的上下文信息。本文通过加入历史<strong>页面维度的曝光和反馈</strong>做一位用户历史行为序列，提出了一种新的上下文感知的用户行为建模方式。通过捕捉页面内的信息和页面间的演化可以更详细的学习用户的偏好。 RACP(Recurrent Attention over Contextualized Page sequence)模型通过<strong>page-context aware attention</strong> 学习页面内的关，<strong>recurrent attention</strong>学习页面间的关系</p>
<p>代码： <a href="https://github.com/racp-submission/racp">https://github.com/racp-submission/racp</a></p>
<span id="more"></span>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>动机</strong></p>
<p>用户行为建模中很少引入用户负反馈，即便一些工作使用了负反馈也是作为一个单独的序列，忽略了正负反馈间的交互及其他上下文信息。实际上用户的反馈受到周边item的影响，且不同的行为间也存在联系，</p>
<p>本文从页面的角度对用户行为进行编码。</p>
<p><strong>解法</strong></p>
<p>模型自下而上可分为4个部分：Embedding Layer, Intra-page Context-aware Interest Layer, Inter-page Interest Backtracking Layer, and Page-level Interest Aggregation Layer.</p>
<ul>
<li><p>embedding</p>
</li>
<li><p>页面内聚合</p>
</li>
</ul>
<p>页面信息通过attention聚合，权重由item，item的反馈，该item的上下文决定。item的上下文特征包括1，query；2.该页面点击的数量；3.页面跟该item同品牌item数量；4.页面内跟该item同商家的数量；5.页面内该item的价格、销量等排序</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[RACP](WSDM)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BRACP%5D(WSDM)/image-20220613205723447.png" class title="image-20220613205723447">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[RACP](WSDM)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BRACP%5D(WSDM)/image-20220613205749193.png" class title="image-20220613205749193">
<ul>
<li>页面间聚合</li>
</ul>
<p>采用GRU进行融合，GRU输入页面间聚合向量p和当前query Q，其中Q是上一层GRU的隐层输出，p是基于Q的attention融合</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[RACP](WSDM)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BRACP%5D(WSDM)/image-20220613210502928.png" class title="image-20220613210502928">
<ul>
<li>页面维度兴趣提取</li>
</ul>
<p>每个页面是一个兴趣向量p，对p进行聚合</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[RACP](WSDM)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BRACP%5D(WSDM)/image-20220613210847327.png" class title="image-20220613210847327">
<p><strong>评论</strong></p>
<p>第四个消融实验表明把所有序列变成长序列并用vanilla attention AUC降低一个千分点。看起来降的并不多，但模型复杂度降低很多。所以是否采用page wise建模序列有待商讨。另一方面表明模型相较于DIN等对比模型的增益可能来源于数据（side info）</p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[RACP](WSDM)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BRACP%5D(WSDM)/image-20220613212149010.png" class title="image-20220613212149010">
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[RACP](WSDM)/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BRACP%5D(WSDM)/image-20220613211911322.png" class title="image-20220613211911322">
<h3 id="quote"><a href="#quote" class="headerlink" title="quote"></a><strong>quote</strong></h3><ul>
<li>“However, they treat users’ positive and negative feedback separately, and rep- resent users’ feedback as a clicked item sequence and a non-clicked item sequence, which cannot generate the mutual context between clicks and non-clicks and ignores other page context information in the page-sequence” 历史工作很少考虑负反馈，即便考虑也是和正反馈分开处理的，这忽略了正负反馈之间的相互作用</li>
<li>页面信息的增益：1）正反馈是有噪音的，避免过拟合。一个用户点了一个品牌不一定是他就偏好这个品牌，有可能是整个页面都是这个品牌 2) 用户对item的行为受曝光的其他item影响</li>
<li>页面间的增益：搜索场景下用户的行为和意图是一个逐渐收敛的过程。例如：搜索—-曝光—-点击—-搜索—-曝光—-点击—-购买</li>
<li>“Recently, some pioneering work (<strong>DFN [33], DSTN</strong> [25]) high- light the importance of modeling both users’ positive and negative feedback for CTR prediction.” 一些负反馈的工作</li>
<li><strong>DFN [33]: DFN treats click behaviors as strong feedback to guide the positive preference extraction from unclicked behavior sequence.</strong></li>
<li><strong>DSTN [25]: DSTN considers the clicked and unclicked be- haviors as heterogeneous auxiliary data to help the user preference modeling.</strong></li>
<li>item画像：item id,品类id,shop id,统计类（成单量等）</li>
<li>query画像：query id,字符串，分词，类别</li>
<li>页内的attention聚合+页间兴趣回溯(GRU，由下一个page表征当前的query) + 页间兴趣融合(attention)</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[STOSA](WWW)(spotity)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BSTOSA%5D/</url>
    <content><![CDATA[<p>(1) Fan, Z.; Liu, Z.; Wang, A.; Nazari, Z.; Zheng, L.; Peng, H.; Yu, P. S. Sequential Recommendation via Stochastic Self-Attention. <em>arXiv:2201.06035 [cs]</em> <strong>2022</strong>.</p>
<p>序列建模中建模用户行为是非常重要的一环，transformer-base的方法把序列中的item嵌入到向量空间，然后通过点积自监督的方式衡量item之间的相似性。这种方式存在两个问题，一是用户的行为是具有不确定性的，这对现有技术带来了挑战。本文把item映射称为随机高斯分布，协方差就能衡量行为的不确定性。第二个问题是item的向量空间没有传递性（ collaborative transitivity）。所谓的传递性是如果a跟b相似，b跟c相似，则a跟c相似。但现有的embedding方法仅能通过共现信息进行编码，无法捕捉这种传递性。这个问题在长尾及冷启动场景下更加明显。</p>
<span id="more"></span>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>本文是spotify的召回模型，模型涉及序列推荐（sequence recommendation）,度量学习(metric learning),表示学习(distribution reprezentation).</p>
<p><strong>动机</strong>：一个item一个embedding的表征方法忽略了item的不确定性，且item向量缺乏传递性。文中每个item的embedding不是固定向量，而是一个高斯分布（向量中的每个元素都是一个高斯分布），由可学习的均值矩阵和方差矩阵表征。此种表征方式下两个item的距离实际上是两个分布的距离，wasserstein距离可表征两个分布距离。相较于点积，其有3个优点：</p>
<ol>
<li>可表征两个分布的距离</li>
<li>满足三角不等式（即向量的传递性）</li>
<li>相较于KL散度更稳定，不容易出现极值</li>
</ol>
<p>为了约束正负样本间的距离差，模型loss加入正则项</p>
<p><strong>解法</strong></p>
<img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[STOSA]/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BSTOSA%5D/image-20220607200031563.png" class title="image-20220607200031563">
<ol>
<li><p>item表征为高斯分布，由均值矩阵$M^\mu \in R^{|v|<em>d}$和方差矩阵$M^{\sum}\in R^{|v|</em>d}$确定，其中v是item数量，p是位置embedding</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[STOSA]/image-20220607200512704.png" alt="image-20220607200512704" style="zoom:50%;"></p>
</li>
<li><p>wasserstein distance计算attention相似度</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[STOSA]/image-20220607201323936.png" alt="image-20220607201323936" style="zoom:50%;"><br><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[STOSA]/image-20220607201344205.png" alt="image-20220607201344205" style="zoom:50%;"><br><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[STOSA]/image-20220607201401199.png" alt="image-20220607201401199" style="zoom:50%;"><br><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[STOSA]/image-20220607201459480.png" alt="image-20220607201459480" style="zoom:50%;"><br><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[STOSA]/image-20220607201515126.png" alt="image-20220607201515126" style="zoom:50%;"></p>
</li>
<li><p>正则项</p>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[STOSA]/image-20220607201641258.png" alt="image-20220607201641258" style="zoom:50%;"></p>
</li>
</ol>
<p><img src="/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[STOSA]/image-20220607201656357.png" alt="image-20220607201656357" style="zoom:50%;"></p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><ul>
<li><p>Most existing self-attention SR models, e.g., SASRec [17] and BERT4Rec [40], represent items as fixed vector embeddings, ignoring the uncertainty in sequential correlations. A recent work DT4SR [7] represents items as distri- butions, which proposes the mean and covariance embedding to model uncertainty in items. However, DT4SR is incapable of model- ing dynamic uncertainty as it models item transition relationships via dot-product attention, which cannot incorporate such dynamic uncertainty.</p>
</li>
<li><p>dif- ferent from dot product, distances typically satisfy triangle inequal- ity1, which transits additional collaborative closeness and benefits a lot in item cold start issue.</p>
<p>用距离代替点击能缓解协同传递性问题，因为距离满足三角不等式。这在冷启动场景有为有用</p>
</li>
<li><p>The choice of distance function is pivotal to collaborative transitivity modeling.</p>
<p>对于建模协同传递性，距离函数的选择尤为重要</p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>表示学习</tag>
        <tag>不确定性建模</tag>
        <tag>度量学习</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[XDM](Alibaba)</title>
    <url>/2022/06/14/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BXDM%5D(Alibaba)/</url>
    <content><![CDATA[<p>Lv, F.; Li, M.; Guo, T.; Yu, C.; Sun, F.; Jin, T.; Ng, W. XDM: Improving Sequential Deep Matching with Unclicked User Behaviors for Recommender System. <em>arXiv:2010.12837 [cs]</em> <strong>2022</strong>.</p>
<p><strong>简介</strong>：阿里向量召回模型。工业界中基于embedding的信息检索（EBR）中很重要的一个问题时捕捉用户的兴趣，常用的做法是以用户点击过购买序列作为输入进行兴趣编码，但此方式忽略了用户完整的行为中的曝光数据。本文引入曝光数据，通过三元损失学习未点击样本的表示，并通过<strong>置信度融</strong>网络与现有序列模型进行融合。</p>
<img src="/2022/06/14/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[XDM](Alibaba)/06/14/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BXDM%5D(Alibaba)/image-20220614192601290.png" class title="image-20220614192601290">
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><h4 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h4><p>序列推荐通常近采用用户正反馈序列进行建模，忽略了用户的其他反馈，导致不全面的用户表示和次优模型性能。少数使用负反馈的也只是特征层面，缺乏正负反馈的交互。</p>
<h4 id="解法"><a href="#解法" class="headerlink" title="解法"></a>解法</h4><p>本文基于的假设是曝光未点击有样本是介于点击和随机样本中的一个中间形式。本文引入三元损失来建模这种中间状态。三元指的是：历史点击，历史未点击，点击三种行为序列。通过加入triplet loss使得1）历史点击向量空间远离历史未点击向量空间，同时又不超过m（超参）；2）点击向量空间靠近label向量空间。通过<strong>置信度融合网络（confidence fusion network）</strong>自适应的学习历史点击向量和曝光向量的权重，从而得到用户兴趣表征。</p>
<p>input：t时刻前历史行为序列（曝光未点击序列，点击序列）</p>
<p>output: t时刻后k次点击</p>
<p>loss:  h(历史点击)和c(label)更近，h和n(历史未点击)更远，距离差不大于m，从而符合以上观察。</p>
<ul>
<li><p>对称三元损失</p>
<p>三元包括历史点击和标签的距离（e_hc）,历史点击和历史未点击（e_hn）,历史未点击和标签（e_nc）。核心思想就是e_hc要近，e_hn和e_nc要远。三元损失就是e_hn &gt; e_hc+m1 ,e_nc &gt; e_hc + m2。</p>
</li>
</ul>
<img src="/2022/06/14/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[XDM](Alibaba)/06/14/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BXDM%5D(Alibaba)/image-20220614192810379.png" class title="image-20220614192810379">
<ul>
<li>置信度融合网络：融合历史点击和未点击向量</li>
</ul>
<img src="/2022/06/14/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[XDM](Alibaba)/06/14/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BXDM%5D(Alibaba)/image-20220614192846924.png" class title="image-20220614192846924">
<ul>
<li>整体loss:</li>
</ul>
<img src="/2022/06/14/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022[XDM](Alibaba)/06/14/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%5BXDM%5D(Alibaba)/image-20220614192905549.png" class title="image-20220614192905549">
<h4 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h4><p>本文借鉴对比学习的方式引入曝光信息，能更有效的学习embedding，从而优化向量召回的结果。但是CTR模型中embedding的学习只是第一步，其增益会随着层数的增加而降低。</p>
]]></content>
      <tags>
        <tag>算法相关 - 表示学习 - 负反馈 - 召回 - E-commerce - categories - 算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/</url>
    <content><![CDATA[<p>搜广推领域文献阅读，文献整理来源于git仓库  <a href="https://github.com/TessieHe/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising">Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</a></p>
<p>【to粗】表示待粗读</p>
<p>【粗】表示已粗读</p>
<p>【to精】表示待精读</p>
<p>【精】表示已精读</p>
<p>没有标注表示还没看</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising"><a href="#Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising" class="headerlink" title="Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising"></a>Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</h1><p>阅读等级：精，粗，to粗</p>
<p>Keyword：Personalized item search</p>
<h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><h3 id="2019-Deep-Learning-Based-Recommender-System"><a href="#2019-Deep-Learning-Based-Recommender-System" class="headerlink" title="2019 [Deep Learning Based Recommender System]"></a>2019 [Deep Learning Based Recommender System]</h3><p>Zhang, S.; Yao, L.; Sun, A.; Tay, Y. Deep Learning Based Recommender System: A Survey and New Perspectives. <em>ACM Computing Surveys (CSUR)</em> <strong>2019</strong>, <em>52</em> (1), 1–38.</p>
<p><strong>简介</strong>：推荐体统的本质是用户与商品的匹配，涉及到两个问题：匹配策略及评判标准</p>
<p><strong>关键词</strong>：Additional Key Words and Phrases: Recommender System; Deep Learning; Survey</p>
<ul>
<li><p>技术层面的分类<img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220311172803323.png" alt="image-20220311172803323" style="zoom:50%;"></p>
</li>
<li><p>应用层面的分类</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220311173113403.png" alt="image-20220311173113403" style="zoom:50%;"></p>
</li>
</ul>
<h2 id="Ranking"><a href="#Ranking" class="headerlink" title="Ranking"></a>Ranking</h2><h3 id="【粗】2022-WWW-FMLP-Rec-—玄学"><a href="#【粗】2022-WWW-FMLP-Rec-—玄学" class="headerlink" title="【粗】2022(WWW)[FMLP-Rec]—玄学"></a>【粗】2022(WWW)[FMLP-Rec]—玄学</h3><p>Zhou K, Yu H, Zhao WX, Wen JR. Filter-enhanced MLP is All You Need for Sequential Recommendation. <em>arXiv:220213556 [cs]</em>. Published online February 28, 2022. doi:<a href="https://doi.org/10.1145/3485447.3512111">10.1145/3485447.3512111</a></p>
<p><strong>关键词</strong>：Sequential Recommendation, All-MLP Model, Filtering Algorithm</p>
<p><strong>简介</strong>：最近RNN，CNN，transformer等深度模型用于推荐系统中基于用户的历史行为提取用户兴趣偏好。但历史行为是充满噪音的，且深度模型容易对噪音过拟合。本文借鉴信号处理领域的过滤算法（filtering algorithms）在频域中衰减噪声。实验表明简单的过滤算法+MLP甚至可以优于transformer这种复杂模型.我们还证明了可学习滤波器相当于时域中的循环卷积，具有更大的感受野，可以更好地捕捉周期性特征</p>
<ul>
<li>最近的研究显示了transformer结构在序列推荐场景下的出色表现，但是存在两个带优化问题：1.巨大的参数量。2.易对噪音过拟合</li>
</ul>
<h3 id="【粗】2022-AAAI-Alibaba-SMINet-—-就是硬检索-self-attention"><a href="#【粗】2022-AAAI-Alibaba-SMINet-—-就是硬检索-self-attention" class="headerlink" title="【粗】2022(AAAI)(Alibaba)[SMINet]—-就是硬检索+self-attention"></a>【粗】2022(AAAI)(Alibaba)[SMINet]—-就是硬检索+self-attention</h3><p>Tao, W.; Li, Y.; Li, L.; Chen, Z.; Wen, H.; Chen, P.; Liang, T.; Lu, Q. SMINet: State-Aware Multi-Aspect Interests Representation Network for Cold-Start Users Recommendation. 9.</p>
<p><strong>简介</strong>:本文通过SMINet结构提取在线旅游平台（OTP）冷启动推荐场景下的用户兴趣表征。模型包括multi-aspect interests extractor（多层面兴趣提取器）, co-attention layer（协同注意力）,  state-aware gating layer（旅行状态感知的门结构）三个部分。OTP与其他电子商务场景区别在于数据非常稀疏。为了缓解冷启动问题，最通用的方式是通过辅助信息帮助表示用户。也有通过元学习利用用户的少数行为解决冷启动问题，其中大部分是居于优化的元学习。但这些方式没有利用用户旅游行为的特点：时空性，群体性，周期性</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220420142943925.png" alt="image-20220420142943925" style="zoom:50%;"></p>
<ul>
<li><p>multi-aspect interests extractor： 得到5个向量分别表示用户的时空兴趣、群体兴趣、周期兴趣、长期兴趣、短期兴趣。其实不同层面的interest就是按照不同规则过滤（硬检索)得到相关的历史topk个行为再进行multi-head self attention。比如时空层面的检索就是照相同城市相同时间的交互</p>
<img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220420143007350.png" class title="image-20220420143007350">
</li>
</ul>
<h3 id="【粗】2022-AAAI-Adobe-DiPS"><a href="#【粗】2022-AAAI-Adobe-DiPS" class="headerlink" title="【粗】2022(AAAI)(Adobe)[DiPS]"></a>【粗】2022(AAAI)(Adobe)[DiPS]</h3><p>Ghosh A, Mitra S, Lan A. DiPS: Differentiable Policy for Sketching in Recommender Systems[J]. arXiv preprint arXiv:2112.07616, 2021.</p>
<p><strong>简介</strong>：序列推荐中用户的长期行为很容易被遗忘，近期的工作表明存储长期行为的小草图（small sketch）对推荐是有帮助的。但是构建方式都依赖域静态草图策略。这样的策略不能随着训练数据的增加而动态调整。本文提出了一种可微分的草图策略（DiPS），是一种端到端的数据驱动的策略，可在未来显示的最大化推荐质量。</p>
<ul>
<li>sketching policy： 决定存储哪些历史行为的策略</li>
<li>背景</li>
</ul>
<p>序列推荐中用户的长期行为很容易被遗忘，近期的工作表明存储长期行为的小草图（small sketch）对推荐是有帮助的，但是构建方式都依赖域静态草图策略（sketching policy，可以理解为用户行为序列的筛选和存储策略）。这样的策略不能随着训练数据的增加而动态调整。本文提出了一种端到端训练的可微分草图策略（DiPS）。</p>
<ul>
<li>方法</li>
</ul>
<p>本文将草图更新和RS模型训练作为双层优化问题。 在外层优化RS模型和草图策略， 内层使用当前草图中优化RS模型。由于任何一个草图策略下当前草图状态都依赖于所有先前决策，即计算梯度时需反向传播到先前所有时间步长，而整个过程是计算密集型的。本文使用计算效率高的单独队列模块（separate queue module）对草图策略参数的真实梯度进行近似估计，有效减少计算复杂度。在5个公开数据集上实验表明采用DiPS草图策略的模型效果由于静态草图策略。达到同样模型效果时，DiPS的存储items是静态草图策略对的一半。</p>
<p>后续代码将会在<a href="https://github.com/arghosh/DiPS.">https://github.com/arghosh/DiPS</a> 开源</p>
<h3 id="【粗】2022-AAAI"><a href="#【粗】2022-AAAI" class="headerlink" title="【粗】2022(AAAI)[]"></a>【粗】2022(AAAI)[]</h3><h3 id="【粗】2022-AAAI-FPAdaMetric-——可借鉴，但缺乏细节公式"><a href="#【粗】2022-AAAI-FPAdaMetric-——可借鉴，但缺乏细节公式" class="headerlink" title="【粗】2022(AAAI)[FPAdaMetric]——可借鉴，但缺乏细节公式"></a>【粗】2022(AAAI)[FPAdaMetric]——可借鉴，但缺乏细节公式</h3><p>Jeong J, Choi J, Cho H, et al. FPAdaMetric: False-positive-aware Adaptive Metric Learning for Session-based Recommendation[J]. 2022.</p>
<p><strong>简介</strong>：推荐场景下存在噪音，主要是伪阳性（False Positive）,本文引入了 FP-Metric 模型，它将具有 FP 约束的基于会话的推荐的目标重新表述为度量学习正则化（metric learning regularization）。 此外，我们提出了 FP-AdaMetric，它通过一个自适应模块来增强度量学习正则化项。</p>
<ul>
<li><p>最简单的处理FP的方式就是通过规则过滤掉FP样本，但由于点击成本很低，很多用户会处于好奇等心理尝试交互，我们应该更积极的考虑FP来提高推荐质量</p>
</li>
<li><p>基础假设：1）FP跟sequence是独立的（跟sequence不相关） 2）FP比TP有更低的相关性</p>
</li>
<li><p>基于以上假设，提出在模型中增加正则项FP-Metric, 让FP和TP的embedding距离较远。</p>
</li>
<li><p>由于不同的FP对对用户的影响程度不同的，所以提出了改进的正则约束FP-AdaMetric（False- positive-aware Adaptive Metric Learning model）</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220420160311360.png" alt="image-20220420160311360" style="zoom:50%;"></p>
</li>
</ul>
<h3 id="【to粗】2016-PNN"><a href="#【to粗】2016-PNN" class="headerlink" title="【to粗】2016 [PNN]"></a>【to粗】2016 [PNN]</h3><p>Qu, Y.; Cai, H.; Ren, K.; Zhang, W.; Yu, Y.; Wen, Y.; Wang, J. Product-Based Neural Networks for User Response Prediction. <em>arXiv:1611.00144 [cs]</em> <strong>2016</strong>.</p>
<h3 id="2020-Alibaba-EdgeRec"><a href="#2020-Alibaba-EdgeRec" class="headerlink" title="2020(Alibaba)[EdgeRec]"></a>2020(Alibaba)[EdgeRec]</h3><p>Gong, Y.; Jiang, Z.; Feng, Y.; Hu, B.; Zhao, K.; Liu, Q.; Ou, W. EdgeRec: Recommender System on Edge in Mobile Taobao. In <em>Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>; 2020; pp 2477–2484.</p>
<h3 id="【to粗】-STARec"><a href="#【to粗】-STARec" class="headerlink" title="【to粗】[STARec]"></a>【to粗】[STARec]</h3><p>Jin, J.; Chen, X.; Zhang, W.; Huang, J.; Feng, Z.; Yu, Y. Learn over Past, Evolve for Future: Search-Based Time-Aware Recommendation with Sequential Behavior Data. <em>arXiv preprint arXiv:2202.03097</em> <strong>2022</strong>.</p>
<p><strong>简介</strong>： Search-based Time-Aware Recommendation (STARec)基于搜索的时间感知的推荐。1.对用户长时间的历史序列进行检索（如品类过滤），融合短时序列。2.加入相似用户的序列。3.label trick,即把历史行为label加入X</p>
<h3 id="【精】2022-Multi-Resolution-Attention-【多时间尺度的attention】"><a href="#【精】2022-Multi-Resolution-Attention-【多时间尺度的attention】" class="headerlink" title="【精】2022[Multi-Resolution Attention] 【多时间尺度的attention】"></a>【精】2022[Multi-Resolution Attention] 【多时间尺度的attention】</h3><p>Kocayusufoglu, F.; Wu, T.; Singh, A.; Roumpos, G.; Cheng, H.-T.; Jain, S.; Chi, E.; Singh, A. Multi-Resolution Attention for Personalized Item Search. In <em>Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</em>; 2022; pp 508–516.</p>
<p>多分辨率注意力机制</p>
<p><strong>简介</strong>：用户行为是个性化搜索的基础。用户行为建模存在两个难点：1.并不是所有的行为都和当前决策有关。2.用户行为是非周期性的，他们与当前query的相关性涉及到复杂的时间依赖。本文的方法可以在多个<strong>时空子空间（temporal subspaces (i.e., resolutions)）</strong>捕获<strong>历史行为和当前query的高阶的相关性</strong>。实现方式是通过多头注意力机制+可微分的阈值方式实现时间维度的掩码（masking）。推荐中的很多模型通过attention提取的是序列的信息，而忽略了时间的信息。也有一些工作引入了时间的信息（ [17, 23, 41, 43, 44]）,但大都是推荐场景，不是个性化搜索场景。</p>
<p><strong>关键词</strong>：item search, personalization, temporal attention, multi-resolution attention, recommender systems</p>
<ul>
<li><p>关键思想：在不同时间子空间(时间尺度)计算query和item的相关性</p>
</li>
<li><p>个性化搜索领域一般用attention提取历史相关信息，忽略了时间信息；推荐领域今年有考虑序列中的时间信息的工作，但没有query约束。我们的工作是在个性化搜索领域考虑时间信息（umm….）</p>
</li>
<li><p>文章先分析了业务场景下用户的交互行为特点，再跟模型结合起来（不同场景有不同的交互行为特点？）数据发现：</p>
<ol>
<li>同样的用户在不同品类上的复购周期是有差异的</li>
<li>同样的品类不同用户的复购周期也是有差异的</li>
</ol>
<p>所以提出时间分辨率（temporal resolutions ）的概念，目标是自适应的对不同用户不同品类选取合适的分辨率，并借此计算当前query和历史行为的相关性</p>
</li>
</ul>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220314150022595.png" alt="image-20220314150022595" style="zoom:50%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317165619270.png" alt="image-20220317165619270" style="zoom:50%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317165638457.png" alt="image-20220317165638457" style="zoom:50%;"></p>
<ul>
<li><p>input layer: 对历史序列的item和query进行embedding</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194828763.png" alt="image-20220317194828763" style="zoom:50%;"></p>
</li>
<li><p>History Encoding Layer：历史序列的自编码（与query无关）</p>
</li>
</ul>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194901838.png" alt="image-20220317194901838" style="zoom:50%;"></p>
<ul>
<li>Query-Aware History Encoding Layer： query相关的历史序列多头自编码，每个头有一个时间阈值</li>
</ul>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194918828.png" alt="image-20220317194918828" style="zoom:50%;"></p>
<h3 id="【精】2022-CLSR-【自监督-对比学习-长短兴趣表征解耦】"><a href="#【精】2022-CLSR-【自监督-对比学习-长短兴趣表征解耦】" class="headerlink" title="【精】2022[CLSR]【自监督+对比学习=长短兴趣表征解耦】"></a>【精】2022[CLSR]【自监督+对比学习=长短兴趣表征解耦】</h3><p>Cite：Zheng, Y.; Gao, C.; Chang, J.; Niu, Y.; Song, Y.; Jin, D.; Li, Y. Disentangling Long and Short-Term Interests for Recommendation. <em>arXiv preprint arXiv:2202.13090</em> <strong>2022</strong>. </p>
<p>code: <a href="https://github.com/tsinghua-fib-lab/CLSR">https://github.com/tsinghua-fib-lab/CLSR</a></p>
<p>CLS：Contrastive learning framework to disentangle Long and Short-term interests for Recommendation (CLSR) with self-supervision.</p>
<p><strong>简介</strong>：现有工作中用户的长短兴趣大都是耦合建模的，这样会降低准确性和可解释性。本文用对比学习的框架通过自监督的方法解耦了长短兴趣。首先用不同的编码器对长短兴趣(不同时间尺度)进行编码<strong>interest representation</strong>，然后从序列中获取<strong>interest proxies</strong>作为用户兴趣的<strong>伪标签</strong>，然后用pairwise的对比学习任务有监督的学习兴趣表征和相应的interest proxies之间的关系。最后用attention机制融合长短兴趣</p>
<p><strong>关键词</strong>：Recommendation, Long and Short-Term Interests, Self-supervised Learning, Disentanglement Learning</p>
<ul>
<li><p>现有的对用户历史行为的处理有三种方式。1.CF-based的方式，主要处理长期行为。2.sequential model(LSTM,CNN)，主要处理短期行为。3.CF-based + sequential, 缺点是无法保证学习到的长短期行为的准确性，因为没有显示的加入长短期的先验，也就是二者会相互影响。（表示怀疑）</p>
</li>
<li><p>长短期行为建模存在3个难点。1.长期行为和短期行为刻画用户的不同时间尺度的信息，公用一个表征是不合适的。2.序列中只有用户的隐反馈，没有标签来区分长短期行为。3.用户不同情况下对长短期行为的依赖是不同的</p>
</li>
<li><p><strong>基本思路</strong></p>
<p>notation</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160528707.png" alt="image-20220310160528707" style="zoom:30%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161624732.png" alt="image-20220310161624732" style="zoom:50%;"></p>
<ul>
<li><p>定义长短期兴趣的query向量（attention中的query概念，并不是真正的query）</p>
<p>长期行为的query是？？？,短期行为的query是行为序列的RNN输出</p>
</li>
</ul>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160613501.png" alt="image-20220310160613501" style="zoom:10%;"></p>
<ul>
<li><p>长期兴趣&amp;短期兴趣编码器</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160720224.png" alt="image-20220310160720224" style="zoom:25%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160739019.png" alt="image-20220310160739019" style="zoom:10%;"></p>
</li>
<li><p>自监督的长短期兴趣解耦</p>
<p>1.不同维度的pooling作为长短期兴趣的伪标签（proxy）；2.用BPR based pairwise loss 或者triplet loss 学习表征</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161821200.png" alt="image-20220310161821200" style="zoom:25%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310162153666.png" alt="image-20220310162153666" style="zoom:25%;"></p>
</li>
<li><p>自适应的兴趣融合</p>
<p>权重是序列RNN+candidate+长短期兴趣决定的；</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161951289.png" alt="image-20220310161951289" style="zoom:25%;"></p>
</li>
</ul>
</li>
<li><p><strong>启发</strong></p>
<ul>
<li>后续可跟进的方向：伪标签的构造方法可以更复杂。作者说目前这种avg pooling的方法出于简单，效果又足够好。后续可以优化</li>
<li>在预估任务中加入伪标签+对比学习框架通过自监督约束表征（representation）是一个指的研究的方向，其实是通过伪标签的形式加入了更多的模糊的先验知识。</li>
</ul>
</li>
<li><p><strong>几个有意思的结论</strong>：</p>
<ul>
<li>所有数据集上短期兴趣模型（如DIEN）基本都比长期兴趣（DIN）模型要好——-&gt;太长序列的增益很有限？</li>
<li>短期行为序列的增长带来的增益会递减，ctr任务上递减的速度高于cvr任务——-&gt; 短期序列更重要</li>
<li>长短期行为联合训练不一定会更有优：因为长短期行为的耦合增加了模型的内部依赖性（ internal dependency ）,会降低模型表现</li>
<li>固定的长短期兴趣融合策略（concat/固定权重）没有自适应的权重好：不同场景下长短兴趣的重要性是不同的</li>
<li>高客单价/购买场景对长期兴趣的依赖性高于低客单价/点击场景</li>
<li>由于作者认为长短兴趣也有重叠的部分，所以没有像其他解耦任务一样增加正则项，强制两个表征不相似</li>
</ul>
</li>
<li><p><strong>引用文献</strong></p>
<ul>
<li>【推荐中的解耦】FrancescoLocatello,StefanBauer,MarioLucic,GunnarRaetsch,SylvainGelly, Bernhard Schölkopf, and Olivier Bachem. 2019. Challenging common assump- tions in the unsupervised learning of disentangled representations. In interna- tional conference on machine learning. PMLR, 4114–4124.</li>
<li>【推荐中的解耦】Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua. 2020. Disentangled graph collaborative filtering. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 1001–1010.</li>
</ul>
</li>
</ul>
<h3 id="【精】2022-RACP-【页面维度信息-负反馈】"><a href="#【精】2022-RACP-【页面维度信息-负反馈】" class="headerlink" title="【精】2022 [RACP]【页面维度信息+负反馈】"></a>【精】2022 [RACP]【页面维度信息+负反馈】</h3><p>2022 (Alibaba) (WSDM)(ZhifangFan)[RACP]Modeling Users’ Contextualized Page-wise Feedback for Click-Through Rate Prediction in E-commerce Search</p>
<p>简介：建模用户的历史行为对个性化搜索和推荐都很重要，现有方法主要是对用户历史正反馈的建模（点击序列），忽略了产生反馈的上下文信息。本文通过加入历史<strong>页面维度的曝光和反馈</strong>做一位用户历史行为序列，提出了一种新的上下文感知的用户行为建模方式。通过捕捉页面内的信息和页面间的演化可以更详细的学习用户的偏好。 RACP(Recurrent Attention over Contextualized Page sequence)模型通过<strong>page-context aware attention</strong> 学习页面内的关系。<strong>recurrent attention</strong>学习页面间的关系</p>
<ul>
<li><p>模型结构：</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228121702691.png" alt="image-20220228121702691" style="zoom:50%;"></p>
</li>
<li><p>quote</p>
<ul>
<li>“However, they treat users’ positive and negative feedback separately, and rep- resent users’ feedback as a clicked item sequence and a non-clicked item sequence, which cannot generate the mutual context between clicks and non-clicks and ignores other page context information in the page-sequence” 历史工作很少考虑负反馈，即便考虑也是和正反馈分开处理的，这忽略了<strong>正负反馈之间的相互作用</strong></li>
<li>页面信息的增益：1）<strong>正反馈是有噪音的</strong>，避免过拟合。一个用户点了一个品牌不一定是他就偏好这个品牌，有可能是整个页面都是这个品牌 2) 用户对item的行为受曝光的其他item影响</li>
<li>页面间的增益：搜索场景下用户的行为和意图是一个逐渐收敛的过程。例如：搜索—-曝光—-点击—-搜索—-曝光—-点击—-购买</li>
<li>“Recently, some pioneering work (<strong>DFN</strong> [33], <strong>DSTN</strong> [25]) high- light the importance of modeling both users’ positive and negative feedback for CTR prediction.” 一些负反馈的工作</li>
<li><strong>DFN</strong> [33]: DFN treats click behaviors as strong feedback to guide the positive preference extraction from unclicked behavior sequence.</li>
<li><strong>DSTN</strong> [25]: DSTN considers the clicked and unclicked be- haviors as heterogeneous auxiliary data to help the user preference modeling.</li>
<li>item画像：item id,品类id,shop id,统计类（成单量等）</li>
<li>query画像：query id,字符串，分词，类别</li>
<li><strong>页内的attention聚合+页间兴趣回溯(GRU，由下一个page表征当前的query) + 页间兴趣融合(attention)</strong></li>
</ul>
</li>
<li></li>
</ul>
<h3 id="【粗】2021-ETA-【长期行为-SimHash相似度】"><a href="#【粗】2021-ETA-【长期行为-SimHash相似度】" class="headerlink" title="【粗】2021[ETA]【长期行为+SimHash相似度】"></a>【粗】2021[ETA]【长期行为+SimHash相似度】</h3><p>2021(Alibaba)(ArXiv)[ETA]End-to-End User Behavior Retrieval in Click-Through Rate Prediction Model</p>
<p>简介：用户的长期行为对CTR预估很重要，但由于性能的约束，超长期用户行为通常是通过两段式训练进行处理的。第一阶段通过长期行为召回topK,第二阶段结合短期行为进行排序。两阶段由于优化目标不一致降低了长期用户行为带来的CTR增益。本文通过<strong>locality- sensitive hashing (LSH)</strong>方法提出端到端的ETA模型，使得满足训练和推理性能要求的前提下端到端训练的长期用户行为ctr模型。主要是通过<strong>SimHash</strong>的方法计算相似度，使得相似度的计算复杂度由O(L<em> B </em> d)变为O(L*B)，其中L是序列长度，B是candidate梳理，d是embedding维度</p>
<ul>
<li><p>模型结构：</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228145221827.png" alt="image-20220228145221827" style="zoom:50%;"></p>
</li>
</ul>
<h3 id="【粗】2021-ZEUS-【预测下一个query-微调】"><a href="#【粗】2021-ZEUS-【预测下一个query-微调】" class="headerlink" title="【粗】2021  [ZEUS]【预测下一个query + 微调】"></a>【粗】2021  [ZEUS]【预测下一个query + 微调】</h3><p>2021 (Alibaba) (CIKM) [ZEUS] Self-Supervised Learning on Users’ Spontaneous Behaviors for Multi-Scenario Ranking in E-commerce</p>
<p>Gu, Y.; Bao, W.; Ou, D.; Li, X.; Cui, B.; Ma, B.; Huang, H.; Liu, Q.; Zeng, X. Self-Supervised Learning on Users’ Spontaneous Behaviors for Multi-Scenario Ranking in E-Commerce. In <em>Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</em>; ACM: Virtual Event Queensland Australia, 2021; pp 3828–3837. <a href="https://doi.org/10.1145/3459637.3481953">https://doi.org/10.1145/3459637.3481953</a>.</p>
<p>关键词：Learning to Rank; Multi-Scenario; Intent Recommendation; Rec- ommender System; E-commerce</p>
<p>简介：多场景下用户<strong>自发行为</strong>的<strong>自监督</strong>学习。搜广推场景下排序模块都非常重要，目前大部分工作聚焦于单场景建模。我们认为多场景面对以下两个挑战：1) Feedback Loop. 模型的训练数据是由模型产生的 2)多场景样本不足。模型包括用户自发行为（如主动搜索，指不受推荐系统影响的行为）的预训练，和用户隐反馈上的微调</p>
<ul>
<li>电子商务中的排序根据上下文和排序对象的不同可以分为三类：1)商品推荐，对象是商品; 2)意图推荐，对象是query; 3)商品搜索，对象是商品，上下文是query</li>
<li>relate work包含4个领域：<strong>learn to rank; 多场景学习(multi-senario LTR) ；自监督学习;意图推荐(intent reommendation)</strong></li>
<li>预训练任务：预测下一个搜索词。微调任务：各个场景的CTR任务。微调先是用全场景的点击作为y进行第一阶段微调，再用各自场景的点击进行第二阶段微调。微调时商品和query的embedding向量是固定的，其他特征是可变的</li>
</ul>
<h3 id="【to粗】2021-DUMN-【加入负反馈-显反馈对隐反馈去噪】"><a href="#【to粗】2021-DUMN-【加入负反馈-显反馈对隐反馈去噪】" class="headerlink" title="【to粗】2021[DUMN]【加入负反馈+显反馈对隐反馈去噪】"></a>【to粗】2021[DUMN]【加入负反馈+显反馈对隐反馈去噪】</h3><p>2021(Alibaba)(ACM)[DUMN]Denoising User-aware Memory Network for Recommendation</p>
<p>简介：最近推荐领域非常多的工作聚焦在用户行为建模。用户的反馈包含显式和隐式的，大部分工作忽略了<strong>隐式反馈的噪音</strong>（用显示反馈对隐式反馈进行去噪），这会导致对于用户兴趣的有偏理解，本文1）通过正交映射( orthogonal mapping)对隐反馈进行去噪  2)基于内存的用户长期行为建模  3)短期行为和长期行为的融合。输入包括4个部分，<strong>显示反馈：喜欢，不喜欢 ；隐式反馈：点击，未点击</strong></p>
<ul>
<li>外卖场景下的显示隐式反馈是什么？？？<img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228150641871.png" alt="image-20220228150641871" style="zoom:50%;"></li>
</ul>
<h3 id="【to粗】2020-CIKM-DMT"><a href="#【to粗】2020-CIKM-DMT" class="headerlink" title="【to粗】2020(CIKM)[DMT]"></a>【to粗】2020(CIKM)[DMT]</h3><p>2020(CIKM)(JD)[DMT]Deep Multifaceted Transformers for Multi-objective Ranking in Large- Scale E-commerce Recommender Systems</p>
<p>Gu, Y.; Ding, Z.; Wang, S.; Zou, L.; Liu, Y.; Yin, D. Deep Multifaceted Transformers for Multi-Objective Ranking in Large-Scale E-Commerce Recommender Systems. In <em>Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>; ACM: Virtual Event Ireland, 2020; pp 2493–2500. <a href="https://doi.org/10.1145/3340531.3412697">https://doi.org/10.1145/3340531.3412697</a>.</p>
<h2 id="【粗】"><a href="#【粗】" class="headerlink" title="【粗】"></a>【粗】</h2><h2 id="Post-Ranking"><a href="#Post-Ranking" class="headerlink" title="Post_Ranking"></a>Post_Ranking</h2><h3 id="【粗】-2021-HUAWAI-CRUM-【比较tricky-没解决关键的反事实标签的问题】"><a href="#【粗】-2021-HUAWAI-CRUM-【比较tricky-没解决关键的反事实标签的问题】" class="headerlink" title="【粗】(2021)(HUAWAI)[CRUM]【比较tricky,没解决关键的反事实标签的问题】"></a>【粗】(2021)(HUAWAI)[CRUM]【比较tricky,没解决关键的反事实标签的问题】</h3><p>通过上下文感知的重排序最大化推荐系统的效用</p>
<p>Xi, Y.; Liu, W.; Dai, X.; Tang, R.; Zhang, W.; Liu, Q.; He, X.; Yu, Y. Context-Aware Reranking with Utility Maximization for Recommendation. <em>arXiv preprint arXiv:2110.09059</em> <strong>2021</strong>.</p>
<p><strong>简介</strong>: 重排能够考虑item之间的相互影响，从全局最优的角度优化推荐系统</p>
<p><strong>keyword</strong>： counterfactual context(反实时上下文)</p>
<p><strong>思考</strong>：已有的很多工作都是使用实际展示序列建模的，会导致数据偏差。本文提出反事实上下文的概念(counterfactual context)代替原始序列。存在两个难点：1.如何评估反事实序列 2.如何生成反事实序列</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220321150342948.png" alt="image-20220321150342948" style="zoom:50%;"></p>
<p>如上图，原始序列中牙膏的点击率为0.47，按照score贪心排序后牙膏排到第二位，此时牙膏的点击率已经改变了。</p>
<h3 id="Neural-Re-ranking-in-Multi-stage-Recommender-Systems-A-Review"><a href="#Neural-Re-ranking-in-Multi-stage-Recommender-Systems-A-Review" class="headerlink" title="Neural Re-ranking in Multi-stage Recommender Systems: A Review"></a>Neural Re-ranking in Multi-stage Recommender Systems: A Review</h3><p>(1) Liu, W.; Xi, Y.; Qin, J.; Sun, F.; Chen, B.; Zhang, W.; Zhang, R.; Tang, R. Neural Re-Ranking in Multi-Stage Recommender Systems: A Review. <em>arXiv:2202.06602 [cs]</em> <strong>2022</strong>.</p>
<p><strong>简介</strong>:本文把rerank算法系统的整合在一个更大的视野中，对算法进行分类，并分别介绍了各个方法的历史发展、网络结构、个性化和复杂性，定量的对各种方法的性能进行讨论，最后展望了未来的发展方向</p>
<p>​        多级的推荐系统已经是推荐系统的主流框架，重拍作为最后一环目标是最大化整体收益，因为用户的行为不仅受item的影响，也受周边item的影响。所以重拍的一个挑战就是模拟list wise的上下文特征。重拍最早的工作追溯到1998年Carbonell[1]的工作，它采用贪心策略排序。随着深度学习技术的发展，由于深度模型的通用近似定理（Universal Approximation Theorem)，应用神经网络进行重新排序是近年来学术界和工业界的主要关注点。</p>
<p>​        本文从学习任务和监督信号两个维度对重排模型进行了分类。学习任务方面有的聚焦于单任务（如准确率），有的聚焦于多任务（如多样性和公平性）。在监督信号方面有的只初始的序列和观察到的信号作为标签（如曝光），有的则使用了反事实序列（如实际并未曝光的序列）及evaluator的评估信号作为标签。</p>
<p>​        通过以下的分类图可以发现有以下三个趋势：</p>
<p>(i) 大多数研究试图通过单一目标纯粹提高准确性，而具有多目标的多样性/公平性感知方法的探索相对较少。</p>
<p> (ii) Self-attention [Vaswani et al., 2017] 或 RNN [Hochreiter and Schmidhuber, 1997] 的组合和注意力已经成为重新排序中流行的网络结构。</p>
<p> (iii) 很少有作品讨论<strong>反事实排列对多目标学习中相关性</strong>的影响（图 1 的第一象限），这可能是一个潜在的研究方向。 </p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220322155759829.png" alt="image-20220322155759829" style="zoom:50%;"></p>
<ul>
<li><p>问题定义</p>
<p>重排问题可以抽象为找到一个排序函数使得目标loss最小。如果Y是单一目标则是单任务，Y是目标则是多任务。Y来evaluator则是学习反事实信号，否则是学习观测信号。</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220322162335078.png" alt="image-20220322162335078" style="zoom:50%;"></p>
<p>通过观察到的信号进行学习通常遵循直接的架构，通过列表上下文建模输出重新排序分数。 而通过反事实信号学习通常采用evaluator-generator范式——生成器在评估器的指导下生成重新排序列表，其中生成器和评估器都关注列表上下文。</p>
</li>
<li><p>技术发展介绍</p>
<p>​        基于观测数据的模型反馈噪音较少，也比较容易训练，但容易产生bias。模型结构方面由于要考虑上下文，主要有RNN系列，Attention系列和其他（MLP，GNN等）。基于反事实序列的模型由Wang[2]在2019年首次采用 evaluator-generator建模范式提出SEG模型，作者指出evaluator需要的两个属性：（i）顺序敏感性，评估者需要对输入列表的顺序敏感； (ii) 概括性，应很好地概括所有可能的排列。 在evaluator的指导下，SEG 设计了一种监督学习方法和一种强化学习方法来训练生成器。后续一系列研究在此建模范式下尝试了不同的模型，如下表。</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220322164252991.png" alt="image-20220322164252991" style="zoom:50%;"></p>
</li>
</ul>
<p>​        </p>
<ul>
<li>挑战及展望</li>
</ul>
<p>1）稀疏反馈。观测到的反馈只是n!种排序的一种。evaluator或点击率模型可用于反事实序列的打标，而这些模型本质上还是基于观测数据训练的。目前缺乏针对evaluator特定的有效的设计</p>
<p>2）公平性/多样性的个性化。近期的个性化工作主要是准确率导向的，而未探索多样性和公平性的个性化。 不同的用户对多样性和公平性有不同的需求。 涉及个性化多样性或公平性的潜力巨大</p>
<p>3）多任务之间的平衡。不同的推荐场景对多样性或公平性有不同程度的需求。 现有的研究主要通过启发式或参数调整来管理权衡。 在没有人工干预的情况下自动平衡多个目标可能是一个很有前途的方向。</p>
<p>4）推荐系统联合训练。重排会受推荐系统前序流程影响，利用其他阶段（例如，参数传递、梯度传递）学到的信息对学术界和工业界都具有很高的价值。</p>
<p>[1][Carbonell and Goldstein, 1998] Jaime Carbonell and Jade Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In <em>SI- GIR</em>, 1998.</p>
<p>[2] Fan Wang, Xiaomin Fang, Lihang Liu, et al. Sequential evaluation and generation framework</p>
<h2 id="Multi-task"><a href="#Multi-task" class="headerlink" title="Multi-task"></a>Multi-task</h2><h2 id="Graph-Neural-Network"><a href="#Graph-Neural-Network" class="headerlink" title="Graph_Neural_Network"></a>Graph_Neural_Network</h2><h2 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer_Learning"></a>Transfer_Learning</h2><h2 id="Reignforcement-Learning"><a href="#Reignforcement-Learning" class="headerlink" title="Reignforcement_Learning"></a>Reignforcement_Learning</h2><h2 id="Self-Supervised-Learning"><a href="#Self-Supervised-Learning" class="headerlink" title="Self_Supervised_Learning"></a>Self_Supervised_Learning</h2><h2 id="Corporation"><a href="#Corporation" class="headerlink" title="Corporation"></a>Corporation</h2><h2 id="New-Papers"><a href="#New-Papers" class="headerlink" title="New_Papers"></a>New_Papers</h2><h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><h2 id="Maching"><a href="#Maching" class="headerlink" title="Maching"></a>Maching</h2><h2 id><a href="#" class="headerlink" title=" "></a> </h2><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p> <a href="https://github.com/guyulongcs/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising">Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</a></p>
<p><a href="https://mp.weixin.qq.com/s/lOCcPexEs9xRwcnfGIdXVw">WSDM2022推荐系统论文集锦</a></p>
<p><a href="https://mp.weixin.qq.com/s/hRLq9Q3NBZcj16uSKHPQaA">WWW 2022 推荐系统和广告相关论文整理分类</a></p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
        <tag>Learning to Rank</tag>
        <tag>Multi-Scenario</tag>
        <tag>Intent Recommendation</tag>
        <tag>Recommender System</tag>
        <tag>E-commerce</tag>
      </tags>
  </entry>
  <entry>
    <title>2022机器学习会议paper list</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%E4%BC%9A%E8%AE%AEpaper/</url>
    <content><![CDATA[<p>各家公司在Cikm2021  wsdm2022上的paper</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="cikm2021"><a href="#cikm2021" class="headerlink" title="cikm2021"></a>cikm2021</h1><p><a href="https://www.cikm2021.org/accepted-papers">https://www.cikm2021.org/accepted-papers</a></p>
<ul>
<li><h3 id="SimpleX-A-Simple-and-Strong-Baseline-for-Collaborative-Filtering"><a href="#SimpleX-A-Simple-and-Strong-Baseline-for-Collaborative-Filtering" class="headerlink" title="SimpleX: A Simple and Strong Baseline for Collaborative Filtering"></a>SimpleX: A Simple and Strong Baseline for Collaborative Filtering</h3><p>Kelong Mao (Renmin University of China, China), Jieming Zhu (Huawei Noah’s Ark Lab, China), Jinpeng Wang (Tsinghua University, China), Quanyu Dai (Huawei Noah’s Ark Lab, China), Zhenhua Dong (Huawei Noah’s Ark Lab, China), Xi Xiao (Tsinghua University, China), Xiuqiang He (Huawei Noah’s Ark Lab, China)</p>
</li>
<li><h3 id="UltraGCN-Ultra-Simplification-of-Graph-Convolutional-Networks-for-Recommendation"><a href="#UltraGCN-Ultra-Simplification-of-Graph-Convolutional-Networks-for-Recommendation" class="headerlink" title="UltraGCN: Ultra Simplification of Graph Convolutional Networks for Recommendation"></a><strong>UltraGCN: Ultra Simplification of Graph Convolutional Networks for Recommendation</strong></h3><p>Kelong Mao (Renmin University of China, China), Jieming Zhu (Huawei Noah’s Ark Lab, China), Xi Xiao (Tsinghua University &amp; Peng Cheng Laboratory, China), Biao Lu (Huawei Noah’s Ark Lab, China), Zhaowei Wang (Huawei Noah’s Ark Lab, China), Xiuqiang He (Huawei Noah’s Ark Lab, China)</p>
</li>
<li><h3 id="To-Be-or-not-to-Be-Tail-Labels-in-Extreme-Multi-label-Learning"><a href="#To-Be-or-not-to-Be-Tail-Labels-in-Extreme-Multi-label-Learning" class="headerlink" title="To Be or not to Be, Tail Labels in Extreme Multi-label Learning"></a>To Be or not to Be, Tail Labels in Extreme Multi-label Learning</h3><p>Zhiqi Ge (Jilin University, China), Ximing Li (Jilin University, China)</p>
</li>
<li><h3 id="Pre-training-for-Ad-hoc-Retrieval-Hyperlink-is-Also-You-Need"><a href="#Pre-training-for-Ad-hoc-Retrieval-Hyperlink-is-Also-You-Need" class="headerlink" title="Pre-training for Ad-hoc Retrieval: Hyperlink is Also You Need"></a>Pre-training for Ad-hoc Retrieval: Hyperlink is Also You Need</h3><p>Zhengyi Ma (Renmin University of China, China), Zhicheng Dou (Renmin University of China, China), Wei Xu (Renmin University of China, China), Xinyu Zhang (Huawei, China), Hao Jiang (Huawei, China), Zhao Cao (Huawei, China), Ji-Rong Wen (Renmin University of China, China)</p>
</li>
<li><h3 id="Pareto-optimal-Community-Search-on-Large-Bipartite-Graphs"><a href="#Pareto-optimal-Community-Search-on-Large-Bipartite-Graphs" class="headerlink" title="Pareto-optimal Community Search on Large Bipartite Graphs"></a><strong>Pareto-optimal Community Search on Large Bipartite Graphs</strong></h3><p>Yuting Zhang (University of New South Wales, Australia), Kai Wang (University of New South Wales, Australia), Wenjie Zhang (University of New South Wales, Australia), Xuemin Lin (University of New South Wales, Australia), Ying Zhang (University of Technology Sydney, Australia)</p>
</li>
<li><h3 id="Learning-Implicit-User-Profile-for-Personalized-Retrieval-Based-Chatbot"><a href="#Learning-Implicit-User-Profile-for-Personalized-Retrieval-Based-Chatbot" class="headerlink" title="Learning Implicit User Profile for Personalized Retrieval-Based Chatbot"></a><strong>Learning Implicit User Profile for Personalized Retrieval-Based Chatbot</strong></h3><p>Hongjin Qian (Renmin University of China, China), Zhicheng Dou (Renmin University of China, China), Yutao Zhu (Université de Montréal, Canada), Yueyuan Ma (Renmin University of China, China), Ji-Rong Wen (Renmin University of China &amp; Beijing Key Laboratory of Big Data Management and Analysis Methods, China)</p>
</li>
<li><h3 id="Modeling-Heterogeneous-Graph-Network-on-Fraud-Detection-A-Community-based-Framework-with-Attention-Mechanism"><a href="#Modeling-Heterogeneous-Graph-Network-on-Fraud-Detection-A-Community-based-Framework-with-Attention-Mechanism" class="headerlink" title="Modeling Heterogeneous Graph Network on Fraud Detection: A Community-based Framework with Attention Mechanism"></a><strong>Modeling Heterogeneous Graph Network on Fraud Detection: A Community-based Framework with Attention Mechanism</strong></h3><p>Li Wang (JD.com, China), Peipei Li (JD.com, China), Kai Xiong (JD.com, China), Jiashu Zhao (Wilfrid Laurier University, Canada), Rui Lin (JD.com, China)</p>
</li>
<li><h3 id="Improving-Chinese-Character-Representation-with-Formation-Graph-Attention-Network"><a href="#Improving-Chinese-Character-Representation-with-Formation-Graph-Attention-Network" class="headerlink" title="Improving Chinese Character Representation with Formation Graph Attention Network"></a><strong>Improving Chinese Character Representation with Formation Graph Attention Network</strong></h3><p>Xiaosu Wang (Fudan University, China), Yun Xiong (Fudan University, China), Hao Niu (Fudan University, China), Jingwen Yue (Fudan University, China), Yangyong Zhu (Fudan University, China), Philip S. Yu (University of Illinois at Chicago, USA)</p>
</li>
<li><h3 id="LiteGT-Efficient-and-Lightweight-Graph-Transformers"><a href="#LiteGT-Efficient-and-Lightweight-Graph-Transformers" class="headerlink" title="LiteGT: Efficient and Lightweight Graph Transformers"></a><strong>LiteGT: Efficient and Lightweight Graph Transformers</strong></h3><p>Cong Chen (The University of Hong Kong, China), Chaofan Tao (The University of Hong Kong, Hong Kong), Ngai Wong (The University of Hong Kong, Hong Kong)</p>
</li>
<li><h3 id="Top-N-Recommendation-with-Counterfactual-User-Preference-Simulation"><a href="#Top-N-Recommendation-with-Counterfactual-User-Preference-Simulation" class="headerlink" title="Top-N Recommendation with Counterfactual User Preference Simulation"></a><strong>Top-N Recommendation with Counterfactual User Preference Simulation</strong></h3><p>Mengyue Yang (University College London, United Kingdom), Quanyu Dai (Huawei, China), Zhenhua Dong (Huawei, China), Xu Chen (Beijing Key Laboratory of Big Data Management and Analysis Methods &amp; Renmin University of China, China), Xiuqiang He (Huawei, China), Jun Wang (University College London, United Kingdom)</p>
</li>
<li><h3 id="Reinforcement-Learning-to-Optimize-Lifetime-Value-in-Cold-Start-Recommendation"><a href="#Reinforcement-Learning-to-Optimize-Lifetime-Value-in-Cold-Start-Recommendation" class="headerlink" title="Reinforcement Learning to Optimize Lifetime Value in Cold-Start Recommendation"></a><strong>Reinforcement Learning to Optimize Lifetime Value in Cold-Start Recommendation</strong></h3><p>Luo Ji (Alibaba Group, China), Qi Qin (Peking University, China), Bingqing Han (Alibaba Group, China), Hongxia Yang (Alibaba Group, China)</p>
</li>
<li><h3 id="Zero-Shot-on-the-Cold-Start-Problem-Model-Agnostic-Interest-Learning-for-Recommender-Systems"><a href="#Zero-Shot-on-the-Cold-Start-Problem-Model-Agnostic-Interest-Learning-for-Recommender-Systems" class="headerlink" title="Zero Shot on the Cold-Start Problem: Model-Agnostic Interest Learning for Recommender Systems"></a><strong>Zero Shot on the Cold-Start Problem: Model-Agnostic Interest Learning for Recommender Systems</strong></h3><p>Philip J. Feng (NetEase Inc., China), Pingjun Pan (NetEase Inc., China), Tingting Zhou (NetEase Inc., China), Hongxiang Chen (NetEase Inc., China), Chuanjiang Luo (NetEase Inc., China)</p>
</li>
<li><h3 id="Multi-hop-Reading-on-Memory-Neural-Network-with-Selective-Coverage-for-Medication-Recommendation"><a href="#Multi-hop-Reading-on-Memory-Neural-Network-with-Selective-Coverage-for-Medication-Recommendation" class="headerlink" title="Multi-hop Reading on Memory Neural Network with Selective Coverage for Medication Recommendation"></a><strong>Multi-hop Reading on Memory Neural Network with Selective Coverage for Medication Recommendation</strong></h3><p>Yanda Wang (Nanjing University of Aeronautics and Astronautics, China), Weitong Chen (The University of Queensland, Australia), Dechang Pi (Nanjing University of Aeronautics and Astronautics, China), Lin Yue (The University of Queensland, Australia), Miao Xu (The University of Queensland, Australia), Xue Li (The University of Queensland, Australia)</p>
</li>
<li><h3 id="DynSTGAT-Dynamic-Spatial-Temporal-Graph-Attention-Network-for-Traffic-Signal-Control"><a href="#DynSTGAT-Dynamic-Spatial-Temporal-Graph-Attention-Network-for-Traffic-Signal-Control" class="headerlink" title="DynSTGAT: Dynamic Spatial-Temporal Graph Attention Network for Traffic Signal Control"></a><strong>DynSTGAT: Dynamic Spatial-Temporal Graph Attention Network for Traffic Signal Control</strong></h3><p>Libing Wu (Wuhan University &amp; Xidian University, China), Min Wang (Wuhan University &amp; Xidian University, China), Dan Wu (University of Windsor, Canada), Jia Wu (Macquarie University, Australia)</p>
</li>
<li><h3 id="Are-Negative-Samples-Necessary-in-Entity-Alignment-An-Approach-with-High-Performance-Scalability-and-Robustness"><a href="#Are-Negative-Samples-Necessary-in-Entity-Alignment-An-Approach-with-High-Performance-Scalability-and-Robustness" class="headerlink" title="Are Negative Samples Necessary in Entity Alignment?: An Approach with High Performance, Scalability and Robustness"></a><strong>Are Negative Samples Necessary in Entity Alignment?: An Approach with High Performance, Scalability and Robustness</strong></h3><p>Xin Mao (East China Normal University, China), Wenting Wang (Alibaba Group, Singapore), Yuanbin Wu (East China Normal University, China), Man Lan (East China Normal University, China)</p>
</li>
<li><h3 id="Contrastive-Learning-of-User-Behavior-Sequence-for-Context-Aware-Document-Ranking"><a href="#Contrastive-Learning-of-User-Behavior-Sequence-for-Context-Aware-Document-Ranking" class="headerlink" title="Contrastive Learning of User Behavior Sequence for Context-Aware Document Ranking"></a><strong>Contrastive Learning of User Behavior Sequence for Context-Aware Document Ranking</strong></h3><p>Yutao Zhu (University of Montreal, Canada), Jian-Yun Nie (University of Montreal, Canada), Zhicheng Dou (Renmin University of China, China), Zhengyi Ma (Renmin University of China, China), Xinyu Zhang (Distributed and Parallel Software Lab, Huawei, China), Pan Du (University of Montreal, Canada), Xiaochen Zuo (Renmin University of China, China), Hao Jiang (Distributed and Parallel Software Lab, Huawei, China)</p>
</li>
<li><h3 id="Deep-Self-Adaptive-Hashing-for-Image-Retrieval"><a href="#Deep-Self-Adaptive-Hashing-for-Image-Retrieval" class="headerlink" title="Deep Self-Adaptive Hashing for Image Retrieval"></a><strong>Deep Self-Adaptive Hashing for Image Retrieval</strong></h3><p>Qinghong Lin (Shenzhen University, China), Xiaojun Chen (Shenzhen University, China), Qin Zhang (Shenzhen University, China), Shangxuan Tian (Tencent, China), Yudong Chen (The University of Queensland, Australia)</p>
</li>
<li><h3 id="How-Powerful-is-Graph-Convolution-for-Recommendation"><a href="#How-Powerful-is-Graph-Convolution-for-Recommendation" class="headerlink" title="How Powerful is Graph Convolution for Recommendation"></a><strong>How Powerful is Graph Convolution for Recommendation</strong></h3><p>Yifei Shen (The Hong Kong University of Science and Technology, Hong Kong), Yongji Wu (Duke University, USA), Yao Zhang (Fudan University, China), Caihua Shan (Microsoft Research Asia, China), Jun Zhang (The Hong Kong University of Science and Technology, Hong Kong), B. Khaled Letaief (The Hong Kong University of Science and Technology, Hong Kong), Dongsheng Li (Microsoft Research Asia, China)</p>
</li>
<li><h3 id="CBML-A-Cluster-based-Meta-learning-Model-for-Session-based-Recommendation"><a href="#CBML-A-Cluster-based-Meta-learning-Model-for-Session-based-Recommendation" class="headerlink" title="CBML: A Cluster-based Meta-learning Model for Session-based Recommendation"></a><strong>CBML: A Cluster-based Meta-learning Model for Session-based Recommendation</strong></h3><p>Jiayu Song (Soochow University, China), Jiajie Xu (Soochow University, China), Rui Zhou (Swinburne University of Technology, Australia), Lu Chen (Swinburne University of Technology, Australia), Jianxin Li (Deakin University, Australia), Chengfei Liu (Swinburne University of Technology, Australia)</p>
</li>
<li><h3 id="AutoIAS-Automatic-Integrated-Architecture-Searcher-for-Click-Trough-Rate-Prediction"><a href="#AutoIAS-Automatic-Integrated-Architecture-Searcher-for-Click-Trough-Rate-Prediction" class="headerlink" title="AutoIAS: Automatic Integrated Architecture Searcher for Click-Trough Rate Prediction"></a><strong>AutoIAS: Automatic Integrated Architecture Searcher for Click-Trough Rate Prediction</strong></h3><p>Zhikun Wei (Tsinghua University, China), Xin Wang (Tsinghua University &amp; Pengcheng Laboratory, China), Wenwu Zhu (Tsinghua University &amp; Pengcheng Laboratory, China)</p>
</li>
<li><h3 id="CMML-Contextual-Modulation-Meta-Learning-for-Cold-Start-Recommendation"><a href="#CMML-Contextual-Modulation-Meta-Learning-for-Cold-Start-Recommendation" class="headerlink" title="CMML: Contextual Modulation Meta Learning for Cold-Start Recommendation"></a><strong>CMML: Contextual Modulation Meta Learning for Cold-Start Recommendation</strong></h3><p>Xidong Feng (University College London, United Kingdom), Chen Chen (Noah’s Ark Lab, Huawei, China), Dong Li (Noah’s Ark Lab, Huawei, China), Mengchen Zhao (Noah’s Ark Lab, Huawei, China), Jianye Hao (Noah’s Ark Lab, Huawei, China), Jun Wang (University College London, United Kingdom)</p>
</li>
<li><h3 id="Unsupervised-Large-Scale-Social-Network-Alignment-via-Cross-Network-Embedding"><a href="#Unsupervised-Large-Scale-Social-Network-Alignment-via-Cross-Network-Embedding" class="headerlink" title="Unsupervised Large-Scale Social Network Alignment via Cross Network Embedding"></a><strong>Unsupervised Large-Scale Social Network Alignment via Cross Network Embedding</strong></h3><p>Zhehan Liang (Xiamen University, China), Yu Rong (Tencent AI Lab, China), Chenxin Li (Xiamen University, China), Yunlong Zhang (Xiamen University, China), Yue Huang (Xiamen University, China), Tingyang Xu (Tencent AI Lab, China), Xinghao Ding (Xiamen University, China), Junzhou Huang (Tencent AI Lab, China)</p>
</li>
<li><h3 id="Learning-Joint-Embedding-with-Modality-Alignments-for-Cross-Modal-Retrieval-of-Recipes-and-Food-Images"><a href="#Learning-Joint-Embedding-with-Modality-Alignments-for-Cross-Modal-Retrieval-of-Recipes-and-Food-Images" class="headerlink" title="Learning Joint Embedding with Modality Alignments for Cross-Modal Retrieval of Recipes and Food Images"></a><strong>Learning Joint Embedding with Modality Alignments for Cross-Modal Retrieval of Recipes and Food Images</strong></h3><p>Zhongwei Xie (Georgia Institute of Technology &amp; Wuhan University of Technology, USA), Ling Liu (Georgia Institute of Technology, USA), Lin Li (Wuhan University of Technology, China), Luo Zhong (Wuhan University of Technology, China)</p>
</li>
<li><h3 id="Seq2Bubbles-Region-Based-Embedding-Learning-for-User-Behaviors-in-Sequential-Recommenders"><a href="#Seq2Bubbles-Region-Based-Embedding-Learning-for-User-Behaviors-in-Sequential-Recommenders" class="headerlink" title="Seq2Bubbles: Region-Based Embedding Learning for User Behaviors in Sequential Recommenders"></a><strong>Seq2Bubbles: Region-Based Embedding Learning for User Behaviors in Sequential Recommenders</strong></h3><p>Qitian Wu (Shanghai Jiao Tong University, China), Chenxiao Yang (Shanghai Jiao Tong University, China), Shuodian Yu (Shanghai Jiao Tong University, China), Xiaofeng Gao (Shanghai Jiao Tong University, China), Guihai Chen (Shanghai Jiao Tong University, China)</p>
</li>
<li><h3 id="Enhancing-User-Interest-Modeling-with-Knowledge-Enriched-Itemsets-for-Sequential-Recommendation"><a href="#Enhancing-User-Interest-Modeling-with-Knowledge-Enriched-Itemsets-for-Sequential-Recommendation" class="headerlink" title="Enhancing User Interest Modeling with Knowledge-Enriched Itemsets for Sequential Recommendation"></a><strong>Enhancing User Interest Modeling with Knowledge-Enriched Itemsets for Sequential Recommendation</strong></h3><p>Chunyang Wang (Shanghai Jiao Tong University, China), Yanmin Zhu (Shanghai Jiao Tong University, China), Haobing Liu (Shanghai Jiao Tong University, China), Wenze Ma (Shanghai Jiao Tong University, China), Tianzi Zang (Shanghai Jiao Tong University, China), Jiadi Yu (Shanghai Jiao Tong University, China)</p>
</li>
<li><h3 id><a href="#" class="headerlink" title="========="></a>=========</h3></li>
<li><h3 id="Learning-Multiple-Intent-Representations-for-Search-Queries，多表达"><a href="#Learning-Multiple-Intent-Representations-for-Search-Queries，多表达" class="headerlink" title="Learning Multiple Intent Representations for Search Queries，多表达"></a>Learning Multiple Intent Representations for Search Queries，多表达</h3><p>Helia Hashemi (University of Massachusetts Amherst, USA), Hamed Zamani (University of Massachusetts Amherst, USA), W. Bruce Croft (University of Massachusetts Amherst, USA)</p>
</li>
</ul>
<h2 id="阿里"><a href="#阿里" class="headerlink" title="阿里"></a>阿里</h2><ul>
<li><h3 id="Reinforcement-Learning-to-Optimize-Lifetime-Value-in-Cold-Start-Recommendation-1"><a href="#Reinforcement-Learning-to-Optimize-Lifetime-Value-in-Cold-Start-Recommendation-1" class="headerlink" title="Reinforcement Learning to Optimize Lifetime Value in Cold-Start Recommendation"></a>Reinforcement Learning to Optimize Lifetime Value in Cold-Start Recommendation</h3><p>Luo Ji (Alibaba Group, China), Qi Qin (Peking University, China), Bingqing Han (Alibaba Group, China), Hongxia Yang (Alibaba Group, China)</p>
</li>
<li><h3 id="Learning-to-Augment-Imbalanced-Data-for-Re-ranking-Models-‐"><a href="#Learning-to-Augment-Imbalanced-Data-for-Re-ranking-Models-‐" class="headerlink" title="Learning to Augment Imbalanced Data for Re-ranking Models ‐"></a>Learning to Augment Imbalanced Data for Re-ranking Models ‐</h3><p>Zi-Hao Qiu (Nanjing University, China), Ying-Chun Jian (Nanjing University, China), Qing-Guo Chen (Alibaba Group, China), Lijun Zhang (Nanjing University, China)</p>
</li>
<li><h3 id="Self-Supervised-Learning-on-Users’-Spontaneous-Behaviors-for-Multi-Scenario-Ranking-in-E-commerce"><a href="#Self-Supervised-Learning-on-Users’-Spontaneous-Behaviors-for-Multi-Scenario-Ranking-in-E-commerce" class="headerlink" title="Self-Supervised Learning on Users’ Spontaneous Behaviors for Multi-Scenario Ranking in E-commerce"></a><strong>Self-Supervised Learning on Users’ Spontaneous Behaviors for Multi-Scenario Ranking in E-commerce</strong></h3><p>Yulong Gu (Alibaba Group, China), Wentian Bao (Alibaba Group, China), Dan Ou (Alibaba Group, China), Xiang Li (Alibaba Group, China), Baoliang Cui (Alibaba Group, China), Biyu Ma (Alibaba Group, China), Haikuan Huang (Alibaba Group, China), Qingwen Liu (Alibaba Group, China), Xiaoyi Zeng (Alibaba Group, China)</p>
</li>
<li><h3 id="Heterogeneous-Graph-Neural-Networks-for-Large-Scale-Bid-Keyword-Matching"><a href="#Heterogeneous-Graph-Neural-Networks-for-Large-Scale-Bid-Keyword-Matching" class="headerlink" title="Heterogeneous Graph Neural Networks for Large-Scale Bid Keyword Matching"></a><strong>Heterogeneous Graph Neural Networks for Large-Scale Bid Keyword Matching</strong></h3><p>Zongtao Liu (Alibaba Group, China), Bin Ma (Alibaba Group, China), Quan Liu (Alibaba Group, China), Jian Xu (Alibaba Group, China), Bo Zheng (Alibaba Group, China)</p>
</li>
<li><h3 id="Unsupervised-Categorical-Representation-Learning-for-Package-Arrival-Time-Prediction，lbs的特点和eta结合"><a href="#Unsupervised-Categorical-Representation-Learning-for-Package-Arrival-Time-Prediction，lbs的特点和eta结合" class="headerlink" title="Unsupervised Categorical Representation Learning for Package Arrival Time Prediction，lbs的特点和eta结合"></a>Unsupervised Categorical Representation Learning for Package Arrival Time Prediction，lbs的特点和eta结合</h3><p>Yang Li (Alibaba Group, China), Xingyu Wu (Alibaba Group, China), Jinglong Wang (Alibaba Group, China), Yong Liu (Alibaba-NTU Singapore Joint Research Institute, Singapore), Xiaoqing Wang (Alibaba Group, China), Yuming Deng (Alibaba Group, China), Chunyan Miao (Nanyang Technological University, Singapore)</p>
</li>
<li><h3 id="Fulfillment-Time-Aware-Personalized-Ranking-for-On-Demand-Food-Recommendation"><a href="#Fulfillment-Time-Aware-Personalized-Ranking-for-On-Demand-Food-Recommendation" class="headerlink" title="Fulfillment-Time-Aware Personalized Ranking for On-Demand Food Recommendation"></a>Fulfillment-Time-Aware Personalized Ranking for On-Demand Food Recommendation</h3><p>Haishuai Wang (Alibaba Group, Fairfield University, China), Zhao Li (Alibaba Group, China), Xuanwu Liu (Alibaba Group, China), Donghui Ding (Alibaba Group, China), Zehong Hu (Alibaba Group, China), Peng Zhang (Guangzhou University, China), Chuan Zhou (Chinese Academy of Sciences, China), Jiajun Bu (Zhejiang University, China)</p>
</li>
<li><h3 id="SAR-Net-A-Scenario-Aware-Ranking-Network-for-Personalized-Fair-Recommendation-in-Hundreds-of-Travel-Scenarios"><a href="#SAR-Net-A-Scenario-Aware-Ranking-Network-for-Personalized-Fair-Recommendation-in-Hundreds-of-Travel-Scenarios" class="headerlink" title="SAR-Net: A Scenario-Aware Ranking Network for Personalized Fair Recommendation in Hundreds of Travel Scenarios"></a><strong>SAR-Net: A Scenario-Aware Ranking Network for Personalized Fair Recommendation in Hundreds of Travel Scenarios</strong></h3></li>
<li><h3 id="SCI-Subspace-Learning-Based-Counterfactual-Inference-for-Individual-Treatment-Effect-Estimation"><a href="#SCI-Subspace-Learning-Based-Counterfactual-Inference-for-Individual-Treatment-Effect-Estimation" class="headerlink" title="SCI: Subspace Learning Based Counterfactual Inference for Individual Treatment Effect Estimation"></a>SCI: Subspace Learning Based Counterfactual Inference for Individual Treatment Effect Estimation</h3><p>Liuyi Yao (Alibaba Group, China), Yaliang Li (Alibaba Group, USA), Sheng Li (University of Georgia, USA), Mengdi Huai (University of Virginia, USA), Jing Gao (Purdue University, USA), Aidong Zhang (University of Virginia, USA)</p>
</li>
<li><h3 id="Learning-to-Expand-Reinforced-Response-Expansion-for-Information-seeking-Conversations"><a href="#Learning-to-Expand-Reinforced-Response-Expansion-for-Information-seeking-Conversations" class="headerlink" title="Learning to Expand: Reinforced Response Expansion for Information-seeking Conversations"></a>Learning to Expand: Reinforced Response Expansion for Information-seeking Conversations</h3><p>Haojie Pan (Alibaba Group, China), Cen Chen (East China Normal University, China), Chengyu Wang (Alibaba Group, China), Minghui Qiu (Alibaba Group, Singapore), Liu Yang (University of Massachusetts at Amherst, USA), Feng Ji (Alibaba Group, China), Jun Huang (Alibaba Group, China)</p>
</li>
<li><h3 id="Binary-Code-based-Hash-Embedding-for-Web-scale-Applications"><a href="#Binary-Code-based-Hash-Embedding-for-Web-scale-Applications" class="headerlink" title="Binary Code based Hash Embedding for Web-scale Applications"></a>Binary Code based Hash Embedding for Web-scale Applications</h3><p>Bencheng Yan (Alibaba Group, China), Pengjie Wang (Alibaba Group, China), Jinquan Liu (Alibaba Group, China), Wei Lin (Alibaba Group, China), Kuang-Chih Lee (Alibaba Group, China), Jian Xu (Alibaba Group, China), Bo Zheng (Alibaba Group, China)</p>
</li>
<li><h3 id="Learning-Effective-and-Efficient-Embedding-via-an-Adaptively-Masked-Twins-based-Layer"><a href="#Learning-Effective-and-Efficient-Embedding-via-an-Adaptively-Masked-Twins-based-Layer" class="headerlink" title="Learning Effective and Efficient Embedding via an Adaptively-Masked Twins-based Layer"></a>Learning Effective and Efficient Embedding via an Adaptively-Masked Twins-based Layer</h3><p>Bencheng Yan (Alibaba Group, China), Pengjie Wang (Alibaba Group, China), Kai Zhang (Alibaba Group, China), Wei Lin (Alibaba Group, China), Kuang-Chih Lee (Alibaba Group, China), Jian Xu (Alibaba Group, China), Bo Zheng (Alibaba Group, China)</p>
</li>
<li><h3 id="AutoHERI-Automated-Hierarchical-Representation-Integration-for-Post-Click-Conversion-Rate-Estimation"><a href="#AutoHERI-Automated-Hierarchical-Representation-Integration-for-Post-Click-Conversion-Rate-Estimation" class="headerlink" title="AutoHERI: Automated Hierarchical Representation Integration for Post-Click Conversion Rate Estimation"></a>AutoHERI: Automated Hierarchical Representation Integration for Post-Click Conversion Rate Estimation</h3><p>Penghui Wei (Alibaba Group, China), Weimin Zhang (Alibaba Group, China), Zixuan Xu (Alibaba Group, China), Shaoguo Liu (Alibaba Group, China), Kuang-chih Lee (Alibaba Group, China), Bo Zheng (Alibaba Group, China)</p>
</li>
<li><h3 id="SMAD-Scalable-Multi-view-Ad-Retrieval-System-for-E-Commerce-Sponsored-Search"><a href="#SMAD-Scalable-Multi-view-Ad-Retrieval-System-for-E-Commerce-Sponsored-Search" class="headerlink" title="SMAD: Scalable Multi-view Ad Retrieval System for E-Commerce Sponsored Search"></a>SMAD: Scalable Multi-view Ad Retrieval System for E-Commerce Sponsored Search</h3><p>Shiyang Wen (Alibaba Group, China), Yiran Chen (Alibaba Group, China), Zhi Yang (Peking University, China), Yan Zhang (Alibaba Group, China), Di Zhang (Alibaba Group, China), Liang Wang (Alibaba Group, China), Bo Zheng (Alibaba Group, China)</p>
</li>
<li><h3 id="From-Community-Search-to-Community-Understanding-A-Multimodal-Community-Query-Engine"><a href="#From-Community-Search-to-Community-Understanding-A-Multimodal-Community-Query-Engine" class="headerlink" title="From Community Search to Community Understanding: A Multimodal Community Query Engine"></a><strong>From Community Search to Community Understanding: A Multimodal Community Query Engine</strong></h3><p>Zhao Li (Alibaba Group, China), Pengcheng Zou (Alibaba Group, China), Xia Chen (Alibaba Group, China), Shichang Hu (Alibaba Group, China), Peng Zhang (Guangzhou University, China), Yumou Zhang (Alibaba Group, China), Bingsheng He (National University of Singapore, Singapore), Yuchen Li (Singapore Management University, Singapore), Xing Tang (Alibaba Group, China)</p>
</li>
<li><h3 id="AliMe-MKG-A-Multi-modal-Knowledge-Graph-for-Live-streaming-E-commerce"><a href="#AliMe-MKG-A-Multi-modal-Knowledge-Graph-for-Live-streaming-E-commerce" class="headerlink" title="AliMe MKG: A Multi-modal Knowledge Graph for Live-streaming E-commerce"></a><strong>AliMe MKG: A Multi-modal Knowledge Graph for Live-streaming E-commerce</strong></h3><p>Guohai Xu (Alibaba Group, China), Hehong Chen (Alibaba Group, China), Feng-Lin Li (Alibaba Group, China), Fu Sun (Alibaba Group, China), Yunzhou Shi (Alibaba Group, China), Zhixiong Zeng (Alibaba Group, China), Wei Zhou (Alibaba Group, China), Zhongzhou Zhao (Alibaba Group, China), Ji Zhang (Alibaba Group, China)</p>
</li>
<li><h3 id="ECEdgeNet-A-Large-Scale-Edge-Computing-Dataset-in-the-Field-of-E-commerce"><a href="#ECEdgeNet-A-Large-Scale-Edge-Computing-Dataset-in-the-Field-of-E-commerce" class="headerlink" title="ECEdgeNet: A Large Scale Edge Computing Dataset in the Field of E-commerce"></a><strong>ECEdgeNet: A Large Scale Edge Computing Dataset in the Field of E-commerce</strong></h3><p> Liangwei Li (Alibaba Group, China), Chenwei Weng (Alibaba Group, China), Chengfu Huo (Alibaba Group, China), Weijun Ren (Alibaba Group, China)</p>
</li>
</ul>
<h2 id="baidu"><a href="#baidu" class="headerlink" title="baidu"></a>baidu</h2><ul>
<li><h3 id="Adversarial-Kernel-Sampling-on-Class-imbalanced-Data-Streams"><a href="#Adversarial-Kernel-Sampling-on-Class-imbalanced-Data-Streams" class="headerlink" title="Adversarial Kernel Sampling on Class-imbalanced Data Streams"></a>Adversarial Kernel Sampling on Class-imbalanced Data Streams</h3><p>Peng Yang (Baidu Research, USA), Ping Li (Baidu Research, USA)</p>
</li>
<li><h3 id="Efficient-Learning-to-Learn-a-Robust-CTR-Model-for-Web-scale-Online-Sponsored-Search-Advertising"><a href="#Efficient-Learning-to-Learn-a-Robust-CTR-Model-for-Web-scale-Online-Sponsored-Search-Advertising" class="headerlink" title="Efficient Learning to Learn a Robust CTR Model for Web-scale Online Sponsored Search Advertising"></a>Efficient Learning to Learn a Robust CTR Model for Web-scale Online Sponsored Search Advertising</h3><p>Xin Wang (Baidu Research, China), Peng Yang (Baidu Research, USA), Shaopeng Chen (Baidu Sponsored Search (Phoenix Nest), China), Lin Liu (Baidu Sponsored Search (Phoenix Nest), China), Lian Zhao (Baidu Sponsored Search (Phoenix Nest), China), Jiacheng Guo (Baidu Sponsored Search (Phoenix Nest), China), Mingming Sun (Baidu Research, China), Ping Li (Baidu Research, USA)</p>
</li>
<li><h3 id="CHASE-Commonsense-Enriched-Advertising-on-Search-Engine-with-Explicit-Knowledge"><a href="#CHASE-Commonsense-Enriched-Advertising-on-Search-Engine-with-Explicit-Knowledge" class="headerlink" title="CHASE: Commonsense-Enriched Advertising on Search Engine with Explicit Knowledge"></a>CHASE: Commonsense-Enriched Advertising on Search Engine with Explicit Knowledge</h3><p>Chao Zhang (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Jingbo Zhou (Baidu Research, China), Xiaoling Zang (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Qing Xu (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Liang Yin (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Xiang He (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Lin Liu (Baidu Search Ads (Phoenix Nest), Baidu Inc., China), Haoyi Xiong (Baidu Research, China), Dejing Dou (Baidu Research, China)</p>
</li>
<li><h3 id="Multi-modal-Dictionary-BERT-for-Cross-modal-Video-Search-in-Baidu-Advertising"><a href="#Multi-modal-Dictionary-BERT-for-Cross-modal-Video-Search-in-Baidu-Advertising" class="headerlink" title="Multi-modal Dictionary BERT for Cross-modal Video Search in Baidu Advertising"></a>Multi-modal Dictionary BERT for Cross-modal Video Search in Baidu Advertising</h3><p>Tan Yu (Baidu Research, USA), Yi Yang (Baidu Inc., China), Yi Li (Baidu Inc., China), Lin Liu (Baidu Inc., China), Mingming Sun (Baidu Research, China), Ping Li (Baidu Research, USA)</p>
</li>
<li><h3 id="MixBERT-for-Image-Ad-Relevance-Scoring-in-Advertising"><a href="#MixBERT-for-Image-Ad-Relevance-Scoring-in-Advertising" class="headerlink" title="MixBERT for Image-Ad Relevance Scoring in Advertising"></a>MixBERT for Image-Ad Relevance Scoring in Advertising</h3><p>Tan Yu (Baidu Research, USA), Xiaokang Li (Baidu Inc., China), Jianwen Xie (Baidu Research, USA), Ruiyang Yin (Baidu Research, China), Qing Xu (Baidu Inc., China), Ping Li (Baidu Research, USA)</p>
</li>
</ul>
<h2 id="腾讯"><a href="#腾讯" class="headerlink" title="腾讯"></a>腾讯</h2><ul>
<li><h3 id="Fast-Extraction-of-Word-Embedding-from-Q-contexts"><a href="#Fast-Extraction-of-Word-Embedding-from-Q-contexts" class="headerlink" title="Fast Extraction of Word Embedding from Q-contexts"></a>Fast Extraction of Word Embedding from Q-contexts</h3><p>Junsheng Kong (South China University of Technology, China), Weizhao Li (South China University of Technology, China), Zeyi Liu (University of Cambridge, United Kingdom), Ben Liao (Tencent Quantum Lab, China), Jiezhong Qiu (Tsinghua University, China), Chang-Yu Hsieh (Tencent Quantum Lab, China), Yi Cai (School of Software Engineering, South China University of Technology, China), Shengyu Zhang (Tencent Quantum Lab, China)</p>
</li>
<li><h3 id="USER-A-Unified-Information-Search-and-Recommendation-Model-based-on-Integrated-Behavior-Sequence"><a href="#USER-A-Unified-Information-Search-and-Recommendation-Model-based-on-Integrated-Behavior-Sequence" class="headerlink" title="USER: A Unified Information Search and Recommendation Model based on Integrated Behavior Sequence"></a><strong>USER: A Unified Information Search and Recommendation Model based on Integrated Behavior Sequence</strong></h3><p>Jing Yao (Renmin University of China &amp; Tencent, China), Zhicheng Dou (Renmin University of China, China), Ruobing Xie (Tencent, China), Yanxiong Lu (Tencent, China), Zhiping Wang (Tencent, China), Ji-Rong Wen (Beijing Key Laboratory of Big Data Management and Analysis Methods &amp; Key Laboratory of Data Engineering and Knowledge Engineering, MOE, China)</p>
</li>
<li><h3 id="Dual-Learning-for-Query-Generation-and-Query-Selection-in-Query-Feeds-Recommendation"><a href="#Dual-Learning-for-Query-Generation-and-Query-Selection-in-Query-Feeds-Recommendation" class="headerlink" title="Dual Learning for Query Generation and Query Selection in Query Feeds Recommendation"></a><strong>Dual Learning for Query Generation and Query Selection in Query Feeds Recommendation</strong></h3><p> Kunxun Qi (Sun Yat-sen University&amp;Tencent, China), Ruoxu Wang (Tencent, China), Qikai Lu (University of Alberta, Canada), Xuejiao Wang (Tencent, China), Ning Jing (Tencent, China), Di Niu (University of Alberta, Canada), Haolan Chen (Tencent, China)</p>
</li>
<li><h3 id="Influence-Maximization-in-Multi-Relational-Social-Networks"><a href="#Influence-Maximization-in-Multi-Relational-Social-Networks" class="headerlink" title="Influence Maximization in Multi-Relational Social Networks"></a>Influence Maximization in Multi-Relational Social Networks</h3><p> Wei Wang (Tencent Inc. China, China), Haili Yang (Tencent Inc. China, China), Yuanfu Lu (Tencent Inc. China, China), Yuanhang Zou (Tencent Inc. China, China), Xu Zhang (Tencent Inc. China, China), Shuting Guo (Tencent Inc. China, China), Leyu Lin (Tencent Inc. China, China)</p>
</li>
<li><h3 id="Spectral-Graph-Attention-Network-with-Fast-Eigen-approximation"><a href="#Spectral-Graph-Attention-Network-with-Fast-Eigen-approximation" class="headerlink" title="Spectral Graph Attention Network with Fast Eigen-approximation"></a><strong>Spectral Graph Attention Network with Fast Eigen-approximation</strong></h3><p>Heng Chang (Tsinghua University, China), Yu Rong (Tencent AI Lab, China), Tingyang Xu (Tencent AI Lab, China), Wenbing Huang (Tsinghua University, China), Somayeh Sojoudi (University of California at Berkeley, USA), Junzhou Huang (Tencent AI Lab, China), Wenwu Zhu (Tsinghua University, China)</p>
</li>
</ul>
<h2 id="Ant-Group"><a href="#Ant-Group" class="headerlink" title="Ant Group"></a>Ant Group</h2><ul>
<li><h3 id="Conditional-Graph-Attention-Networks-for-Distilling-and-Refining-Knowledge-Graphs-in-Recommendation"><a href="#Conditional-Graph-Attention-Networks-for-Distilling-and-Refining-Knowledge-Graphs-in-Recommendation" class="headerlink" title="Conditional Graph Attention Networks for Distilling and Refining Knowledge Graphs in Recommendation"></a>Conditional Graph Attention Networks for Distilling and Refining Knowledge Graphs in Recommendation</h3><p> Ke Tu (Ant Group, China), Peng Cui (Tsinghua University, China), Daixin Wang (Ant Group, China), Zhiqiang Zhang (Ant Group, China), Jun Zhou (Ant Group, China), Yuan Qi (Ant Group, China), Wenwu Zhu (Tsinghua University, China)</p>
</li>
<li><h3 id="Self-supervised-Representation-Learning-on-Dynamic-Graphs"><a href="#Self-supervised-Representation-Learning-on-Dynamic-Graphs" class="headerlink" title="Self-supervised Representation Learning on Dynamic Graphs"></a>Self-supervised Representation Learning on Dynamic Graphs</h3><p>Sheng Tian (Ant Group, China), Ruofan Wu (Ant Group, China), Leilei Shi (Ant Group, China), Liang Zhu (Ant Group, China), Tao Xiong (Ant Group, China)</p>
</li>
<li><h3 id="Learning-Representations-of-Inactive-Users-A-Cross-Domain-Approach-with-Graph-Neural-Networks"><a href="#Learning-Representations-of-Inactive-Users-A-Cross-Domain-Approach-with-Graph-Neural-Networks" class="headerlink" title="Learning Representations of Inactive Users: A Cross Domain Approach with Graph Neural Networks"></a>Learning Representations of Inactive Users: A Cross Domain Approach with Graph Neural Networks</h3><p>Ziqi Liu (Ant Group, China), Yue Shen (Ant Group, China), Xiaocheng Cheng (Ant Group, China), Qiang Li (Ant Group, China), Jianping Wei (Ant Group, China), Zhiqiang Zhang (Ant Group, China), Dong Wang (Ant Group, China), Xiaodong Zeng (Ant Group, China), Jinjie Gu (Ant Group, China), Jun Zhou (Ant Group, China)</p>
</li>
</ul>
<h2 id="Microsoft"><a href="#Microsoft" class="headerlink" title="Microsoft"></a>Microsoft</h2><ul>
<li><h3 id="CoPE-Modeling-Continuous-Propagation-and-Evolution-on-Interaction-Graph"><a href="#CoPE-Modeling-Continuous-Propagation-and-Evolution-on-Interaction-Graph" class="headerlink" title="CoPE: Modeling Continuous Propagation and Evolution on Interaction Graph"></a>CoPE: Modeling Continuous Propagation and Evolution on Interaction Graph</h3><p>Yao Zhang (Fudan University, China), Yun Xiong (Fudan University, China), Dongsheng Li (Microsoft Research Asia, China), Caihua Shan (Microsoft Research Asia, China), Kan Ren (Microsoft Research Asia, China), Yangyong Zhu (Fudan University, China)</p>
</li>
<li><h3 id="Improving-Query-Representations-for-Dense-Retrieval-with-Pseudo-Relevance-Feedback"><a href="#Improving-Query-Representations-for-Dense-Retrieval-with-Pseudo-Relevance-Feedback" class="headerlink" title="Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback"></a>Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback</h3><p>HongChien Yu (Carnegie Mellon University, USA), Chenyan Xiong (Microsoft Research, USA), Jamie Callan (Carnegie Mellon University, USA)</p>
</li>
<li><h3 id="Is-a-Single-Model-Enough-MuCoS-A-Multi-Model-Ensemble-Learning-Approach-for-Semantic-Code-Search"><a href="#Is-a-Single-Model-Enough-MuCoS-A-Multi-Model-Ensemble-Learning-Approach-for-Semantic-Code-Search" class="headerlink" title="Is a Single Model Enough? MuCoS: A Multi-Model Ensemble Learning Approach for Semantic Code Search"></a>Is a Single Model Enough? MuCoS: A Multi-Model Ensemble Learning Approach for Semantic Code Search</h3><p>Lun Du (Microsoft Research Asia, China), Xiaozhou Shi (Beijing University of Technology, China), Yanlin Wang (Microsoft Research Asia, China), Ensheng Shi (Xi’an Jiaotong University, China), Shi Han (Microsoft Research Asia, China), Dongmei Zhang (Microsoft Research Asia, China)</p>
</li>
<li></li>
<li></li>
</ul>
<ul>
<li></li>
</ul>
<h2 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a>Tutorials</h2><ul>
<li><p><strong>CIKM 2021 Tutorial on Fairness of Machine Learning in Recommender Systems</strong> ‐ Yunqi Li (Rutgers University, USA), Yingqiang Ge (Rutgers University, USA), Yongfeng Zhang (Rutgers University, USA)</p>
</li>
<li><p><strong>AutoML: From Methodology to Application</strong> ‐ Yaliang Li (Alibaba Group, USA), Zhen Wang (Alibaba Group, China), Yuexiang Xie (Alibaba Group, China), Bolin Ding (Alibaba Group, USA), Kai Zeng (Alibaba Group, China), Ce Zhang (ETH Zürich, Switzerland)</p>
</li>
<li><p><strong>IR From Bag-of-words to BERT and Beyond through Practical Experiments</strong> </p>
<p><a href="https://github.com/terrier-org/ecir2021tutorial">https://github.com/terrier-org/ecir2021tutorial</a></p>
<p>Craig Macdonald (University of Glasgow, United Kingdom), Nicola Tonellotto (University of Pisa, Italy), Sean MacAvaney (University of Glasgow, United Kingdom)</p>
</li>
</ul>
<h1 id="wsdm2022"><a href="#wsdm2022" class="headerlink" title="wsdm2022"></a>wsdm2022</h1><p><a href="https://www.wsdm-conference.org/2022/accepted-papers/">https://www.wsdm-conference.org/2022/accepted-papers/</a></p>
<h2 id="阿里-1"><a href="#阿里-1" class="headerlink" title="阿里"></a>阿里</h2><ul>
<li><p>A Cooperative-Competitive Multi-Agent Framework for Auto-bidding in Online Advertising</p>
<p>Chao Wen (Nanjing University of Aeronautics and Astronautics)*; Miao Xu (Alibaba Group); Zhilin Zhang (Alibaba Group); ZHENZHE ZHENG (Shanghai Jiao Tong University); Yuhui Wang (Nanjing University of Aeronautics and Astronautics, China); Xiangyu Liu (Alibaba Group)</p>
</li>
<li><p>Learning-To-Ensemble by Contextual Rank Aggregation in E-Commerce</p>
<p>Xuesi Wang (Alibaba); Guangda Huzhang (Alibaba); Qianying Lin (Alibaba)*; Qing Da (Alibaba Group)</p>
</li>
<li><p>Joint Learning of E-commerce Search and Recommendation with A Unified Graph Neural Network</p>
<p>Kai Zhao (Alibaba Group)*; Yukun Zheng (Alibaba inc.); Tao Zhuang (Alibaba Group); Xiang Li (Alibaba Group); Xiaoyi Zeng (Alibaba Group)</p>
</li>
<li><p>Triangle Graph Interest Network for Click-through Rate Prediction</p>
<p>Wensen Jiang (Alibaba Group)*; Yizhu Jiao (Fudan University); Qingqin Wang (Fudan University); Chuanming Liang (Alibaba Group); Lijie Guo (Alibaba Group); Yao Zhang (Fudan University); Zhijun Sun (Zhejiang Cainiao Supply Chain Management Co Ltd); Yun Xion</p>
</li>
<li><p>Modeling Users’ Contextualized Page-wise Feedback for Click-Through Rate Prediction in E-commerce Search</p>
<p>Zhifang Fan (Alibaba Group)*; Dan Ou (Alibaba Group); Yulong Gu (Alibaba Group); Bairan Fu (Nanjing University); Xiang Li (Alibaba Group); WenTian Bao (alibaba); Xin-yu Dai (Nanjing University); Xiaoyi Zeng (Alibaba Group); Tao Zhuang (Alibaba Group); Qin</p>
</li>
<li><p>Leaving No One Behind: A Multi-Scenario Multi-Task Meta Learning Approach for Advertiser Modeling</p>
<p>qianqian zhang (Alibaba)*; Xinru Liao (Alibaba Group); Quan Liu (Alibaba Group); Jian Xu (Alibaba Group); Bo Zheng (Alibaba Group)</p>
</li>
<li><p>An Adaptive Unified Allocation Framework for Guaranteed Display Advertising</p>
<p>Xiao Cheng (Alibaba); Chuanren Liu (University of Tennessee)*; Liang Dai (Alibaba); Peng Zhang (Alibaba); Zhen Fang (Alibaba); Zhonglin Zu (alibaba)</p>
</li>
<li></li>
</ul>
<h2 id="Tencent"><a href="#Tencent" class="headerlink" title="Tencent"></a>Tencent</h2><ul>
<li><p>RecGURU: Adversarial Learning of Generalized User Representations for Cross-Domain Recommendation</p>
</li>
<li><p>Personalized Transfer of User Preferences for Cross-domain Recommendation</p>
<p>Yongchun Zhu (Institute of Computing Technology, Chinese Academy of Sciences)*; Zhenwei Tang (King Abdullah University of Science and Technology); Yudan Liu (WeChat Search Application Department, Tencent); Fuzhen Zhuang (Institute of Artificial Intelligencem, Beihang University)</p>
</li>
<li><p>A Peep into the Future: Adversarial Future Encoding in Recommendation</p>
<p>Ruobing Xie (WeChat Search Application Department, Tencent)*; Shaoliang Zhang (Tencent); Rui Wang (Tencent); Feng Xia (WeChat Search Application Department, Tencent); Leyu Lin (WeChat Search Application Department, Tencent)</p>
</li>
<li><p>Efﬁcient two-stage label noise reduction for retrieval-based tasks</p>
<p>“Mengmeng Kuang (Tencent Holdings Ltd.)*; Weiyan Wang (HKUST); Zhenhong Chen (Tencent Holdings Ltd. ); Lie Kang (Tencent Holdings Ltd. ); Qiang Yan (Tencent)”</p>
</li>
</ul>
<h2 id="baidu-1"><a href="#baidu-1" class="headerlink" title="baidu"></a>baidu</h2><ul>
<li><p>Fast Semantic Matching via Flexible Contextualized Interaction</p>
<p>Wenwen Ye (Baidu Inc.)*; Yiding Liu (Baidu Inc.); Lixin Zou (Baidu Inc.); Hengyi Cai (Baidu Inc.); Suqi Cheng (Baidu Inc.); Shuaiqiang Wang (Baidu Inc.); Dawei Yin (Baidu)</p>
</li>
<li><p>A GNN-based Multi-task Learning Framework for Personalized Video Search</p>
<p>Li Zhang (University of Sheffield)*; Lei Shi ( Baidu); Jiashu Zhao (Wilfrid Laurier University); Juan Yang (Baidu); Tianshu Lyv (Baidu); Dawei Yin (Baidu); Haiping Lu (University of Sheffield)</p>
</li>
<li></li>
</ul>
<ul>
<li><h2 id="Bytedance"><a href="#Bytedance" class="headerlink" title="Bytedance"></a>Bytedance</h2></li>
<li><p>Diversified Query Generation Guided by Knowledge Graph</p>
<p>Xinyao Shen (Fudan University)*; Jiangjie Chen (Fudan University); Jiaze Chen (Bytedance); Chun Zeng (Fudan University); Yanghua Xiao (Fudan University)</p>
</li>
</ul>
<h2 id="kuaishou"><a href="#kuaishou" class="headerlink" title="kuaishou"></a>kuaishou</h2><ul>
<li><p>C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational Recommender System</p>
<p>Yuanhang Zhou (Renmin University of China)*; Kun Zhou (Renmin University of China); Wayne Xin Zhao (Renmin University of China); Cheng Wang (Kuaishou Inc); Peng Jiang (Kuaishou Inc.); He Hu (Renmin University of China)</p>
</li>
<li></li>
</ul>
<h2 id="Ant-Group-1"><a href="#Ant-Group-1" class="headerlink" title="Ant Group"></a>Ant Group</h2><ul>
<li><h3 id="Scope-aware-Re-ranking-with-Gated-Attention-in-Feed"><a href="#Scope-aware-Re-ranking-with-Gated-Attention-in-Feed" class="headerlink" title="Scope-aware Re-ranking with Gated Attention in Feed"></a>Scope-aware Re-ranking with Gated Attention in Feed</h3><p>Hao Qian (Ant Services Group)*; Qintong Wu (Ant Group ); Kai Zhang (University of Science and Technology of China); Zhiqiang Zhang (Ant Group); Lihong Gu (Ant Group); Xiaodong Zeng (Ant Services Group ); Jun Zhou (Ant Financial); Jinjie Gu (Ant Group)</p>
</li>
</ul>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul>
<li><h3 id="Multi-Resolution-Attention-for-Personalized-Item-Search"><a href="#Multi-Resolution-Attention-for-Personalized-Item-Search" class="headerlink" title="Multi-Resolution Attention for Personalized Item Search"></a>Multi-Resolution Attention for Personalized Item Search</h3><p>Furkan Kocayusufoglu (UC, Santa Barbara)*; Tao Wu (Google Research); Anima Singh (Google); Georgios Roumpos (Google Research); Heng-Tze Cheng (Google Research); Sagar Jain (Google); Ed H. Chi (Google); Ambuj K Singh (UCSB)</p>
</li>
<li><p>Supervised Advantage Actor-Critic for Recommender Systems</p>
<p>Xin Xin (Shandong University); Alexandros Karatzoglou (Google Research)*; Ioannis Arapakis (Telefonica Research); Joemon M Jose ( University of Glasgow)</p>
</li>
<li><p>Lightweight Composite Re-Ranking for Efficient Keyword Search with BERT</p>
<p>Yingrui Yang (University of California, Santa Barbara)*; Yifan Qiao (University of California, Santa Barbara); Jinjin Shao (UCSB); Xifeng Yan (University of California, Santa Barbara); Tao Yang (UC Santa Barbara)</p>
</li>
<li><p>Unsupervised Cross-Domain Adaptation for Response Selection Using Self-Supervised and Adversarial Training</p>
<p>Jia Li (Peking University); Chongyang Tao (Microsoft)*; Huang Hu (Microsoft); Can Xu (microsoft); Yining Chen (Microsoft); Daxin Jiang (Microsoft, Beijing, China)</p>
</li>
<li><p>GraSP: Optimizing Graph-based Nearest Neighbor Search with Subgraph Sampling and Pruning</p>
<p>Minjia Zhang (Microsoft AI and Research)*; Wenhan Wang (Microsoft); Yuxiong He (Microsoft)</p>
</li>
<li><p>Learning Multi-granularity Consecutive User Intent Unit for Session-based Recommendation</p>
<p>Jiayan Guo (Peking University)*; Yaming Yang (MSRA); Xiangchen Song (Carnegie Mellon University); Yuan Zhang (Peking University); Yujing Wang (MSRA); Jing Bai (Microsoft); Yan Zhang (Peking University)</p>
</li>
<li><p>MtCut: A Multi-Task Framework for Ranked List Truncation</p>
<p>Jianxin Li (Beihang University)*; Wang Dong (Beihang University); Tianchen Zhu (Beihang University); Qishan Zhu (Beihang University); Yuxin Wen (Beihang University); Piao Hongming (Beihang University)</p>
</li>
<li><p>Improving Session Search by Modeling Multi-Granularity Historical Query Change</p>
<p>Xiaochen Zuo (Renmin University of China)*; Zhicheng Dou (Remin University of China)</p>
</li>
<li><p>Learning Discrete Representations via Constrained Clustering for Effective and Efficient Dense Retrieval</p>
<p>Jingtao Zhan (Tsinghua University)*; Jiaxin Mao (Renmin University of China); Yiqun LIU (Tsinghua University); Jiafeng Guo (Institute of Computing Technology, Chinese Academy of Sciences); Min Zhang (Tsinghua University); Shaoping Ma (Tsinghua University)</p>
</li>
<li><p>ST-GSP: Spatial-Temporal Global Semantic Representation Learning for Urban Flow Prediction</p>
<p>Liang Zhao (Chongqing University); Min Gao (Chongqing University)*; Zongwei Wang (Chongqing University)</p>
</li>
<li><p>Improving Personalized Search with Dual-Feedback Network</p>
<p>Chenlong Deng (Renmin University of China)*; Yujia Zhou (Renmin University of China); Zhicheng Dou (Remin University of China)</p>
</li>
<li><p>Sequential Modeling with Multiple Attributes for Watchlist Recommendation in E-Commerce</p>
<p>Uriel Singer (Technion, Israel Institute of Technology)*; Haggai Roitman (IBM Research Haifa); yotam eshel (eBay); Alexander Nus (eBay); Ido Guy (eBay); Or Levi (eBay); Idan Hasson (eBay ); Eliyahu Kiperwasser (eBay)</p>
</li>
<li><p>Heterogeneous Global Graph Neural Networks for Personalized Session-based Recommendation</p>
<p>Yitong Pang (Tongji University)*; Lingfei Wu (JD.COM Silicon Valley Research Center); Qi Shen (Tongji University); Yiming Zhang (Tongji University); Zhihua Wei (Tongji University); Fangli Xu (College of William and Mary); Ethan Chang (Middlesex School); B</p>
</li>
<li><p>Learning Multi-granularity Consecutive User Intent Unit for Session-based Recommendation</p>
<p>Jiayan Guo (Peking University)*; Yaming Yang (MSRA); Xiangchen Song (Carnegie Mellon University); Yuan Zhang (Peking University); Yujing Wang (MSRA); Jing Bai (Microsoft); Yan Zhang (Peking University)</p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>FM</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/FM/</url>
    <content><![CDATA[<p>FM</p>
<span id="more"></span>
<h1 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h1>
<h1 id="为什么时间复杂度是O-kn"><a href="#为什么时间复杂度是O-kn" class="headerlink" title="为什么时间复杂度是O(kn)"></a>为什么时间复杂度是O(kn)</h1><p>我们考虑二次项</p>

<p>哇塞，这么复杂的公式怎么看得懂，我们一步步来，其实很简单。</p>
<p>第一步，拆解过程如图</p>

<p> 拆解</p>
<p>第二步，向量点乘</p>
<p>第三步，将k求和提出来</p>
<p>第四步，左边i和j式子相同，可以认为两者相等，直接得出平方</p>
<p>到此，很明显，它的计算复杂度为O(kn)，左边求和之后平方，右边平方后求和，没有出现</p>

<p>接下来我们看看FM如何收敛，照常使用SGD，计算FM的梯度是：</p>

<p>求Xi的梯度，令Xj固定，则第三项左边求和是一个定值，与Xi无关。时间复杂度为O(kn)</p>
<p>FM也可以扩展到更高阶的形式</p>

<p>到这，我们可以推断，FM能够在O(kn)时间复杂度处理特征间关联问题。</p>
<p>作者：邹金伟</p>
<p>链接：</p>
<p><a href="https://www.jianshu.com/p/67b4f7ec919e">https://www.jianshu.com/p/67b4f7ec919e</a></p>
<p>来源：简书</p>
<p>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<h1 id="为什么能处理稀疏矩阵"><a href="#为什么能处理稀疏矩阵" class="headerlink" title="为什么能处理稀疏矩阵"></a>为什么能处理稀疏矩阵</h1><blockquote>
<ul>
<li>用$<v_i,v_j>$代替$W$,理论依据是任何一个正定阵$W$都可表视为  $W=V\cdot V^T$, 其中$W \in (n<em>n),V\in (n</em>k)$, 只要k足够大。</v_i,v_j></li>
<li>FM中通过选定一个较小的超参k可捕捉交叉特征稀疏空间的联</li>
</ul>
</blockquote>
<p>​                        </p>
<p>那么，这和SVM相比有什么优势呢，SVM通过相应的核函数也能做到。还记得我们开头说的吗，相比SVM，FM能够胜任稀疏矩阵。</p>
<p>首先我们来看一下SVM如何处理特征间关联问题。SVM的公式是：</p>

<p>选用合适的核函数，这里我们设d=2， 例如</p>

<p>展开后公式可得</p>

<p>通过大量的数据训练，我们也能够得出对应的Weight。但是，如果特征i，和特征j没有同时出现呢。例如，从来没有一个人既买过啤酒，又买过烧鸭，那么你能认为某个人买完啤酒后不会再买烧鸭吗？这就是数据稀疏时候出现的问题，这时候Wi,j没有对应的x值训练。FM通过Vi *  Vj来确定W，那么只要其他记录有Vi，和Vj，不用同时出现，就可以分别对其进行训练，最后通过点乘来确定值。这牺牲了Wi,j一点自由度，却能够很好的处理稀疏矩阵的问题。</p>
<p>链接：</p>
<p><a href="https://www.jianshu.com/p/67b4f7ec919e">https://www.jianshu.com/p/67b4f7ec919e</a></p>
<p>来源：简书</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>LDA算法</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/LDA%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>LDA算法</p>
<span id="more"></span>
<h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>PLSA </p>
<p>每篇文章有个<script type="math/tex">\theta_i</script>确定每篇文章到topic的概率分布</p>
<p>每个topic_j有个<script type="math/tex">\phi_j</script>确定每篇文章到词的概率分布</p>
<p>求解theta_i，phi_j</p>
<p>LDA</p>
<p>每篇文i章有个alpha（对每篇文章都一样，是依靠先验人工设置的） 确定的地理克雷分布确定theta_i，由theta_i确定文章i到topic的概率分布</p>
<p>每个topic_j有个beta（对每个词都一样，是依靠先验人工设置的） 确定的地理克雷分布确定 phi_j, 由phi_j 确定topic_j到词的概率分布</p>
<p>求解theta_i，phi_j</p>
<h1 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h1><p>LDA</p>
<ol>
<li>每篇文i章有个alpha（对每篇文章都一样，是依靠先验人工设置的） 确定的地理克雷分布确定theta_i，由theta_i确定文章i到topic的概率分布</li>
</ol>
<script type="math/tex; mode=display">
\theta_i=P_d(\alpha) \\
P(j|i) = P_{mult}(\theta_i) \\
文章i到各个topic_j的分布由\theta_i确定,其中P_d是狄利克雷分布，P_{mult}是多项式分布</script><ol>
<li>每个topic_j有个beta（对每个词都一样，是依靠先验人工设置的） 确定的地理克雷分布确定 phi_j, 由phi_j 确定topic_j到词的概率分布</li>
</ol>
<script type="math/tex; mode=display">
\phi_j=P_d(\beta) \\
P(k|j) = P_{mult}(\phi_j) \\
topic_j到词k的分布由\phi_j确定,其中P_d是狄利克雷分布，P_{mult}是多项式分布</script><ol>
<li>求解theta_i，phi_j</li>
</ol>
<h1 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h1>]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning to Rank：Point-wise、Pair-wise 和 List-wise区别</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Learning%20to%20Rank%EF%BC%9APoint-wise%E3%80%81Pair-wise%20%E5%92%8C%20List-wise%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>Learning to Rank：Point-wise、Pair-wise 和 List-wise区别</p>
<span id="more"></span>
<h1 id="Learning-to-Rank：Point-wise、Pair-wise-和-List-wise区别"><a href="#Learning-to-Rank：Point-wise、Pair-wise-和-List-wise区别" class="headerlink" title="Learning to Rank：Point-wise、Pair-wise 和 List-wise区别"></a>Learning to Rank：Point-wise、Pair-wise 和 List-wise区别</h1><p> 机器学习的 ranking 技术——learning2rank，包括 pointwise、pairwise、listwise 三大类型。</p>
<p> <img src="https://img2018.cnblogs.com/blog/818082/201809/818082-20180929163323836-2075825354.png" alt="img"></p>
<p><a href="https://stackoverflow.com/questions/17411986/what-is-the-difference-between-point-wise-and-pair-wise-ranking-in-machine-learn">【Ref-1】</a>给出的：</p>
<Point wise ranking 类似于回归>

<p>Point wise ranking is analogous to regression. Each point has an associated rank score, and you want to predict that rank score. So your labeled data set will have a feature vector and associated rank score given a query</p>
<p>IE: {d1, r1} {d2, r2} {d3, r3} {d4, r4}</p>
<p>where r1 &gt; r2 &gt; r3 &gt;r4</p>
<Pairwise ranking 类似于分类>

<p>Pairwise ranking is analogous to classification. Each data point is associated with another data point, and the goal is to learn a classifier which will predict which of the two is “more” relevant to a given query.</p>
<p>IE: {d1 &gt; d2} {d2 &gt; d3} {d3 &gt; d4}</p>
<h1 id="1、Pointwise-Approach"><a href="#1、Pointwise-Approach" class="headerlink" title="\1、Pointwise Approach**"></a><strong><em>\</em>1、Pointwise Approach**</strong></h1><h2 id="1-1-特点"><a href="#1-1-特点" class="headerlink" title="　　*\*1.1 特点****"></a>　　<strong>*\</strong>*1.1 特点**<em>**</em></h2><p>　　Pointwise 类方法，其 L2R 框架具有以下特征：</p>
<ul>
<li>输入空间中样本是单个 doc（和对应 query）构成的特征向量；</li>
<li>输出空间中样本是单个 doc（和对应 query）的相关度；</li>
<li>假设空间中样本是打分函数；</li>
<li>损失函数评估单个 doc 的预测得分和真实得分之间差异。</li>
</ul>
<p>　　这里讨论下，关于人工标注标签怎么转换到 pointwise 类方法的输出空间：</p>
<ol>
<li>如果标注直接是相关度 s_j，则 doc x_j 的真实标签定义为 y_j=s_j</li>
<li>如果标注是 pairwise preference s_{u,v}，则 doc x_j 的真实标签可以利用该 doc 击败了其他 docs 的频次</li>
<li>如果标注是整体排序 π，则 doc x_j 的真实标签可以利用映射函数，如将 doc 的排序位置序号当作真实标签</li>
</ol>
<h2 id="1-2-根据使用的-ML-方法不同，pointwise-类可以进一步分成三类：基于回归的算法、基于分类的算法，基于有序回归的算法。"><a href="#1-2-根据使用的-ML-方法不同，pointwise-类可以进一步分成三类：基于回归的算法、基于分类的算法，基于有序回归的算法。" class="headerlink" title="　　1.2 根据使用的 ML 方法不同，pointwise 类可以进一步分成三类：基于回归的算法、基于分类的算法，基于有序回归的算法。"></a>　　1.2 根据使用的 ML 方法不同，pointwise 类可以进一步分成三类：基于回归的算法、基于分类的算法，基于有序回归的算法。</h2><p>　　（1）基于回归的算法</p>
<p>　　　　此时，输出空间包含的是实值相关度得分。采用 ML 中传统的回归方法即可。</p>
<p>　　（2）基于分类的算法</p>
<p>　　　　此时，输出空间包含的是无序类别。对于二分类，SVM、LR 等均可；对于多分类，提升树等均可。</p>
<p>　　（3）基于有序回归的算法</p>
<p>　　　　此时，输出空间包含的是有序类别。通常是找到一个打分函数，然后用一系列阈值对得分进行分割，得到有序类别。采用 PRanking、基于 margin 的方法都可以。</p>
<h2 id="1-3-缺陷"><a href="#1-3-缺陷" class="headerlink" title="　　1.3 缺陷"></a>　　1.3 缺陷</h2><p>　　　　回顾概述中提到的评估指标应该基于 query 和 position，</p>
<ul>
<li>ranking 追求的是排序结果，并不要求精确打分，只要有相对打分即可。</li>
<li>pointwise 类方法并没有考虑同一个 query 对应的 docs 间的内部依赖性。一方面，导致输入空间内的样本不是 IID 的，违反了 ML 的基本假设，另一方面，没有充分利用这种样本间的结构性。其次，当不同 query 对应不同数量的 docs 时，整体 loss 将会被对应 docs 数量大的 query 组所支配，前面说过应该每组 query 都是等价的。</li>
<li>损失函数也没有 model 到预测排序中的位置信息。因此，损失函数可能无意的过多强调那些不重要的 docs，即那些排序在后面对用户体验影响小的 doc。</li>
</ul>
<h2 id="1-4-改进"><a href="#1-4-改进" class="headerlink" title="　　1.4 改进"></a>　　1.4 改进</h2><p>　　　　如在 loss 中引入基于 query 的正则化因子的 RankCosine 方法。</p>
<h1 id="2、Pairwise-Approach"><a href="#2、Pairwise-Approach" class="headerlink" title="2、Pairwise Approach"></a>2、Pairwise Approach</h1><h2 id="2-1-特点"><a href="#2-1-特点" class="headerlink" title="　  2.1 特点"></a>　  2.1 特点</h2><p>　　Pairwise 类方法，其 L2R 框架具有以下特征：</p>
<ul>
<li>输入空间中样本是（同一 query 对应的）两个 doc（和对应 query）构成的两个特征向量；</li>
<li>输出空间中样本是 pairwise preference；</li>
<li>假设空间中样本是二变量函数；</li>
<li>损失函数评估 doc pair 的预测 preference 和真实 preference 之间差异。</li>
</ul>
<p>　　这里讨论下，关于人工标注标签怎么转换到 pairwise 类方法的输出空间：</p>
<ol>
<li>如果标注直接是相关度 s_j，则 doc pair (x_u,x_v) 的真实标签定义为 y_{u,v}=2*I_{s_u&gt;s_v}-1</li>
<li>如果标注是 pairwise preference s_{u,v}，则 doc pair (x_u,x_v) 的真实标签定义为y_{u,v}=s_{u,v}</li>
<li>如果标注是整体排序 π，则 doc pair (x_u,x_v) 的真实标签定义为y_{u,v}=2*I_{π_u,π_v}-1</li>
</ol>
<h2 id="2-2-基于二分类的算法"><a href="#2-2-基于二分类的算法" class="headerlink" title="　　2.2 基于二分类的算法　　"></a>　　2.2 基于二分类的算法　　</h2><p>　　Pairwise 类方法基本就是使用二分类算法即可。</p>
<p>　　经典的算法有 基于 NN 的 SortNet，基于 NN 的 RankNet，基于 fidelity loss 的 FRank，基于 AdaBoost 的 RankBoost，基于 SVM 的 RankingSVM，基于提升树的 GBRank。</p>
<h2 id="2-3-缺陷"><a href="#2-3-缺陷" class="headerlink" title="　　2.3 缺陷"></a>　　2.3 缺陷</h2><p>　　虽然 pairwise 类相较 pointwise 类 model 到一些 doc pair 间的相对顺序信息，但还是存在不少问题，回顾概述中提到的评估指标应该基于 query 和 position，</p>
<ul>
<li>如果人工标注给定的是第一种和第三种，即已包含多有序类别，那么转化成 pairwise preference 时必定会损失掉一些更细粒度的相关度标注信息。</li>
<li>doc pair 的数量将是 doc 数量的二次，从而 pointwise 类方法就存在的 query 间 doc 数量的不平衡性将在 pairwise 类方法中进一步放大。</li>
<li>pairwise 类方法相对 pointwise 类方法对噪声标注更敏感，即一个错误标注会引起多个 doc pair 标注错误。</li>
<li>pairwise 类方法仅考虑了 doc pair 的相对位置，损失函数还是没有 model 到预测排序中的位置信息。</li>
<li>pairwise 类方法也没有考虑同一个 query 对应的 doc pair 间的内部依赖性，即输入空间内的样本并不是 IID 的，违反了 ML 的基本假设，并且也没有充分利用这种样本间的结构性。</li>
</ul>
<h2 id="2-4-改进"><a href="#2-4-改进" class="headerlink" title="　　2.4 改进"></a>　　2.4 改进</h2><p>　　　pairwise 类方法也有一些尝试，去一定程度解决上述缺陷，比如：</p>
<ul>
<li>Multiple hyperplane ranker，主要针对前述第一个缺陷</li>
<li>magnitude-preserving ranking，主要针对前述第一个缺陷</li>
<li>IRSVM，主要针对前述第二个缺陷</li>
<li>采用 Sigmoid 进行改进的 pairwise 方法，主要针对前述第三个缺陷</li>
<li>P-norm push，主要针对前述第四个缺陷</li>
<li>Ordered weighted average ranking，主要针对前述第四个缺陷</li>
<li>LambdaRank，主要针对前述第四个缺陷</li>
<li>Sparse ranker，主要针对前述第四个缺陷</li>
</ul>
<p> 　<strong><em>\</em>3、Listwise Approach**</strong></p>
<h2 id="3-1-特点"><a href="#3-1-特点" class="headerlink" title="　　3.1 特点　　"></a>　　3.1 特点　　</h2><p>　　Listwise 类方法，其 L2R 框架具有以下特征：</p>
<ul>
<li>输入空间中样本是（同一 query 对应的）所有 doc（与对应的 query）构成的多个特征向量（列表）；</li>
<li>输出空间中样本是这些 doc（和对应 query）的相关度排序列表或者排列；</li>
<li>假设空间中样本是多变量函数，对于 docs 得到其排列，实践中，通常是一个打分函数，根据打分函数对所有 docs 的打分进行排序得到 docs 相关度的排列；</li>
<li>损失函数分成两类，一类是直接和评价指标相关的，还有一类不是直接相关的。具体后面介绍。</li>
</ul>
<p>　　这里讨论下，关于人工标注标签怎么转换到 listwise 类方法的输出空间：</p>
<ol>
<li>如果标注直接是相关度 s_j，则 doc set 的真实标签可以利用相关度 s_j 进行比较构造出排列</li>
<li>如果标注是 pairwise preference s_{u,v}，则 doc set 的真实标签也可以利用所有 s_{u,v} 进行比较构造出排列</li>
<li>如果标注是整体排序 π，则 doc set 则可以直接得到真实标签</li>
</ol>
<h2 id="3-2-根据损失函数构造方式的不同，listwise-类可以分成两类直接基于评价指标的算法，间接基于评价指标的算法。"><a href="#3-2-根据损失函数构造方式的不同，listwise-类可以分成两类直接基于评价指标的算法，间接基于评价指标的算法。" class="headerlink" title="　　3.2 根据损失函数构造方式的不同，listwise 类可以分成两类直接基于评价指标的算法，间接基于评价指标的算法。"></a>　　3.2 根据损失函数构造方式的不同，listwise 类可以分成两类直接基于评价指标的算法，间接基于评价指标的算法。</h2><p>　　　（1）直接基于评价指标的算法</p>
<p>　　直接取优化 ranking 的评价指标，也算是 listwise 中最直观的方法。但这并不简单，因为前面说过评价指标都是离散不可微的，具体处理方式有这么几种：</p>
<ul>
<li>优化基于评价指标的 ranking error 的连续可微的近似，这种方法就可以直接应用已有的优化方法，如SoftRank，ApproximateRank，SmoothRank</li>
<li>优化基于评价指标的 ranking error 的连续可微的上界，如 SVM-MAP，SVM-NDCG，PermuRank</li>
<li>使用可以优化非平滑目标函数的优化技术，如 AdaRank，RankGP</li>
</ul>
<p>　　上述方法的优化目标都是直接和 ranking 的评价指标有关。现在来考虑一个概念，informativeness。通常认为一个更有信息量的指标，可以产生更有效的排序模型。而多层评价指标（NDCG）相较二元评价（AP）指标通常更富信息量。因此，有时虽然使用信息量更少的指标来评估模型，但仍然可以使用更富信息量的指标来作为 loss 进行模型训练。</p>
<p>　　  （2）非直接基于评价指标的算法</p>
<p>　　这里，不再使用和评价指标相关的 loss 来优化模型，而是设计能衡量模型输出与真实排列之间差异的 loss，如此获得的模型在评价指标上也能获得不错的性能。<br>　　经典的如 ，ListNet，ListMLE，StructRank，BoltzRank。</p>
<h2 id="3-3-缺陷"><a href="#3-3-缺陷" class="headerlink" title="　　3.3 缺陷"></a>　　3.3 缺陷</h2><p>listwise 类相较 pointwise、pairwise 对 ranking 的 model 更自然，解决了 ranking 应该基于 query 和 position 问题。</p>
<p>listwise 类存在的主要缺陷是：一些 ranking 算法需要基于排列来计算 loss，从而使得训练复杂度较高，如 ListNet和 BoltzRank。此外，位置信息并没有在 loss 中得到充分利用，可以考虑在 ListNet 和 ListMLE 的 loss 中引入位置折扣因子。</p>
<h2 id="3-4-改进"><a href="#3-4-改进" class="headerlink" title="　　3.4 改进"></a>　　3.4 改进</h2><p>　　　pairwise 类方法也有一些尝试，去一定程度解决上述缺陷，比如：</p>
<ul>
<li>Multiple hyperplane ranker，主要针对前述第一个缺陷</li>
<li>magnitude-preserving ranking，主要针对前述第一个缺陷</li>
<li>IRSVM，主要针对前述第二个缺陷</li>
<li>采用 Sigmoid 进行改进的 pairwise 方法，主要针对前述第三个缺陷</li>
<li>P-norm push，主要针对前述第四个缺陷</li>
<li>Ordered weighted average ranking，主要针对前述第四个缺陷</li>
<li>LambdaRank，主要针对前述第四个缺陷</li>
<li>Sparse ranker，主要针对前述第四个缺陷</li>
</ul>
<p>以上，<strong>这三大类方法主要区别在于损失函数。不同的损失函数决定了不同的模型学习过程和输入输出空间。</strong></p>
<p>rating数据集：</p>
<p>：所以关于这个问题，是要使用topN=1的对吗？并把指标改为 AUC和 NDCG对吗？</p>
<p>——是这样，这个是一个rating数据集。</p>
<p>如果是按照pairwise ranking的正确率，应该是我们的oPR和oMRR，PR和MAP都是没有用的。</p>
<p>如果不按照pairwise，（按照listwise），就是AUC和NDCG，所以我让你算那个。</p>
<p>当然还有就是按照数值，（按照pointwise），RMSE，不过我们的没法计算RMSE。</p>
<p>：啊这个“不按照pairwise”，没太明白，还是按照原来的思路，用的 winner 和 loser 比较对呀。尤其在这个rating数据集，是每个比较对当成一个session，这点还是不变的吧？？</p>
<p>——这不就是pairwise吗？</p>
<p>rating是可以按照每个用户得到一个排序的，这是listwise，也就是算出NDCG，AUC的指标。</p>
<p>还可以按照pointwise，每个分数预测的怎么样，就是RMSE。</p>
<p>【Reference】</p>
<p>1、<a href="https://stackoverflow.com/questions/17411986/what-is-the-difference-between-point-wise-and-pair-wise-ranking-in-machine-learn">What is the difference between point-wise and pair-wise ranking in machine learning</a></p>
<p>2、<a href="https://blog.csdn.net/lipengcn/article/details/80373744">学习排序 Learning to Rank：从 pointwise 和 pairwise 到 listwise，经典模型与优缺点</a></p>
<p>3、<a href="https://cloud.tencent.com/developer/news/135904">基于 Pairwise 和 Listwise 的排序学习</a></p>
</Pairwise></Point>]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>Uplift Modeling</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Uplift%20Modeling/</url>
    <content><![CDATA[<p>Uplift Modeling</p>
<span id="more"></span>
<p>Uplift Modeling</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>增量模型，用于预估某种干预对结果的因果关系（ITE，Individual Treatment Effect），即预测：</p>
<h1 id="基本假设"><a href="#基本假设" class="headerlink" title="基本假设"></a>基本假设</h1>]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning based Recommender System A Survey and New Perspectives</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%5Bcomment%5DDeep%20Learning%20based%20Recommender%20System%20A%20Survey%20and%20New%20Perspectives/</url>
    <content><![CDATA[<p>Deep Learning based Recommender System A Survey and New Perspectives</p>
<span id="more"></span>
<h1 id="【PAPER-COMMENT】Deep-Learning-based-Recommender-System-A-Survey-and-New-Perspectives"><a href="#【PAPER-COMMENT】Deep-Learning-based-Recommender-System-A-Survey-and-New-Perspectives" class="headerlink" title="【PAPER COMMENT】Deep Learning based Recommender System: A Survey and New Perspectives"></a>【PAPER COMMENT】Deep Learning based Recommender System: A Survey and New Perspectives</h1><p>high-profile conferences ： NIPS, ICML, ICLR,KDD,WWW, SIGIR, WSDM, RecSys,<br>[TOC]</p>
<h2 id="2-OVERVIEW-OF-RECOMMENDER-SYSTEMS-AND-DEEP-LEARNING"><a href="#2-OVERVIEW-OF-RECOMMENDER-SYSTEMS-AND-DEEP-LEARNING" class="headerlink" title="2 OVERVIEW OF RECOMMENDER SYSTEMS AND DEEP LEARNING"></a>2 OVERVIEW OF RECOMMENDER SYSTEMS AND DEEP LEARNING</h2><h3 id="2-1-Rrecommendation-System"><a href="#2-1-Rrecommendation-System" class="headerlink" title="2.1 Rrecommendation System"></a>2.1 Rrecommendation System</h3><ul>
<li>recommendation system classification:<ul>
<li>CF(Interaction pnly): learning from user-item historical interactions, including explicit and implicit feedback</li>
<li>Content based: learning from auxiliary information( feature engineering)</li>
<li>Hybrid<h3 id="2-2-Deep-Learning-Techniques"><a href="#2-2-Deep-Learning-Techniques" class="headerlink" title="2.2 Deep Learning Techniques"></a>2.2 Deep Learning Techniques</h3>deep learning: <em>deep representation</em></li>
</ul>
</li>
<li><code>Multilayer Perceptiron(MLP)</code> :多层感知机 learning hierarchical feature representations</li>
<li><code>Autoencoder(AE)</code>: bottleneck  layer (the middle-most layer) is used as a salient feature representation of the input<br>data.</li>
<li><code>CNN</code>:It performs well in processing data with grid-like topology (网络拓扑结构的data)</li>
<li><code>RNN,LSTM, GRU</code></li>
<li><em><code>Restricted Boltzman Machine(RBM)</code></em></li>
<li><code>Adversarial Networks (AN)</code></li>
<li><code>Atentional Models</code></li>
<li><p><code>Deep Reinforcement Learning(DRL)</code>:consists of agents, environments, states, actions and rewards</p>
<h3 id="2-3-Why-DNN-for-Recommendation"><a href="#2-3-Why-DNN-for-Recommendation" class="headerlink" title="2.3 Why DNN for Recommendation"></a>2.3 Why DNN for Recommendation</h3><p>the sequential structure of session or click-logs are highly suitable for the inductive<br>biases provided by recurrent/convolutional models</p>
</li>
<li><p>Conten Bsed: When dealing with textual data (reviews, tweets ), image data (social posts, product images), CNNs/RNNs become indispensable neural building blocks.traditional alternative (designing modality-specific features etc.) becomes significantly less atractive and consequently </p>
</li>
<li>Interaction Only:  deep neural networks are justied when there is a huge amount of complexity or when there is<br><em>a large number of training instances</em> (用SGD的思想优化矩阵分解过程，可使用online数据，也可减少运算量，狭义的深度学习不适合）</li>
<li>ADVANTAGES：Nonlinear Transformation.（非线性拟合能力），Representation Learning（特征提取），Sequence Modelling(序列性特征)，Flexibility.(深度学习框架的模块化开发)<h2 id="3-DEEP-LEARNING-BASED-RECOMMENDATION-STATE-OF-THE-ART"><a href="#3-DEEP-LEARNING-BASED-RECOMMENDATION-STATE-OF-THE-ART" class="headerlink" title="3 DEEP LEARNING BASED RECOMMENDATION: STATE-OF-THE-ART"></a>3 DEEP LEARNING BASED RECOMMENDATION: STATE-OF-THE-ART</h2><h3 id="3-1-Categories-of-deep-learning-based-recommendation-models"><a href="#3-1-Categories-of-deep-learning-based-recommendation-models" class="headerlink" title="3.1 Categories of deep learning based recommendation models"></a>3.1 Categories of deep learning based recommendation models</h3></li>
<li>Recommendation with Neural Building Blocks：<code>MLP, AE, CNNs, RNNs, RBM, NADE,AM, AN and DRL based recommender system</code>。 <em>MLP</em> can easily model the non-linear interactions between users and items; <em>CNNs</em> are capable of extracting local and global representations from heterogeneous data(CNN 可用于异质的特征融合) sources such as textual and visual information; <em>RNNs</em>  enable the recommender system to model the temporal dynamics and sequential evolution of content information</li>
<li>Recommendation with Deep Hybrid Models:</li>
</ul>
<h3 id="3-2-MLP"><a href="#3-2-MLP" class="headerlink" title="3.2 MLP"></a>3.2 MLP</h3><ul>
<li><p><strong>Neural Extension of Traditional Recommendation Methods</strong>：<code>Neural Network Matrix Factorization (NNMF)</code>  and <code>Neural Collaborative Filtering(NCF)</code></p>

</li>
<li><p><strong>Feature Representation Learning with MLP.</strong> </p>
</li>
</ul>

<p><code>wide &amp; deep</code>wide 部分负责memorization，使用人工特征，deep部分负generalization（泛化），使用id特征（用户id，item id）。<a href="https://blog.csdn.net/u010352603/article/details/80590129#22-wide-part">https://blog.csdn.net/u010352603/article/details/80590129#22-wide-part</a></p>
<h3 id="3-3-Auto-encoder"><a href="#3-3-Auto-encoder" class="headerlink" title="3.3 Auto encoder"></a>3.3 Auto encoder</h3>
<h3 id="3-4-CNN"><a href="#3-4-CNN" class="headerlink" title="3.4 CNN"></a>3.4 CNN</h3><p>Tang et al. [143] presented sequential recommendation (with user identier) with CNNs, where two CNNs (hierarchical and vertical) are used to model the union-level sequential paerns and skip behaviors for sequence-aware recommendation</p>
<h3 id="3-5-RNN"><a href="#3-5-RNN" class="headerlink" title="3.5 RNN"></a>3.5 RNN</h3><ul>
<li>Session-Based（基于会话的推荐）<h2 id="4-Future-Rsearch-Directions-and-Open-Issues"><a href="#4-Future-Rsearch-Directions-and-Open-Issues" class="headerlink" title="4 Future Rsearch Directions and Open Issues"></a>4 Future Rsearch Directions and Open Issues</h2><h3 id="4-1-Joint-Representation-Learning-from-User-and-Item-Content-Information"><a href="#4-1-Joint-Representation-Learning-from-User-and-Item-Content-Information" class="headerlink" title="4.1 Joint Representation Learning from User and Item Content Information"></a>4.1 Joint Representation Learning from User and Item Content Information</h3>多种异质性信息的联合学习，如图片，text，side infomation <h3 id="4-2-Explainable-Recommendation-with-Deep-Leadrning"><a href="#4-2-Explainable-Recommendation-with-Deep-Leadrning" class="headerlink" title="4.2 Explainable Recommendation with Deep Leadrning"></a>4.2 Explainable Recommendation with Deep Leadrning</h3></li>
</ul>
<ol>
<li>to ussers: explainable prediction</li>
<li>to practitioner(从业者)： explainable weight<br><code>attention model</code> ： action weights give insights about the inner work of the model.<br>research dirextion:  <code>pre deep learning</code> <h3 id="4-3-Going-Deeper-for-Recommendation"><a href="#4-3-Going-Deeper-for-Recommendation" class="headerlink" title="4.3 Going Deeper for Recommendation"></a>4.3 Going Deeper for Recommendation</h3><h3 id="4-4-Machine-Reasoning-for-Recommendation"><a href="#4-4-Machine-Reasoning-for-Recommendation" class="headerlink" title="4.4 Machine Reasoning for Recommendation"></a>4.4 Machine Reasoning for Recommendation</h3><code>Machine Reasoning</code> 机理学习，通常用于文本和图像理解，很少用于推荐系统。担忧共通点，都是信息检索。interaction-only recommendation 跟<code>reasoning over meta-paths</code>很相似<h3 id="4-5-Cross-Domain-Recommendation-with-Deep-Neural-Networks"><a href="#4-5-Cross-Domain-Recommendation-with-Deep-Neural-Networks" class="headerlink" title="4.5 Cross Domain Recommendation with Deep Neural Networks"></a>4.5 Cross Domain Recommendation with Deep Neural Networks</h3>融合多个场景特征，可解决冷启动<br><code>transfer learning</code><h3 id="4-6-Deep-Multi-Task-Learning-for-Recommendation"><a href="#4-6-Deep-Multi-Task-Learning-for-Recommendation" class="headerlink" title="4.6 Deep Multi-Task Learning for Recommendation"></a>4.6 Deep Multi-Task Learning for Recommendation</h3>优点：<br>(1) learning several tasks at a time can prevent overfing by generalizing the shared hidden representations;减少过拟合，增加泛化<br>(2) auxiliary task provides interpretable output for explaining the recommendation;附加任务可增加可解释信<br>(3) multi-task provides an implicit data augmentation for alleviating the sparsity problem.减轻稀疏问题<h3 id="4-7-Scalability-of-Deep-Neural-Networks-for-Recommendation"><a href="#4-7-Scalability-of-Deep-Neural-Networks-for-Recommendation" class="headerlink" title="4.7 Scalability of Deep Neural Networks for Recommendation"></a>4.7 Scalability of Deep Neural Networks for Recommendation</h3>改进方向：<br>(1) incremental learning for non-stationary and streaming data such as large volume of incoming users<br>and items; 使用流式数据增量训练<br>(2) computation eficiency for high-dimensional tensors and multimedia data sources高维张量的计算效率<br>(3) balancing of the model complexity and scalability with the exponential growth of parameters<br>可能的解决方案：<br>(1) the key idea is to train a <code>smaller student</code> model that absorbs knowledge from the large<code>teacher model</code>.<br>(2) the high-dimensional input data can be compressed to compact embedding to reduce the space and computation time during model learning 压缩或者embedding稀疏编码</li>
</ol>
<h3 id="4-8-The-Field-Needs-Beer-More-Unified-and-Harder-Evaluation"><a href="#4-8-The-Field-Needs-Beer-More-Unified-and-Harder-Evaluation" class="headerlink" title="4.8 The Field Needs Beer, More Unified and Harder Evaluation"></a>4.8 The Field Needs Beer, More Unified and Harder Evaluation</h3><p>学术界没有统一的数据集，没有统一的评价标准，paper结果难以复现</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>Exact-K Recommendation</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%5Bcomment%5DExact-K%20Recommendation/</url>
    <content><![CDATA[<p>Exact-K Recommendation</p>
<span id="more"></span>
<p>Exact-K Recommendation via Maximal Clique Optimization</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><blockquote>
<ol>
<li>传统的top k推荐基于的假设是要把点击概率最高的商品排在前面</li>
<li>exact-K目标是通过排序优化K个商品的联合概率</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>airbnb embedding</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%5Bcomment%5Dairbnb%20embedding/</url>
    <content><![CDATA[<p>[comment]</p>
<span id="more"></span>
<p>Real-time Personalization using Embeddings for Search<br>Ranking at Airbnb</p>
<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><ul>
<li>airbnb是租客与房东双向预测 -&gt; 解决方法：用pair wise的loss（每一对样本有正反馈和负反馈）</li>
</ul>
<h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><h2 id="Listing-Embedding"><a href="#Listing-Embedding" class="headerlink" title="Listing Embedding"></a>Listing Embedding</h2>]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>XGBOOST文献</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%5Bcomment%5DXGBOOST%E6%96%87%E7%8C%AE/</url>
    <content><![CDATA[<p>XGBOOST文献</p>
<span id="more"></span>
<h1 id="XGBOOST文献笔记"><a href="#XGBOOST文献笔记" class="headerlink" title="XGBOOST文献笔记"></a>XGBOOST文献笔记</h1><p><a href="http://delivery.acm.org/10.1145/2940000/2939785/p785-chen.pdf?ip=111.200.23.13&amp;id=2939785&amp;acc=CHORUS&amp;key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;__acm__=1536805596_740dd7db7cc67a94ca9b28d83bd32678">http://delivery.acm.org/10.1145/2940000/2939785/p785-chen.pdf?ip=111.200.23.13&amp;id=2939785&amp;acc=CHORUS&amp;key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;__acm__=1536805596_740dd7db7cc67a94ca9b28d83bd32678</a></p>
<h2 id="决策相关知识点"><a href="#决策相关知识点" class="headerlink" title="决策相关知识点"></a>决策相关知识点</h2><ul>
<li><p>输入特征是连续特征&amp;离散特征</p>
<p>连续特征可直接输入，算法处理时暴力选择改特征划分点 或者按照该特征值的分布选择候选划分点</p>
<p>离散特征要进过one-hot后输入</p>
</li>
<li><p>输出是连续值（回归）&amp;离散值（分类）</p>
<p>回归：损失函数用均方误差</p>
<p>分类：损失函数用基尼值之类的</p>
</li>
<li><p>如何数值计算导数</p>
<p>$\frac{\partial J}{\partial \theta} = \lim_{\varepsilon \to 0} \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon} $</p>
</li>
</ul>
<h1 id="XGBoost-A-Scalable-Tree-Boosting-System"><a href="#XGBoost-A-Scalable-Tree-Boosting-System" class="headerlink" title="XGBoost: A Scalable Tree Boosting System"></a>XGBoost: A Scalable Tree Boosting System</h1><ul>
<li>字母解释</li>
</ul>
<p>$n:样本数 \\  m: 特征维度 \\  K:数的颗数 \\ D: 样本空间 \\ F:cart树空间 \\q:每棵树的结构\\ T：每棵树的叶子 \\ w:叶子权重 $</p>
<h2 id="与gradient-boosting相比改进的地方"><a href="#与gradient-boosting相比改进的地方" class="headerlink" title="与gradient boosting相比改进的地方"></a>与gradient boosting相比改进的地方</h2><blockquote>
<ol>
<li>增加正则项，防止过拟合。类似的方法用在RGF上</li>
<li>算每一颗数的loss时用$L_{t}=L_{t-1}+\Delta L\\  $，$\Delta L用L对\hat{y}_{t}$的二阶泰勒展开代替</li>
<li>优化时逐棵树优化，每棵树只在上一棵树的基础上分裂一次</li>
<li>叶子节点分裂时先对样本进行排序，分箱，再按分箱值进行分裂并筛选合适的分裂值。这样一方面能减少运算量，一方面可减轻过拟合, 为了保证每个分箱产生的loss均一，用残差的二阶导作为分箱依据（Weighted Quantile）</li>
</ol>
</blockquote>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>$\hat{y_i}=\sum_{i=1}^{K}w_i$</p>

<p>当正则项为0时，目标函数就跟传统的gradient tree boosting一样</p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>低t轮迭代时（第t棵树），对于第i个样本，用一阶倒数近似就是$y_i^{t}=y_i^{t-1}+f_t(x_i)$，损失函数就是</p>

<p>第二棵树开始，每棵树预测残差</p>



<p>只要确定了树结构，二阶近似有以上的最优解。但实际上无法确定树结构，即无法全局优化，所以采用贪婪地逐个叶子优化：</p>

<p>其中$L_{split}$是一个节点分裂前的loss-分裂后的loss，$L_{split}$越大越好</p>
<h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3>

<p>解读：</p>
<p>首先对将全量样本分别按照各个特征排序，分箱（百分位数），箱值即为之后树分裂会用到的值；</p>
<p>假设前一颗数有两个叶子节点，生成第三棵树时：</p>
<ol>
<li>对第一个叶子节点上的sample<ol>
<li>计算各个分箱值时score，取使得score最大的分箱值</li>
<li>同样的方法遍历所有特征，得到各个特征在第一个节点上的最佳分裂值及score</li>
<li>选择score最大的特征及对应分分裂值</li>
</ol>
</li>
<li>同样的方式得到第二个叶子节点上的sample最佳分裂特征和分裂值</li>
<li>比较score，选择score最大的节点及特征及分裂值</li>
</ol>
<blockquote>
<p>分箱方法有两个：global variant 和 local variant</p>
<p>global variant是全局分箱，计算量少，但需要数据量大，分箱粒度大，不适合太深的树</p>
<p>local variant是每个叶子节点上的数据进行分箱</p>
</blockquote>
<h2 id="weighted-quantile"><a href="#weighted-quantile" class="headerlink" title="weighted quantile"></a>weighted quantile</h2>
<p>解读：</p>
<p>不是按特征值大小排序，按百分位分箱，而是构造特征排序函数r，其中h是残差在特征x上的二阶导。</p>
<p>推导：</p>

<p>loss函数$\sum_{i=1}^n=\sum_{k=1}^k\sum_{i\in z_j}\frac{h_i}{2}（f_t-\frac{g_i}{h_i}）+  ….$</p>
<p>rankz函数$r_k$的构造可以保证每个分箱上的loss的高阶系数是均一的，这样能加速优化</p>
<h2 id="Sparsity-aware-Split-Finding-空值"><a href="#Sparsity-aware-Split-Finding-空值" class="headerlink" title="Sparsity-aware Split Finding(空值)"></a>Sparsity-aware Split Finding(空值)</h2><p>处理每一个分支时默认空值朝左或者朝右，找到最合适的方向</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>silk_road</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%5Bcomment%5Dsilk_road/</url>
    <content><![CDATA[<p>silk_road</p>
<span id="more"></span>
<h1 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h1><p>基于购买行为的information domain 和 基于社交关系的 social domain联合推荐，最终实现对social domain中的用户进行item预</p>
<p>特点：</p>
<ol>
<li><p>info domain中用pooling的办法把交互特征和side information 融合在一起；</p>
<ol>
<li>bridge 用户很少；</li>
<li>两个网络时异质的</li>
</ol>
</li>
</ol>
<h2 id="名词解释："><a href="#名词解释：" class="headerlink" title="名词解释："></a>名词解释：</h2>
<h3 id="info-domain"><a href="#info-domain" class="headerlink" title="info-domain"></a>info-domain</h3><p>包括有交互特征$Y$和side info $G$ 。用户的G指的是一些tag标签，如喜欢自然，喜欢欧洲，一共有$v_u$个tag。item的G指的是item的一些标签（与用户标签对应的），如自然，欧洲，一共有$v_i$ 个tag。</p>
<script type="math/tex; mode=display">
\begin{split}
User_1&:&U_1&={\{u_t}\}_{t=1}^{M_1}  \\
Item_1&:&I_1&=\{i_t\}_{t=1}^{m}  \\
Interaction&:&Y&=\{y_{ij}\} \\
Arttibute&:& \\
&&G_u&=\{g_1^u,g_2^u\quad ...\quad g_{v_u}^u\} \\
&&G_i&=\{g_1^i,g_1^i \quad ... \quad g_{v_i}^i\}
\end{split}</script><h3 id="social-domain"><a href="#social-domain" class="headerlink" title="social-domain"></a>social-domain</h3><script type="math/tex; mode=display">
User_2:U_2=\{u_t^{'}\}_{t=1}^{M_2} \\
Interaction: S=\{s_{u{'},u^{''}}\}</script><h1 id="Solution-NSCR"><a href="#Solution-NSCR" class="headerlink" title="Solution: NSCR"></a>Solution: NSCR</h1><p>Neural Social Collaborative Ranking (NSCR)</p>
<h2 id="info-domain-1"><a href="#info-domain-1" class="headerlink" title="info-domain"></a>info-domain</h2>
<h3 id="pairwise-pooling"><a href="#pairwise-pooling" class="headerlink" title="pairwise pooling"></a>pairwise pooling</h3>

<h3 id="pairwise-loss"><a href="#pairwise-loss" class="headerlink" title="pairwise loss"></a>pairwise loss</h3>
<p>其中$y_{u,i}=1,t_{u,j}=0$</p>

<h3 id="forward-propagation"><a href="#forward-propagation" class="headerlink" title="forward propagation"></a>forward propagation</h3>
<p>prediction:</p>

<h2 id="social-domain-1"><a href="#social-domain-1" class="headerlink" title="social-domain"></a>social-domain</h2><p>两个约束作为loss：</p>
<h3 id="平滑约束（smothness）"><a href="#平滑约束（smothness）" class="headerlink" title="平滑约束（smothness）"></a>平滑约束（smothness）</h3>
<p>$s_{u^{‘’},u^{‘’}} 越大，p_{u^{‘}},p_{u^{‘’}}就$</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>【专题调研】搜广推中的context处理</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E3%80%90%E4%B8%93%E9%A2%98%E8%B0%83%E7%A0%94%E3%80%91%E6%90%9C%E5%B9%BF%E6%8E%A8%E4%B8%AD%E7%9A%84context%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<p>搜广推领域文献阅读，文献整理来源于git仓库  <a href="https://github.com/TessieHe/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising">Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</a></p>
<p>【to粗】表示待粗读</p>
<p>【粗】表示已粗读</p>
<p>【to精】表示待精读</p>
<p>【精】表示已精读</p>
<p>没有标注表示还没看</p>
<span id="more"></span>]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
        <tag>Learning to Rank</tag>
        <tag>Multi-Scenario</tag>
        <tag>Intent Recommendation</tag>
        <tag>Recommender System</tag>
        <tag>E-commerce</tag>
      </tags>
  </entry>
  <entry>
    <title>中文分词</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/</url>
    <content><![CDATA[<p>中文分词</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="jieba分词"><a href="#jieba分词" class="headerlink" title="jieba分词"></a>jieba分词</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_corpus</span>(<span class="params">f_corpus</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param f_corpus: txt</span></span><br><span class="line"><span class="string">    :return: list</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(f_corpus, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;f_corpus lines: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(lines)))</span><br><span class="line">    <span class="built_in">print</span>(lines[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> lines</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stopwords</span>(<span class="params">f_stopwords</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param f_stopwords: txt</span></span><br><span class="line"><span class="string">    :return: list</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(f_stopwords, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        stopwords = f.readlines()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;stop words lines: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(stopwords)))</span><br><span class="line">    <span class="keyword">return</span> stopwords</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_keyword_dict</span>(<span class="params">filename</span>):</span></span><br><span class="line">    <span class="built_in">dict</span> = &#123;&#125;</span><br><span class="line">    keys = []</span><br><span class="line">    num=<span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        line = f.readline()</span><br><span class="line">        <span class="keyword">while</span> line :</span><br><span class="line">            num +=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> num % <span class="number">10000</span> ==<span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;line &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(num))</span><br><span class="line">            word = line.strip()</span><br><span class="line">            word = get_keyword(word).strip(<span class="string">&#x27;【&#x27;</span>).strip(<span class="string">&#x27;】&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> keys:</span><br><span class="line">                keys.append(word)</span><br><span class="line">                <span class="built_in">dict</span>[word] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">dict</span>[word] += <span class="number">1</span></span><br><span class="line">            line = f.readline()</span><br><span class="line">    <span class="built_in">dict</span> = <span class="built_in">sorted</span>(<span class="built_in">dict</span>.items(),key=<span class="keyword">lambda</span> s:s[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">dict</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main_count</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    统计词频</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    f_corpus = <span class="string">&#x27;part1.txt&#x27;</span></span><br><span class="line">    f_stopwords = <span class="string">&#x27;stopwords.txt&#x27;</span></span><br><span class="line">    f_count_words = <span class="string">&#x27;wordsCount_part1.txt&#x27;</span></span><br><span class="line">    corpus=get_corpus(f_corpus) <span class="comment">#list</span></span><br><span class="line">    stopwords=get_stopwords(f_stopwords) <span class="comment">#list</span></span><br><span class="line">    word_dic=count_word(corpus,stopwords) <span class="comment">#list</span></span><br><span class="line">    <span class="built_in">print</span> (word_dic)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(f_count_words):</span><br><span class="line">        os.system(<span class="string">r&quot;touch &#123;&#125;&quot;</span>.<span class="built_in">format</span>(f_count_words))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(f_count_words,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> word_dic:</span><br><span class="line">            res = i[<span class="number">0</span>].strip()+<span class="string">&#x27;\t&#x27;</span>+<span class="built_in">str</span>(i[<span class="number">1</span>])</span><br><span class="line">            f.write(res+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;done!&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>吴恩达卷积神经网络笔记</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>吴恩达卷积神经网络笔记</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="第一周-卷积神经网络"><a href="#第一周-卷积神经网络" class="headerlink" title="第一周 卷积神经网络"></a>第一周 卷积神经网络</h1><h2 id="计算及视觉要解决的问题"><a href="#计算及视觉要解决的问题" class="headerlink" title="计算及视觉要解决的问题"></a>计算及视觉要解决的问题</h2><ul>
<li>Image Classification</li>
<li>Object detection<h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2></li>
<li>图像计算数据量非常大</li>
<li>所以需要通过卷积减少参数量</li>
</ul>
<h2 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h2><ul>
<li>valid padding: 不填充</li>
<li>same padding：输出和输入一样的size。步长为1时 p=(f-1)/2 ,f为卷积核的大小</li>
</ul>
<h2 id="stride（步长）"><a href="#stride（步长）" class="headerlink" title="stride（步长）"></a>stride（步长）</h2><ul>
<li>输出图像大小：floor[(n+2p-f)/s]+1<h2 id="多通道卷积"><a href="#多通道卷积" class="headerlink" title="多通道卷积"></a>多通道卷积</h2></li>
<li>卷积核的通道数=输入的通道数</li>
<li>一个卷积核将输入映射为单通道图片</li>
<li>卷积核的数量=输出图片的通道数</li>
<li>每个卷积核的bias是一个数<h2 id="pooling-池化"><a href="#pooling-池化" class="headerlink" title="pooling(池化)"></a>pooling(池化)</h2></li>
<li>max pooling: 只要过滤器检测到了特征，就保留下来<ul>
<li>输出的size和padding计算方法一致</li>
<li>pooling前后通道数目不变（跟卷积核不一样的地方）</li>
<li>没有参数需要学习<h2 id="使用卷积的意义"><a href="#使用卷积的意义" class="headerlink" title="使用卷积的意义"></a>使用卷积的意义</h2></li>
</ul>
</li>
<li>参数共享(parameter sharing):<ul>
<li>卷积核(过滤器)可通用语图片的各个位置</li>
</ul>
</li>
<li>稀疏连接(sparsity of connections)<ul>
<li>卷积后的图片每个像素点只与输入中卷集合大小的像素点有关，与其他像素点无关。这保证图片有平移不变性，即原始图片平移几个像素不太会导致结果的变化</li>
</ul>
</li>
</ul>
<h1 id="第二周-深度卷积网络：实例探究"><a href="#第二周-深度卷积网络：实例探究" class="headerlink" title="第二周 深度卷积网络：实例探究"></a>第二周 深度卷积网络：实例探究</h1><h2 id="经典网络"><a href="#经典网络" class="headerlink" title="经典网络"></a>经典网络</h2><ul>
<li>LeNet-5 (1998)</li>
<li>AlexNet</li>
<li>VGG</li>
<li>ResNet</li>
<li>Inception</li>
</ul>
<h2 id="LeNet-5-（1998）"><a href="#LeNet-5-（1998）" class="headerlink" title="LeNet-5 （1998）"></a>LeNet-5 （1998）</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-11 下午3.00.23.png" alt="屏幕快照 2019-11-11 下午3.00.23"></p>
<p>6w 参数</p>
<h2 id="AlexNet（2012）"><a href="#AlexNet（2012）" class="headerlink" title="AlexNet（2012）"></a>AlexNet（2012）</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-11 下午8.11.06.png" alt></p>
<p>6kw 参数</p>
<h2 id="VGG-2015"><a href="#VGG-2015" class="headerlink" title="VGG(2015)"></a>VGG(2015)</h2><p>用同样大小的卷积核（3*3 ， s=1, padding=same），同样的池化策略</p>
<h2 id="ResNet-2015"><a href="#ResNet-2015" class="headerlink" title="ResNet(2015)"></a>ResNet(2015)</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-11 下午8.20.45.png" alt="屏幕快照 2019-11-11 下午8.20.45"></p>
<p>随着层数增加，理论上来说损失会减少，但是实际上随着层数增加，对优化算法的要求越高，导致损失上升。</p>
<p>ResNet: $a_{l+1}=g(z(l+1)+a_l)$</p>
<h2 id="1-1卷积核"><a href="#1-1卷积核" class="headerlink" title="1*1卷积核"></a>1*1卷积核</h2><p>输入图片用1个1*1的卷积核座卷积意义是：输入图片各个通道加权成一个通道</p>
<h2 id="Inception-Network-2014"><a href="#Inception-Network-2014" class="headerlink" title="Inception Network(2014)"></a>Inception Network(2014)</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-11 下午8.40.29.png" alt="屏幕快照 2019-11-11 下午8.40.29"></p>
<h2 id="迁移学习-transfer-learning"><a href="#迁移学习-transfer-learning" class="headerlink" title="迁移学习 transfer learning"></a>迁移学习 transfer learning</h2><p>冻结前面几层，只训练最后一层全连接层。实现方案之一为：输入通过冻结的几层得到预计算输出，写入硬盘。之后每次从硬盘读入数据，训练最后几层网络，这样不需要每次迭代时都进行前面的计算。</p>
<p>或者只把下载的权重作为初始化，训练整个网络。</p>
<h2 id="数据扩充-data-augmentation"><a href="#数据扩充-data-augmentation" class="headerlink" title="数据扩充 data augmentation"></a>数据扩充 data augmentation</h2><p>当数据量不够时。</p>
<ul>
<li>镜像对称</li>
<li>随机剪裁</li>
<li>色彩转换 color shifting(PCA增强)</li>
</ul>
<h2 id="计算机视觉现状"><a href="#计算机视觉现状" class="headerlink" title="计算机视觉现状"></a>计算机视觉现状</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-11 下午8.56.18.png" alt="屏幕快照 2019-11-11 下午8.56.18"></p>
<p>数据量越少，人工特征提取越重要。</p>
<h1 id="第三周-目标检测"><a href="#第三周-目标检测" class="headerlink" title="第三周 目标检测"></a>第三周 目标检测</h1><h2 id="目标定位-localization-and-detection"><a href="#目标定位-localization-and-detection" class="headerlink" title="目标定位 localization and detection"></a>目标定位 localization and detection</h2><p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E5%90%B4%E6%81%A9%E8%BE%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/屏幕快照 2019-11-12 下午6.32.06.png" alt="屏幕快照 2019-11-12 下午6.32.06"></p>
<ul>
<li><p>目标定位：图片中只有一个目标，要定位目标并识别目标。</p>
<p> 实现方法：输出除了类别向量外还有四个数：中心点x,y值，box长度，box高度</p>
</li>
<li><p>定义Y</p>
<p> 假设检测目标有三种，图片中最多只会有一个目标物体，则y为：</p>
<script type="math/tex; mode=display">\left[\begin{matrix}p_c\\b_x\\b_y\\b_h\\b_w\\c_1\\c_2\\c_3\end{matrix}\right]</script><p> 其中如果图片中有三种中的一种，则$p_c=1 $，$c_1,c_2,c_3$为对应的onehot向量。如果图片中没有目标种类的则$p_c=0$,其他数字为任意值</p>
</li>
<li><p>loss</p>
<script type="math/tex; mode=display">loss=\left\{\begin{matrix} \sum_{i=1}^8(y_i-\hat{y_i})^2,\quad if  \quad p_c=1\\ (y_i-\hat{y_i})^2,\quad else \end{matrix}\right.</script><p> 即如果图片中有目标物体，则loss包含每个y的分量误差。如果没有，则loss只计算$p_c$和预测值的误差。实际上y不同的部分可采用不同的误差，如$p_c$用logistic误差，b用均方误差，c用softmax误差</p>
</li>
</ul>
<h2 id="特征点检测"><a href="#特征点检测" class="headerlink" title="特征点检测"></a>特征点检测</h2><p>在图片分类的基础上做改造：y第一个元素实$p_c$,其他元素实特征点的坐标值。</p>
<p>体态检测也是一样，只不过特征点是关节点的坐标。要注意的实特征点的顺序需要是一致的。</p>
<h2 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h2><ul>
<li><p>滑动窗口 sliding window detection</p>
<ol>
<li>针对被检测物体（如车）训练图片分类网络</li>
<li><p>用不同大小的box扫过目标图片，并输出相应位置的概率</p>
<p>计算成本很大</p>
</li>
</ol>
</li>
</ul>
<h2 id="卷积的滑动窗口实现"><a href="#卷积的滑动窗口实现" class="headerlink" title="卷积的滑动窗口实现"></a>卷积的滑动窗口实现</h2><ul>
<li><p>FC层可用卷积实现，具体操作就是卷积核大小与输入相同，卷积核数量与FC的输出层相同。这种卷积表示与全连接的数学实现是一样的</p>
</li>
<li><p>将滑动窗口并卷积得到不同box的预测值—&gt;将整张图片进行卷积，最后输出的就是哥哥box对应的概率</p>
</li>
<li><p>问题：该方法隐式的预测bounding box的位置，结果不是很准确</p>
<p> 由于box的size是一定的（卷积网络的第一层卷积核大小），移动步长也是一定的(卷积网络的移动步长)</p>
</li>
</ul>
<h2 id="bounding-box预测"><a href="#bounding-box预测" class="headerlink" title="bounding box预测"></a>bounding box预测</h2><ul>
<li><p>YOLO (you only look once) 2015</p>
<p> 将问题简化为子图上的目标定位问题</p>
<ol>
<li>将图片分割，假设分割成3*3的小图</li>
<li>按照目标定位的方法对每个小图标定8维向量y，由于有9个小图，最终Y为3<em>3 </em> 8 的矢量</li>
<li>按照一般的方法进行训练。</li>
<li><p>预测时看每$\hat{Y}$的第一个分量，为1的地方就表示对应的子图有目标物体，对应的$b_i$即为box位置, 对应的$c_i$就是目标物体的种类</p>
<p>注意：</p>
</li>
<li><p>标定物体的时候如果物体横跨多个子图，物体只会被分配到一个图上。</p>
</li>
<li>标定$b_i$的时候用的是子图的相对比例坐标。$b_x,b_y$一定小于等于1，$b_x,b_y$可以大于1</li>
</ol>
</li>
<li><p>好处：</p>
<ol>
<li>bounding box大小和位置不受限制</li>
<li>只进行单词卷积，而非滑动多次卷积。这是由于滑动卷积过程中有很多计算实可以共享的</li>
</ol>
</li>
</ul>
<h2 id="交并比-intersection-over-union"><a href="#交并比-intersection-over-union" class="headerlink" title="交并比 intersection over union"></a>交并比 intersection over union</h2><p>用来评价目标检测模型好坏。</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>搜广推技术调研</title>
    <url>/2022/03/04/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%90%9C%E5%B9%BF%E6%8E%A8%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<p>开始前的一些思考：</p>
<p>搜广推近年来模型越来越复杂，但收益越来越小，可能原因是什么？</p>
<ol>
<li>技术水位提高带来的边际收益的降低</li>
<li>数据处理时的的信息折损。从原始log数据生成各个场景的数据（序列、特征）过程是存在很大的信息折损的，原始数据的信息量是最大的，所以未来的发展模型的输入数据会想原始的方式靠拢。纵观搜广推的技术发展路线，从特征工程到序列建模也是符合这个思路的。</li>
<li>模型结构和信息传播方式不匹配，导致信息提取的低效。也就是说应该根据业务特征更精巧的设计模型结构，依照先验显式的提取数据中的一些结构化信息，提高信息提取效率，而不是粗暴的加参数加数据。</li>
</ol>
<p>第一点确实存在，预估没有ground truth，难以判断天花板在哪。2和3中更偏向于2，因为数据直接决定了模型的天花板，而近年大量paper都是模型方面的工作，数据端的工作是比较被忽视的。</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="技术调研"><a href="#技术调研" class="headerlink" title="技术调研"></a>技术调研</h1><h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>深度学习的赋能下，推荐领域主要有<strong>特征交叉、序列建模</strong>两个技术方向，特征交叉以CAN为代表交叉粒度越来越细，向笛卡尔积靠拢。序列建模以阿里的一些列工作为代表，主要有<strong>序列增强</strong>和<strong>模糊序列</strong>两个方向。NLP技术的赋能下越来越多的序列模型落地在推荐领域，受到业界的认可。我们不禁要问，Then what’s next?</p>
<p>可以参考CV和NLP的发展，各自领域的重大突破都是基于<strong>对数据产生过程的深刻理解</strong>的。CNN捕捉的是图像的平移不变性；bert捕捉的是上下文的交互特点。</p>
<p>搜索和推荐不同于NLP和CV这些”自然”的数据生成方式，而是人类交互行为产生的数据。这天然决定了数据中存在大量噪音（隐反馈，bias），例如：一个用户点了一个品牌不一定是他就偏好这个品牌，有可能是整个页面都是这个品牌；推荐item同质的场景下点不点击很随机。历史的工作更多的是粗暴的通过大幅度增加数据量，增加模型复杂度来进行低效的<strong>交互和去噪</strong>（基于的假设是噪音数据出现的频率远低于非噪音数据）。业务初期这种方式能快速迭代产生效果，但随着技术水位的提高，这条路边际收益越来越低，需要考虑更高效的数据处理和信息提取形式。推荐场景序列建模是一个比较大的突破，符合用户时间维度的行为模式，一定程度刻画了用户的偏好。</p>
<p>纵观推荐技术演化方向，我认为未来会<strong>由深度加工数据向原始数据形式（用户反馈数据流）靠拢，更“自然”的融合用户多域/多形式的反馈，且更“柔和”的处理用户的反馈</strong>（而不是非黑即白，如点击就是感兴趣，不点击就是不感兴趣）</p>
<p><img src alt="draw.io"></p>
<h2 id="近期工作"><a href="#近期工作" class="headerlink" title="近期工作"></a>近期工作</h2><div class="table-container">
<table>
<thead>
<tr>
<th>出处</th>
<th>要解决的问题</th>
<th>关键词</th>
<th>借鉴点</th>
<th>模型结构</th>
<th>comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>阿里GIN：Graph Intention Network for Click-through Rate Prediction in Sponsored Search，SIGIR19,alibaba</td>
<td>CTR预估中用户行为稀疏; 跳出用户历史行为的限制探索更多的兴趣</td>
<td>信息嵌入</td>
<td>graph&amp;ctr端到端训练可以通过引入各种共现信息来提高信息的流动性</td>
<td><img src alt="image.jpeg"><img src alt="image.jpeg"></td>
<td>共现信息生成异构图对用户点击序列的每个item进行邻近节点查找和embed聚合</td>
</tr>
<tr>
<td>阿里Res-embedding for Deep Learning Based Click-Through Rate Prediction Modeling，2019</td>
<td>现有embedding方式容易产生过拟合。</td>
<td>信息嵌入</td>
<td>1、 每个POI的embedding是不是可以表征为区域embedding和独立embedding的和？？</td>
<td><img src alt="image.jpeg"></td>
<td>用图中相邻节点的central embedding + 当前item的bias embedding来表征当前item，提高泛化性。\</td>
<td>\</td>
<td>bias embed\</td>
<td>\</td>
<td>= 0.1*\</td>
<td>\</td>
<td>central embed时效果最好\</td>
<td>\</td>
<td>量化分析了影响模型泛化能力的变量是GIN的升级版，GIN相当于只用centra embedding</td>
</tr>
<tr>
<td>第四范式TabGNN: Multiplex Graph Neural Network for Tabular Data Prediction,KDD2021,</td>
<td>通过多重图来建模样本间关系</td>
<td>信息嵌入</td>
<td>样本间的关系可以通过图的方式构建图除了通过共现方式构建，也可以通过特征的方式构建（适用于分客群之类的场景）</td>
<td><img src alt="image.jpeg"></td>
<td>对于表格特征通过离散化构建多重图。可以理解为每一维特征都可以生成一个 graph layer</td>
</tr>
<tr>
<td>阿里DSGL:Dynamic Sequential Graph Learning for Click-Through Rate Prediction ,2021,aliba,</td>
<td>用户行为序列受曝光影响动态序列图捕捉用户兴趣变化</td>
<td>信息嵌入</td>
<td></td>
<td><img src alt="image.jpeg"></td>
<td>1、 图中带时间戳，捕捉时间维度的兴趣变化</td>
</tr>
<tr>
<td>阿里CAN: Feature Co-Action for Click-Through Rate Prediction</td>
<td>attention等特征交叉方式都是在embed空间的隐式交叉，共现关系不如cartesian方法，但后者参数量太大</td>
<td>信息融合</td>
<td></td>
<td><img src alt="image.jpeg"></td>
<td>提出一种显示的特征交叉，加入特征笛卡尔积信息，又不会增加太多参数量。用户历史点击过的item的embedding在不同的candidate下有不同的值其实是DIN中attention unit变换成co-action unit，由相似度计算变成了融合的MLP。FM可以看成co-action unit的一种特殊形式。</td>
</tr>
<tr>
<td>新浪FiBiNet ：Feature Importance and Bilinear feature Interaction</td>
<td>提出通过使用SENET结构动态学习特征的重要性使用双线性函数来更好的建模交叉特征</td>
<td>信息嵌入</td>
<td>可通增加embed通道并通过SENET融合各通道。</td>
<td><img src alt="image.jpeg"><img src alt="image.jpeg"></td>
<td>结构动态学习特征的重要性以及使用一个双线性函数来更好的建模交叉特征</td>
</tr>
<tr>
<td>腾讯Masked Transformer for Neighhourhood-aware Click-Through Rate Prediction</td>
<td>主流的CTR模型都是通过用户显示交互的item学习特征的交互和用户兴趣。然而交互行为受推荐系统曝光、用户活跃度限制，简而言之就是信息量不够。通过构建异构图引入邻接节点信息增强信息表征</td>
<td></td>
<td></td>
<td><img src alt="image.jpeg"></td>
<td>本质上还是通过图的方式引入邻域信息。mask不mask的感觉不重要</td>
</tr>
<tr>
<td>阿里RACP:Modeling Users’ Contextualized Page-wise Feedback for Click-Through Rate Prediction in E-commerce Search</td>
<td>本文通过加入历史<strong>页面维度的曝光和反馈</strong>做一位用户历史行为序列，提出了一种新的上下文感知的用户行为建模方式。。通过<strong>page-context aware attention</strong> 学习页面内的关系。<strong>recurrent attention</strong>学习页面间的关系</td>
<td></td>
<td></td>
<td><img src alt="image.jpeg"></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
        <tag>调研</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐模型中的负反馈处理</title>
    <url>/2022/04/27/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%B4%9F%E5%8F%8D%E9%A6%88%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<p>用户行为可以按照置信度分为显示反馈和隐式反馈，显示反馈是能直接反映用户对于item的偏好的信息（如评分、点赞）；隐式反馈则是间接的暗示了用户的偏好（如点击、不点击）。</p>
<p>目前大多数搜索推荐算法只关注正反馈（点击、加购、下单等），忽略了用户其他丰富的隐式负反馈，这回存在3个问题：</p>
<p>1.仅知道用户喜欢什么，而不知道用户不喜欢什么，这会导致模型的短视（myopic）</p>
<p>2.用户需要和推荐系统有高效的互动机制，而不是被动接受模型的结果。</p>
<p>3.用户的隐反馈存在大量噪音。</p>
<p>用户的各种反馈相辅相成，共同表征了其无偏兴趣。</p>
<p>本文列举了负反馈相关的业界工作，包括XDM(2022,阿里)，DFN(2020,腾讯),FeedRec(2022,阿里）<br><span id="more"></span></p>
<h3 id="2020-IJCAI-Tencent-DFN-—-可借鉴强信息序列对弱信息序列的增强"><a href="#2020-IJCAI-Tencent-DFN-—-可借鉴强信息序列对弱信息序列的增强" class="headerlink" title="2020(IJCAI)(Tencent)[DFN]—-可借鉴强信息序列对弱信息序列的增强"></a>2020(IJCAI)(Tencent)[DFN]—-可借鉴强信息序列对弱信息序列的增强</h3><p> Xie R, Ling C, Wang Y, Wang R, Xia F, Lin L. Deep Feedback Network for Recommendation. In: <em>Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence</em>. International Joint Conferences on Artificial Intelligence Organization; 2020:2519-2525. doi:<a href="https://doi.org/10.24963/ijcai.2020/349">10.24963/ijcai.2020/349</a></p>
<p><strong>代码链接</strong>：<a href="https://github.com/qqxiaochongqq/DFN">https://github.com/qqxiaochongqq/DFN</a></p>
<p><strong>简介</strong>：用户的显式、隐式反馈都反映了其兴趣偏好。但是目前大多数推荐模型都只利用了用户的隐式正反馈（点击）。本文综合利用用户的[显式，隐式]×[正反馈，负反馈]联合建模用户的<strong>无偏兴趣</strong>（unbiased preference）。</p>
<p><img src="/2022/04/27/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%B4%9F%E5%8F%8D%E9%A6%88%E5%A4%84%E7%90%86/image-20220427153641627.png" alt="image-20220427153641627" style="zoom:50%;"></p>
<p><strong>总结</strong>：微信头条（WeChat Top Stories ）的精排模型。用点击、曝光未点击、不喜欢三个序列，序列内部用transformer编码，<strong>序列间用点击和不喜欢两个序列对曝光未点击序列进行增强和过滤</strong>，优化目标中预估点击、曝光未点击、不喜欢三种行为。实验时仅用了微信自己的数据集。</p>
<h3 id="2022-Alibaba-XDM"><a href="#2022-Alibaba-XDM" class="headerlink" title="2022(Alibaba)[XDM]"></a>2022(Alibaba)[XDM]</h3><p>Lv, F.; Li, M.; Guo, T.; Yu, C.; Sun, F.; Jin, T.; Ng, W. XDM: Improving Sequential Deep Matching with Unclicked User Behaviors for Recommender System. <em>arXiv:2010.12837 [cs]</em> <strong>2022</strong>.</p>
<p><strong>简介</strong>：阿里向量召回模型。核心思想就是通过三元损失使得点击序列的向量表示远离未点击序列的向量表示；点击序列向量靠近点击label item向量；未点击序列向量靠近未点击label item向量。</p>
<p>TIPS:</p>
<ul>
<li><p>曝光未点击的item并非是用户完全不感兴趣的，只是相对于点击不感兴趣的。相对于随件的item来说还是用户感兴趣的（因为推荐系统只会展示用户感兴趣的item）。所以曝光未点击可以看做是用户感兴趣和不感兴趣之间的一种中间态。</p>
</li>
<li><p>序列是历史点击序列和历史曝光未点击序列，标签是t时刻后k次点击（只有正样本）</p>
</li>
<li><p>对称三元损失（symmetrical triplet constraint ）: 三元包括历史点击和标签的距离（e_hc）,历史点击和历史未点击（e_hn）,历史未点击和标签（e_nc）。核心思想就是e_hc要近，e_hn和e_nc要远。三元损失就是e_hn &gt; e_hc+m1 ,e_nc &gt; e_hc + m2。</p>
<p><img src="/2022/04/27/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%B4%9F%E5%8F%8D%E9%A6%88%E5%A4%84%E7%90%86/image-20220427194105718.png" alt="image-20220427194105718" style="zoom:50%;"></p>
</li>
</ul>
<h3 id="2022-WWW-Alibaba-FeedRec"><a href="#2022-WWW-Alibaba-FeedRec" class="headerlink" title="2022(WWW)(Alibaba)[FeedRec]"></a>2022(WWW)(Alibaba)[FeedRec]</h3><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://zhuanlan.zhihu.com/p/394751885">知乎：推荐系统 用户序列行为建模</a></p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>算法相关</tag>
        <tag>Recommender System</tag>
        <tag>E-commerce</tag>
        <tag>Implicit Feedback</tag>
        <tag>Negative Feedback</tag>
      </tags>
  </entry>
  <entry>
    <title>2022[STOSA](WWW)(spotity)</title>
    <url>/2022/05/20/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%96%87%E7%8C%AE%E7%AC%94%E8%AE%B0%E6%A8%A1%E6%9D%BF/</url>
    <content><![CDATA[<p>(1) Fan, Z.; Liu, Z.; Wang, A.; Nazari, Z.; Zheng, L.; Peng, H.; Yu, P. S. Sequential Recommendation via Stochastic Self-Attention. <em>arXiv:2201.06035 [cs]</em> <strong>2022</strong>.</p>
<p><strong>简介</strong>：….</p>
<span id="more"></span>
<h3 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h3><p><strong>动机</strong></p>
<p><strong>解法</strong></p>
<p><strong>评论</strong></p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><ul>
<li><p>dif- ferent from dot product, distances typically satisfy triangle inequal- ity1, which transits additional collaborative closeness and benefits a lot in item cold start issue.</p>
<p>用距离代替点击能缓解协同传递性问题，因为距离满足三角不等式。这在冷启动场景有为有用</p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>用户行为建模</tag>
        <tag>表示学习</tag>
        <tag>不确定性建模</tag>
        <tag>度量学习</tag>
      </tags>
  </entry>
  <entry>
    <title>时间序列模型</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>时间序列模型</p>
<span id="more"></span>
<hr>
<h2 id="typora-copy-images-to-image"><a href="#typora-copy-images-to-image" class="headerlink" title="typora-copy-images-to: ./image"></a>typora-copy-images-to: ./image</h2><h1 id="时间序列模型"><a href="#时间序列模型" class="headerlink" title="时间序列模型"></a>时间序列模型</h1><h2 id="WEEK1"><a href="#WEEK1" class="headerlink" title="WEEK1"></a>WEEK1</h2><ul>
<li><p>符号解释</p>
<p>$x^{(i)<t>}$:  第i个样本的第t维分量</t></p>
<p>$T_x^{(i)}$ : 第i个样本x的维度</p>
</li>
<li><p>主体抓取</p>
<ol>
<li><p>多对多模型</p>
</li>
<li><p>不能用全连接，因为输入和输出的长度不定，而且输入矩阵太大</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/E36DF04F-C0BD-42D3-9A0D-CA2F2B1C7DE9.png" alt="E36DF04F-C0BD-42D3-9A0D-CA2F2B1C7DE9"></p>
</li>
</ol>
</li>
</ul>
<p>$a^{<0>} = \vec{0}$</0></p>
<p>$a^{<1>} = g(W_{aa}a^{<0>} +W_{ax}x^{<1>} +b_a)$</1></0></1></p>
<p>$\hat{y}^{<1>} = g(W_{ya}a^{<1>}+b_y)$</1></1></p>
<ul>
<li>Forward propagation</li>
</ul>
<p>$a^{<t>} = g(W_{aa}a^{<t-1>} +W_{ax}x^{<t-1>}+b_a)$</t-1></t-1></t></p>
<p>$\hat{y^{<t>}} = g(W_{ya}a^{<t>}+b_y)$</t></t></p>
<p>为了简化模型，可把$W_{ax},W_{aa}$横向排列成为$W_a$，$a^{<t-1>},x^{t}$纵向排列</t-1></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/D71818E3-4031-4EF4-99F4-BD47FC6BD0C5.png" alt="D71818E3-4031-4EF4-99F4-BD47FC6BD0C5"></p>
<ul>
<li><p>Back propagation</p>
<p>$L^{<t>} (\hat{y}^{<t>},y^{t}) = -y^{<t>}log(\hat{y})-(1-y^{<t>})log(1-\hat{y}^{<t>})$</t></t></t></t></t></p>
<p>$L(\hat{y},y) = \sum_{t=1}^{T_x}L^{<t>}(\hat{y}^{<t>},y^{<t>})$</t></t></t></p>
</li>
<li><p>Different types of RNN</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/FF3C6BD2-518A-480C-ADE5-3B71224C7DDB.png" alt="FF3C6BD2-518A-480C-ADE5-3B71224C7DDB"></p>
</li>
<li><p>Language model</p>
<ul>
<li><p>tokenize (one hot)</p>
</li>
<li><p><UNK>来编码非常用单词</UNK></p>
</li>
<li><p>目标：判断一个句子的概率</p>
<ul>
<li><p>训练：</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/FC45A4AF-B524-425F-8C28-14FF8C16B802.png" alt="ßFC45A4AF-B524-425F-8C28-14FF8C16B802"></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Sample a sequence model from trained RNN</p>
<ul>
<li>初始化输入（零向量）</li>
<li>按照预测softmax后的概率sample出一个词</li>
<li>以新词作为输入，softmax预测下一个词的概率，按照概率分布sample出第二个词</li>
</ul>
</li>
<li><p>RNN的梯度消失</p>
<p>梯度爆炸可使用gradient clipping</p>
</li>
<li><p>GRU（Gradient Recurrent Unit）</p>
<ul>
<li><p>c:memory cell</p>
<p>$c^{<t>} = a^{<t>}$</t></t></p>
<p>$\hat{c}^{<t>}=tanh(W_c[c^{<t-1>},x^{<t>}]+b_c)$</t></t-1></t></p>
<p>$\Gamma_u=\sigma(W_u[c^{<t-1>},x^{<t>}]+b_u)$   (u: update,$\Gamma$ 约为0或1)</t></t-1></p>
<p>$c^{<t>} = \Gamma_u\hat{c}^{<t>} +(1-\Gamma_u)c^{<t-1>}$  （$\Gamma$维度和c一样；elemet wise multiply）</t-1></t></t></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/05728660-E7EF-4289-9665-45E6653B03F5.png" alt="05728660-E7EF-4289-9665-45E6653B03F5"></p>
</li>
<li><p>Full GRU</p>
<p>$\hat{c}^{<t>} = tanh(Wc[\Gamma_r*c^{<t-1>},x^{<t>}]+b_c)$</t></t-1></t></p>
<p>$\Gamma_r=\sigma(W_r[c^{<t-1>},x^{t}]+b_c)$</t-1></p>
<p>$\Gamma _u=\sigma(W_u[c^{<t-1>},x^{<t>}]+b_u)$</t></t-1></p>
<p>$c^{<t>} = \Gamma_u<em>\hat{c}^{<t>}+(1-\Gamma_u)</t></em>c^{<t-1>}$</t-1></t></p>
<p>$a^{<t>} = c^{<t>}$</t></t></p>
<p>​</p>
</li>
</ul>
</li>
<li><p>LSTM (Long Short Term Memory)</p>
<p>$\hat{c}^{<t>} = tanh(W_c[a^{<t-1>},x^{<t>}]+b_c)$</t></t-1></t></p>
<p>$\Gamma_u=\sigma(W_u[a^{<t-1>},x^{<t>}]+b_u)$</t></t-1></p>
<p>$\Gamma_f=\sigma(W_f[a^{<t-1>},x^{<t>}]+b_f)$</t></t-1></p>
<p>$\Gamma_o=\sigma(W_o[a^{<t-1>},x^{<t>}]+b_o)$</t></t-1></p>
<p>$c^{<t>}=\Gamma_u<em>\hat{c}^{<t>}+\Gamma_f</t></em>c^{<t-1>}$</t-1></t></p>
<p>$a^{<t>}=\Gamma_o*c^{<t>}$</t></t></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/tessiehe/Documents/study_notes/吴恩达时间序列笔记/image/C9ED60FC-BEA6-49F4-A735-90C7B76F782D.png" alt="C9ED60FC-BEA6-49F4-A735-90C7B76F782D"></p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<p>机器学习基础</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="Woe"><a href="#Woe" class="headerlink" title="Woe"></a>Woe</h1><p>WOE的全称是“weight of evidence”，即证据权重, WOE表示的含义即是”<strong>当前分组中响应客户占所有响应客户的比例”和”当前分组中没有响应的客户占所有没有响应客户的比例</strong>“的差异。先把分析变量进行分箱，每个分箱内的$w_{oe}$为</p>
<script type="math/tex; mode=display">
woe_i=\frac{当前分组中响应客户占所有响应客户的比例}{当前分组中没有响应的客户占所有没有响应客户的比例}=ln\frac{P_{y_i}}{P_{n_i}}=ln\frac{y_1/y_2}{n_i/n_s}</script><script type="math/tex; mode=display">
woe_i=\frac{sum(y_i)/sum(y_s)}{sum(1-y_i)/sum(1-y_s)}</script><p>该值绝对值越大说明变量区分能力越强</p>
<h1 id="IV"><a href="#IV" class="headerlink" title="IV"></a>IV</h1><p>IV衡量的是某一个变量的信息量，从公式来看的话，相当于是自变量WOE值的一个加权求和，其值的大小决定了自变量对于目标变量的影响程度</p>
<script type="math/tex; mode=display">
IV_i=(P_{y_i}-P_{n_i})*woe_i</script><p>WOE 和 IV 都能表达某个分组对目标变量的预测能力。但实际中，我们通常选择 IV 而不是 WOE 的和来衡量变量预测的能力，这是为什么呢？首先，因为我们在衡量一个变量的预测能力时，我们所使用的指标值不应该是负数。从这意义上来说，IV 比 WOE 多乘以前面那个因子，就保证了它不会是负数；然后，乘以(Pyi−Pni)这个因子，体现出了变量当前分组中个体的数量占整体的比例，从而很好考虑了这个分组中样本占整体的比例，比例越低，这个分组对变量整体预测能力的贡献越低。相反，如果直接用 WOE 的绝对值加和，会因为该分组出现次数偏少的影响而得到一个很高的指标。</p>
<h1 id="AUC-amp-KS"><a href="#AUC-amp-KS" class="headerlink" title="AUC &amp; KS"></a>AUC &amp; KS</h1><h1 id="信息熵（information-entropy）"><a href="#信息熵（information-entropy）" class="headerlink" title="信息熵（information entropy）"></a>信息熵（information entropy）</h1><p>衡量样本纯度，熵越小越纯,样本D有K类样本，其信息熵为</p>
<script type="math/tex; mode=display">
Ent(D)=-\sum_{k=1}^{K}p_klog_2p_k</script>]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>李宏毅强化学习笔记</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>李宏毅强化学习笔记</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="PART1"><a href="#PART1" class="headerlink" title="PART1"></a>PART1</h1><p><strong>什么是强化学习</strong></p>
<p>强化学习决策过程包括4个环节：agent观察环境（observation）—-agent做出动作（action）——动作会引起环境的变化 —- agent得到奖励（reward）—-agent再次观察环境（observation）。强化学习就是通过学习实现agent的决策序列收益（reward）最大。</p>
<p><strong>强化学习的分类</strong></p>
<p>policy based, grade based, model based。 这三种方式其实是不同的reward方式</p>
<h1 id="PART-2"><a href="#PART-2" class="headerlink" title="PART 2"></a>PART 2</h1><h1 id="PART-3"><a href="#PART-3" class="headerlink" title="PART 3"></a>PART 3</h1>]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习笔记</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>深度学习笔记</p>
<span id="more"></span>
<h1 id="深度学习笔记"><a href="#深度学习笔记" class="headerlink" title="深度学习笔记"></a>深度学习笔记</h1><h2 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h2><ul>
<li><p>基本思想：</p>
<p>深度网络对输入的分布式敏感的，若采用mini-batch方法训练模型，则每次样本分布式不同的。不仅第一层如此，由于非线性的变换，后面每一层的输入（即前一层的输出）的分布都是不一样的，不符合IID独立同分布假设，模型训练也会越来越困难，也就是所谓的internal covariate shift问题。所以考虑在每一层的线下变换后，非线性变化之前，将输出强制变换为0-1分布。</p>
<p>这样做是受图像处理中的白化（whiten）操作的启发：就是对输入数据分布变换到0均值，单位方差的正态分布</p>
<p>所以本质就是：<strong>对于每个隐层神经元，把逐渐向非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0方差为1的比较标准的正态分布，使得非线性变换函数的输入值落入对输入比较敏感的区域，以此避免梯度消失问题。</strong> </p>
<p>但是，都通过BN，那么不就跟把非线性函数替换成线性函数效果相同了？这意味着什么？我们知道，如果是多层的线性函数变换其实这个深层是没有意义的，因为多层线性网络跟一层线性网络是等价的。这意味着网络的<strong>表达能力</strong>下降了，这也意味着深度的意义就没有了。<strong>所以BN为了保证非线性的获得，对变换后的满足均值为0方差为1的x又进行了scale加上shift操作(y=scale*x+shift)</strong>，每个神经元增加了两个参数scale和shift参数，这两个参数是通过训练学习到的，意思是通过scale和shift把这个值从标准正态分布左移或者右移一点并长胖一点或者变瘦一点，每个实例挪动的程度不一样，这样等价于非线性函数的值从正中心周围的线性区往非线性区动了动。核心思想应该是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠非线性区两头使得网络收敛速度太慢。 </p>
</li>
<li><p>流程：</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1541386887738.png" alt="1541386887738"></p>
</li>
<li><p>inference过程：</p>
<p>由于inference过程只有一个实例，无法获得期望和方差，可用全局方差代替。具体来说就是记住每一个mini-batch的方差和期望，然后统计出全局统计量</p>
</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>联邦树模型</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%81%94%E9%82%A6%E6%A0%91%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>联邦树模型</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="普通XGB原理"><a href="#普通XGB原理" class="headerlink" title="普通XGB原理"></a>普通XGB原理</h1><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><h1 id="联邦GXB"><a href="#联邦GXB" class="headerlink" title="联邦GXB"></a>联邦GXB</h1>]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言处理笔记</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>自然语言处理笔记</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="文本特征提取"><a href="#文本特征提取" class="headerlink" title="文本特征提取"></a>文本特征提取</h1><h2 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h2><p><a href="https://blog.csdn.net/The_lastest/article/details/79093407">链接</a></p>
<blockquote>
<p>TF-IDF是传统的统计算法，用于评估一个词在一个文档集中对于某一个文档的重要程度。它与这个词在当前文档中的词频成正比，与文档集中的其他词频成反比</p>
</blockquote>
<p>x:多个文档，如多个电影评论</p>
<p>y:针对每个文档可以提取关键词</p>
<h1 id="gensim"><a href="#gensim" class="headerlink" title="gensim"></a>gensim</h1><p><a href="https://blog.csdn.net/CoderPai/article/details/80250380">https://blog.csdn.net/CoderPai/article/details/80250380</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#train</span></span><br><span class="line"><span class="keyword">from</span> gensim.test.utils <span class="keyword">import</span> common_texts, get_tmpfile</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line">model_name=<span class="string">&#x27;test&#x27;</span></span><br><span class="line">path = get_tmpfile(model_name + <span class="string">&#x27;.model&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> params <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;size&#x27;</span>: <span class="number">100</span>,</span><br><span class="line">        <span class="string">&#x27;window&#x27;</span>: <span class="number">10</span>,</span><br><span class="line">        <span class="string">&#x27;min_count&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;workers&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">        <span class="string">&#x27;compute_loss&#x27;</span>: <span class="literal">True</span></span><br><span class="line">    &#125;</span><br><span class="line">model = Word2Vec([[<span class="string">&#x27;我&#x27;</span>,<span class="string">&#x27;是&#x27;</span>,<span class="string">&#x27;天才&#x27;</span>],[<span class="string">&#x27;你&#x27;</span>，<span class="string">&#x27;是&#x27;</span>，<span class="string">&#x27;呵呵&#x27;</span>]] **params)  <span class="comment"># get_latest_training_loss().</span></span><br><span class="line">model.save(path)</span><br><span class="line"><span class="comment">#pred</span></span><br><span class="line">model=Word2Vec.load(path)</span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<ul>
<li>size: 词向量的维度。</li>
<li>alpha: 模型初始的学习率。</li>
<li>window: 表示在一个句子中，当前词于预测词在一个句子中的最大距离。</li>
<li>min_count: 用于过滤操作，词频少于 min_count 次数的单词会被丢弃掉，默认值为 5。</li>
<li>max_vocab_size: 设置词向量构建期间的 RAM 限制。如果所有的独立单词数超过这个限定词，那么就删除掉其中词频最低的那个。根据统计，每一千万个单词大概需要 1GB 的RAM。如果我们把该值设置为 None ，则没有限制。</li>
<li>sample: 高频词汇的随机降采样的配置阈值，默认为 1e-3，范围是 (0, 1e-5)。</li>
<li>seed: 用于随机数发生器。与词向量的初始化有关。</li>
<li>workers: 控制训练的并行数量。</li>
<li>min_alpha: 随着训练进行，alpha 线性下降到 min_alpha。</li>
<li>sg: 用于设置训练算法。当 sg=0，使用 CBOW 算法来进行训练；当 sg=1，使用 skip-gram 算法来进行训练。</li>
<li>hs: 如果设置为 1 ，那么系统会采用 hierarchica softmax 技巧。如果设置为 0（默认情况），则系统会采用 negative samping 技巧。</li>
<li>negative: 如果这个值大于 0，那么 negative samping 会被使用。该值表示 “noise words” 的数量，一般这个值是 5 - 20，默认是 5。如果这个值设置为 0，那么 negative samping 没有使用。</li>
<li>cbow_mean: 如果这个值设置为 0，那么就采用上下文词向量的总和。如果这个值设置为 1 （默认情况下），那么我们就采用均值。但这个值只有在使用 CBOW 的时候才起作用。</li>
<li>hashfxn: hash函数用来初始化权重，默认情况下使用 Python 自带的 hash 函数。</li>
<li>iter: 算法迭代次数，默认为 5。</li>
<li>trim_rule: 用于设置词汇表的整理规则，用来指定哪些词需要被剔除，哪些词需要保留。默认情况下，如果 word count &lt; min_count，那么该词被剔除。这个参数也可以被设置为 None，这种情况下 min_count 会被使用。</li>
<li>sorted_vocab: 如果这个值设置为 1（默认情况下），则在分配 word index 的时候会先对单词基于频率降序排序。</li>
<li>batch_words: 每次批处理给线程传递的单词的数量，默认是 10000。</li>
</ul>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>表示学习调研</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<p>表示学习调研</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h1><p>representation learning；data representation; Deep learning, representation learning, feature learning, unsupervised learning, Boltzmann Machine, autoencoder, neural nets</p>
<h1 id="粗读文献笔记"><a href="#粗读文献笔记" class="headerlink" title="粗读文献笔记"></a>粗读文献笔记</h1><h2 id="Bengio，2014，Representation-Learning-A-Review-and-New-Perspectives"><a href="#Bengio，2014，Representation-Learning-A-Review-and-New-Perspectives" class="headerlink" title="Bengio，2014，Representation Learning: A Review and New Perspectives"></a>Bengio，2014，Representation Learning: A Review and New Perspectives</h2><p><strong>Index Terms</strong>:Deep learning, representation learning, feature learning, unsupervised learning, Boltzmann Machine, autoencoder, neural nets,underlying explanatory factors</p>
<ul>
<li>机器学习的成功依赖于数据的表征（data representation），我们假设这是因为数据的表征或多或少的揭示了数据的内在结构。当然可以采用专家经验设计表征方式，但AI的目的在于依照通用的先验（generic priors）设计表征，并通过数据实例化这个表征。</li>
<li>“ This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in <strong>probabilistic models, auto-encoders, manifold learning, and deep networks.</strong> “<ul>
<li>本文聚焦与<strong>无监督学习</strong>，实现的方式包括以上三种方式。auto-encoders是基于信息重建的算法， manifold learning是基于拓扑学的算法</li>
</ul>
</li>
<li>这个工作有助于理解一个长期没有确定答案的问题：什么样的数据表征是一个好的表征？数据表征的优化目标是什么？<ul>
<li><strong>好的特征能够解耦数据中的关键潜在影响变量，这些变量最好是通用的（例如通用的语言模型、图像模型）。特征提取的过程就是冗余信息删减聚合的过程</strong>。如果不能通用，那退一步特征最好能提取针对下游任务有区分性的潜在因子，因子和任务目标之间最好有简单关系（如线性关系）</li>
</ul>
</li>
<li>“In order to expand the scope and ease of applicability of machine learning, it would be highly desirable to make learning algorithms <strong>less dependent on feature engineering</strong>, so that novel applications could be constructed faster, and more importantly, to <strong>make progress towards Artificial Intelligence</strong> (AI). An AI must fundamentally <em>understand the world around us</em>, and we argue that this can only be achieved if it can learn to identify and disentangle the underlying explanatory factors hidden in the observed milieu of <strong>low-level sensory data</strong>.” P1<ul>
<li>借助专家经验的特征工程能一定程度描述数据的内在结构，但真正的AI应该是解耦低等级的感官数据中的影响因子，从而了解这个世界的</li>
</ul>
</li>
<li>“In the case of probabilistic models, a good representation is often one that captures the posterior distribution of the <strong>underlying explanatory factors</strong> for the observed input.” P1<ul>
<li>对于概率模型，一个好的表征能够提取观察到的输入数据中的潜在影响因子。</li>
</ul>
</li>
<li>AI中的表示学习中的先验：<ul>
<li>平滑性（smoothness): x ≈ y generally implies f(x) ≈ f(y)</li>
<li>解耦（ Multiple explanatory factors）</li>
<li>层次化的组织方式（A hierarchical organization of explanatory factors）：越抽象的特征处于越高层</li>
<li>半监督（semi-supervised learning）:有一些解释X分布的因子也能解释Y的分布，基于这个假设，对于P(X)有用的表征对P(Y|X)也有用。所以note2vec的embeding才可以用于下游任务。但这个假设并不强，也就是用在下游任务不一定效果好</li>
<li>通用性（Shared factors across tasks）：能在不同的任务中共享一些因子</li>
<li>自然的聚集性（Natural clustering）</li>
</ul>
</li>
</ul>
<h2 id="Chen-2018-A-Tutorial-on-Network-Embeddings"><a href="#Chen-2018-A-Tutorial-on-Network-Embeddings" class="headerlink" title="Chen,2018,A Tutorial on Network Embeddings"></a>Chen,2018,A Tutorial on Network Embeddings</h2><p>Chen, H.; Perozzi, B.; Al-Rfou, R.; Skiena, S. A Tutorial on Network Embeddings. <em>arXiv:1808.02590 [cs]</em> <strong>2018</strong>.</p>
<ul>
<li><p>模型分类：unsupervised NE(以deepwalk为代表的无监督方法);  attributed NE(网络结构信息+节点和边的属性学习节点表征); Heterogeneous NE(从有多类节点或边的网络中学习表征)</p>
</li>
<li><p>NE的应用</p>
<ul>
<li><p>知识图谱（Knowledge Representation）：GenVector(2015), PDF2Vec(2016)</p>
</li>
<li><p>推荐（recommender system）</p>
<p>Chih-Ming Chen, Po-Chuan Chien, Yu-Ching Lin, Ming-Feng Tsai, and Yi-Hsuan Yang. Ex- ploiting latent social listening representations for music recommendations. In Proc Ninth ACM Int. Conf. Recommender Syst. Poster, 2015</p>
<p>Chih-Ming Chen, Ming-Feng Tsai, Yu-Ching Lin, and Yi-Hsuan Yang. Query-based music recommendations via preference embedding. In Proceedings of the 10th ACM Conference on Recommender Systems, pages 79–82. ACM, 2016.</p>
</li>
<li><p>NLP: PLE(2016), CANE(2017),</p>
<p>Hanyin Fang, Fei Wu, Zhou Zhao, Xinyu Duan, Yueting Zhuang, and Martin Ester. Community-based question answering via heterogeneous social network learning. In Thirtieth AAAI Conference on Artificial Intelligence, 2016.</p>
<p>Zhou Zhao, Qifan Yang, Deng Cai, Xiaofei He, and Yueting Zhuang. Expert finding for community-based question answering via ranking metric network learning. In IJCAI, pages 3000–3006, 2016.</p>
</li>
<li><p>社会关系（social network analysis）</p>
<p>Bryan Perozzi and Steven Skiena. Exact age prediction in social networks. In Proceedings of the 24th International Conference on World Wide Web, pages 91–92. ACM, 2015.</p>
<p>Cheng Yang, Maosong Sun, Wayne Xin Zhao, Zhiyuan Liu, and Edward Y Chang. A neural network approach to joint modeling social networks and mobile trajectories. arXiv preprint arXiv:1606.08154, 2016.</p>
</li>
</ul>
</li>
</ul>
<h1 id="精读文献笔记"><a href="#精读文献笔记" class="headerlink" title="精读文献笔记"></a>精读文献笔记</h1><h1 id="杂七杂八的comment"><a href="#杂七杂八的comment" class="headerlink" title="杂七杂八的comment"></a>杂七杂八的comment</h1><ul>
<li>无监督学习侧重于学习数据的内在关系、结构，比如clustering、grouping、density estimation, or anomaly detection等等，而自监督是根据数据集本身生成标签</li>
<li>表示学习领域的会议：ICML（ International Conference on Learning Representations）</li>
</ul>
<h1 id="文献总结"><a href="#文献总结" class="headerlink" title="文献总结"></a>文献总结</h1><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>[1]Bengio, Y.; Courville, A.; Vincent, P. Representation Learning: A Review and New Perspectives. <em>arXiv:1206.5538 [cs]</em> <strong>2014</strong>.【done】</p>
<p>[2] <a href="https://www.cxyzjd.com/article/weixin_42137700/106039656">图灵奖得主Bengio和LeCun称自监督学习可使AI达到人类智力水平</a>  【done】</p>
<p>[3] <a href="https://cloud.tencent.com/developer/article/1523877">图灵奖得主LeCun力推无监督学习：要重视基于能量的学习方法</a> 【done】</p>
<p><strong>[4] Weston, J.; Bengio, S.; Usunier, N. Large Scale Image Annotation: Learning to Rank with Joint Word-Image Embeddings. <em>Machine learning</em> 2010, <em>81</em> (1), 21–35.</strong> </p>
<p><strong>[5] Srivastava, N., &amp; Salakhutdinov, R. R. (2012). Multimodal learning with deep boltzmann machines. <em>Advances in neural information processing systems</em>, <em>25</em>.</strong></p>
<p>[6] Chen, H.; Perozzi, B.; Al-Rfou, R.; Skiena, S. A Tutorial on Network Embeddings. <em>arXiv:1808.02590 [cs]</em> <strong>2018</strong>. </p>
<p>[7]   Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social repre- sentations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 701–710. ACM, 2014.</p>
<p>[8] Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou, and Alex Alemi. Watch your step: Learning graph embeddings through attention. arXiv preprint arXiv:1710.09599, 2017.</p>
<p>[9]  Xiaofei Sun, Jiang Guo, Xiao Ding, and Ting Liu. A general framework for content-enhanced network representation learning. arXiv preprint arXiv:1610.02906, 2016.【图的节点中有文本信息作为arttibute】</p>
<p>[][12][10]  Jifan Chen, Qi Zhang, and Xuanjing Huang. Incorporate group information to enhance network embedding. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, pages 1901–1904. ACM, 2016.  【图中的节点有标签信息】</p>
<p>[11]  Chih-Ming Chen, Po-Chuan Chien, Yu-Ching Lin, Ming-Feng Tsai, and Yi-Hsuan Yang. Ex- ploiting latent social listening representations for music recommendations. In Proc Ninth ACM Int. Conf. Recommender Syst. Poster, 2015. 【NE在推荐中的应用】</p>
<p>[12]  Chih-Ming Chen, Ming-Feng Tsai, Yu-Ching Lin, and Yi-Hsuan Yang. Query-based music recommendations via preference embedding. In Proceedings of the 10th ACM Conference on Recommender Systems, pages 79–82. ACM, 2016.【NE在推荐中的应用】</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/</url>
    <content><![CDATA[<p>计算广告</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="1-好文"><a href="#1-好文" class="headerlink" title="1. 好文"></a>1. 好文</h1><p><a href="https://borgwang.github.io/adtech/2020/12/09/adtech-buying-type.html">https://borgwang.github.io/adtech/2020/12/09/adtech-buying-type.html</a> </p>
<h1 id="2-出价模式"><a href="#2-出价模式" class="headerlink" title="2. 出价模式"></a>2. 出价模式</h1><p>转化链路：曝光 M -&gt; 点击 C -&gt; 转化 A -&gt; 消费 P</p>
<p> 考核出价 ： bidROI</p>
<p><img src="/Users/hetianqi/Library/Application Support/typora-user-images/image-20210805144947093.png" alt="image-20210805144947093"></p>
<ul>
<li>本质上 CPM 到 CPC 的变化是计费点和出价点从 M 移动到 C，这个点之前的部分（ CTR 预估）让渡给平台去完成了，广告主只负责这个点后面的预估</li>
<li>因为 CPA 模式按照转化计费，只要广告主不回传或只回传部分转化数据，就可以进行作弊，薅媒体平台羊毛。因此实际中 CPA 模式应用的很少。</li>
<li>从广告主的角度，从 CPM 到 CPC 到 CPA，出价点越来越靠近广告主考核点，平台需要预估的东西越来越多，承担的风险也越来越大。到了 CPA 这种模式，由于转化数据平台无法完全控制，<strong>预估 CVR 带来的期望风险已经超过了期望收益了</strong>，因此看上去很难再继续往链路后端发展。这时 Facebook 提出了 oCPX 模式，这种模式的创新点在于<strong>分离了计费点和出价点</strong>。我们仍希望利用媒体平台的能力对 CVR 进行预估，因此将出价点往后移到 A，因为这会带来平台收益；同时将计费点保留在 M 或者 C（对应 oCPM、oCPC），仍然按照曝光或点击计费，这会降低进行预估的期望风险（广告主没有动力作弊了）。</li>
</ul>
<h1 id="3-oCPX的成本控制"><a href="#3-oCPX的成本控制" class="headerlink" title="3. oCPX的成本控制"></a>3. oCPX的成本控制</h1><ul>
<li>oCPX 中的成本控制和预算控制<ul>
<li>oCPX 是一种保转化成本的模式，即媒体平台需要在一个广告投放周期内对广告转化成本进行控制，使其尽量等于广告主设定的目标成本。因此 oCPX 中通常会有智能调价的功能，即如果前期出价出高了，比如广告主设定 80 元一个转化，前期投放下来发现一个转化要 100 元，这时候智能调价需要将出价调低，拉低其平均转化成本。最朴素的是做法就是用 PID 反馈控制出价</li>
<li>除了成本控制之外也应该对预算进行控制，让预算在周期内以合理的节奏消耗，这个节奏通常与流量的分布差不多一致。</li>
</ul>
</li>
</ul>
<h1 id="4-计算广告中的PID成本控制"><a href="#4-计算广告中的PID成本控制" class="headerlink" title="4. 计算广告中的PID成本控制"></a>4. 计算广告中的PID成本控制</h1><p>参考资料：</p>
<p> <a href="https://cloud.tencent.com/developer/article/1745934">干货 | PID算法在广告成本控制领域的应用</a></p>
<p>背景：</p>
<ul>
<li>在实际的广告投放系统中，会包含诸如广告主端的点击率预估模型、用户价值预估模型、竞价算法，媒体端的OCPA、OCPC出价模型，以及多方竞价、二价成交等不可控机制，最终的投放系统十分复杂，影响投放成本的因素过多，造成<strong>用户成交价与实际出价并不相等</strong>，实际投放成本难以契合广告主在投放初期所制定的预算。</li>
<li>以信息流广告投放为例，广告主通过采买媒体平台广告位进行广告投放。在广告投放前，综合考虑投放目标以及历史投放经验等，会对广告投放预算成本进行控制，希望能够以预先规划的价格拿到广告位资源（即控制广告成交价）。但由于如前所述的广告投放系统中的出价优化模型以及二价成交机制等，<strong>广告主往往不能直接控制成交价</strong>，而需通过调整出价等方式间接控制成交价。</li>
<li>为了能够实现控制成交价的目的，我们实时监控成交价<strong>（输出）</strong>与预算成本<strong>（目标）</strong>间关系，并通过PID控制算法来动态调整出价<strong>(输入)</strong></li>
</ul>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/计算广告/image-20210805152419480.png" alt="image-20210805152419480" style="zoom:50%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/计算广告/image-20210805152357961.png" alt="image-20210805152357961" style="zoom:50%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/计算广告/image-20210805152447320.png" alt="image-20210805152447320" style="zoom:50%;"></p>
<h1 id="5-其他"><a href="#5-其他" class="headerlink" title="5. 其他"></a>5. 其他</h1><h2 id="CPX与OCPX的区别"><a href="#CPX与OCPX的区别" class="headerlink" title="CPX与OCPX的区别"></a>CPX与OCPX的区别</h2><p>CPX（如CPC,CPM等）是出价点与计费点一致，oCPX_a指的是计费点在X，出价点在a。相较与CPX，相当于媒体帮助广告主预估计费点到出价点的转化率，实现出价点成本控制下的动态竞价。</p>
<h2 id="eCPM-流量对于媒体的变现能力评估"><a href="#eCPM-流量对于媒体的变现能力评估" class="headerlink" title="eCPM 流量对于媒体的变现能力评估"></a>eCPM 流量对于媒体的变现能力评估</h2><p>eCPM的竞价模式下竞价点都是在<strong>展示</strong>,任何出价计费模式下eCPM的万能公式：</p>
<blockquote>
<p>eCPM =P(计费|展示) <em> bid_计费  </em> 1000   </p>
</blockquote>
<p>例子：</p>
<p>eCPM = CTR <em> CPC </em> 1000  #点击出价，点击计费，即CPC模式</p>
<p>eCPM = CPM  # 展示出价，展示计费，即CPM模式</p>
<p>eCPM = CTR <em> P(授信|点击) </em>  bid_授信 * 1000  #授信出价，点击计费，即oCPC_a </p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告学笔记</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E5%AD%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>计算广告学笔记</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="业务知识"><a href="#业务知识" class="headerlink" title="业务知识"></a>业务知识</h1><h2 id="广告分类"><a href="#广告分类" class="headerlink" title="广告分类"></a>广告分类</h2><p>广告的根本目的，是广告主通过媒体达到低成本的用户接触。</p>
<p>也就是说，按某种市场意图接触相应的人群，进而影响其中的潜在用户，使他们选择广告主产品的机率增加，或者对产品性价比的苛求程度降低，才是广告的根本目的。至于短期内的转化效果，由于市场意图或媒体性质的不同，并不是直接可比。因此ROI中的产出是很难计算的</p>
<h2 id="广告发展史"><a href="#广告发展史" class="headerlink" title="广告发展史"></a>广告发展史</h2><ul>
<li><p>售卖模式1：合约式广告(Agreement-based Advertising)</p>
</li>
<li><p>广告投放方式：定向广告（Target Ad），是为了<code>拆分流量以获得更高的营收</code>，具体来说：媒体向广告主保证某个投放量，并在此基础上确定合同的总金额以及量未完成情况下的赔偿方案；<strong><code>只卖好苹果</code></strong></p>
<blockquote>
<p><code>博弈</code>：定向太准了可能导致尾部流量卖不出去，对媒体不利，但广告主效果好的话整个广告市场规模就会变大，对媒体有利。</p>
</blockquote>
</li>
<li><p>交易方式：<code>担保式投送(Guaranteed Delivery)</code>：媒体向广告主保证某个投放量，并在此基础上确定合同的总金额以及量未完成情况下的赔偿方案<strong><code>保证交易苹果的量</code></strong></p>
</li>
<li><p>计费方式：按千次展示付费(Cost Per Mille, CPM)的计费方式</p>
</li>
</ul>
<blockquote>
<p>难点：一是如何有效地将流量分配到各个合约互相交叉的人群覆盖上；二是要在在线的环境下实时且经济地完成每一次展示决策。</p>
</blockquote>
<ul>
<li>在线分配(Online Allocation):将各<code>合约的量</code>看做约束条件，将某种意义下的质看做目标函数，我们可以利用带约束优化(Constrained Optimization)的数学框架来探索这一问题；搜索排序以优化相关性为目的，在线分配  是以<code>优化投入产出比</code>为目标。</li>
<li>售卖模式2：<code>竞价广告(Auction-based Advertising)</code>，抛弃量的保证，而采用最唯利是图的策略来进行广告决策，具体来说就是：供给方只向广告主保证质即单位流量的成本，但不再以合约的方式给出量的保证，换言之，对每一次展示，都基本按照收益最高的原则来决策。<strong><code>线下对每批苹果进行出价</code></strong> </li>
</ul>
<blockquote>
<p>由于只能在广告网络定义好的定向标签组合上预先指定出价，而不能控制每一次展示的出价，因此，市场看起来象一个黑盒子，需求方只能靠选择合适的标签组合，以及阶段性调整出价来间接控制效果。</p>
<p>随着人群定向越来越精准，广告主数量越来越多，一方面担保是投送难以对流量做精确的分配来保证各广告主的投放量，另一方面当同一流量满足多个合约要求时，仅仅考虑量的约束会导致本来可以卖得更高的流量的浪费。</p>
</blockquote>
<ul>
<li>售卖模式3：实时竞价（real time bidding）。竞价广告是在媒体平台上用媒体已有的标签进行人群定向，并对定向人群进行出价。实时竞价是实时判断单个流量是不是自己的定向人群，并进行出价，可以实现更精准的人群定向</li>
</ul>
<blockquote>
<p>所谓实时竞价，就是把拍卖的过程由广告主预先出价，变成每次展示时实时出价。只要把广告展示的上下文页面url，以及访客的cookie等信息传给需求方，它就有充分的信息来完成定制化的人群选择和出价。</p>
</blockquote>
<ul>
<li>需求方平台(Demand Side Platform, DSP) ：通过实时竞价的方式，按照定制化的人群标签购买广告，这样与广告交易平台接口的产品叫做DSP。DSP可以方便的设置对于每个流量的定向于出价，并把结果返回媒体的平台，<code>DSP需要尽可能准确地估计每一次展示带来的期望价值。</code></li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>首先是<code>合约阶段</code>，广告主通过代理公司(Agency)从媒体方采买广告，而媒体方的Ad Server则负责完成和优化各个广告主的合约；</p>
<p>然后，市场进化出了<code>竞价售卖方式</code>，从而在靠近供给方产生了广告网络(Ad Network)这样的产品形态，而需求方的代理公司为了适应这一市场变化，孵化除了对应的广告采买平台(Media Buying Platform)；</p>
<p>最后，当市场产生了<code>实时竞价方式交易</code>时，供给方进化出了广告交易平台(Ad Exchange)，而需求方则需要用需求方平台(DSP)与其对接来出价和投送广告。</p>
<h1 id="计算广告基础"><a href="#计算广告基础" class="headerlink" title="计算广告基础"></a>计算广告基础</h1><p>广告平台优化目标： $ 对1…T次广告选择a_{i…T} \quad s.t. \quad max \sum_i^T r(a_i,u_i,c_i)/\sum_i^Tp_i $</p>
<p>表达式中的a,u,c三个变量，分别代表广告、用户与上下文，即广告活动的三个参与主体。<em>i</em>代表从第1次到第<em>T</em>次之间的某一次广告展示。我们优化的目标，就是在这<em>T</em>次展示上的总产出(<em>r</em>)与总投入(<em>p</em>)的比，即ROI。</p>
<p>$eCPM(a,u,c)=r(a,u,c) =点击率<em>点击价值= ctr(a,u,c)</em>v(a,u)$</p>
<h2 id="广告系统构架图"><a href="#广告系统构架图" class="headerlink" title="广告系统构架图"></a>广告系统构架图</h2><ol>
<li>广告投放机（Ad Server）：调用哥哥模块返回前端结果</li>
<li>广告检索：实时接受投放信息，搜索广告备选集</li>
<li>广告排序，包括Click modeling和Ad ranking。关键技术是1.离线分布式计算平台上的海量数据支持的点击率预测模型的训练；2.线上高效查询用户特征并进行实时计算。在ctr的基础上简历点击价值估计模型，通常是简单的规则</li>
<li>数据高速公路（Data highway）：将在线数据准实时的传输到离线分部式平台和流计算平台，供后续数据处理和建模</li>
<li>用户日志生成：收集各渠道日志，整理成kv形式进行存储</li>
<li>商业智能（Business Inteligence）：看板等对外交流平台</li>
<li>行为定向：产生结构化标签库</li>
<li>上下文定向：页面抓取给上下文打标签，与行为定向一起产生定向效果</li>
<li>定制化用户：接收广告主定向需求（比如推包）</li>
<li>在线行为反馈：利用日志或买点进行准实时任务，如实时反馈点击，用户行为标签等。在利用日志完成这些逻辑之前，必须要进行的步骤是反作弊(Anti-spam)与计价(Billing)。<code>在很多情形下，把系统信息反馈调整做得更快，比把模型预测做得更准确效果更加显著</code></li>
<li>广告管理系统：只有这部分是面向用户的。通过广告管理系统定制和调整广告投放，并且与数据仓库交互</li>
<li>实时竞价接口：对接DSP（竞价平台）的接口。对于媒体即平台的case，不需要</li>
</ol>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E5%AD%A6%E7%AC%94%E8%AE%B0/hetianqi/Documents/charging/notes_of_the_world/计算广告学笔记.assets/image-20200414143343558.png" alt="image-20200414143343558"></p>
<h1 id="准备知识"><a href="#准备知识" class="headerlink" title="准备知识"></a>准备知识</h1><h2 id="带约束优化方法和拉格朗日乘子法"><a href="#带约束优化方法和拉格朗日乘子法" class="headerlink" title="带约束优化方法和拉格朗日乘子法"></a>带约束优化方法和拉格朗日乘子法</h2>]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>评估指标</title>
    <url>/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<p>评估指标</p>
<span id="more"></span>
<p>[TOC]</p>
<h2 id><a href="#" class="headerlink" title=" "></a> </h2><h2 id="1-ROC-KS-AUC"><a href="#1-ROC-KS-AUC" class="headerlink" title="1. ROC, KS, AUC"></a>1. ROC, KS, AUC</h2><h3 id="1-TP-FP-FN-TN"><a href="#1-TP-FP-FN-TN" class="headerlink" title="1. TP, FP, FN, TN"></a>1. TP, FP, FN, TN</h3><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>预测1</th>
<th>预测0</th>
<th>合计</th>
</tr>
</thead>
<tbody>
<tr>
<td>真实1</td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
<td>Actual   Positive(TP+FN)</td>
</tr>
<tr>
<td>真实0</td>
<td>False Positive (FP)</td>
<td>True Negative(TN)</td>
<td>Actual   Negative(FP+TN)</td>
</tr>
<tr>
<td>合计</td>
<td>Predicted   Positive(TP+FP)</td>
<td>Predicted   Negative(FN+TN)</td>
<td>TP+FP+FN+TN</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>True Positive Rate（TPR），计算公式为TPR=TP/(TP+FN)；所有真实的“1”中，有多少被模型成功选出</li>
<li>False Positive Rate（FPR），计算公式为FPR=FP/(FP+TN)；所有真实的“0”中，有多少被模型误判为1了；</li>
<li>Precision=TP/(TP+FP)，或2TP/((TP+FN)+(TP+FP))。所有判为1的用户，判对的比例</li>
<li>好的模型：TPR尽量高而FPR尽量低</li>
</ul>
<h3 id="2-ROC"><a href="#2-ROC" class="headerlink" title="2. ROC"></a>2. ROC</h3><ul>
<li><p>ROC(Receiver Operating Characteristic Curve):接受者操作特征曲线。</p>
</li>
<li><p>ROC曲线：设定不同的阀值，计算不同的点(FPR,TPR)，连成曲线</p>
</li>
<li><p>ROC曲线确定阈值的方法：</p>
</li>
<li><ul>
<li>给出ROC曲线的拟合函数表达式，然后计算出最优的阀值，这个目前通过软件实现难度不大：如何给出最优拟合函数，计算数学上有很多方法；</li>
<li>计算出ΔTPR≈ΔFPR的点即为最优的阀值；</li>
<li>从业务上给出最优的阀值。</li>
</ul>
</li>
</ul>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/dev\Blog\machine-learning-note\基础算法\.images\1560344119508.png" alt="1560344119508"></p>
<h3 id="3-AUC"><a href="#3-AUC" class="headerlink" title="3. AUC"></a>3. AUC</h3><ul>
<li>AUC：ROC曲线下方的面积Area Under the ROC      Curve，简称为AUC。这是评价模型的另一个方法，AUC值越大，说明模型的分辨效果越好</li>
<li>gini系数：在SAS的评分模型输出中，常用来判断收入分配公平程度，此时gini=2*AUC-1</li>
</ul>
<p>XGB中</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> sum_pospair = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">double</span> sum_npos = <span class="number">0.0</span>, sum_nneg = <span class="number">0.0</span>, buf_pos = <span class="number">0.0</span>, buf_neg = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">size_t</span> j = <span class="number">0</span>; j &lt; rec.<span class="built_in">size</span>(); ++j) &#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">float</span> wt = info.<span class="built_in">GetWeight</span>(rec[j].second);</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">float</span> ctr = info.labels[rec[j].second];</span><br><span class="line">  <span class="comment">// keep bucketing predictions in same bucket</span></span><br><span class="line">  <span class="keyword">if</span> (j != <span class="number">0</span> &amp;&amp; rec[j].first != rec[j - <span class="number">1</span>].first) &#123; <span class="comment">// 遍历所有的预测值</span></span><br><span class="line">    sum_pospair += buf_neg * (sum_npos + buf_pos *<span class="number">0.5</span>); <span class="comment">// 逐个梯形计算</span></span><br><span class="line">    sum_npos += buf_pos;</span><br><span class="line">    sum_nneg += buf_neg;</span><br><span class="line">    buf_neg = buf_pos = <span class="number">0.0f</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  buf_pos += ctr * wt; <span class="comment">// 累计加权TP</span></span><br><span class="line">  buf_neg += (<span class="number">1.0f</span> - ctr) * wt; <span class="comment">// 累计加权FP</span></span><br><span class="line">&#125;</span><br><span class="line">sum_pospair += buf_neg * (sum_npos + buf_pos *<span class="number">0.5</span>);</span><br><span class="line">sum_npos += buf_pos;</span><br><span class="line">sum_nneg += buf_neg;</span><br><span class="line"><span class="comment">// check weird conditions</span></span><br><span class="line">utils::<span class="built_in">Check</span>(sum_npos &gt; <span class="number">0.0</span> &amp;&amp; sum_nneg &gt; <span class="number">0.0</span>,</span><br><span class="line">             <span class="string">&quot;AUC: the dataset only contains pos or neg samples&quot;</span>);</span><br><span class="line"><span class="comment">// this is the AUC</span></span><br><span class="line">sum_auc += sum_pospair / (sum_npos*sum_nneg);<span class="comment">// 计算AUC</span></span><br></pre></td></tr></table></figure>
<p>R语言中的计算方法</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> (y_pred, y_true) </span><br><span class="line">&#123;</span><br><span class="line">rank &lt;- rank(y_pred) <span class="comment"># rank[i] 为 y_pred[i]从小到大的排序号，最小为1,两个数并列第5，则都为5.5</span></span><br><span class="line">n_pos &lt;- <span class="built_in">sum</span>(y_true == <span class="number">1</span>)</span><br><span class="line">n_neg &lt;- <span class="built_in">sum</span>(y_true == <span class="number">0</span>)</span><br><span class="line">AUC &lt;- (<span class="built_in">sum</span>(rank[y_true == <span class="number">1</span>]) - n_pos * (n_pos + <span class="number">1</span>)/<span class="number">2</span>)/(n_pos * </span><br><span class="line">n_neg)</span><br><span class="line"><span class="built_in">return</span>(AUC)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src=".images\auc计算" alt="img"></p>
<p>原因：</p>

<h3 id="4-KS"><a href="#4-KS" class="headerlink" title="4. KS"></a>4. KS</h3><ul>
<li>K-S曲线：它和ROC曲线的画法异曲同工。以Logistic模型为例，首先把Logistic模型输出的概率从大到小排序，然后取10%的值（也就是概率值）作为阀值，同理把10%*k（k=1,2,3,…,9）处的值作为阀值，计算出不同的FPR和TPR值，以10%*k（k=1,2,3,…,9）为横坐标，分别以TPR和FPR的值为纵坐标，就可以画出两个曲线，这就是K-S曲线。</li>
<li>KS值：KS=max(TPR-FPR)，即是两条曲线之间的最大间隔距离。当(TPR-FPR)最大时，也就是ΔTPR-ΔFPR=0，这和ROC曲线上找最优阀值的条件ΔTPR=ΔFPR是一样的。从这点也可以看出，ROC曲线、K-S曲线、KS值的本质是相同的。</li>
</ul>
<p><img src=".images\1560344142780.png" alt="1560344142780"></p>
<ul>
<li><p>K-S曲线能直观地找出模型中差异最大的一个分段，比如评分模型就比较适合用KS值进行评估；</p>
</li>
<li><p>KS值只能反映出哪个分段是区分度最大的，不能反映出所有分段的效果。</p>
</li>
</ul>
<p>因此，在实际应用中，模型评价一般需要将ROC曲线、K-S曲线、KS值、AUC指标结合起来使用。</p>
<h2 id="2-PSI"><a href="#2-PSI" class="headerlink" title="2. PSI"></a>2. PSI</h2><h3 id="1-含义"><a href="#1-含义" class="headerlink" title="1. 含义"></a>1. 含义</h3><p>PopulationStability Index(PSI)群体稳定性指标</p>
<h3 id="2-公式"><a href="#2-公式" class="headerlink" title="2. 公式"></a>2. 公式</h3><p> psi = sum(（实际占比-预期占比）*ln(实际占比/预期占比))</p>
<p>数学<strong>原理</strong>：</p>
<ul>
<li><p>平衡符号</p>
</li>
<li><p>占比小的区间权重小</p>
<p><img src=".images\1560344829786.png" alt="1560344829786"></p>
</li>
</ul>
<h3 id="3-计算"><a href="#3-计算" class="headerlink" title="3. 计算"></a>3. 计算</h3><p>形式上比较像WoE和IV，下面是<strong>计算</strong>举例：</p>
<p><img src=".images\1560344565889.png" alt="1560344565889"></p>
<p>计算表：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Score bands</th>
<th><strong>Actual %</strong></th>
<th>Expected %</th>
<th><strong>Ac-Ex</strong></th>
<th><strong>ln(Ac/Ex)</strong></th>
<th><strong>Index</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>&lt; 251</td>
<td>5%</td>
<td>8%</td>
<td>-3%</td>
<td>-0.47</td>
<td><strong>0.014</strong></td>
</tr>
<tr>
<td>251–290</td>
<td>6%</td>
<td>9%</td>
<td>-3%</td>
<td>-0.41</td>
<td><strong>0.012</strong></td>
</tr>
<tr>
<td>291–320</td>
<td>6%</td>
<td>10%</td>
<td>-4%</td>
<td>-0.51</td>
<td><strong>0.020</strong></td>
</tr>
<tr>
<td>321–350</td>
<td>8%</td>
<td>13%</td>
<td>-5%</td>
<td>-0.49</td>
<td><strong>0.024</strong></td>
</tr>
<tr>
<td>351–380</td>
<td>10%</td>
<td>12%</td>
<td>-2%</td>
<td>-0.18</td>
<td><strong>0.004</strong></td>
</tr>
<tr>
<td>381–410</td>
<td>12%</td>
<td>11%</td>
<td>1%</td>
<td>0.09</td>
<td><strong>0.001</strong></td>
</tr>
<tr>
<td>411–440</td>
<td>14%</td>
<td>10%</td>
<td>4%</td>
<td>0.34</td>
<td><strong>0.013</strong></td>
</tr>
<tr>
<td>441–470</td>
<td>14%</td>
<td>9%</td>
<td>5%</td>
<td>0.44</td>
<td><strong>0.022</strong></td>
</tr>
<tr>
<td>471–520</td>
<td>13%</td>
<td>9%</td>
<td>4%</td>
<td>0.37</td>
<td><strong>0.015</strong></td>
</tr>
<tr>
<td>520 &lt;</td>
<td>9%</td>
<td>8%</td>
<td>1%</td>
<td>0.12</td>
<td><strong>0.001</strong></td>
</tr>
<tr>
<td><strong>(PSI)= </strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><strong>0.1269</strong></td>
</tr>
</tbody>
</table>
</div>
<p>指标取值解释说明：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>PSI Value</strong></th>
<th><strong>Inference</strong></th>
<th><strong>Action</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Less than 0.1</td>
<td>无关紧要的差距</td>
<td>不需要进一步操作</td>
</tr>
<tr>
<td>0.1 – 0.25</td>
<td>有一点差距</td>
<td>检查一下其他度量</td>
</tr>
<tr>
<td>Greater than 0.25</td>
<td>差距较大</td>
<td>需要进一步研究</td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-使用"><a href="#4-使用" class="headerlink" title="4. 使用"></a>4. 使用</h3><h2 id="3-VIF"><a href="#3-VIF" class="headerlink" title="3. VIF"></a>3. VIF</h2><h3 id="1-含义-1"><a href="#1-含义-1" class="headerlink" title="1. 含义"></a>1. 含义</h3><p>方差膨胀因子（Variance Inflation Factor，VIF）</p>
<ul>
<li>容忍度的倒数，VIF越大，显示共线性越严重。经验判断方法表明：当0&lt;VIF&lt;10，不存在<a href="https://baike.baidu.com/item/多重共线性/10201978">多重共线性</a>；当10≤VIF&lt;100，存在较强的多重共线性；当VIF≥100，存在严重多重共线性。</li>
</ul>
<h2 id="4-LIFT"><a href="#4-LIFT" class="headerlink" title="4. LIFT"></a>4. LIFT</h2><h3 id="1-什么是LIFT"><a href="#1-什么是LIFT" class="headerlink" title="1. 什么是LIFT"></a>1. 什么是LIFT</h3><p>Lift是评估一个预测模型是否有效的一个度量；它衡量的是一个模型（或规则）对目标中“响应”的预测能力优于随机选择的倍数，以1为界线，大于1的Lift表示该模型或规则比随机选择捕捉了更多的“响应”，等于1的Lift表示该模型的表现独立于随机选择，小于1则表示该模型或规则比随机选择捕捉了更少的“响应”。维基百科中提升度被解释为“Target response divided by average response”。</p>
<h3 id="2-计算方法"><a href="#2-计算方法" class="headerlink" title="2. 计算方法"></a>2. 计算方法</h3><p>在模型评估中，我们常用到增益/提升（Gain/Lift）图来评估模型效果，其中的<strong>Lift是“运用该模型”和“未运用该模型”所得结果的比值。</strong>以信用评分卡模型的评分结果为例，我们通常会将打分后的样本按分数从低到高排序，取10或20等分（有同分数对应多条观测的情况，所以各组观测数未必完全相等），并对组内观测数与坏样本数进行统计。用评分卡模型捕捉到的坏客户的占比，可由该组坏样本数除以总的坏样本数计算得出；而不使用此评分卡，以随机选择的方法覆盖到的坏客户占比，等价于该组观测数占总观测数的比例（分子分母同时乘以样本整体的坏账率）。对两者取累计值，取其比值，则得到提升度Lift，即该评分卡抓取坏客户的能力是随机选择的多少倍。</p>
<h3 id="3-示例"><a href="#3-示例" class="headerlink" title="3. 示例"></a>3. 示例</h3><p> 下表是一个提升表（Lift Table）的示例：</p>
<p><img src=".images\1560345165281.png" alt="1560345165281"></p>
<p>以分数段为横轴，以捕捉到的“坏”占比为纵轴，可绘制出提升图，示例如下：</p>
<p><img src=".images\1560345217251.png" alt="1560345217251"></p>
<p> 以分数段为横轴，以提升度为纵轴，可绘制出累计提升图，示例如下：</p>
<p><img src=".images\1560345243738.png" alt="1560345243738"></p>
<p>有了累计提升图，我们就能直观地去比较不同模型或策略给我们带来的区分能力增益程度。</p>
<h2 id="5-RMSE-R-2"><a href="#5-RMSE-R-2" class="headerlink" title="5. RMSE, R^2^"></a>5. RMSE, R^2^</h2><h3 id="1-RMSE"><a href="#1-RMSE" class="headerlink" title="1. RMSE"></a>1. RMSE</h3>
<h3 id="2-R-2"><a href="#2-R-2" class="headerlink" title="2. R^2^"></a>2. R^2^</h3><p><img src=".images\clip_image002.png" alt="img"></p>
<h2 id="6-变异系数"><a href="#6-变异系数" class="headerlink" title="6. 变异系数"></a>6. 变异系数</h2><h3 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h3><p>变异系数（Coefficient of Variation）：当需要比较两组数据<a href="https://baike.baidu.com/item/离散程度/6775049">离散程度</a>大小的时候，如果两组数据的测量尺度相差太大，或者数据<a href="https://baike.baidu.com/item/量纲/100412">量纲</a>的不同，直接使用<a href="https://baike.baidu.com/item/标准差/1415772">标准差</a>来进行比较不合适，此时就应当消除测量尺度和量纲的影响，而变异系数可以做到这一点，它是原始数据标准差与原始数据<a href="https://baike.baidu.com/item/平均数/11031224">平均数</a>的比。CV没有量纲，这样就可以进行客观比较了。事实上，可以认为变异系数和极差、标准差和<a href="https://baike.baidu.com/item/方差/3108412">方差</a>一样，都是反映数据离散程度的绝对值。其数据大小不仅受变量值离散程度的影响，而且还受变量值平均水平大小的影响。</p>
<h3 id="2-计算公式"><a href="#2-计算公式" class="headerlink" title="2. 计算公式"></a>2. 计算公式</h3><p>标准差与平均值之比：</p>
<script type="math/tex; mode=display">
C_v=\frac{\sigma}{\mu}</script><h2 id="7-WOE"><a href="#7-WOE" class="headerlink" title="7. WOE"></a>7. WOE</h2><h3 id="1-什么是WOE"><a href="#1-什么是WOE" class="headerlink" title="1. 什么是WOE"></a>1. 什么是WOE</h3><h3 id="2-计算公式-1"><a href="#2-计算公式-1" class="headerlink" title="2. 计算公式"></a>2. 计算公式</h3><p>WOE（Weight of Evidence）</p>
<p>某个变量第i个属性对应的WOE值计算公式如下：</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}
WOE_i &=& ln(\frac{好用户占比}{坏用户占比})
\\
\\
&=&  ln(\frac {\frac{g_i}{g_T}} {\frac{b_i}{b_T}})
\\
\\
&=&  ln(\frac{g_i}{b_i}）- ln(\frac{g_T}{b_T})

\end{eqnarray*}</script><p>其中：g~i~为第i个属性上好用户数，g~T~表示总好人数，b~i~为第i个属性上坏用户数，b~T~表示总坏人数</p>
<p><strong>WOE</strong>的值<strong>越高</strong>，代表着该分组中客户是坏客户的<strong>风险越低</strong></p>
<h2 id="8-IV"><a href="#8-IV" class="headerlink" title="8. IV"></a>8. IV</h2><h3 id="1-IV是什么"><a href="#1-IV是什么" class="headerlink" title="1. IV是什么"></a>1. IV是什么</h3><p><strong>IV</strong>值是用来衡量某个变量对好坏客户区分能力的一个指标</p>
<h3 id="2-计算公式-2"><a href="#2-计算公式-2" class="headerlink" title="2. 计算公式"></a>2. 计算公式</h3><p>IV值公式如下：</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}
IV &=& \sum_i (\frac{g_i}{g_T}- \frac{b_i}{b_T})WOE_i
\\
\\
&=& \sum_i (\frac{g_i}{g_T}- \frac{b_i}{b_T})ln(\frac {\frac{g_i}{g_T}} {\frac{b_i}{b_T}})
\\
\\
&=& \sum_i (P_g-P_b) ln(\frac{P_g}{P_b})

\end{eqnarray*}</script><p>P~g~表示如果我是个好用户，我属于第i个属性的概率</p>
<script type="math/tex; mode=display">
P_g=P(x\epsilon i|x\epsilon g)=\frac{g_i}{g_T}</script><h3 id="3-取值经验"><a href="#3-取值经验" class="headerlink" title="3. 取值经验"></a>3. 取值经验</h3><p>KL散度与IV见 九-4</p>
<h2 id="9-KL散度"><a href="#9-KL散度" class="headerlink" title="9. KL散度"></a>9. KL散度</h2><h3 id="1-什么是KL散度"><a href="#1-什么是KL散度" class="headerlink" title="1. 什么是KL散度"></a>1. 什么是KL散度</h3><p>在概率论或信息论中，KL散度(Kullback–Leibler divergence)，又称相对熵（relative entropy)，是<strong>描述两个概率分布P和Q差异</strong>的一种方法。它是<strong>非对称</strong>的，这意味着$D(P||Q) ≠ D(Q||P)$。特别的，在信息论中，$D(P||Q)$表示当用<strong>概率分布Q来拟合真实分布P时，产生的信息损耗</strong>，其中P表示真实分布，Q表示P的拟合分布。有人将KL散度称为KL距离，但事实上，KL散度并不满足距离的概念，应为:1）KL散度不是对称的；2）KL散度不满足三角不等式。</p>
<h3 id="2-计算公式-3"><a href="#2-计算公式-3" class="headerlink" title="2. 计算公式"></a>2. 计算公式</h3>
<h3 id="3-信息论含义"><a href="#3-信息论含义" class="headerlink" title="3. 信息论含义"></a>3. 信息论含义</h3><p>KL散度在信息论中有自己明确的物理意义，它是用来度量使用基于Q分布的编码来编码来自P分布的样本平均所需的额外的Bit个数。而其在机器学习领域的物理意义则是用来度量两个函数的相似程度或者相近程度，在泛函分析中也被频繁地用到[2]。在香农信息论中，用基于P的编码去编码来自P的样本，其最优编码平均所需要的比特个数（即这个字符集的熵）为:</p>

<h3 id="4-KL散度与IV"><a href="#4-KL散度与IV" class="headerlink" title="4. KL散度与IV"></a>4. KL散度与IV</h3><script type="math/tex; mode=display">
\begin{eqnarray*}
IV &=& \sum_i (P_g-P_b) ln(\frac{P_g}{P_b})
\\
\\
&=& \sum_i P_gln(\frac{P_g}{P_b}) + \sum_i P_bln(\frac{P_b}{P_g})
\\
\\
&=& KL(P_g||P_b) +KL(P_b||P_g)

\end{eqnarray*}</script><p>即：好用户落在一个特征某个段上概率和坏用户落在这个段上的概率差别越大，IV值越大</p>
<p>即：好坏用户落在同一个属性上的概率越小（指P~g~和P~b~的分布差异越大）则IV值越大</p>
<h2 id="10-F1-score"><a href="#10-F1-score" class="headerlink" title="10. F1-score"></a>10. F1-score</h2><h3 id="1-混淆矩阵"><a href="#1-混淆矩阵" class="headerlink" title="1. 混淆矩阵"></a>1. 混淆矩阵</h3><h3 id="2-二级指标"><a href="#2-二级指标" class="headerlink" title="2. 二级指标"></a>2. 二级指标</h3><h2 id="11-AMS"><a href="#11-AMS" class="headerlink" title="11. AMS"></a>11. AMS</h2><p><a href="https://higgsml.lal.in2p3.fr/files/2014/04/documentation_v1.8.pdf"></a></p>
<p><a href="https://www.kaggle.com/c/higgs-boson/overview/evaluation-score">https://www.kaggle.com/c/higgs-boson/overview/evaluation-score</a></p>
<h3 id="1-混淆矩阵-1"><a href="#1-混淆矩阵-1" class="headerlink" title="1. 混淆矩阵"></a>1. 混淆矩阵</h3><h3 id="2-二级指标-1"><a href="#2-二级指标-1" class="headerlink" title="2. 二级指标"></a>2. 二级指标</h3><h2 id="11-AMS-1"><a href="#11-AMS-1" class="headerlink" title="11. AMS"></a>11. AMS</h2><p><a href="https://higgsml.lal.in2p3.fr/files/2014/04/documentation_v1.8.pdf"></a></p>
<p><a href="https://www.kaggle.com/c/higgs-boson/overview/evaluation">https://www.kaggle.com/c/higgs-boson/overview/evaluation</a></p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>算法相关</tag>
      </tags>
  </entry>
  <entry>
    <title>Zotero高效管理文献</title>
    <url>/2022/03/01/6_%E9%AB%98%E6%95%88tips/Zotero%E9%AB%98%E6%95%88%E7%AE%A1%E7%90%86%E6%96%87%E7%8C%AE/</url>
    <content><![CDATA[<p>Zotero高效管理文献</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h1><p>现在 Zotero 有两种主流的同步方式</p>
<ul>
<li>WebDAV 方式</li>
<li>Zotfile+Onedriver 方式</li>
</ul>
<p>两种同步方式源于对文件管理的不同：</p>
<p>第一种方式：如果直接把论文文件拖入 Zotero 中，它会在数据文件夹自动拷贝一份并建立无意义的文件夹。而 WebDAV 方式就是直接同步数据文件夹。</p>
<p>第二种方式：由于第一种文件存储方式的原因，拷贝一份浪费空间，也不便查找。因此 Zotfile+Onedriver 同步方式是个人（强迫症）推荐的。Zotfile 用来管理文件的存储路径而 onedriver 则用来同步文件本身。</p>
<p>两者选择一种即可，如何选择呢？</p>
<p>如果你完全使用 Zotero 管理论文不在意本地文件夹，那么 WebDAV 方式同步论文就很方便，同时还可以支持移动端预览。如果你忽略文件夹的问题，你会发现这种方式省心省力。</p>
<p>如果你还想使用本地文件夹管理，zotero 仅仅作为写论文时导入方便那么 Zotfile+Onedrive 的方式最合适（本人也习惯使用这种方式）</p>
<h2 id="WebDAV-方式"><a href="#WebDAV-方式" class="headerlink" title="WebDAV 方式"></a>WebDAV 方式</h2><p>选用坚果云进行同步配置</p>
<ul>
<li>申请坚果云账号 www.jianguoyun.com</li>
<li>在个人网盘页面右上角账户名找到“帐户信息”-“安全选项”</li>
<li>在第三方应用管理中添加应用，应用名称随意</li>
</ul>
<p>zotero 客户端</p>
<ul>
<li>编辑-首选项-同步</li>
<li>数据同步登录 zotero 账号即可</li>
<li>文件同步中选择 WebDAV</li>
<li>URL：使用刚刚坚果云给的服务器地址 dav.jianguoyun.com/dav</li>
<li>用户名：使用坚果云账号</li>
<li>密码：使用刚刚坚果云给的的应用密码</li>
</ul>
<h2 id="ZotFile-OneDriver"><a href="#ZotFile-OneDriver" class="headerlink" title="ZotFile+OneDriver"></a>ZotFile+OneDriver</h2><p>上文<strong>配置路径</strong>中提到由于 Zotero 下载的文件或者直接通过拖动导入的文件会随机建立文件夹管理。ZotFile 可以转换成正常文件夹。</p>
<p>下载地址：<a href="http://zotfile.com/">http://zotfile.com/</a></p>
<p>在“工具”-“插件”中进行安装</p>
<h3 id="配置路径"><a href="#配置路径" class="headerlink" title="配置路径"></a>配置路径</h3><p>现存的论文文件可以直接通过拖动到 zotero 中，但是 zotero 会拷贝一份论文文件到数据存储路径并且存储文件夹命名是随机字符。不方便本地管理。</p>
<p>因此推荐使用导入文件链接的形式导入论文。在此之前</p>
<ul>
<li>在设置界面选择“高级”-“文件和文件夹”</li>
<li>链接附件的根目录设定为你论文存储的最最最根目录，本人使用的是 onedrive 文件夹“E:\下载\OneDrive”。</li>
<li>设定为相对路径（方便同步）</li>
</ul>
<p>设定完成之后就可以通过链接导入。</p>
<p>如果你在另一台电脑（PC-B）上也是用 onedrive，那么论文文件就可以同步，同时由于我们使用的相对路径，只要在另一台电脑（PC-B）上 zotero 设定“链接附件的根目录”也为这台电脑（PC-B）的 onedrive 根路径，那么 zotero 中也可以直接双击打开附件。</p>
<h3 id="分类同步配置"><a href="#分类同步配置" class="headerlink" title="分类同步配置"></a>分类同步配置</h3><ul>
<li><strong>“工具”-“zotfile preference”</strong>打开设置界面</li>
<li>General Setting 中第一个路径看作你将使用 zotero 下载文件或者拖动文件时的缓存路径</li>
<li>第二个路径就是你常用的论文文件存储的根路径。（“E:\下载\OneDrive”）</li>
<li>配置完成后可以测试随意拖动一个文件到 zetero 的分类条目中，zotero 会私自建立乱码文件夹。然后右键条目 Manage attachments-rename attachments 。Zotfile 会自动在刚才设定的根目录根据你的分类建立文件夹并且讲论文文件放置到该目录下并在条目中设定文件链接。</li>
<li>这样就保持了你文件夹存储方式和 zotero 分类标签的同步</li>
<li>即使你在 zotero 移动你的论文分类标签，只需要重新执行 rename attachments 就可以再次整理本地文件夹</li>
<li>你也可以在 Renaming Rules 设定重命名的格式</li>
</ul>
<h3 id="几点注意"><a href="#几点注意" class="headerlink" title="几点注意"></a>几点注意</h3><ul>
<li>如果你选用 WebDAV 方式进行同步，那么如果想在移动端（iPad,手机）查看那么使用 <strong>PaperShip</strong>可以直接同步附件文件你可以理解成移动端的 Zotero</li>
<li>如果你使用 ZotFile+ 同步盘的方式，如果想在移动端阅读那么可以直接下载你同步盘的客户端，或者使用 zotero 的 Table 功能，移动端 PDF Expert 同步查看</li>
</ul>
<h1 id="协同"><a href="#协同" class="headerlink" title="协同"></a>协同</h1><h2 id="与-Word-协同"><a href="#与-Word-协同" class="headerlink" title="与 Word 协同"></a>与 Word 协同</h2><p>使用 word 书写论文配合 zotero 可以方便管理引用</p>
<ul>
<li>首先在 zotero 设置界面“引用”-“文字处理软件”安装 word 插件。</li>
<li>在 word 的 zotero 插件选项卡中，在你想插入的文章位置选择 Add/Edit Citation，选择需要的论文样式，如果没有可以在线搜索。选择要引用的论文就可以了。</li>
<li>之后在文章末尾，点击 Add/Edit Bibliography 插入参考文献具体内容。</li>
</ul>
<h2 id="与-GoogleScholar-协同"><a href="#与-GoogleScholar-协同" class="headerlink" title="与 GoogleScholar 协同"></a>与 GoogleScholar 协同</h2><p>有时候我们需要找一些参考文献，但是我们不需要下载文件内容只是知道引用格式即可。前提已经安装好 Zotero chrome 插件。</p>
<ul>
<li>在 Google Scholar 设置界面，找到“参考书目管理软件”选择显示导入 EndNotes(必须)，点击保存。</li>
<li>我们随便搜索论文，在每个条目下面有个导入 Endnote 按钮，点击会弹出对话框就可以使用 zotero 保存这篇文章的引用了。</li>
<li>同时你也可以点击 chrome 中的 zotero 插件图标多选保存，如果你在 zotero 设置了保存条目时自动附加 PDF 文档（常规-文字处理），他也会帮你把文件下载下来。</li>
</ul>
<h2 id="与-Tablet-协同"><a href="#与-Tablet-协同" class="headerlink" title="与 Tablet 协同"></a>与 Tablet 协同</h2><p>此方法是适用于 ZotFile+ 同步盘文件管理方式。</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzAxNzgyMDg0MQ==&amp;mid=2650457410&amp;idx=1&amp;sn=1198b535f1624ff63ff2f544c11e801c&amp;chksm=83d1d884b4a65192a238fd3fc2b0c4241b8768c2fc4e6ab927b8b669d99dcdd185278a83b3ee&amp;scene=158#rd">https://mp.weixin.qq.com/s?__biz=MzAxNzgyMDg0MQ==&amp;mid=2650457410&amp;idx=1&amp;sn=1198b535f1624ff63ff2f544c11e801c&amp;chksm=83d1d884b4a65192a238fd3fc2b0c4241b8768c2fc4e6ab927b8b669d99dcdd185278a83b3ee&amp;scene=158#rd</a></p>
<h2 id="与Latex协同"><a href="#与Latex协同" class="headerlink" title="与Latex协同"></a>与Latex协同</h2><p>有时候我们用word写完论文需要转为latex格式，其中引用部分很头疼。可以使用下面的工具直接从word中提取引用为bibtex格式，也可以选择在zotero选中引用论文，然后你可以将选中论文拖动到一个单独的分类下面，之后就可以用zotero自带的导出功能生成bibtex文件</p>
<p><a href="https://rintze.zelle.me/ref-extractor/">https://rintze.zelle.me/ref-extractor/</a></p>
<h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><p><a href="https://zhuanlan.zhihu.com/p/104848524">https://zhuanlan.zhihu.com/p/104848524</a> </p>
]]></content>
      <categories>
        <category>高效tips</category>
      </categories>
      <tags>
        <tag>高效tips</tag>
        <tag>default</tag>
      </tags>
  </entry>
  <entry>
    <title>marginnote</title>
    <url>/2022/03/01/6_%E9%AB%98%E6%95%88tips/marginnote/</url>
    <content><![CDATA[<p>marginnote</p>
<span id="more"></span>
<p>导出word的大纲，用word打开，完美！</p>
]]></content>
      <categories>
        <category>高效tips</category>
      </categories>
      <tags>
        <tag>高效tips</tag>
        <tag>default</tag>
      </tags>
  </entry>
  <entry>
    <title>拉普拉斯矩阵映射</title>
    <url>/2022/03/01/3_%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5%E6%98%A0%E5%B0%84/</url>
    <content><![CDATA[<p>拉普拉斯矩阵映射</p>
<span id="more"></span>
<h1 id="专业词汇"><a href="#专业词汇" class="headerlink" title="专业词汇"></a>专业词汇</h1><ul>
<li><strong>边（edge）</strong>：$W_{ij}$ 特点：对称矩阵</li>
<li><strong>digree</strong>: $D=dig(d);d=rowSum(W_{i,j]})$ 特点：对角阵</li>
<li><p><strong>拉普拉斯矩阵</strong>：$L=D-W$ </p>
</li>
<li><p><strong>拉普拉斯特征映射</strong>：将处于流形上的数据，在尽量保留原数据间相似度的情况下，映射到低维下表示</p>
</li>
</ul>
]]></content>
      <categories>
        <category>数理统计</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>数理统计</tag>
      </tags>
  </entry>
  <entry>
    <title>大话数据结构笔记</title>
    <url>/2022/03/01/3_%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>大话数据结构笔记</p>
<span id="more"></span>
<p>大话数据结构</p>
<p>[TOC]</p>
<h1 id="数据结构绪论"><a href="#数据结构绪论" class="headerlink" title="数据结构绪论"></a>数据结构绪论</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>数据项 -&gt; 数据元素 -&gt; 数据对象 -&gt; 数据结构</p>
<h2 id="逻辑结构与物理结构"><a href="#逻辑结构与物理结构" class="headerlink" title="逻辑结构与物理结构"></a>逻辑结构与物理结构</h2><blockquote>
<p>逻辑结构：集合，线性结构（1对1），树形结构（1对多），图形结构（多对多）</p>
<p>物理结构：</p>
<ul>
<li>顺序储存结构：元素放在连续的储存单元</li>
<li>链式储存结构：元素放在任意单元，用指针存放数据地址</li>
</ul>
</blockquote>
<h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><h2 id="算法时间复杂度"><a href="#算法时间复杂度" class="headerlink" title="算法时间复杂度"></a>算法时间复杂度</h2><h3 id="线性阶-O-n"><a href="#线性阶-O-n" class="headerlink" title="线性阶 O(n)"></a>线性阶 O(n)</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>,i&lt;n;i++)</span><br></pre></td></tr></table></figure>
<h3 id="对数阶-O-lodn"><a href="#对数阶-O-lodn" class="headerlink" title="对数阶 O(lodn)"></a>对数阶 O(lodn)</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> count=<span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (count&lt;n)</span><br><span class="line">&#123;</span><br><span class="line">    counc =count*<span class="number">2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="平方阶"><a href="#平方阶" class="headerlink" title="平方阶"></a>平方阶</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i,j;</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>,i&lt;n;i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span> (j=<span class="number">0</span>,j&lt;n;j++)</span><br><span class="line">    &#123;</span><br><span class="line">        .....</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>循环的时间复杂度=循环体的时间复杂度*循环运行时的次数</strong></p>
<h3 id="常见时间复杂度"><a href="#常见时间复杂度" class="headerlink" title="常见时间复杂度"></a>常见时间复杂度</h3><blockquote>
<p>O(1)&lt;O(logn) &lt; O(n) &lt; O(n^2) &lt; O(n!) &lt;O(n^n)</p>
</blockquote>
<h2 id="空间复杂度"><a href="#空间复杂度" class="headerlink" title="空间复杂度"></a>空间复杂度</h2><blockquote>
<p>S(n)=O(f(n)) 其中f(n)是n所占空间</p>
</blockquote>
<h1 id="线性表（List）"><a href="#线性表（List）" class="headerlink" title="线性表（List）"></a>线性表（List）</h1><h2 id="顺序储存"><a href="#顺序储存" class="headerlink" title="顺序储存"></a>顺序储存</h2><p>一维数组来实现顺序储存结构</p>
<blockquote>
<p>顺序储存结构的三个属性：</p>
<ol>
<li>起始位置：数组储存的地方</li>
<li>线性表最大储存容量：数组长度</li>
<li>线性表当前长度：length（任意时刻线性表长度应小于等于数组长度）</li>
</ol>
</blockquote>
<ul>
<li>地址计算方法：储存器中每个单元都有自己的编号，且编号是连续的，这个编号称为地址，假设一个元素占用c个储存空间(一个储存空间就是一个0/1)，LOC表示获得储存位置的函数，则$LOC(a_{i+1})=LOC(a-i)+c$</li>
<li>存取时间复杂度是O(1) ，即跟数据规模无关；插入删除时间复杂度是O(n)</li>
</ul>
<h1 id="栈（Stack）"><a href="#栈（Stack）" class="headerlink" title="栈（Stack）"></a>栈（Stack）</h1><p>仅在表尾插入和删除元素：后进先出的线性表</p>
<h1 id="串（string）"><a href="#串（string）" class="headerlink" title="串（string）"></a>串（string）</h1><blockquote>
<p>ASCII编码：8位二进制，一共能表示256个字符</p>
<p>Unicode编码：16位二进制</p>
</blockquote>
<h1 id="树"><a href="#树" class="headerlink" title="树"></a>树</h1><blockquote>
<p>度（degree）:结点中子树的数目</p>
</blockquote>
<h2 id="树的储存结构"><a href="#树的储存结构" class="headerlink" title="树的储存结构"></a>树的储存结构</h2>]]></content>
      <categories>
        <category>数理统计</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>数理统计</tag>
      </tags>
  </entry>
  <entry>
    <title>拉格朗日乘子法</title>
    <url>/2022/03/01/3_%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/</url>
    <content><![CDATA[<p>拉格朗日乘子法</p>
<span id="more"></span>
<h1 id="原始问题"><a href="#原始问题" class="headerlink" title="原始问题"></a>原始问题</h1><p>$f(x),c_i(x),h_i(x)$是在$R^n$上的<code>连续可微</code>函数，考虑约束最优化问题：</p>
<script type="math/tex; mode=display">
\begin{align}
min \quad f(x) \quad st \quad c_i(x)<0,i &=1,2...k  \\, 
h_j(x)=0,j &=1,2...l
\end{align}</script><p>此问题我们成为原始问题。</p>
<p>为了方便解决此问题，我们引入<strong><code>广义拉格朗日函数</code></strong>L，可证明原始问题等价于拉格朗日函数的极小极大值问题。拉格朗日函数构造如下：</p>
<script type="math/tex; mode=display">
L(x,\alpha_i,\beta_j)=f(x)+\sum_{i=1}^k\alpha_ic_i(x)+\sum_{j=1}^l\beta_jh_j(x)，其中 x\in R^n,\alpha_i>0,\beta_j>0</script><p>我们考虑x的函数：</p>
<script type="math/tex; mode=display">
\theta_p(x)=max \quad L(x,\alpha_i,\beta_j),其中 x\in R^n,\alpha_i>0,\beta_j>0</script><p>可以证明  $min(\theta_p(x)) $等价于原始问题,即约束下的优化问题转化为了广义拉格朗日的极小极大值问题。</p>
<p>【证明】约束下的优化问题转化为了广义拉格朗日的极小极大值问题</p>
<p>满足$c_i(x)&lt;0,i =1,2…k ,h_j(x)=0,j =1,2…l$时， $max(L(x,\alpha_i,\beta_j)) = f(x)$,即$\theta_p(x)=f(x)$。</p>
<p>不满足$c_i(x)&lt;0,i =1,2…k ,h_j(x)=0,j =1,2…l$时，可通过设置$\alpha_i 和\beta_j$ 使得$\theta_p(x)=+\infin $</p>
<p>所以</p>
<script type="math/tex; mode=display">
\theta_p=\begin{cases}f(x),x满足原始问题条件 \\ 
+\infin , x不满足原始问题条件
\end{cases}</script>]]></content>
      <categories>
        <category>数理统计</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>数理统计</tag>
      </tags>
  </entry>
  <entry>
    <title>股价问题动态规划</title>
    <url>/2022/03/01/3_%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%82%A1%E4%BB%B7%E9%97%AE%E9%A2%98%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/</url>
    <content><![CDATA[<p>股价问题动态规划</p>
<span id="more"></span>
<p>很多读者抱怨股票系列问题奇技淫巧太多，如果面试真的遇到这类问题，基本不会想到那些巧妙的办法，怎么办？所以本文拒绝奇技淫巧，而是稳扎稳打，只用一种通用方法解决所用问题，以不变应万变。</p>
<p>这篇文章用状态机的技巧来解决，可以全部提交通过。不要觉得这个名词高大上，文学词汇而已，实际上就是 DP table，看一眼就明白了。</p>
<p>先随便抽出一道题，看看别人的解法：</p>
<p>int maxProfit(vector<int>&amp; prices) {<br>    if(prices.empty()) return 0;<br>    int s1=-prices[0],s2=INT_MIN,s3=INT_MIN,s4=INT_MIN;</int></p>
<pre><code>for(int i=1;i&lt;prices.size();++i) &#123;            
    s1 = max(s1, -prices[i]);
    s2 = max(s2, s1+prices[i]);
    s3 = max(s3, s2-prices[i]);
    s4 = max(s4, s3+prices[i]);
&#125;
return max(0,s4);
</code></pre><p>}<br>能看懂吧？会做了吗？不可能的，你看不懂，这才正常。就算你勉强看懂了，下一个问题你还是做不出来。为什么别人能写出这么诡异却又高效的解法呢？因为这类问题是有框架的，但是人家不会告诉你的，因为一旦告诉你，你五分钟就学会了，该算法题就不再神秘，变得不堪一击了。</p>
<p>本文就来告诉你这个框架，然后带着你一道一道秒杀。</p>
<p>这 6 道股票买卖问题是有共性的，我们通过对第四题（限制最大交易次数为 k）的分析一道一道解决。因为第四题是一个最泛化的形式，其他的问题都是这个形式的简化。</p>
<p>第一题是只进行一次交易，相当于 k = 1；第二题是不限交易次数，相当于 k = +infinity（正无穷）；第三题是只进行 2 次交易，相当于 k = 2；剩下两道也是不限次数，但是加了交易「冷冻期」和「手续费」的额外条件，其实就是第二题的变种，都很容易处理。</p>
<p>一、穷举框架<br>首先，还是一样的思路：如何穷举？这里的穷举思路和上篇文章递归的思想不太一样。</p>
<p>递归其实是符合我们思考的逻辑的，一步步推进，遇到无法解决的就丢给递归，一不小心就做出来了，可读性还很好。缺点就是一旦出错，你也不容易找到错误出现的原因。比如上篇文章的递归解法，肯定还有计算冗余，但确实不容易找到。</p>
<p>而这里，我们不用递归思想进行穷举，而是利用「状态」进行穷举。我们具体到每一天，看看总共有几种可能的「状态」，再找出每个「状态」对应的「选择」。我们要穷举所有「状态」，穷举的目的是根据对应的「选择」更新状态。听起来抽象，你只要记住「状态」和「选择」两个词就行，下面实操一下就很容易明白了。</p>
<p>for 状态1 in 状态1的所有取值：<br>    for 状态2 in 状态2的所有取值：<br>        for …<br>            dp[状态1][状态2][…] = 择优(选择1，选择2…)<br>比如说这个问题，每天都有三种「选择」：买入、卖出、无操作，我们用 buy, sell, rest 表示这三种选择。但问题是，并不是每天都可以任意选择这三种选择的，因为 sell 必须在 buy 之后，buy 必须在 sell 之后。那么 rest 操作还应该分两种状态，一种是 buy 之后的 rest（持有了股票），一种是 sell 之后的 rest（没有持有股票）。而且别忘了，我们还有交易次数 k 的限制，就是说你 buy 还只能在 k &gt; 0 的前提下操作。</p>
<p>很复杂对吧，不要怕，我们现在的目的只是穷举，你有再多的状态，老夫要做的就是一把梭全部列举出来。这个问题的「状态」有三个，第一个是天数，第二个是允许交易的最大次数，第三个是当前的持有状态（即之前说的 rest 的状态，我们不妨用 1 表示持有，0 表示没有持有）。然后我们用一个三维数组就可以装下这几种状态的全部组合：</p>
<p>dp[i][k][0 or 1]<br>0 &lt;= i &lt;= n-1, 1 &lt;= k &lt;= K<br>n 为天数，大 K 为最多交易数<br>此问题共 n × K × 2 种状态，全部穷举就能搞定。</p>
<p>for 0 &lt;= i &lt; n:<br>    for 1 &lt;= k &lt;= K:<br>        for s in {0, 1}:<br>            dp[i][k][s] = max(buy, sell, rest)<br>而且我们可以用自然语言描述出每一个状态的含义，比如说 dp[3][2][1] 的含义就是：今天是第三天，我现在手上持有着股票，至今最多进行 2 次交易。再比如 dp[2][3][0] 的含义：今天是第二天，我现在手上没有持有股票，至今最多进行 3 次交易。很容易理解，对吧？</p>
<p>我们想求的最终答案是 dp[n - 1][K][0]，即最后一天，最多允许 K 次交易，最多获得多少利润。读者可能问为什么不是 dp[n - 1][K][1]？因为 [1] 代表手上还持有股票，[0] 表示手上的股票已经卖出去了，很显然后者得到的利润一定大于前者。</p>
<p>记住如何解释「状态」，一旦你觉得哪里不好理解，把它翻译成自然语言就容易理解了。</p>
<p>二、状态转移框架<br>现在，我们完成了「状态」的穷举，我们开始思考每种「状态」有哪些「选择」，应该如何更新「状态」。只看「持有状态」，可以画个状态转移图。</p>
<p>通过这个图可以很清楚地看到，每种状态（0 和 1）是如何转移而来的。根据这个图，我们来写一下状态转移方程：</p>
<p>dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i])<br>              max(   选择 rest  ,           选择 sell      )</p>
<p>解释：今天我没有持有股票，有两种可能：<br>要么是我昨天就没有持有，然后今天选择 rest，所以我今天还是没有持有；<br>要么是我昨天持有股票，但是今天我 sell 了，所以我今天没有持有股票了。</p>
<p>dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i])<br>              max(   选择 rest  ,           选择 buy         )</p>
<p>解释：今天我持有着股票，有两种可能：<br>要么我昨天就持有着股票，然后今天选择 rest，所以我今天还持有着股票；<br>要么我昨天本没有持有，但今天我选择 buy，所以今天我就持有股票了。<br>这个解释应该很清楚了，如果 buy，就要从利润中减去 prices[i]，如果 sell，就要给利润增加 prices[i]。今天的最大利润就是这两种可能选择中较大的那个。而且注意 k 的限制，我们在选择 buy 的时候，把 k 减小了 1，很好理解吧，当然你也可以在 sell 的时候减 1，一样的。</p>
<p>现在，我们已经完成了动态规划中最困难的一步：状态转移方程。如果之前的内容你都可以理解，那么你已经可以秒杀所有问题了，只要套这个框架就行了。不过还差最后一点点，就是定义 base case，即最简单的情况。</p>
<p>dp[-1][k][0] = 0<br>解释：因为 i 是从 0 开始的，所以 i = -1 意味着还没有开始，这时候的利润当然是 0 。<br>dp[-1][k][1] = -infinity<br>解释：还没开始的时候，是不可能持有股票的，用负无穷表示这种不可能。<br>dp[i][0][0] = 0<br>解释：因为 k 是从 1 开始的，所以 k = 0 意味着根本不允许交易，这时候利润当然是 0 。<br>dp[i][0][1] = -infinity<br>解释：不允许交易的情况下，是不可能持有股票的，用负无穷表示这种不可能。<br>把上面的状态转移方程总结一下：</p>
<p>base case：<br>dp[-1][k][0] = dp[i][0][0] = 0<br>dp[-1][k][1] = dp[i][0][1] = -infinity</p>
<p>状态转移方程：<br>dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i])<br>dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i])<br>读者可能会问，这个数组索引是 -1 怎么编程表示出来呢，负无穷怎么表示呢？这都是细节问题，有很多方法实现。现在完整的框架已经完成，下面开始具体化。</p>
<p>三、秒杀题目<br>第一题，k = 1</p>
<p>直接套状态转移方程，根据 base case，可以做一些化简：</p>
<p>dp[i][1][0] = max(dp[i-1][1][0], dp[i-1][1][1] + prices[i])<br>dp[i][1][1] = max(dp[i-1][1][1], dp[i-1][0][0] - prices[i])<br>            = max(dp[i-1][1][1], -prices[i])<br>解释：k = 0 的 base case，所以 dp[i-1][0][0] = 0。</p>
<p>现在发现 k 都是 1，不会改变，即 k 对状态转移已经没有影响了。<br>可以进行进一步化简去掉所有 k：<br>dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i])<br>dp[i][1] = max(dp[i-1][1], -prices[i])<br>直接写出代码：</p>
<p>int n = prices.length;<br>int[][] dp = new int[n][2];<br>for (int i = 0; i &lt; n; i++) {<br>    dp[i][0] = Math.max(dp[i-1][0], dp[i-1][1] + prices[i]);<br>    dp[i][1] = Math.max(dp[i-1][1], -prices[i]);<br>}<br>return dp[n - 1][0];<br>显然 i = 0 时 dp[i-1] 是不合法的。这是因为我们没有对 i 的 base case 进行处理。可以这样处理：</p>
<p>for (int i = 0; i &lt; n; i++) {<br>    if (i - 1 == -1) {<br>        dp[i][0] = 0;<br>        // 解释：<br>        //   dp[i][0]<br>        // = max(dp[-1][0], dp[-1][1] + prices[i])<br>        // = max(0, -infinity + prices[i]) = 0<br>        dp[i][1] = -prices[i];<br>        //解释：<br>        //   dp[i][1]<br>        // = max(dp[-1][1], dp[-1][0] - prices[i])<br>        // = max(-infinity, 0 - prices[i])<br>        // = -prices[i]<br>        continue;<br>    }<br>    dp[i][0] = Math.max(dp[i-1][0], dp[i-1][1] + prices[i]);<br>    dp[i][1] = Math.max(dp[i-1][1], -prices[i]);<br>}<br>return dp[n - 1][0];<br>第一题就解决了，但是这样处理 base case 很麻烦，而且注意一下状态转移方程，新状态只和相邻的一个状态有关，其实不用整个 dp 数组，只需要一个变量储存相邻的那个状态就足够了，这样可以把空间复杂度降到 O(1):</p>
<p>// k == 1<br>int maxProfit_k_1(int[] prices) {<br>    int n = prices.length;<br>    // base case: dp[-1][0] = 0, dp[-1][1] = -infinity<br>    int dp_i_0 = 0, dp_i_1 = Integer.MIN_VALUE;<br>    for (int i = 0; i &lt; n; i++) {<br>        // dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i])<br>        dp_i_0 = Math.max(dp_i_0, dp_i_1 + prices[i]);<br>        // dp[i][1] = max(dp[i-1][1], -prices[i])<br>        dp_i_1 = Math.max(dp_i_1, -prices[i]);<br>    }<br>    return dp_i_0;<br>}<br>两种方式都是一样的，不过这种编程方法简洁很多。但是如果没有前面状态转移方程的引导，是肯定看不懂的。后续的题目，我主要写这种空间复杂度 O(1) 的解法。</p>
<p>第二题，k = +infinity</p>
<p>如果 k 为正无穷，那么就可以认为 k 和 k - 1 是一样的。可以这样改写框架：</p>
<p>dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i])<br>dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i])<br>            = max(dp[i-1][k][1], dp[i-1][k][0] - prices[i])</p>
<p>我们发现数组中的 k 已经不会改变了，也就是说不需要记录 k 这个状态了：<br>dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i])<br>dp[i][1] = max(dp[i-1][1], dp[i-1][0] - prices[i])<br>直接翻译成代码：</p>
<p>int maxProfit_k_inf(int[] prices) {<br>    int n = prices.length;<br>    int dp_i_0 = 0, dp_i_1 = Integer.MIN_VALUE;<br>    for (int i = 0; i &lt; n; i++) {<br>        int temp = dp_i_0;<br>        dp_i_0 = Math.max(dp_i_0, dp_i_1 + prices[i]);<br>        dp_i_1 = Math.max(dp_i_1, temp - prices[i]);<br>    }<br>    return dp_i_0;<br>}<br>第三题，k = +infinity with cooldown</p>
<p>每次 sell 之后要等一天才能继续交易。只要把这个特点融入上一题的状态转移方程即可：</p>
<p>dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i])<br>dp[i][1] = max(dp[i-1][1], dp[i-2][0] - prices[i])<br>解释：第 i 天选择 buy 的时候，要从 i-2 的状态转移，而不是 i-1 。<br>翻译成代码：</p>
<p>int maxProfit_with_cool(int[] prices) {<br>    int n = prices.length;<br>    int dp_i_0 = 0, dp_i_1 = Integer.MIN_VALUE;<br>    int dp_pre_0 = 0; // 代表 dp[i-2][0]<br>    for (int i = 0; i &lt; n; i++) {<br>        int temp = dp_i_0;<br>        dp_i_0 = Math.max(dp_i_0, dp_i_1 + prices[i]);<br>        dp_i_1 = Math.max(dp_i_1, dp_pre_0 - prices[i]);<br>        dp_pre_0 = temp;<br>    }<br>    return dp_i_0;<br>}<br>第四题，k = +infinity with fee</p>
<p>每次交易要支付手续费，只要把手续费从利润中减去即可。改写方程：</p>
<p>dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i])<br>dp[i][1] = max(dp[i-1][1], dp[i-1][0] - prices[i] - fee)<br>解释：相当于买入股票的价格升高了。<br>在第一个式子里减也是一样的，相当于卖出股票的价格减小了。<br>直接翻译成代码：</p>
<p>int maxProfit_with_fee(int[] prices, int fee) {<br>    int n = prices.length;<br>    int dp_i_0 = 0, dp_i_1 = Integer.MIN_VALUE;<br>    for (int i = 0; i &lt; n; i++) {<br>        int temp = dp_i_0;<br>        dp_i_0 = Math.max(dp_i_0, dp_i_1 + prices[i]);<br>        dp_i_1 = Math.max(dp_i_1, temp - prices[i] - fee);<br>    }<br>    return dp_i_0;<br>}<br>第五题，k = 2</p>
<p>k = 2 和前面题目的情况稍微不同，因为上面的情况都和 k 的关系不太大。要么 k 是正无穷，状态转移和 k 没关系了；要么 k = 1，跟 k = 0 这个 base case 挨得近，最后也没有存在感。</p>
<p>这道题 k = 2 和后面要讲的 k 是任意正整数的情况中，对 k 的处理就凸显出来了。我们直接写代码，边写边分析原因。</p>
<p>原始的动态转移方程，没有可化简的地方<br>dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i])<br>dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i])<br>按照之前的代码，我们可能想当然这样写代码（错误的）：</p>
<p>int k = 2;<br>int[][][] dp = new int[n][k + 1][2];<br>for (int i = 0; i &lt; n; i++)<br>    if (i - 1 == -1) { /<em> 处理一下 base case</em>/ }<br>    dp[i][k][0] = Math.max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]);<br>    dp[i][k][1] = Math.max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]);<br>}<br>return dp[n - 1][k][0];<br>为什么错误？我这不是照着状态转移方程写的吗？</p>
<p>还记得前面总结的「穷举框架」吗？就是说我们必须穷举所有状态。其实我们之前的解法，都在穷举所有状态，只是之前的题目中 k 都被化简掉了。这道题由于没有消掉 k 的影响，所以必须要对 k 进行穷举：</p>
<p>int max_k = 2;<br>int[][][] dp = new int[n][max_k + 1][2];<br>for (int i = 0; i &lt; n; i++) {<br>    for (int k = max_k; k &gt;= 1; k—) {<br>        if (i - 1 == -1) {<br>            /<em> 处理 base case </em>/<br>            dp[i][k][0] = 0;<br>            dp[i][k][1] = -prices[i];<br>            continue;<br>        }<br>        dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]);<br>        dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]);<br>    }<br>}<br>// 穷举了 n × max_k × 2 个状态，正确。<br>return dp[n - 1][max_k][0];<br>如果你不理解，可以返回第一点「穷举框架」重新阅读体会一下。</p>
<p>这里 k 取值范围比较小，所以可以不用 for 循环，直接把 k = 1 和 2 的情况手动列举出来也可以：</p>
<p>dp[i][2][0] = max(dp[i-1][2][0], dp[i-1][2][1] + prices[i])<br>dp[i][2][1] = max(dp[i-1][2][1], dp[i-1][1][0] - prices[i])<br>dp[i][1][0] = max(dp[i-1][1][0], dp[i-1][1][1] + prices[i])<br>dp[i][1][1] = max(dp[i-1][1][1], -prices[i])</p>
<p>int maxProfit_k_2(int[] prices) {<br>    int dp_i10 = 0, dp_i11 = Integer.MIN_VALUE;<br>    int dp_i20 = 0, dp_i21 = Integer.MIN_VALUE;<br>    for (int price : prices) {<br>        dp_i20 = Math.max(dp_i20, dp_i21 + price);<br>        dp_i21 = Math.max(dp_i21, dp_i10 - price);<br>        dp_i10 = Math.max(dp_i10, dp_i11 + price);<br>        dp_i11 = Math.max(dp_i11, -price);<br>    }<br>    return dp_i20;<br>}<br>有状态转移方程和含义明确的变量名指导，相信你很容易看懂。其实我们可以故弄玄虚，把上述四个变量换成 a, b, c, d。这样当别人看到你的代码时就会一头雾水，大惊失色，不得不对你肃然起敬。</p>
<p>第六题，k = any integer</p>
<p>有了上一题 k = 2 的铺垫，这题应该和上一题的第一个解法没啥区别。但是出现了一个超内存的错误，原来是传入的 k 值会非常大，dp 数组太大了。现在想想，交易次数 k 最多有多大呢？</p>
<p>一次交易由买入和卖出构成，至少需要两天。所以说有效的限制 k 应该不超过 n/2，如果超过，就没有约束作用了，相当于 k = +infinity。这种情况是之前解决过的。</p>
<p>直接把之前的代码重用：</p>
<p>int maxProfit_k_any(int max_k, int[] prices) {<br>    int n = prices.length;<br>    if (max_k &gt; n / 2)<br>        return maxProfit_k_inf(prices);</p>
<pre><code>int[][][] dp = new int[n][max_k + 1][2];
for (int i = 0; i &lt; n; i++) 
    for (int k = max_k; k &gt;= 1; k--) &#123;
        if (i - 1 == -1) &#123; 
            /* 处理 base case */
            dp[i][k][0] = 0;
            dp[i][k][1] = -prices[i];
            continue;
        &#125;
        dp[i][k][0] = max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]);
        dp[i][k][1] = max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]);     
    &#125;
return dp[n - 1][max_k][0];
</code></pre><p>}<br>至此，6 道题目通过一个状态转移方程全部解决。</p>
<p>四、最后总结<br>本文给大家讲了如何通过状态转移的方法解决复杂的问题，用一个状态转移方程秒杀了 6 道股票买卖问题，现在想想，其实也不算难对吧？这已经属于动态规划问题中较困难的了。</p>
<p>关键就在于列举出所有可能的「状态」，然后想想怎么穷举更新这些「状态」。一般用一个多维 dp 数组储存这些状态，从 base case 开始向后推进，推进到最后的状态，就是我们想要的答案。想想这个过程，你是不是有点理解「动态规划」这个名词的意义了呢？</p>
<p>具体到股票买卖问题，我们发现了三个状态，使用了一个三维数组，无非还是穷举 + 更新，不过我们可以说的高大上一点，这叫「三维 DP」，怕不怕？这个大实话一说，立刻显得你高人一等，名利双收有没有。</p>
<p>所以，大家不要被各种高大上的名词吓到，再多的困难问题，奇技淫巧，也不过是基本套路的不断升级组合产生的。只要把住算法的底层原理，即可举一反三，逐个击破。</p>
<p>作者：labuladong<br>链接：<a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/solution/yi-ge-fang-fa-tuan-mie-6-dao-gu-piao-wen-ti-by-l-3/">https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/solution/yi-ge-fang-fa-tuan-mie-6-dao-gu-piao-wen-ti-by-l-3/</a><br>来源：力扣（LeetCode）<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
]]></content>
      <categories>
        <category>数理统计</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>数理统计</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论与数理统计--浙大</title>
    <url>/2022/03/01/3_%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1--%E6%B5%99%E5%A4%A7/</url>
    <content><![CDATA[<p>概率论与数理统计—浙大</p>
<span id="more"></span>
<p>[TOC]</p>
<p>概率论与数理统计—浙大</p>
<h1 id="期望"><a href="#期望" class="headerlink" title="期望"></a>期望</h1><h2 id="离散期望"><a href="#离散期望" class="headerlink" title="离散期望"></a>离散期望</h2><script type="math/tex; mode=display">
   E(X)=\sum_1^{\infty}x_kp_k</script><h2 id="连续数学期望"><a href="#连续数学期望" class="headerlink" title="连续数学期望"></a>连续数学期望</h2><script type="math/tex; mode=display">
   E(X) = \int_{-\infty}^{\infty}xf(s)</script><h2 id="函数的数学期望"><a href="#函数的数学期望" class="headerlink" title="函数的数学期望"></a>函数的数学期望</h2><script type="math/tex; mode=display">
Z=g(X<Y),二维随机变量的概率密度(X,Y)为f(x,y),则Z的期望：</script><script type="math/tex; mode=display">
   E(Z) = E(g(Z)) = \int_{-\infty}^{+\infty}g(x,y)f(x,y)dxdy</script><p>   若（X，Y）为离散型随机变量，则：</p>
<script type="math/tex; mode=display">
   E(Z) = E(g(X,Y)) = \sum_{j=1}^{\infty}\sum_{i=1}^{\infty}g(x_i,y_j)p_{ij}</script><h1 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h1><script type="math/tex; mode=display">
D(X)=E([X-E(X)]^2)</script><h2 id="均方差-标准差"><a href="#均方差-标准差" class="headerlink" title="均方差/标准差"></a>均方差/标准差</h2><script type="math/tex; mode=display">
   \sqrt{(D(X))}</script><h2 id="离散方差"><a href="#离散方差" class="headerlink" title="离散方差"></a>离散方差</h2><script type="math/tex; mode=display">
   D(X) =\sum_{k=1}^{\infty}[x-E(x)]^2p_k</script><h2 id="连续方差"><a href="#连续方差" class="headerlink" title="连续方差"></a>连续方差</h2><script type="math/tex; mode=display">
   D(X)=\int_{-\infty}^{\infty}[x-E(X)]^2f(x)dx</script><script type="math/tex; mode=display">
   D(X) = E(X^2)-(E(X))^2</script><h2 id="标准化变换"><a href="#标准化变换" class="headerlink" title="标准化变换"></a>标准化变换</h2><script type="math/tex; mode=display">
   X^* = \frac{X-\mu}{\sigma}</script><p>   $X^*$均值为1，方差为0，是X的标准化变量</p>
<h1 id="切比雪夫不等式"><a href="#切比雪夫不等式" class="headerlink" title="切比雪夫不等式"></a>切比雪夫不等式</h1><p>估计未知概率分布的变量取期望附近区间的概率，这个估计是粗糙的</p>
<p>对于任意正数$\epsilon$:</p>
<p>$P{|X-\mu|&gt;=\epsilon} &lt;=\frac{\sigma^2}{\epsilon^2}$</p>
<h1 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h1><p>   $Cov(X,Y) = E{[X-E(X)][Y-E(Y)]}$ 称为X，Y的协方差</p>
<p>   $\rho_{XY} = \frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}$  称为X，Y的相关系数。</p>
<h2 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h2><p>两个随机变量X，Y相互独立的充要条件是$Cove(X,Y)\neq0$</p>
<ul>
<li>$Cov(X,X) = D(X)$</li>
<li>$Cov(X,Y) = E(XY) - E(X)E(Y)$</li>
<li>$Cov(aX,bY) = abCov(X,Y)$</li>
<li>$Cov(X_1+X_2,Y) = Cov(X_1,Y)+Cov(X_2,Y)$</li>
<li>$|\rho_{xy}|\le1$</li>
<li>$|\rho|=1$ 的充要条件是存在常数a,b 使得</li>
<li>$P\{Y=aX+b\}=1$</li>
</ul>
<h1 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h1><p>若总体X属于离散型，其分布规律$P\{X=x\} = p(x;\theta)$形式已知，参数未知，事件$\{X_1=x_1,X_2=x_2 …\}$的联合概率：</p>
<p>$L(\theta) = L(x_1,x_2…;\theta) = \prod_{i=1}^{n}p(x_1;\theta)$</p>
<p>$L(\theta)$为样本的似然函数</p>
<ul>
<li>若总体X属于连续型</li>
</ul>
<p>$L(\theta) = \prod_{i=1}^{n}f(x_1;\theta)$</p>
<ul>
<li><p>对数似然方程</p>
<p> $\frac{d}{d\theta}lnL(\theta)=0$</p>
</li>
<li><p>无偏估计</p>
<p> 估计值的期望和实际值期望相同</p>
</li>
</ul>
]]></content>
      <categories>
        <category>数理统计</category>
      </categories>
      <tags>
        <tag>default</tag>
        <tag>数理统计</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型100问</title>
    <url>/2022/03/04/obsidian/20240225-%E5%A4%A7%E6%A8%A1%E5%9E%8B100%E9%97%AE/</url>
    <content><![CDATA[<ol>
<li><strong>transformer是什么？用于处理什么问题？长什么样？</strong><br>transformer是一种深度学习模型，由Google Brain团队在2017年《attention is all you need 》中首次提出，用于解决自然语言处理中的Seq2Seq类任务，如机器翻译任务。</li>
</ol>
<p>其核心创新点是完全采用注意力机制处理序列类数据，该方法能有效解决传统的RNN和CNN类序列处理方法存在的梯度消失/爆炸和无法并行的问题。</p>
<p>具体来说，transformer包括编码器和解码器两个部分，编码器通过自注意力机制对输入序列进行编码，核心思想是用输入序列中的上下文的加权表示当前字（Multi-head Attention）；解码器先用生成的前序序列表示当前词(Masked Multi-head Attention), 再用编码器编码过的输入序列表示当前字（Multi-head Attention）,最后以当前词的表示作为输入，预测下一个词。 </p>
<p>由于attention机制没有序的概念，还会通过position embedding的方式将词的位置信息融入词的编码中。同时会增加LayerNorm和ResNet时模型更容易收敛；通过FFN对每个词的编码先升维再降维，增加模型表达能力。<img src="/2022/03/04/obsidian/20240225-%E5%A4%A7%E6%A8%A1%E5%9E%8B100%E9%97%AE/20240225-大模型100问/image-20240225155727980.png" alt="|250"><br>transformer模型的提出不仅在机器翻译任务上取得突破性性能，其构架也称为了后续很多NLP模型的基础，如Bert、GPT等，甚至是CV领域。<br>transformer在CV领域的成功运用通常归功于Google Research在2020年提出的Vision Transformer[1]，用于图片分类任务，其核心思想是把图片分成很多个小块(patch)，每个patch是一个向量，拼接后一张图片的表示就类似于一个句子的表示，通过transformer进行编码，然后预测目标类别。</p>
<ol>
<li><strong>如何计算大模型参数计算量</strong><br><a href="https://zhuanlan.zhihu.com/p/624740065">分析transformer模型的参数量、计算量、中间激活、KV cache</a><br>gpt参数量计算方法</li>
</ol>
<ul>
<li>MHA：4个h×h的矩阵（QKV的三个和最后线性变换的一个）</li>
<li>AddAndNorm 忽略不计</li>
<li>feed forward： h先升维到4h再降维到h,  8hxh+5h<br>L个transformer堆叠的模型参数量$L(12h^2+5h+Vh)$  V是词表大小。忽略一次项即12Lh^2<br><img src="/2022/03/04/obsidian/20240225-%E5%A4%A7%E6%A8%A1%E5%9E%8B100%E9%97%AE/20240225-大模型100问/image-20240225200352419.png" alt><br><img src="/2022/03/04/obsidian/20240225-%E5%A4%A7%E6%A8%A1%E5%9E%8B100%E9%97%AE/20240225-大模型100问/image-20240225194708508.png" alt></li>
</ul>
<p>上面是一个简化的算法，multi-head attention也符合这个参数量，但实际上需要分head计算再组合，即还是通过同样大小的三个W矩阵对QKV进行线性变换后拆分成n_head组QKV，每一组的h’=h/n_head, 每组attention后得到n_head个维度为h’的向量，concat到一起后进行一个线性变换。</p>
<p>gpt3 L=96，h=12288，词表 计算得到1.74×10^11</p>
<ol>
<li><strong>GPT系列的参数量是多少</strong><br>参考<a href="https://zhuanlan.zhihu.com/p/656192138">GPT系列解读（一）</a><br>GPT系列有大大小小很多个模型，175B参数的是GPT3的参数量，GPT3.5是在GPT3的基础上+指令调优和RLHF，参数量估计也是175B。gpt-3.5-turbo是经过蒸馏的，实际参数可能十几亿。<img src="/2022/03/04/obsidian/20240225-%E5%A4%A7%E6%A8%A1%E5%9E%8B100%E9%97%AE/03/04/obsidian/20240225-%E5%A4%A7%E6%A8%A1%E5%9E%8B100%E9%97%AE/image-20240225201622511-8926674.png" class title="image-20240225201622511.png">
<img src="/2022/03/04/obsidian/20240225-%E5%A4%A7%E6%A8%A1%E5%9E%8B100%E9%97%AE/03/04/obsidian/20240225-%E5%A4%A7%E6%A8%A1%E5%9E%8B100%E9%97%AE/image-20240225202845150.png" class title="GPT系列技术对比">
</li>
</ol>
<p>L: transformer block数，n_head:头数，V:词表大，h:隐层大小，max_token：最长上下文长度</p>
<ul>
<li>GPT-1：      L=12,n_head=12,h=768,V=50257,max_token=512,参数量0.1B</li>
<li>GPT-2(XL): L=48,n_head=64,h=1600, V=50257,  max_token=1024, 参数量1.5B</li>
<li>GPT-3：     L=96,n_head=96,h=12288, V=50257,  max_token=4K/16K(3.5-turbo)/32K?, 参数量1.5B，训练数据45T<img src="/2022/03/04/obsidian/20240225-%E5%A4%A7%E6%A8%A1%E5%9E%8B100%E9%97%AE/03/04/obsidian/20240225-%E5%A4%A7%E6%A8%A1%E5%9E%8B100%E9%97%AE/image-20240225203858573.png" class title="image-20240225203858573.png"></li>
</ul>
<ol>
<li><p><strong>手写GPT代码</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LlamaAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Multi-headed attention from &#x27;Attention Is All You Need&#x27; paper&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, config: LlamaConfig</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.config = config</span><br><span class="line">        self.hidden_size = config.hidden_size</span><br><span class="line">        self.num_heads = config.num_attention_heads</span><br><span class="line">        self.head_dim = self.hidden_size // self.num_heads</span><br><span class="line">        self.max_position_embeddings = config.max_position_embeddings</span><br><span class="line"></span><br><span class="line">        self.q_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=<span class="literal">False</span>)</span><br><span class="line">        self.k_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=<span class="literal">False</span>)</span><br><span class="line">        self.v_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=<span class="literal">False</span>)</span><br><span class="line">        self.o_proj = nn.Linear(self.num_heads * self.head_dim, self.hidden_size, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        hidden_states: torch.Tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">        attention_mask: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        position_ids: <span class="type">Optional</span>[torch.LongTensor] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        past_key_value: <span class="type">Optional</span>[<span class="type">Tuple</span>[torch.Tensor]] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        output_attentions: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        use_cache: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, <span class="type">Optional</span>[torch.Tensor], <span class="type">Optional</span>[<span class="type">Tuple</span>[torch.Tensor]]]:</span></span><br><span class="line">        bsz, q_len, _ = hidden_states.size()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获得qkv向量</span></span><br><span class="line">        query_states = self.q_proj(hidden_states).view(bsz, q_len, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        key_states = self.k_proj(hidden_states).view(bsz, q_len, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        value_states = self.v_proj(hidden_states).view(bsz, q_len, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 拼接kvcache</span></span><br><span class="line">        kv_seq_len = key_states.shape[-<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">if</span> past_key_value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            kv_seq_len += past_key_value[<span class="number">0</span>].shape[-<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> past_key_value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># reuse k, v, self_attention</span></span><br><span class="line">            key_states = torch.cat([past_key_value[<span class="number">0</span>], key_states], dim=<span class="number">2</span>)</span><br><span class="line">            value_states = torch.cat([past_key_value[<span class="number">1</span>], value_states], dim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        past_key_value = (key_states, value_states) <span class="keyword">if</span> use_cache <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算attention权重</span></span><br><span class="line">        attn_weights = torch.matmul(query_states, key_states.transpose(<span class="number">2</span>, <span class="number">3</span>)) / math.sqrt(self.head_dim)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加入mask矩阵，decoder-only为下三角</span></span><br><span class="line">        <span class="keyword">if</span> attention_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            attn_weights = attn_weights + attention_mask</span><br><span class="line">            dtype_min = torch.tensor(</span><br><span class="line">                torch.finfo(attn_weights.dtype).<span class="built_in">min</span>, device=attn_weights.device, dtype=attn_weights.dtype</span><br><span class="line">            )</span><br><span class="line">            attn_weights = torch.<span class="built_in">max</span>(attn_weights, dtype_min)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算softmax，这里需要从fp16升为fp32</span></span><br><span class="line">        <span class="comment"># upcast attention to fp32</span></span><br><span class="line">        attn_weights = nn.functional.softmax(attn_weights, dim=-<span class="number">1</span>, dtype=torch.float32).to(query_states.dtype)</span><br><span class="line">        attn_output = torch.matmul(attn_weights, value_states)</span><br><span class="line"></span><br><span class="line">        attn_output = attn_output.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        attn_output = attn_output.reshape(bsz, q_len, self.hidden_size)</span><br><span class="line"></span><br><span class="line">        attn_output = self.o_proj(attn_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> output_attentions:</span><br><span class="line">            attn_weights = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> attn_output, attn_weights, past_key_value</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>NLU和NLG的区别</strong><br>NLU（Neural Language Understanding）是自然语言理解，通常是分类模型：文本分类，意图识别，关系抽取，阅读理解等<br>NLG(Neural Language Genaration )是自然语言生成，通常是生成模型：机器翻译、文本摘要、故事续写、问答等</p>
</li>
<li><p><strong>BPE 和BBPE的区别是什么</strong><br>二者都是NLP领域的分词方法（tokenization）.BPE（Byte Pair Encoding）是字符级别的分词方法，即以字符为最小单位，逐步合并频率最高的字符对，直到达到预设词表大小。可有效减少词表的大小。BBPE（Byte-level Byte Pair Encoding）是以字节为单位，UTF-8中每个字符可以用1~4个字节表示，在字节粒度进行合并生成词表，该方法理论上可以表示任何字符，对多语言支持好，可有效解决OOV（Out Of Vocalbulary）问题.</p>
</li>
<li><p><strong>bert参数量计算</strong><br>bert-base: L=12，h=768,V=30522,max_token=512,参数量110M<br>bert-Large: L=24, h=1024,</p>
</li>
<li><p><strong>参数量和显存、模型大小之间的关系</strong><br>参考<a href="https://zhuanlan.zhihu.com/p/624740065">分析transformer模型的参数量、计算量、中间激活、KV cache</a></p>
</li>
</ol>
<ul>
<li>推理时显存的下限是 2n GB ，至少要把模型加载完全。</li>
<li>训练时，如果用Adam优化器，有个<strong>2+2+12</strong>的公式，<strong>训练时显存下限是16n GB</strong>，需要把模型参数、梯度和优化器状态（4+4+4），保持在显存，具体可以参考微软的ZeRO论文。</li>
</ul>
<ol>
<li><p><strong>attention为什么要进行scaling?</strong><br>防止随着h增大导致内积QK内积过大</p>
</li>
<li><p><strong>为什么transformer要用LayerNorm,可以用BatchNorm吗？</strong><br>norm是为了防止梯度爆炸或小时，不能用batchNorm, LayerNorm是每个样本的每一层进行归一化，保证各个特征之间的相对大小；batchNorm是batch内样本间同一个特征的归一化，保证样本间的相对大小。NLP的样本间没有关系，输入的词序列间有关系，所以应该用LayerNorm</p>
</li>
<li><p>transformer为什么要用三个不一样的QKV</p>
</li>
<li>Bert中为什么要在开头加个[CLS]?</li>
<li>有什么技术降低复杂度提升输入长度的？</li>
<li>Bert是如何处理传统方法难以搞定的溢出词表词(oov)的语义学习的？</li>
<li>中文是如何处理溢出词表词(oov)的语义学习的？</li>
<li>Bert如何处理一词多义？</li>
<li>Bert中的transformer和原生的transformer有什么区别？</li>
</ol>
<p>[1]: |Dosovitskiy A, Beyer L, Kolesnikov A, et al. An image is worth 16x16 words: Transformers for image recognition at scale[J]. arXiv preprint arXiv:2010.11929, 2020</p>
]]></content>
      <categories>
        <category>算法相关</category>
      </categories>
      <tags>
        <tag>算法相关</tag>
        <tag>调研</tag>
      </tags>
  </entry>
</search>
