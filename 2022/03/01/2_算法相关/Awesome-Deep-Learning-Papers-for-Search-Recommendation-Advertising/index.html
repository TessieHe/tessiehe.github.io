<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">



<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"tessiehe.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>




  <meta name="description" content="搜广推领域文献阅读，文献整理来源于git仓库  Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising 【to粗】表示待粗读 【粗】表示已粗读 【to精】表示待精读 【精】表示已精读 没有标注表示还没看">
<meta property="og:type" content="article">
<meta property="og:title" content="Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising">
<meta property="og:url" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/index.html">
<meta property="og:site_name" content="天气桑的blog">
<meta property="og:description" content="搜广推领域文献阅读，文献整理来源于git仓库  Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising 【to粗】表示待粗读 【粗】表示已粗读 【to精】表示待精读 【精】表示已精读 没有标注表示还没看">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220311172803323.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220311173113403.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220420142943925.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220420143007350.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220420160311360.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220314150022595.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317165619270.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317165638457.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194828763.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194901838.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194918828.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160528707.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161624732.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160613501.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160720224.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160739019.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161821200.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310162153666.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161951289.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228121702691.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228145221827.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228150641871.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220321150342948.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220322155759829.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220322162335078.png">
<meta property="og:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220322164252991.png">
<meta property="article:published_time" content="2022-03-01T03:32:38.000Z">
<meta property="article:modified_time" content="2022-04-22T11:35:01.710Z">
<meta property="article:author" content="Tenki San">
<meta property="article:tag" content="default">
<meta property="article:tag" content="算法相关">
<meta property="article:tag" content="Learning to Rank">
<meta property="article:tag" content="Multi-Scenario">
<meta property="article:tag" content="Intent Recommendation">
<meta property="article:tag" content="Recommender System">
<meta property="article:tag" content="E-commerce">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220311172803323.png">

<link rel="canonical" href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
      

</script>

  <title>Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising | 天气桑的blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


  
<script>
    (function(){
        if(''){
            if (prompt('请输入密码') !== ''){
                alert('密码错误');
                history.back();
            }
        }
    })();
</script>


</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">天气桑的blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">这个人很懒，还没写介绍</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://tessiehe.github.io/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Tenki San">
      <meta itemprop="description" content="缘分让我们相遇">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="天气桑的blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-01 11:32:38" itemprop="dateCreated datePublished" datetime="2022-03-01T11:32:38+08:00">2022-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-04-22 19:35:01" itemprop="dateModified" datetime="2022-04-22T19:35:01+08:00">2022-04-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/" itemprop="url" rel="index"><span itemprop="name">算法相关</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>搜广推领域文献阅读，文献整理来源于git仓库  <a target="_blank" rel="noopener" href="https://github.com/TessieHe/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising">Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</a></p>
<p>【to粗】表示待粗读</p>
<p>【粗】表示已粗读</p>
<p>【to精】表示待精读</p>
<p>【精】表示已精读</p>
<p>没有标注表示还没看</p>
<span id="more"></span>
<p>[TOC]</p>
<h1 id="Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising"><a href="#Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising" class="headerlink" title="Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising"></a>Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</h1><p>阅读等级：精，粗，to粗</p>
<p>Keyword：Personalized item search</p>
<h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><h3 id="2019-Deep-Learning-Based-Recommender-System"><a href="#2019-Deep-Learning-Based-Recommender-System" class="headerlink" title="2019 [Deep Learning Based Recommender System]"></a>2019 [Deep Learning Based Recommender System]</h3><p>Zhang, S.; Yao, L.; Sun, A.; Tay, Y. Deep Learning Based Recommender System: A Survey and New Perspectives. <em>ACM Computing Surveys (CSUR)</em> <strong>2019</strong>, <em>52</em> (1), 1–38.</p>
<p><strong>简介</strong>：推荐体统的本质是用户与商品的匹配，涉及到两个问题：匹配策略及评判标准</p>
<p><strong>关键词</strong>：Additional Key Words and Phrases: Recommender System; Deep Learning; Survey</p>
<ul>
<li><p>技术层面的分类<img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220311172803323.png" alt="image-20220311172803323" style="zoom:50%;"></p>
</li>
<li><p>应用层面的分类</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220311173113403.png" alt="image-20220311173113403" style="zoom:50%;"></p>
</li>
</ul>
<h2 id="Ranking"><a href="#Ranking" class="headerlink" title="Ranking"></a>Ranking</h2><h3 id="【粗】2022-WWW-FMLP-Rec-—玄学"><a href="#【粗】2022-WWW-FMLP-Rec-—玄学" class="headerlink" title="【粗】2022(WWW)[FMLP-Rec]—玄学"></a>【粗】2022(WWW)[FMLP-Rec]—玄学</h3><p>Zhou K, Yu H, Zhao WX, Wen JR. Filter-enhanced MLP is All You Need for Sequential Recommendation. <em>arXiv:220213556 [cs]</em>. Published online February 28, 2022. doi:<a target="_blank" rel="noopener" href="https://doi.org/10.1145/3485447.3512111">10.1145/3485447.3512111</a></p>
<p><strong>关键词</strong>：Sequential Recommendation, All-MLP Model, Filtering Algorithm</p>
<p><strong>简介</strong>：最近RNN，CNN，transformer等深度模型用于推荐系统中基于用户的历史行为提取用户兴趣偏好。但历史行为是充满噪音的，且深度模型容易对噪音过拟合。本文借鉴信号处理领域的过滤算法（filtering algorithms）在频域中衰减噪声。实验表明简单的过滤算法+MLP甚至可以优于transformer这种复杂模型.我们还证明了可学习滤波器相当于时域中的循环卷积，具有更大的感受野，可以更好地捕捉周期性特征</p>
<ul>
<li>最近的研究显示了transformer结构在序列推荐场景下的出色表现，但是存在两个带优化问题：1.巨大的参数量。2.易对噪音过拟合</li>
</ul>
<h3 id="【粗】2022-AAAI-Alibaba-SMINet-—-就是硬检索-self-attention"><a href="#【粗】2022-AAAI-Alibaba-SMINet-—-就是硬检索-self-attention" class="headerlink" title="【粗】2022(AAAI)(Alibaba)[SMINet]—-就是硬检索+self-attention"></a>【粗】2022(AAAI)(Alibaba)[SMINet]—-就是硬检索+self-attention</h3><p>Tao, W.; Li, Y.; Li, L.; Chen, Z.; Wen, H.; Chen, P.; Liang, T.; Lu, Q. SMINet: State-Aware Multi-Aspect Interests Representation Network for Cold-Start Users Recommendation. 9.</p>
<p><strong>简介</strong>:本文通过SMINet结构提取在线旅游平台（OTP）冷启动推荐场景下的用户兴趣表征。模型包括multi-aspect interests extractor（多层面兴趣提取器）, co-attention layer（协同注意力）,  state-aware gating layer（旅行状态感知的门结构）三个部分。OTP与其他电子商务场景区别在于数据非常稀疏。为了缓解冷启动问题，最通用的方式是通过辅助信息帮助表示用户。也有通过元学习利用用户的少数行为解决冷启动问题，其中大部分是居于优化的元学习。但这些方式没有利用用户旅游行为的特点：时空性，群体性，周期性</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220420142943925.png" alt="image-20220420142943925" style="zoom:50%;"></p>
<ul>
<li><p>multi-aspect interests extractor： 得到5个向量分别表示用户的时空兴趣、群体兴趣、周期兴趣、长期兴趣、短期兴趣。其实不同层面的interest就是按照不同规则过滤（硬检索)得到相关的历史topk个行为再进行multi-head self attention。比如时空层面的检索就是照相同城市相同时间的交互</p>
<img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220420143007350.png" class title="image-20220420143007350">
</li>
</ul>
<h3 id="【粗】2022-AAAI-Adobe-DiPS"><a href="#【粗】2022-AAAI-Adobe-DiPS" class="headerlink" title="【粗】2022(AAAI)(Adobe)[DiPS]"></a>【粗】2022(AAAI)(Adobe)[DiPS]</h3><p>Ghosh A, Mitra S, Lan A. DiPS: Differentiable Policy for Sketching in Recommender Systems[J]. arXiv preprint arXiv:2112.07616, 2021.</p>
<p><strong>简介</strong>：序列推荐中用户的长期行为很容易被遗忘，近期的工作表明存储长期行为的小草图（small sketch）对推荐是有帮助的。但是构建方式都依赖域静态草图策略。这样的策略不能随着训练数据的增加而动态调整。本文提出了一种可微分的草图策略（DiPS），是一种端到端的数据驱动的策略，可在未来显示的最大化推荐质量。</p>
<ul>
<li>sketching policy： 决定存储哪些历史行为的策略</li>
<li>背景</li>
</ul>
<p>序列推荐中用户的长期行为很容易被遗忘，近期的工作表明存储长期行为的小草图（small sketch）对推荐是有帮助的，但是构建方式都依赖域静态草图策略（sketching policy，可以理解为用户行为序列的筛选和存储策略）。这样的策略不能随着训练数据的增加而动态调整。本文提出了一种端到端训练的可微分草图策略（DiPS）。</p>
<ul>
<li>方法</li>
</ul>
<p>本文将草图更新和RS模型训练作为双层优化问题。 在外层优化RS模型和草图策略， 内层使用当前草图中优化RS模型。由于任何一个草图策略下当前草图状态都依赖于所有先前决策，即计算梯度时需反向传播到先前所有时间步长，而整个过程是计算密集型的。本文使用计算效率高的单独队列模块（separate queue module）对草图策略参数的真实梯度进行近似估计，有效减少计算复杂度。在5个公开数据集上实验表明采用DiPS草图策略的模型效果由于静态草图策略。达到同样模型效果时，DiPS的存储items是静态草图策略对的一半。</p>
<p>后续代码将会在<a target="_blank" rel="noopener" href="https://github.com/arghosh/DiPS.">https://github.com/arghosh/DiPS</a> 开源</p>
<h3 id="【粗】2022-AAAI"><a href="#【粗】2022-AAAI" class="headerlink" title="【粗】2022(AAAI)[]"></a>【粗】2022(AAAI)[]</h3><h3 id="【粗】2022-AAAI-FPAdaMetric-——可借鉴，但缺乏细节公式"><a href="#【粗】2022-AAAI-FPAdaMetric-——可借鉴，但缺乏细节公式" class="headerlink" title="【粗】2022(AAAI)[FPAdaMetric]——可借鉴，但缺乏细节公式"></a>【粗】2022(AAAI)[FPAdaMetric]——可借鉴，但缺乏细节公式</h3><p>Jeong J, Choi J, Cho H, et al. FPAdaMetric: False-positive-aware Adaptive Metric Learning for Session-based Recommendation[J]. 2022.</p>
<p><strong>简介</strong>：推荐场景下存在噪音，主要是伪阳性（False Positive）,本文引入了 FP-Metric 模型，它将具有 FP 约束的基于会话的推荐的目标重新表述为度量学习正则化（metric learning regularization）。 此外，我们提出了 FP-AdaMetric，它通过一个自适应模块来增强度量学习正则化项。</p>
<ul>
<li><p>最简单的处理FP的方式就是通过规则过滤掉FP样本，但由于点击成本很低，很多用户会处于好奇等心理尝试交互，我们应该更积极的考虑FP来提高推荐质量</p>
</li>
<li><p>基础假设：1）FP跟sequence是独立的（跟sequence不相关） 2）FP比TP有更低的相关性</p>
</li>
<li><p>基于以上假设，提出在模型中增加正则项FP-Metric, 让FP和TP的embedding距离较远。</p>
</li>
<li><p>由于不同的FP对对用户的影响程度不同的，所以提出了改进的正则约束FP-AdaMetric（False- positive-aware Adaptive Metric Learning model）</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220420160311360.png" alt="image-20220420160311360" style="zoom:50%;"></p>
</li>
</ul>
<h3 id="【to粗】2016-PNN"><a href="#【to粗】2016-PNN" class="headerlink" title="【to粗】2016 [PNN]"></a>【to粗】2016 [PNN]</h3><p>Qu, Y.; Cai, H.; Ren, K.; Zhang, W.; Yu, Y.; Wen, Y.; Wang, J. Product-Based Neural Networks for User Response Prediction. <em>arXiv:1611.00144 [cs]</em> <strong>2016</strong>.</p>
<h3 id="2020-Alibaba-EdgeRec"><a href="#2020-Alibaba-EdgeRec" class="headerlink" title="2020(Alibaba)[EdgeRec]"></a>2020(Alibaba)[EdgeRec]</h3><p>Gong, Y.; Jiang, Z.; Feng, Y.; Hu, B.; Zhao, K.; Liu, Q.; Ou, W. EdgeRec: Recommender System on Edge in Mobile Taobao. In <em>Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>; 2020; pp 2477–2484.</p>
<h3 id="【to粗】-STARec"><a href="#【to粗】-STARec" class="headerlink" title="【to粗】[STARec]"></a>【to粗】[STARec]</h3><p>Jin, J.; Chen, X.; Zhang, W.; Huang, J.; Feng, Z.; Yu, Y. Learn over Past, Evolve for Future: Search-Based Time-Aware Recommendation with Sequential Behavior Data. <em>arXiv preprint arXiv:2202.03097</em> <strong>2022</strong>.</p>
<p><strong>简介</strong>： Search-based Time-Aware Recommendation (STARec)基于搜索的时间感知的推荐。1.对用户长时间的历史序列进行检索（如品类过滤），融合短时序列。2.加入相似用户的序列。3.label trick,即把历史行为label加入X</p>
<h3 id="【精】2022-Multi-Resolution-Attention-【多时间尺度的attention】"><a href="#【精】2022-Multi-Resolution-Attention-【多时间尺度的attention】" class="headerlink" title="【精】2022[Multi-Resolution Attention] 【多时间尺度的attention】"></a>【精】2022[Multi-Resolution Attention] 【多时间尺度的attention】</h3><p>Kocayusufoglu, F.; Wu, T.; Singh, A.; Roumpos, G.; Cheng, H.-T.; Jain, S.; Chi, E.; Singh, A. Multi-Resolution Attention for Personalized Item Search. In <em>Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</em>; 2022; pp 508–516.</p>
<p>多分辨率注意力机制</p>
<p><strong>简介</strong>：用户行为是个性化搜索的基础。用户行为建模存在两个难点：1.并不是所有的行为都和当前决策有关。2.用户行为是非周期性的，他们与当前query的相关性涉及到复杂的时间依赖。本文的方法可以在多个<strong>时空子空间（temporal subspaces (i.e., resolutions)）</strong>捕获<strong>历史行为和当前query的高阶的相关性</strong>。实现方式是通过多头注意力机制+可微分的阈值方式实现时间维度的掩码（masking）。推荐中的很多模型通过attention提取的是序列的信息，而忽略了时间的信息。也有一些工作引入了时间的信息（ [17, 23, 41, 43, 44]）,但大都是推荐场景，不是个性化搜索场景。</p>
<p><strong>关键词</strong>：item search, personalization, temporal attention, multi-resolution attention, recommender systems</p>
<ul>
<li><p>关键思想：在不同时间子空间(时间尺度)计算query和item的相关性</p>
</li>
<li><p>个性化搜索领域一般用attention提取历史相关信息，忽略了时间信息；推荐领域今年有考虑序列中的时间信息的工作，但没有query约束。我们的工作是在个性化搜索领域考虑时间信息（umm….）</p>
</li>
<li><p>文章先分析了业务场景下用户的交互行为特点，再跟模型结合起来（不同场景有不同的交互行为特点？）数据发现：</p>
<ol>
<li>同样的用户在不同品类上的复购周期是有差异的</li>
<li>同样的品类不同用户的复购周期也是有差异的</li>
</ol>
<p>所以提出时间分辨率（temporal resolutions ）的概念，目标是自适应的对不同用户不同品类选取合适的分辨率，并借此计算当前query和历史行为的相关性</p>
</li>
</ul>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220314150022595.png" alt="image-20220314150022595" style="zoom:50%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317165619270.png" alt="image-20220317165619270" style="zoom:50%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317165638457.png" alt="image-20220317165638457" style="zoom:50%;"></p>
<ul>
<li><p>input layer: 对历史序列的item和query进行embedding</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194828763.png" alt="image-20220317194828763" style="zoom:50%;"></p>
</li>
<li><p>History Encoding Layer：历史序列的自编码（与query无关）</p>
</li>
</ul>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194901838.png" alt="image-20220317194901838" style="zoom:50%;"></p>
<ul>
<li>Query-Aware History Encoding Layer： query相关的历史序列多头自编码，每个头有一个时间阈值</li>
</ul>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220317194918828.png" alt="image-20220317194918828" style="zoom:50%;"></p>
<h3 id="【精】2022-CLSR-【自监督-对比学习-长短兴趣表征解耦】"><a href="#【精】2022-CLSR-【自监督-对比学习-长短兴趣表征解耦】" class="headerlink" title="【精】2022[CLSR]【自监督+对比学习=长短兴趣表征解耦】"></a>【精】2022[CLSR]【自监督+对比学习=长短兴趣表征解耦】</h3><p>Cite：Zheng, Y.; Gao, C.; Chang, J.; Niu, Y.; Song, Y.; Jin, D.; Li, Y. Disentangling Long and Short-Term Interests for Recommendation. <em>arXiv preprint arXiv:2202.13090</em> <strong>2022</strong>. </p>
<p>code: <a target="_blank" rel="noopener" href="https://github.com/tsinghua-fib-lab/CLSR">https://github.com/tsinghua-fib-lab/CLSR</a></p>
<p>CLS：Contrastive learning framework to disentangle Long and Short-term interests for Recommendation (CLSR) with self-supervision.</p>
<p><strong>简介</strong>：现有工作中用户的长短兴趣大都是耦合建模的，这样会降低准确性和可解释性。本文用对比学习的框架通过自监督的方法解耦了长短兴趣。首先用不同的编码器对长短兴趣(不同时间尺度)进行编码<strong>interest representation</strong>，然后从序列中获取<strong>interest proxies</strong>作为用户兴趣的<strong>伪标签</strong>，然后用pairwise的对比学习任务有监督的学习兴趣表征和相应的interest proxies之间的关系。最后用attention机制融合长短兴趣</p>
<p><strong>关键词</strong>：Recommendation, Long and Short-Term Interests, Self-supervised Learning, Disentanglement Learning</p>
<ul>
<li><p>现有的对用户历史行为的处理有三种方式。1.CF-based的方式，主要处理长期行为。2.sequential model(LSTM,CNN)，主要处理短期行为。3.CF-based + sequential, 缺点是无法保证学习到的长短期行为的准确性，因为没有显示的加入长短期的先验，也就是二者会相互影响。（表示怀疑）</p>
</li>
<li><p>长短期行为建模存在3个难点。1.长期行为和短期行为刻画用户的不同时间尺度的信息，公用一个表征是不合适的。2.序列中只有用户的隐反馈，没有标签来区分长短期行为。3.用户不同情况下对长短期行为的依赖是不同的</p>
</li>
<li><p><strong>基本思路</strong></p>
<p>notation</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160528707.png" alt="image-20220310160528707" style="zoom:30%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161624732.png" alt="image-20220310161624732" style="zoom:50%;"></p>
<ul>
<li><p>定义长短期兴趣的query向量（attention中的query概念，并不是真正的query）</p>
<p>长期行为的query是？？？,短期行为的query是行为序列的RNN输出</p>
</li>
</ul>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160613501.png" alt="image-20220310160613501" style="zoom:10%;"></p>
<ul>
<li><p>长期兴趣&amp;短期兴趣编码器</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160720224.png" alt="image-20220310160720224" style="zoom:25%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310160739019.png" alt="image-20220310160739019" style="zoom:10%;"></p>
</li>
<li><p>自监督的长短期兴趣解耦</p>
<p>1.不同维度的pooling作为长短期兴趣的伪标签（proxy）；2.用BPR based pairwise loss 或者triplet loss 学习表征</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161821200.png" alt="image-20220310161821200" style="zoom:25%;"></p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310162153666.png" alt="image-20220310162153666" style="zoom:25%;"></p>
</li>
<li><p>自适应的兴趣融合</p>
<p>权重是序列RNN+candidate+长短期兴趣决定的；</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220310161951289.png" alt="image-20220310161951289" style="zoom:25%;"></p>
</li>
</ul>
</li>
<li><p><strong>启发</strong></p>
<ul>
<li>后续可跟进的方向：伪标签的构造方法可以更复杂。作者说目前这种avg pooling的方法出于简单，效果又足够好。后续可以优化</li>
<li>在预估任务中加入伪标签+对比学习框架通过自监督约束表征（representation）是一个指的研究的方向，其实是通过伪标签的形式加入了更多的模糊的先验知识。</li>
</ul>
</li>
<li><p><strong>几个有意思的结论</strong>：</p>
<ul>
<li>所有数据集上短期兴趣模型（如DIEN）基本都比长期兴趣（DIN）模型要好——-&gt;太长序列的增益很有限？</li>
<li>短期行为序列的增长带来的增益会递减，ctr任务上递减的速度高于cvr任务——-&gt; 短期序列更重要</li>
<li>长短期行为联合训练不一定会更有优：因为长短期行为的耦合增加了模型的内部依赖性（ internal dependency ）,会降低模型表现</li>
<li>固定的长短期兴趣融合策略（concat/固定权重）没有自适应的权重好：不同场景下长短兴趣的重要性是不同的</li>
<li>高客单价/购买场景对长期兴趣的依赖性高于低客单价/点击场景</li>
<li>由于作者认为长短兴趣也有重叠的部分，所以没有像其他解耦任务一样增加正则项，强制两个表征不相似</li>
</ul>
</li>
<li><p><strong>引用文献</strong></p>
<ul>
<li>【推荐中的解耦】FrancescoLocatello,StefanBauer,MarioLucic,GunnarRaetsch,SylvainGelly, Bernhard Schölkopf, and Olivier Bachem. 2019. Challenging common assump- tions in the unsupervised learning of disentangled representations. In interna- tional conference on machine learning. PMLR, 4114–4124.</li>
<li>【推荐中的解耦】Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua. 2020. Disentangled graph collaborative filtering. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 1001–1010.</li>
</ul>
</li>
</ul>
<h3 id="【精】2022-RACP-【页面维度信息-负反馈】"><a href="#【精】2022-RACP-【页面维度信息-负反馈】" class="headerlink" title="【精】2022 [RACP]【页面维度信息+负反馈】"></a>【精】2022 [RACP]【页面维度信息+负反馈】</h3><p>2022 (Alibaba) (WSDM)(ZhifangFan)[RACP]Modeling Users’ Contextualized Page-wise Feedback for Click-Through Rate Prediction in E-commerce Search</p>
<p>简介：建模用户的历史行为对个性化搜索和推荐都很重要，现有方法主要是对用户历史正反馈的建模（点击序列），忽略了产生反馈的上下文信息。本文通过加入历史<strong>页面维度的曝光和反馈</strong>做一位用户历史行为序列，提出了一种新的上下文感知的用户行为建模方式。通过捕捉页面内的信息和页面间的演化可以更详细的学习用户的偏好。 RACP(Recurrent Attention over Contextualized Page sequence)模型通过<strong>page-context aware attention</strong> 学习页面内的关系。<strong>recurrent attention</strong>学习页面间的关系</p>
<ul>
<li><p>模型结构：</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228121702691.png" alt="image-20220228121702691" style="zoom:50%;"></p>
</li>
<li><p>quote</p>
<ul>
<li>“However, they treat users’ positive and negative feedback separately, and rep- resent users’ feedback as a clicked item sequence and a non-clicked item sequence, which cannot generate the mutual context between clicks and non-clicks and ignores other page context information in the page-sequence” 历史工作很少考虑负反馈，即便考虑也是和正反馈分开处理的，这忽略了<strong>正负反馈之间的相互作用</strong></li>
<li>页面信息的增益：1）<strong>正反馈是有噪音的</strong>，避免过拟合。一个用户点了一个品牌不一定是他就偏好这个品牌，有可能是整个页面都是这个品牌 2) 用户对item的行为受曝光的其他item影响</li>
<li>页面间的增益：搜索场景下用户的行为和意图是一个逐渐收敛的过程。例如：搜索—-曝光—-点击—-搜索—-曝光—-点击—-购买</li>
<li>“Recently, some pioneering work (<strong>DFN</strong> [33], <strong>DSTN</strong> [25]) high- light the importance of modeling both users’ positive and negative feedback for CTR prediction.” 一些负反馈的工作</li>
<li><strong>DFN</strong> [33]: DFN treats click behaviors as strong feedback to guide the positive preference extraction from unclicked behavior sequence.</li>
<li><strong>DSTN</strong> [25]: DSTN considers the clicked and unclicked be- haviors as heterogeneous auxiliary data to help the user preference modeling.</li>
<li>item画像：item id,品类id,shop id,统计类（成单量等）</li>
<li>query画像：query id,字符串，分词，类别</li>
<li><strong>页内的attention聚合+页间兴趣回溯(GRU，由下一个page表征当前的query) + 页间兴趣融合(attention)</strong></li>
</ul>
</li>
<li></li>
</ul>
<h3 id="【粗】2021-ETA-【长期行为-SimHash相似度】"><a href="#【粗】2021-ETA-【长期行为-SimHash相似度】" class="headerlink" title="【粗】2021[ETA]【长期行为+SimHash相似度】"></a>【粗】2021[ETA]【长期行为+SimHash相似度】</h3><p>2021(Alibaba)(ArXiv)[ETA]End-to-End User Behavior Retrieval in Click-Through Rate Prediction Model</p>
<p>简介：用户的长期行为对CTR预估很重要，但由于性能的约束，超长期用户行为通常是通过两段式训练进行处理的。第一阶段通过长期行为召回topK,第二阶段结合短期行为进行排序。两阶段由于优化目标不一致降低了长期用户行为带来的CTR增益。本文通过<strong>locality- sensitive hashing (LSH)</strong>方法提出端到端的ETA模型，使得满足训练和推理性能要求的前提下端到端训练的长期用户行为ctr模型。主要是通过<strong>SimHash</strong>的方法计算相似度，使得相似度的计算复杂度由O(L<em> B </em> d)变为O(L*B)，其中L是序列长度，B是candidate梳理，d是embedding维度</p>
<ul>
<li><p>模型结构：</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228145221827.png" alt="image-20220228145221827" style="zoom:50%;"></p>
</li>
</ul>
<h3 id="【粗】2021-ZEUS-【预测下一个query-微调】"><a href="#【粗】2021-ZEUS-【预测下一个query-微调】" class="headerlink" title="【粗】2021  [ZEUS]【预测下一个query + 微调】"></a>【粗】2021  [ZEUS]【预测下一个query + 微调】</h3><p>2021 (Alibaba) (CIKM) [ZEUS] Self-Supervised Learning on Users’ Spontaneous Behaviors for Multi-Scenario Ranking in E-commerce</p>
<p>Gu, Y.; Bao, W.; Ou, D.; Li, X.; Cui, B.; Ma, B.; Huang, H.; Liu, Q.; Zeng, X. Self-Supervised Learning on Users’ Spontaneous Behaviors for Multi-Scenario Ranking in E-Commerce. In <em>Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</em>; ACM: Virtual Event Queensland Australia, 2021; pp 3828–3837. <a target="_blank" rel="noopener" href="https://doi.org/10.1145/3459637.3481953">https://doi.org/10.1145/3459637.3481953</a>.</p>
<p>关键词：Learning to Rank; Multi-Scenario; Intent Recommendation; Rec- ommender System; E-commerce</p>
<p>简介：多场景下用户<strong>自发行为</strong>的<strong>自监督</strong>学习。搜广推场景下排序模块都非常重要，目前大部分工作聚焦于单场景建模。我们认为多场景面对以下两个挑战：1) Feedback Loop. 模型的训练数据是由模型产生的 2)多场景样本不足。模型包括用户自发行为（如主动搜索，指不受推荐系统影响的行为）的预训练，和用户隐反馈上的微调</p>
<ul>
<li>电子商务中的排序根据上下文和排序对象的不同可以分为三类：1)商品推荐，对象是商品; 2)意图推荐，对象是query; 3)商品搜索，对象是商品，上下文是query</li>
<li>relate work包含4个领域：<strong>learn to rank; 多场景学习(multi-senario LTR) ；自监督学习;意图推荐(intent reommendation)</strong></li>
<li>预训练任务：预测下一个搜索词。微调任务：各个场景的CTR任务。微调先是用全场景的点击作为y进行第一阶段微调，再用各自场景的点击进行第二阶段微调。微调时商品和query的embedding向量是固定的，其他特征是可变的</li>
</ul>
<h3 id="【to粗】2021-DUMN-【加入负反馈-显反馈对隐反馈去噪】"><a href="#【to粗】2021-DUMN-【加入负反馈-显反馈对隐反馈去噪】" class="headerlink" title="【to粗】2021[DUMN]【加入负反馈+显反馈对隐反馈去噪】"></a>【to粗】2021[DUMN]【加入负反馈+显反馈对隐反馈去噪】</h3><p>2021(Alibaba)(ACM)[DUMN]Denoising User-aware Memory Network for Recommendation</p>
<p>简介：最近推荐领域非常多的工作聚焦在用户行为建模。用户的反馈包含显式和隐式的，大部分工作忽略了<strong>隐式反馈的噪音</strong>（用显示反馈对隐式反馈进行去噪），这会导致对于用户兴趣的有偏理解，本文1）通过正交映射( orthogonal mapping)对隐反馈进行去噪  2)基于内存的用户长期行为建模  3)短期行为和长期行为的融合。输入包括4个部分，<strong>显示反馈：喜欢，不喜欢 ；隐式反馈：点击，未点击</strong></p>
<ul>
<li>外卖场景下的显示隐式反馈是什么？？？<img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220228150641871.png" alt="image-20220228150641871" style="zoom:50%;"></li>
</ul>
<h3 id="【to粗】2020-CIKM-DMT"><a href="#【to粗】2020-CIKM-DMT" class="headerlink" title="【to粗】2020(CIKM)[DMT]"></a>【to粗】2020(CIKM)[DMT]</h3><p>2020(CIKM)(JD)[DMT]Deep Multifaceted Transformers for Multi-objective Ranking in Large- Scale E-commerce Recommender Systems</p>
<p>Gu, Y.; Ding, Z.; Wang, S.; Zou, L.; Liu, Y.; Yin, D. Deep Multifaceted Transformers for Multi-Objective Ranking in Large-Scale E-Commerce Recommender Systems. In <em>Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>; ACM: Virtual Event Ireland, 2020; pp 2493–2500. <a target="_blank" rel="noopener" href="https://doi.org/10.1145/3340531.3412697">https://doi.org/10.1145/3340531.3412697</a>.</p>
<h2 id="【粗】"><a href="#【粗】" class="headerlink" title="【粗】"></a>【粗】</h2><h2 id="Post-Ranking"><a href="#Post-Ranking" class="headerlink" title="Post_Ranking"></a>Post_Ranking</h2><h3 id="【粗】-2021-HUAWAI-CRUM-【比较tricky-没解决关键的反事实标签的问题】"><a href="#【粗】-2021-HUAWAI-CRUM-【比较tricky-没解决关键的反事实标签的问题】" class="headerlink" title="【粗】(2021)(HUAWAI)[CRUM]【比较tricky,没解决关键的反事实标签的问题】"></a>【粗】(2021)(HUAWAI)[CRUM]【比较tricky,没解决关键的反事实标签的问题】</h3><p>通过上下文感知的重排序最大化推荐系统的效用</p>
<p>Xi, Y.; Liu, W.; Dai, X.; Tang, R.; Zhang, W.; Liu, Q.; He, X.; Yu, Y. Context-Aware Reranking with Utility Maximization for Recommendation. <em>arXiv preprint arXiv:2110.09059</em> <strong>2021</strong>.</p>
<p><strong>简介</strong>: 重排能够考虑item之间的相互影响，从全局最优的角度优化推荐系统</p>
<p><strong>keyword</strong>： counterfactual context(反实时上下文)</p>
<p><strong>思考</strong>：已有的很多工作都是使用实际展示序列建模的，会导致数据偏差。本文提出反事实上下文的概念(counterfactual context)代替原始序列。存在两个难点：1.如何评估反事实序列 2.如何生成反事实序列</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220321150342948.png" alt="image-20220321150342948" style="zoom:50%;"></p>
<p>如上图，原始序列中牙膏的点击率为0.47，按照score贪心排序后牙膏排到第二位，此时牙膏的点击率已经改变了。</p>
<h3 id="Neural-Re-ranking-in-Multi-stage-Recommender-Systems-A-Review"><a href="#Neural-Re-ranking-in-Multi-stage-Recommender-Systems-A-Review" class="headerlink" title="Neural Re-ranking in Multi-stage Recommender Systems: A Review"></a>Neural Re-ranking in Multi-stage Recommender Systems: A Review</h3><p>(1) Liu, W.; Xi, Y.; Qin, J.; Sun, F.; Chen, B.; Zhang, W.; Zhang, R.; Tang, R. Neural Re-Ranking in Multi-Stage Recommender Systems: A Review. <em>arXiv:2202.06602 [cs]</em> <strong>2022</strong>.</p>
<p><strong>简介</strong>:本文把rerank算法系统的整合在一个更大的视野中，对算法进行分类，并分别介绍了各个方法的历史发展、网络结构、个性化和复杂性，定量的对各种方法的性能进行讨论，最后展望了未来的发展方向</p>
<p>​        多级的推荐系统已经是推荐系统的主流框架，重拍作为最后一环目标是最大化整体收益，因为用户的行为不仅受item的影响，也受周边item的影响。所以重拍的一个挑战就是模拟list wise的上下文特征。重拍最早的工作追溯到1998年Carbonell[1]的工作，它采用贪心策略排序。随着深度学习技术的发展，由于深度模型的通用近似定理（Universal Approximation Theorem)，应用神经网络进行重新排序是近年来学术界和工业界的主要关注点。</p>
<p>​        本文从学习任务和监督信号两个维度对重排模型进行了分类。学习任务方面有的聚焦于单任务（如准确率），有的聚焦于多任务（如多样性和公平性）。在监督信号方面有的只初始的序列和观察到的信号作为标签（如曝光），有的则使用了反事实序列（如实际并未曝光的序列）及evaluator的评估信号作为标签。</p>
<p>​        通过以下的分类图可以发现有以下三个趋势：</p>
<p>(i) 大多数研究试图通过单一目标纯粹提高准确性，而具有多目标的多样性/公平性感知方法的探索相对较少。</p>
<p> (ii) Self-attention [Vaswani et al., 2017] 或 RNN [Hochreiter and Schmidhuber, 1997] 的组合和注意力已经成为重新排序中流行的网络结构。</p>
<p> (iii) 很少有作品讨论<strong>反事实排列对多目标学习中相关性</strong>的影响（图 1 的第一象限），这可能是一个潜在的研究方向。 </p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220322155759829.png" alt="image-20220322155759829" style="zoom:50%;"></p>
<ul>
<li><p>问题定义</p>
<p>重排问题可以抽象为找到一个排序函数使得目标loss最小。如果Y是单一目标则是单任务，Y是目标则是多任务。Y来evaluator则是学习反事实信号，否则是学习观测信号。</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220322162335078.png" alt="image-20220322162335078" style="zoom:50%;"></p>
<p>通过观察到的信号进行学习通常遵循直接的架构，通过列表上下文建模输出重新排序分数。 而通过反事实信号学习通常采用evaluator-generator范式——生成器在评估器的指导下生成重新排序列表，其中生成器和评估器都关注列表上下文。</p>
</li>
<li><p>技术发展介绍</p>
<p>​        基于观测数据的模型反馈噪音较少，也比较容易训练，但容易产生bias。模型结构方面由于要考虑上下文，主要有RNN系列，Attention系列和其他（MLP，GNN等）。基于反事实序列的模型由Wang[2]在2019年首次采用 evaluator-generator建模范式提出SEG模型，作者指出evaluator需要的两个属性：（i）顺序敏感性，评估者需要对输入列表的顺序敏感； (ii) 概括性，应很好地概括所有可能的排列。 在evaluator的指导下，SEG 设计了一种监督学习方法和一种强化学习方法来训练生成器。后续一系列研究在此建模范式下尝试了不同的模型，如下表。</p>
<p><img src="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising/image-20220322164252991.png" alt="image-20220322164252991" style="zoom:50%;"></p>
</li>
</ul>
<p>​        </p>
<ul>
<li>挑战及展望</li>
</ul>
<p>1）稀疏反馈。观测到的反馈只是n!种排序的一种。evaluator或点击率模型可用于反事实序列的打标，而这些模型本质上还是基于观测数据训练的。目前缺乏针对evaluator特定的有效的设计</p>
<p>2）公平性/多样性的个性化。近期的个性化工作主要是准确率导向的，而未探索多样性和公平性的个性化。 不同的用户对多样性和公平性有不同的需求。 涉及个性化多样性或公平性的潜力巨大</p>
<p>3）多任务之间的平衡。不同的推荐场景对多样性或公平性有不同程度的需求。 现有的研究主要通过启发式或参数调整来管理权衡。 在没有人工干预的情况下自动平衡多个目标可能是一个很有前途的方向。</p>
<p>4）推荐系统联合训练。重排会受推荐系统前序流程影响，利用其他阶段（例如，参数传递、梯度传递）学到的信息对学术界和工业界都具有很高的价值。</p>
<p>[1][Carbonell and Goldstein, 1998] Jaime Carbonell and Jade Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In <em>SI- GIR</em>, 1998.</p>
<p>[2] Fan Wang, Xiaomin Fang, Lihang Liu, et al. Sequential evaluation and generation framework</p>
<h2 id="Multi-task"><a href="#Multi-task" class="headerlink" title="Multi-task"></a>Multi-task</h2><h2 id="Graph-Neural-Network"><a href="#Graph-Neural-Network" class="headerlink" title="Graph_Neural_Network"></a>Graph_Neural_Network</h2><h2 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer_Learning"></a>Transfer_Learning</h2><h2 id="Reignforcement-Learning"><a href="#Reignforcement-Learning" class="headerlink" title="Reignforcement_Learning"></a>Reignforcement_Learning</h2><h2 id="Self-Supervised-Learning"><a href="#Self-Supervised-Learning" class="headerlink" title="Self_Supervised_Learning"></a>Self_Supervised_Learning</h2><h2 id="Corporation"><a href="#Corporation" class="headerlink" title="Corporation"></a>Corporation</h2><h2 id="New-Papers"><a href="#New-Papers" class="headerlink" title="New_Papers"></a>New_Papers</h2><h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><h2 id="Maching"><a href="#Maching" class="headerlink" title="Maching"></a>Maching</h2><h2 id><a href="#" class="headerlink" title=" "></a> </h2><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p> <a target="_blank" rel="noopener" href="https://github.com/guyulongcs/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising">Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/lOCcPexEs9xRwcnfGIdXVw">WSDM2022推荐系统论文集锦</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/hRLq9Q3NBZcj16uSKHPQaA">WWW 2022 推荐系统和广告相关论文整理分类</a></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/default/" rel="tag"># default</a>
              <a href="/tags/%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/" rel="tag"># 算法相关</a>
              <a href="/tags/Learning-to-Rank/" rel="tag"># Learning to Rank</a>
              <a href="/tags/Multi-Scenario/" rel="tag"># Multi-Scenario</a>
              <a href="/tags/Intent-Recommendation/" rel="tag"># Intent Recommendation</a>
              <a href="/tags/Recommender-System/" rel="tag"># Recommender System</a>
              <a href="/tags/E-commerce/" rel="tag"># E-commerce</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/03/01/2_%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3/2022%E4%BC%9A%E8%AE%AEpaper/" rel="prev" title="2022机器学习会议paper list">
      <i class="fa fa-chevron-left"></i> 2022机器学习会议paper list
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/03/01/3_%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%82%A1%E4%BB%B7%E9%97%AE%E9%A2%98%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" rel="next" title="股价问题动态规划">
      股价问题动态规划 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising"><span class="nav-number">1.</span> <span class="nav-text">Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Review"><span class="nav-number">1.1.</span> <span class="nav-text">Review</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-Deep-Learning-Based-Recommender-System"><span class="nav-number">1.1.1.</span> <span class="nav-text">2019 [Deep Learning Based Recommender System]</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ranking"><span class="nav-number">1.2.</span> <span class="nav-text">Ranking</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%97%E3%80%912022-WWW-FMLP-Rec-%E2%80%94%E7%8E%84%E5%AD%A6"><span class="nav-number">1.2.1.</span> <span class="nav-text">【粗】2022(WWW)[FMLP-Rec]—玄学</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%97%E3%80%912022-AAAI-Alibaba-SMINet-%E2%80%94-%E5%B0%B1%E6%98%AF%E7%A1%AC%E6%A3%80%E7%B4%A2-self-attention"><span class="nav-number">1.2.2.</span> <span class="nav-text">【粗】2022(AAAI)(Alibaba)[SMINet]—-就是硬检索+self-attention</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%97%E3%80%912022-AAAI-Adobe-DiPS"><span class="nav-number">1.2.3.</span> <span class="nav-text">【粗】2022(AAAI)(Adobe)[DiPS]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%97%E3%80%912022-AAAI"><span class="nav-number">1.2.4.</span> <span class="nav-text">【粗】2022(AAAI)[]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%97%E3%80%912022-AAAI-FPAdaMetric-%E2%80%94%E2%80%94%E5%8F%AF%E5%80%9F%E9%89%B4%EF%BC%8C%E4%BD%86%E7%BC%BA%E4%B9%8F%E7%BB%86%E8%8A%82%E5%85%AC%E5%BC%8F"><span class="nav-number">1.2.5.</span> <span class="nav-text">【粗】2022(AAAI)[FPAdaMetric]——可借鉴，但缺乏细节公式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90to%E7%B2%97%E3%80%912016-PNN"><span class="nav-number">1.2.6.</span> <span class="nav-text">【to粗】2016 [PNN]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2020-Alibaba-EdgeRec"><span class="nav-number">1.2.7.</span> <span class="nav-text">2020(Alibaba)[EdgeRec]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90to%E7%B2%97%E3%80%91-STARec"><span class="nav-number">1.2.8.</span> <span class="nav-text">【to粗】[STARec]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%BE%E3%80%912022-Multi-Resolution-Attention-%E3%80%90%E5%A4%9A%E6%97%B6%E9%97%B4%E5%B0%BA%E5%BA%A6%E7%9A%84attention%E3%80%91"><span class="nav-number">1.2.9.</span> <span class="nav-text">【精】2022[Multi-Resolution Attention] 【多时间尺度的attention】</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%BE%E3%80%912022-CLSR-%E3%80%90%E8%87%AA%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-%E9%95%BF%E7%9F%AD%E5%85%B4%E8%B6%A3%E8%A1%A8%E5%BE%81%E8%A7%A3%E8%80%A6%E3%80%91"><span class="nav-number">1.2.10.</span> <span class="nav-text">【精】2022[CLSR]【自监督+对比学习&#x3D;长短兴趣表征解耦】</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%BE%E3%80%912022-RACP-%E3%80%90%E9%A1%B5%E9%9D%A2%E7%BB%B4%E5%BA%A6%E4%BF%A1%E6%81%AF-%E8%B4%9F%E5%8F%8D%E9%A6%88%E3%80%91"><span class="nav-number">1.2.11.</span> <span class="nav-text">【精】2022 [RACP]【页面维度信息+负反馈】</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%97%E3%80%912021-ETA-%E3%80%90%E9%95%BF%E6%9C%9F%E8%A1%8C%E4%B8%BA-SimHash%E7%9B%B8%E4%BC%BC%E5%BA%A6%E3%80%91"><span class="nav-number">1.2.12.</span> <span class="nav-text">【粗】2021[ETA]【长期行为+SimHash相似度】</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%97%E3%80%912021-ZEUS-%E3%80%90%E9%A2%84%E6%B5%8B%E4%B8%8B%E4%B8%80%E4%B8%AAquery-%E5%BE%AE%E8%B0%83%E3%80%91"><span class="nav-number">1.2.13.</span> <span class="nav-text">【粗】2021  [ZEUS]【预测下一个query + 微调】</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90to%E7%B2%97%E3%80%912021-DUMN-%E3%80%90%E5%8A%A0%E5%85%A5%E8%B4%9F%E5%8F%8D%E9%A6%88-%E6%98%BE%E5%8F%8D%E9%A6%88%E5%AF%B9%E9%9A%90%E5%8F%8D%E9%A6%88%E5%8E%BB%E5%99%AA%E3%80%91"><span class="nav-number">1.2.14.</span> <span class="nav-text">【to粗】2021[DUMN]【加入负反馈+显反馈对隐反馈去噪】</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90to%E7%B2%97%E3%80%912020-CIKM-DMT"><span class="nav-number">1.2.15.</span> <span class="nav-text">【to粗】2020(CIKM)[DMT]</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E3%80%90%E7%B2%97%E3%80%91"><span class="nav-number">1.3.</span> <span class="nav-text">【粗】</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Post-Ranking"><span class="nav-number">1.4.</span> <span class="nav-text">Post_Ranking</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E3%80%90%E7%B2%97%E3%80%91-2021-HUAWAI-CRUM-%E3%80%90%E6%AF%94%E8%BE%83tricky-%E6%B2%A1%E8%A7%A3%E5%86%B3%E5%85%B3%E9%94%AE%E7%9A%84%E5%8F%8D%E4%BA%8B%E5%AE%9E%E6%A0%87%E7%AD%BE%E7%9A%84%E9%97%AE%E9%A2%98%E3%80%91"><span class="nav-number">1.4.1.</span> <span class="nav-text">【粗】(2021)(HUAWAI)[CRUM]【比较tricky,没解决关键的反事实标签的问题】</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Re-ranking-in-Multi-stage-Recommender-Systems-A-Review"><span class="nav-number">1.4.2.</span> <span class="nav-text">Neural Re-ranking in Multi-stage Recommender Systems: A Review</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multi-task"><span class="nav-number">1.5.</span> <span class="nav-text">Multi-task</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Graph-Neural-Network"><span class="nav-number">1.6.</span> <span class="nav-text">Graph_Neural_Network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Transfer-Learning"><span class="nav-number">1.7.</span> <span class="nav-text">Transfer_Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reignforcement-Learning"><span class="nav-number">1.8.</span> <span class="nav-text">Reignforcement_Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Self-Supervised-Learning"><span class="nav-number">1.9.</span> <span class="nav-text">Self_Supervised_Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Corporation"><span class="nav-number">1.10.</span> <span class="nav-text">Corporation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#New-Papers"><span class="nav-number">1.11.</span> <span class="nav-text">New_Papers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Embedding"><span class="nav-number">1.12.</span> <span class="nav-text">Embedding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Maching"><span class="nav-number">1.13.</span> <span class="nav-text">Maching</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.14.</span> <span class="nav-text"> </span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">1.15.</span> <span class="nav-text">参考资料</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Tenki San</p>
  <div class="site-description" itemprop="description">缘分让我们相遇</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">90</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">37</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:wangdongdong122@163.com" title="E-Mail → mailto:wangdongdong122@163.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        <div class="wechat_OA">
            <span>欢迎加微信讨论</span>
            <br>
            <!-- 这里添加你的二维码图片 -->
            <img src ="/images/wechat.png" style="zoom:40%;" />
        </div>
      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Tenki San</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>


        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  

  

</body>
</html>
